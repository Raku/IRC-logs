[00:05] *** jeffreykegler left
[00:06] *** jeffreykegler joined
[00:13] *** monomorph left
[00:24] <jeffreykegler> jql: "I see perl6 as the language between the {} in the rules syntax"

[00:24] <jeffreykegler> That makes perl6 sound like a parser generator

[00:31] <TimToady> not on the level of say yacc; it just makes it really easy to write top-down parsers that can call into bottom-up parsers, and really easy to integrate something like a simple operator precedence parser

[00:31] <TimToady> what gets generated automatically is the lexer for all the alternative points in the grammar

[00:32] <jeffreykegler> Yeah, when I saw the rules stuff in the Perl 6 docs

[00:32] <TimToady> but very little in the standard grammar requires more than 1-token lookahead

[00:32] <jeffreykegler> I was thinking just in terms of an extension of regular expressions

[00:32] <TimToady> and there are precisely two spots that use backtracking

[00:32] <jeffreykegler> A feature of the languages like formats in Perl 5

[00:33] <jeffreykegler> Not the framework of the language

[00:33] <TimToady> it would be easy to substitute in a bottom-up matcher that did more lookahead, but I'm not personally interested in making the user look ahead that far

[00:33] <TimToady> let alone the computer

[00:34] *** jordilin joined
[00:34] <TimToady> the main thing that's going on is that you can derive new grammars and mix in new rules that have the same lexical and grammatical status as the original rules

[00:34] <jeffreykegler> The track record for more than one token of look-ahead is not good

[00:35] <meppl> good night

[00:35] <TimToady> which means every time you mix in more grammar you have to potentially regenerate the lexer

[00:35] <jeffreykegler> Is this going on in a fixed number of phases?

[00:36] <TimToady> and *that* part of it is supposed to be deterministic in the DFA sense

[00:36] <jeffreykegler> The generation of new grammar I mean

[00:37] <jeffreykegler> Is this like a two or three pass process?

[00:37] *** meppl left
[00:39] <TimToady> it's however many passes are necessary; every new language must manage its set of lexers and generate them on demand, caching results for efficiency

[00:39] <jeffreykegler> The top down parser is kind of LL?

[00:39] <TimToady> the same subrule call in a base grammar may call out to a different set of subrules that were mixed in by the derived langauge

[00:40] <TimToady> so it has to keep track of that

[00:40] <jeffreykegler> Not a lot of parsing techniques are very friendly to having their grammars modified on the fly

[00:40] <TimToady> yeah, pretty much LL, but mixing in a bottom-up parser generally gets rid of most left recursion problems

[00:40] <jeffreykegler> LL tends to be only one

[00:41] <TimToady> my feeling is that machines are getting fast enough that we can pay the overhead for the flexibility if we're clever about autogenerating efficient lexers

[00:42] <TimToady> and LL tends to give much better error messages

[00:42] *** devogon left
[00:42] *** justatheory joined
[00:42] <jeffreykegler> LL does have the advantage that it's intuitive for programmers -- it's just kind of like subroutine calls

[00:44] <TimToady> I hope so; parrot's approximation seems to be well accepted by those writing grammars in it

[00:44] <TimToady> but I really have to finish the autolexing before it can really be properly extensible

[00:45] <jeffreykegler> Is the problem automatically determining where the lexing should end and the LL start?

[00:46] <TimToady> not really, I can already do that, and it's pretty well defined what is "declarative" and what is "procedural" in S05

[00:46] <TimToady> and I can already generate the set of lexemes at a particular set of alternatives

[00:46] <jeffreykegler> So that's what "declarative" and "procedural" are all about!

[00:46] <TimToady> I just have to up and write the NFA/DFA engine

[00:46] <TimToady> for lack of better terms

[00:47] <TimToady> sort of a pattern/action notion

[00:47] <TimToady> but longest tokens are the part we can determine without risking side effects, basically

[00:47] <TimToady> we assume the "procedural" bits have side effects

[00:48] <TimToady> and it seems to be a natural place to break it for lexical purposes

[00:49] <TimToady> tricky bit is letting the lexer tell the parser how much it has already "cheated"

[00:49] <jeffreykegler> I've just done some NFA / DFA programming, so I've kind of got this stuff in mind

[00:49] <TimToady> fortunately we have TDFAs that can at least do captures in DFA region

[00:49] <TimToady> so we don't have to reparse for the

[00:50] <jeffreykegler> Where's the cheating?

[00:50] <TimToady> if you're writing a recursive descent parser, your token may encompass some implicit recursions that you'll have to return from someday

[00:51] <TimToady> we define longest-token matching transitively through subrules

[00:51] <jeffreykegler> TDFA == tagged DFA?

[00:51] <TimToady> yes

[00:52] *** nipotaway is now known as nipotan

[00:52] <TimToady> but I haven't integrated that notion yet.  I was first gonna just write a non-bactracking NFA

[00:52] <jeffreykegler> Right

[00:53] <jeffreykegler> "implicit recursions that you'll have to return from someday"

[00:53] <TimToady> I already have the mechanism to do that

[00:53] <TimToady> basically your tag tells you the route to call down

[00:54] <TimToady> and the rules are smart enough to pay attention to "fate"

[00:54] <jeffreykegler> Does this mean some of the Rec Descent stuff may be returning into your NFA/DFA

[00:54] <TimToady> and just pick up where the token leaves off

[00:55] <TimToady> essentially.  doesn't seem to be a problem in practice

[00:55] <jeffreykegler> If you say so :)

[00:55] <TimToady> the NFA/DFA doesn't really do anything

[00:55] <TimToady> all the "actions" are either above or below it

[00:56] <jeffreykegler> That's why it's "declarative" ?

[00:56] <jeffreykegler> Procedures are elsewhere

[00:57] <TimToady> yes, it's a strategy for mixing in as much "determinstic" matching as possible into the programmer's grammar view without the programmer having to worry about it much

[00:57] <jeffreykegler> Sorry to stack questions here, but you're looking at some academic stuff on DFA's?

[00:58] <TimToady> yeah, I've been looking at various papers

[00:58] <jeffreykegler> Any online?

[00:58] <TimToady> all of them :)

[00:59] <jeffreykegler> I'd be curious

[00:59] <jeffreykegler> I'm 54 and my mind works in low gear.  Studying papers helps me understand issues.

[01:01] <jeffreykegler> And also just having written a NFA to semi-deterministic finite automata translator I've got the math fresh in my mind.

[01:02] <TimToady> laurikari.net/ville/spire2000-tnfa.pdf

[01:02] <TimToady> that's kind of the direction I'm aiming

[01:03] <jeffreykegler> Found it.

[01:04] <TimToady> and I have to get as much done before I turn 54 this year me own self :)

[01:04] <jeffreykegler> As this stuff goes, it doesn't look too deadly.

[01:04] <jeffreykegler> They say Newton gave up math by the time he turned 50.

[01:04] <jeffreykegler> I've been reading GH Hardy's Apology of a Mathematician

[01:05] <TimToady> well, it's easy for my eyes to glaze over as soon as I see "System XYZZY is a seven tuple of greek alphabetic soup..."

[01:06] <jeffreykegler> I recommend you read the Hardy *AFTER* you write the TDFA engine

[01:06] <jeffreykegler> So you won't know you're doing the impossible until you're finished

[01:06] <SamB> TimToady: where did you see that?

[01:07] <TimToady> that's the generic first definition of any paper on DFA magic  :)

[01:08] <TimToady> or pretty much any paper on parsing

[01:11] *** jordilin left
[01:22] *** lisppaste3 left
[01:33] *** lisppaste3 joined
[01:38] *** chris2_ left
[01:40] *** pdy left
[01:40] *** pdy joined
[01:56] *** Patterner left
[02:21] *** justatheory left
[02:22] *** Limbic_Region left
[02:29] *** justatheory joined
[02:32] *** jeffreykegler left
[02:34] *** icwiener left
[02:48] *** brysonm joined
[02:48] *** brysonm left
[03:03] *** jferrero left
[03:04] *** cathyal joined
[03:05] *** alester left
[03:05] *** cathyal left
[03:58] *** kanru left
[04:03] *** alester joined
[04:16] *** kanru joined
[04:27] *** OuLouFu joined
[04:32] *** OuLouFu_ joined
[04:34] *** sri_work left
[04:37] *** pbuetow left
[04:38] *** pbuetow joined
[04:43] *** orafu left
[04:43] *** OuLouFu left
[05:01] *** cyberpass joined
[05:10] *** wknight8111 is now known as wknight-away

[05:29] *** wknight-away left
[05:33] *** DarkWolf84 left
[06:21] *** manfred joined
[06:29] *** Belaf left
[06:44] *** cyberpass left
[07:12] *** gbacon left
[07:13] *** dduncan joined
[07:19] *** devogon joined
[07:20] *** gbacon joined
[07:23] *** manfred left
[07:24] *** manfred joined
[07:31] <dduncan> I have an opinion question if anyone can help me with it ... 

[07:33] <dduncan> let's see if copy-paste works ...

[07:33] <dduncan> I intend to make another release of my language spec tonight, just prior to when the proposals would start being looked at (as if it might make any difference), and I have a design question you (or anyone else) may have experience with or advice on ... it relates to the names of 2 main groups of language dialects

[07:33] <dduncan> in a nutshell, Muldis D has multiple dialects, which are compatible at the very least due to Muldis D code always having to declare what dialect it is in, akin to Perl's "use 5.6" vs "use 5.8" etc

[07:33] <dduncan> one dialect group is currently called "non-hosted" or "concrete", and is any dialect where code is written as text strings or files like a typical programming language ... examples how you normally write Perl, or how you normally write SQL

[07:33] <dduncan> the other dialect group is called "hosted" or "abstract", and it is always written in terms of data structures written in some other language like Perl ... an analogy is that SQL::Abstract would be hosted (in Perl), while SQL is non-hosted

[07:33] <dduncan> my question is what might be better category names than the ones I chose ...

[07:33] <dduncan> in particular, I like "hosted", but am wondering if its complement group might be something better than "non-hosted", something with one word that means the same thing ... maybe "independent" but better sounding or less misleading?

[07:33] <dduncan> anyone have thoughts on this?

[07:33] <dduncan> in SQL terms, I"m looking for the "foo" in "SQL is foo and the inputs of SQL::Abstract is (Perl) hosted"

[07:33] <dduncan> yep, it did

[07:51] *** Aankhen`` joined
[07:55] *** meppl joined
[07:55] <dduncan> slightly longer names, the 2 groups could be named "plain text" and "hosted data", and abbreviate to 'PT' and 'HD' respectively, and used together with 'Muldis D', could be 'PTMD' and 'HDMD' for abbreviation purposes

[08:18] *** blindfish joined
[08:21] *** barney joined
[08:23] *** cyberpass joined
[08:27] *** iblechbot joined
[08:46] *** blindfish left
[08:52] *** njbartlett left
[08:58] *** alester left
[09:11] *** meppl left
[09:26] *** cognominal_ left
[09:26] *** cognominal_ joined
[09:31] *** iblechbot left
[09:31] *** blindfish joined
[09:31] *** cognominal_ left
[09:35] *** araujo left
[09:36] *** cyberpass left
[09:52] *** dduncan left
[09:54] *** Psyche^ joined
[09:54] *** Psyche^ is now known as Patterner

[10:09] *** mj41 joined
[10:18] *** iblechbot joined
[10:24] *** penk left
[10:27] *** njbartlett joined
[10:28] *** njbartlett left
[10:29] *** njbartlett joined
[10:31] *** njbartlett_ joined
[10:31] *** njbartlett left
[10:32] *** zamolxes joined
[10:40] *** ebassi joined
[10:41] *** penk joined
[10:47] *** DarkWolf84 joined
[10:51] *** pbuetow left
[10:51] *** pbuetow joined
[10:52] *** pcbuetow joined
[10:58] *** DarkWolf84 left
[10:59] *** broquain1 is now known as broquaint

[11:03] *** chris2 joined
[11:04] *** nipotan is now known as nipotaway

[11:05] *** njbartlett_ left
[11:07] *** rindolf joined
[11:13] *** blindfish left
[11:42] *** manfred left
[11:52] *** njbartlett joined
[11:55] *** blindfish joined
[12:02] *** wknight-away joined
[12:14] *** barney left
[12:16] <spinclad> @tell mncharity i must have been blind... debian etch has ruby1.9.

[12:16] <lambdabot> Consider it noted.

[12:16] <moritz_> spinclad: it has, but it's a prerelease

[12:17] <spinclad> lenny has a later prerelease, sid has 1.9.0.0

[12:19] *** rindolf left
[12:25] *** njbartlett left
[12:25] <pdy> the version in etch is from June 2006?

[12:32] <spinclad> i may try installing it, it looks like it only depends on sid/lenny libc6 (already installed on my etch system) and libncurses6.

[12:32] <spinclad> pdy: yes

[12:33] <spinclad> which i take it is pretty old as these things go

[12:35] *** njbartlett joined
[12:35] *** wknight-away left
[12:36] <spinclad> i think i'll be upgrading to lenny one of these days, as it's approaching release slush, and i'm already seeing ghc 6.6.1 (older lenny) disappearing in favor of 6.8.2

[12:37] <pdy> spinclad: depends on your requirements. for a production system it could make sense to stay with the stable release - etch, and use only selected pieces of software from the backports repository

[12:40] <spinclad> sure, this is just my desktop, tho

[12:40] <pdy> ah ok, on my desktop i always go with "testing" :-)

[12:40] <spinclad> expect i will soon too

[12:41] <pdy> you will get the joy of tags with it

[12:41] <pdy> debtags is awesome for searches

[12:42] <pdy> apt-get install ept-cache

[12:44] <moritz_> debtags is missing the data from popcon

[12:44] <moritz_> if it had that, it would be even more useful

[12:44] <pdy> its not missing it. its admin duty to combine them :-)

[12:44] <spinclad> i see the tags in aptitude already, have apt-cache, ept-cache is different?

[12:44] <spinclad> (looking)

[12:45] <pdy> check the homepage of Enrico Zini for his talk how to combine popcon data with other information

[12:45] <moritz_> I saw his talk at LinuxTag 2006

[12:45] <moritz_> back then it didn't include any popcon information

[12:45] <moritz_> so it seems I'm not up to date

[12:45] <pdy> moritz_: his talk's from 2007 are taking it even further :-)

[12:46] * pdy builds a temple for Enrico

[12:47] <pdy> now if i would be a master of the Perl i could make use of all the wealth of information that is out there to my feet!

[12:47] <spinclad> looks nice. look forward to playing with it.

[12:48] <pdy> e.g. you like a software and know a friend likes that software too. what other software does the friend have which is not on my system yet, but could be of interest to me

[12:50] <moritz_> social packaging ;)

[12:50] <pdy> then restrict the results based on tags is::implemented::in:perl

[12:50] <pdy> yeah :-)

[12:54] *** Aankh|Clone joined
[13:05] *** takanori left
[13:12] *** wknight-away joined
[13:12] *** Aankhen`` left
[13:14] *** pcbuetow left
[13:14] *** alester joined
[13:14] *** pcbuetow joined
[13:15] *** ebassi is now known as ebassi|lunch

[13:15] *** ebassi|lunch left
[13:15] *** ebassi joined
[13:16] *** ebassi is now known as ebassi|lunch

[13:20] *** jiing joined
[13:27] *** alester left
[13:39] *** thoughtp1lice joined
[13:40] *** viklund joined
[13:50] *** thoughtpolice left
[13:54] *** ebassi|lunch is now known as ebassi

[13:55] *** monomorph joined
[13:57] *** cognominal_ joined
[14:01] *** jferrero joined
[14:02] *** mico joined
[14:04] <pugs_svn> r19799 | putter++ | a possible talk and project.

[14:05] <pugs_svn> r19800 | ruoso++ | [smop] more leaks solved. Now the first test have only 10 objects leaking...

[14:09] *** njbartlett left
[14:09] *** alester joined
[14:13] *** alester left
[14:35] *** thoughtp1lice left
[14:36] *** volp joined
[14:38] *** acmoore left
[14:43] *** cognominal_ left
[14:47] *** cognominal_ joined
[14:49] *** volp left
[14:50] *** manfred joined
[14:50] *** cognominal_ left
[14:59] *** TJCRI joined
[15:03] *** alester joined
[15:16] *** njbartlett joined
[15:17] *** takanori joined
[15:19] *** mico left
[15:25] *** njbartlett left
[15:28] *** njbartlett joined
[15:29] *** peeps[work] joined
[15:30] *** faxathisia joined
[15:32] *** Auzon left
[15:44] *** sahadev joined
[15:50] *** jhorwitz joined
[15:58] *** rindolf joined
[16:01] *** mico joined
[16:06] *** konusinua joined
[16:11] *** njbartlett left
[16:11] *** cyberpass joined
[16:12] *** njbartlett joined
[16:15] *** mico left
[16:21] *** jjore left
[16:26] *** Psyche^ joined
[16:26] *** Patterner left
[16:26] *** Psyche^ is now known as Patterner

[16:28] *** rindolf left
[16:29] *** takanori left
[16:32] *** mico joined
[16:35] *** rindolf joined
[16:45] *** chris2 left
[16:45] *** chris2 joined
[16:50] *** cosimo left
[16:56] *** zamolxes left
[16:57] *** konusinua left
[17:05] *** pcbuetow left
[17:09] *** viklund left
[17:10] *** meppl joined
[17:13] *** meppl left
[17:15] *** meppl joined
[17:22] *** xinming_ is now known as xinming

[17:38] *** Jamtech joined
[17:41] *** simcop2387 left
[17:43] <ruoso> I was testing smop with valgrind and I don't have any more errors, only some memory leaks that seems to be already identified by the SMOP_LOWLEVEL_MEM_TRACE code

[17:43] *** simcop2387 joined
[17:43] <[particle]> \o/

[17:44] *** mico left
[17:45] <ruoso> and it seems that I'm missing some SMOP_RELEASE on the continuation, as the objects not being destroyed are SMOP__SLIME__Frames and Nodes (the nodes are referenced by the frames, so, it's probably frame's fault)

[17:46] <ruoso> brb &

[17:46] *** mico joined
[17:49] <TimToady> \oJ  # left arm hurts

[17:49] <TimToady> gah, it's too early to be this late...

[17:57] *** pmurias joined
[17:57] *** pmurias left
[17:59] *** jferrero left
[18:17] *** tobeya joined
[18:21] *** cognominal_ joined
[18:27] *** cognominal__ joined
[18:27] *** ebassi left
[18:27] *** cognominal_ left
[18:29] *** pmurias joined
[18:31] *** mico left
[18:46] *** cognominal__ left
[19:04] *** mico joined
[19:07] *** mico left
[19:14] *** cognominal_ joined
[19:21] *** vainguard joined
[19:37] *** chris2 left
[19:44] *** ntgrl joined
[19:46] *** sri_work joined
[19:50] *** cognominal_ left
[19:52] *** ludan joined
[19:53] <ludan> hi

[19:54] <moritz_> good localtime() ;)

[19:54] <pmurias> moritz_: good evening

[19:56] *** integral left
[20:01] <moritz_> pmurias: how are kp6 things going?

[20:08] *** mico joined
[20:10] <pmurias> moritz_: ruoso is making good progress on smop

[20:11] <pmurias> i didn't have time to work on kp6 recently

[20:11] <pmurias> the ruby backend passes some tests

[20:11] <moritz_> cool

[20:12] <moritz_> mncharity++

[20:15] *** iblechbot left
[20:18] *** mico left
[20:26] *** Aankh|Clone left
[20:30] *** rindolf left
[20:35] *** mico joined
[20:40] *** Schwern joined
[20:55] <ruoso> hi pmurias... I'm very near of finishing stage 0 smop... I'm only chasing some memory leaks to have it finished... have some time to help?

[21:02] <moritz_> what are you using to detect mem leaks? valgrind?

[21:03] <moritz_> or your internal tracer?

[21:03] <ruoso> bltn]

[21:03] <ruoso> both

[21:03] * ruoso with the hand misplaced in the keyboard

[21:03] <ruoso> right now, it seems that the interpreter is leaving a reference to the frame unreleased

[21:03] *** Schwern left
[21:04] <moritz_> how does that work? at termination of program it checks all refcounts and reports if it's != 0?

[21:04] <pugs_svn> r19801 | ruoso++ | [smop] some more fixes, but still with some memory leaks...

[21:04] <pmurias> ruoso: hi

[21:04] <ruoso> moritz_, yep... 

[21:05] <ruoso> moritz_, actually, it maintains a list with all allocced values

[21:05] <ruoso> and everytime you free a value, it removes from the list

[21:05] <ruoso> in the end, every value in the list is a memory leak

[21:06] <pmurias> i'm having an algorithmic competition we-thr (leaving on tu), and i'll be going to sleep soon

[21:06] <[particle]> you can add uids, and print them upon creation and destruction to check what's going on

[21:06] <[particle]> we did that with parrot

[21:07] <ruoso> [particle], that's kind of what the tracer does..

[21:08] <ruoso> I already have a debug message that shows every operation 

[21:08] <[particle]> sweet

[21:08] *** pmurias left
[21:10] <[particle]> TimToady++ # context updates

[21:10] *** cognominal_ joined
[21:11] <TimToady> I decided that simplifying = was a better idea that splitting it into two operators

[21:11] <TimToady> it still has to glare at the left arg a bit, but the cases that can be considered item assignment are drastically cut down

[21:12] <TimToady> and more importantly, easily recognizable by a human

[21:12] <TimToady> without having to delve into subscripts and such

[21:17] <[particle]> i'm happy = stays =

[21:18] <[particle]> yes, it seems list context is the default now

[21:19] <[particle]> and that's fine. users can be trained to expect that.

[21:19] <TimToady> I wanted to save $a = 1, $b = 2 though

[21:19] <TimToady> and this does that

[21:20] <[particle]> catering to the c-lovers among us

[21:35] *** manfred left
[21:49] *** yaberger_home joined
[21:50] *** ntgrl is now known as integral

[21:58] *** mico left
[21:58] *** jhorwitz left
[22:02] <pugs_svn> r19802 | ruoso++ | [smop] small progress... only 6 objects leaking in test/01...

[22:12] *** jferrero joined
[22:35] <pugs_svn> r19803 | ruoso++ | [smop] additional debug infomarmation. Every responder interface have a char* id that is used by the tracer to present a more usefull message.

[22:47] *** ispy_ joined
[22:49] *** araujo joined
[22:52] *** TJCRI left
[22:55] *** Limbic_Region joined
[23:14] <pugs_svn> r19804 | ruoso++ | [smop] now a real improvement... only one object leaking in test/01

[23:15] *** peeps[work] left
[23:16] *** yaberger_home left
[23:19] *** pdy left
[23:21] <ruoso> night &

[23:21] <TimToady> good night

[23:21] <wolverian> nice work, ruoso++

[23:21] *** Jamtech left
[23:29] *** wknight-away left
[23:31] *** aindilis left
[23:35] *** Auzon joined
[23:39] <peepsalot> i don't understand this syntax:     @values.sort: { $^b cmp $^a };

[23:39] <Limbic_Region> you are calling the sort method on @values

[23:39] <peepsalot> is it like creating an anonymous function and passing it to sort somehow.  what is the colon doing?

[23:40] <peepsalot> and the curly braces

[23:40] <Limbic_Region> it is synonomous in perl 5 as sort {$b cmp $a} @values;

[23:40] <peepsalot> ok, but I never learned perl 5 ;-)

[23:41] <TimToady> the colon is replacing a pair of parens there, so it's equivalent to @values.sort({$^b cmp $^a})

[23:41] <Limbic_Region> oh, sorry

[23:41] <peepsalot> TimToady, ok, that notation makes more sense to me.  is there any reason doing it with a colon is better?

[23:42] <TimToady> you don't have to figure out where to put the ending paren

[23:42] <Auzon> Well, it's a piece of code that has $^a and $^b representing the two items you are comparing. You then return -1, 0, or 1 (or the P6 object equivalents) to tell it how to sort.

[23:42] <peepsalot> so you can replace ANY function call parenthesis with a colon like that?

[23:42] <TimToady> no, only methods

[23:43] <TimToady> a normal function call doesn't need the colon in the first place

[23:43] <TimToady> foo(1,2,3) is equivalent to foo 1,2,3

[23:43] <TimToady> interestingly, you can also write @values.sort :{$^b cmp $^a}

[23:43] <peepsalot> hmm, ok

[23:44] <TimToady> but then it's parsed as an adverbial block rather than an argument list

[23:44] <Limbic_Region> TimToady - did you see the /msg I sent you on PerlMonks?

[23:44] *** wknight-away joined
[23:45] <TimToady> not yet

[23:45] <peepsalot> thanks for the tips.  gotta go for the moment. afk

[23:45] <Limbic_Region> ok, it was a pointer to a node I thought might interest you

[23:46] <TimToady> ah, my "And 0 more" mutated to "And 1 more", which is easy not to see

[23:46] <TimToady> yeah, was looking at that and wondering whether to respond

[23:47] <TimToady> 'course, delete is really an op on a container, which adds an additional wrinkle

[23:50] *** monomorph left
[23:55] *** cyberpass left
