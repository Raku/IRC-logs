[00:11] *** Ontolog left
[00:25] *** BinGOs left
[00:31] <[particle]> when did STD.pm grow backslashes after the opening block markers in statement_control:foo rules?

[00:31] <[particle]> and why?

[00:36] *** elmex left
[00:46] *** sail0r joined
[00:48] *** sail0r left
[01:00] *** Exodist left
[01:19] *** kanru joined
[01:25] *** xinming joined
[01:25] *** sail0r_ joined
[01:27] *** sail0r_ left
[01:33] *** kanru left
[01:37] *** xinming_ left
[01:47] *** xinming_ joined
[01:59] *** xinming left
[02:00] <hercynium> are those european backslashes or african backslashes?

[02:03] *** aindilis left
[02:04] *** aindilis joined
[02:24] *** Ontolog joined
[02:25] <Ontolog> moritz_: thanks for the checkin

[02:25] <Ontolog> moritz_: why can't we just move Str.split(Str) now? Did you try and have tests fail because of it?

[02:27] *** xinming joined
[02:39] *** xinming_ left
[02:43] *** wknight8111 left
[02:49] *** xinming_ joined
[02:56] *** meppl left
[02:57] *** meppl joined
[02:58] *** xinming__ joined
[03:02] *** xinming left
[03:08] *** jhorwitz left
[03:14] *** xinming_ left
[03:20] *** eternaleye_ left
[03:20] *** eternaleye_ joined
[03:22] *** hercynium left
[03:27] *** FreshCat joined
[03:41] *** justatheory joined
[03:42] *** Ontolog left
[03:44] *** justatheory left
[03:45] *** apeiron left
[03:47] *** Ontolog joined
[03:53] *** eternaleye_ is now known as eternaleye

[04:04] *** apeiron joined
[04:04] <Ontolog> Why do the perl6 tests on my machine always get stuck after t/spec/S29-trig/trig........................................... ok

[04:04] <Ontolog> cpu is 100%

[04:05] <Ontolog> and whatever test is running just isn't budging

[04:05] <Ontolog> i see it's t/spec/S04-statements/gather.rakudo

[04:06] <s1n> Ontolog: 64-bit system?

[04:06] <Ontolog> nope

[04:06] <Ontolog> 32-bit Linux

[04:06] <s1n> nevermind then

[04:13] <Ontolog> what is gather / take and where are the docs on it?

[04:15] <Ontolog> nevermind found the docs

[04:18] *** bennymack-work left
[04:29] *** Bzek joined
[04:32] *** xinming joined
[04:34] *** xinming__ left
[04:46] *** xinming_ joined
[04:47] <s1n> @tell pmichaud check your email

[04:48] <lambdabot> Consider it noted.

[04:49] *** kanru joined
[05:03] *** xinming left
[05:10] *** justatheory joined
[05:14] *** xinming joined
[05:26] *** justatheory left
[05:26] *** xinming_ left
[05:29] *** bennymack-work joined
[05:32] *** xinming_ joined
[05:34] *** pastasauce joined
[05:34] *** xinming left
[05:39] *** xinming joined
[05:52] *** xinming_ left
[05:53] *** xinming_ joined
[05:56] *** Psyche^ joined
[05:59] *** xinming left
[06:04] *** ashizawa joined
[06:12] *** Patterner left
[06:12] *** Psyche^ is now known as Patterner

[06:30] *** cognominal left
[06:34] *** dalek joined
[06:35] <Ontolog> There is yet another .sub 'split' method in Str.pir, this one does not have :multi in the method signature

[06:36] *** BinGOs joined
[06:37] *** BinGOs left
[06:40] <Ontolog> should it be removed? i'm not even sure what it does

[06:40] <Ontolog> it just takes two strings, makes them into Perl6Str, and runs a.'split'(b)

[06:40] <Ontolog> Which 'split' method would it be running in this case?

[06:41] <Ontolog> could this cause a recursive call?

[06:55] *** mtrimpe left
[06:55] *** BinGOs joined
[07:05] *** cognominal joined
[07:08] *** jfredett left
[07:09] *** sri_work joined
[07:10] <moritz_> Ontolog: yes, I had some failures

[07:13] <Ontolog> moritz_: I ran a sepctest_regression and I get Files=166, Tests=5084, 372 wallclock secs ( 1.85 usr  0.11 sys + 345.99 cusr  8.55 csys = 356.50 CPU)

[07:13] <Ontolog> Result: PASS

[07:14] *** iblechbot joined
[07:15] <moritz_> Ontolog: then nopaste your patch

[07:17] *** zamolxes left
[07:19] <Ontolog> pasted to #parrot

[07:20] <Ontolog> however there is still another split method

[07:20] <Ontolog> that i am confused about

[07:20] <Ontolog> removing also seems to not affect the tests

[07:21] <moritz_> there's a sub form of split also

[07:22] <moritz_> for split("delim", "longstring")

[07:23] <Ontolog> isn't $string.split("delim") and split("delim", $string) the same?

[07:24] <Ontolog> also if you look at 350     .return a.'split'(b) of Str.pir

[07:24] <Ontolog> which 'split' method is being called here?

[07:24] <moritz_> it's the same in terms of semantics, but it needs to be declared separately

[07:24] <moritz_> because you can't call a method as a sub

[07:26] <moritz_> usually we can use the export mechanism, but that would translate to split(lonstring, delim), which is not what we want

[07:26] <moritz_> weird stuff

[07:29] <Ontolog> i see

[07:29] <Ontolog> so should all three forms of split be in any-str.pir then?

[07:29] <Ontolog> or should this one stay in Str.pir?

[07:31] <moritz_> I think it should also be moved...

[07:35] <rakudo_svn> r31250 | moritz++ | [rakudo] move Str.split(Str) to any-str.pir, Ontolog++

[07:35] <rakudo_svn> r31250 | moritz++ | Now Str.split(/regex/) works because the method is no longer masked.

[07:35] <rakudo_svn> r31250 | moritz++ | I still don't understand why it fails with :multi(_,'String') though

[07:36] <Ontolog> hmm moving the non-method split causes compile to fail

[07:39] *** jfredett joined
[07:41] <moritz_> yes

[07:41] <moritz_> which is quite weird

[07:41] <moritz_> I guess because it has no :multi

[07:41] <moritz_> and then it's in the same namespace as the other subs with the same name

[07:48] *** zamolxes joined
[07:54] *** Alias_ joined
[08:00] *** charsbar left
[08:02] <Ontolog> in what namespace should normal subroutines be in?

[08:02] *** charsbar joined
[08:02] <Ontolog> normal as in , not a method attached to an object

[08:13] *** elmex joined
[08:15] <Ontolog>  .sub 'split' :multi('String','String')

[08:15] <Ontolog> Method 'split' not found for invocant of class 'String'

[08:15] <Ontolog> humph

[08:23] *** Alias_ left
[08:42] *** meppl left
[09:01] *** pastasauce left
[09:01] *** sri_work left
[09:12] *** Ontolog left
[09:17] *** Ontolog joined
[09:20] <moritz_> Ontolog: I couldn't find an easy way of moving the split sub, so I just left it as it is now

[09:20] <moritz_> rakudo: say 'abc2345df56'.split(/\d+/).perl

[09:20] <p6eval> rakudo 31254: OUTPUT[["abc", "df", ""]␤]

[09:21] <moritz_> I'm very happy this works, that will help the November hackers a lot

[09:22] <Ontolog> cool

[09:41] *** masak joined
[09:51] <masak> Ontolog++ # Str.split(Regex)

[09:51] <moritz_> uhm, I meant november development, not rakudo ;)

[09:51] <moritz_> in that mail

[09:51] <moritz_> perlbot: karma Ontolog 

[09:51] <perlbot> Karma for Ontolog: 5

[09:52] <Ontolog> haha

[09:52] <Ontolog> just getting started :p

[09:52] <Ontolog> perlbot: karma cdavaz

[09:52] <perlbot> Karma for cdavaz: 1

[09:52] <Ontolog> ok so 6 ;-)

[09:52] <Ontolog> perlbot cdavaz is Ontolog

[09:52] <perlbot> added cdavaz to the database

[09:52] <Ontolog> perlbot Ontolog is cdavaz

[09:52] <perlbot> added Ontolog to the database

[09:52] <masak> moritz_: I've been known to confuse Rakudo and November, too :)

[09:53] <moritz_> perlbot moritz is moritz_

[09:53] <perlbot> added moritz to the database

[09:53] <moritz_> perlbot, karma moritz_

[09:53] <perlbot> Karma for moritz_: 74

[09:53] <masak> perlbot masak is masak

[09:53] <perlbot> added masak to the database

[09:53] <moritz_> perlbot, karma moritz

[09:53] <perlbot> Karma for moritz: 1148

[09:53] <Ontolog> moritz_: i have no idea if that actually merges my karma haha

[09:53] <Ontolog> guess not

[09:53] <moritz_> perlbot, moritz?

[09:53] <perlbot> moritz_

[09:53] <moritz_> Ontolog: no, it just stores answers ;)

[09:54] <masak> karma merging could be badly abused

[09:54] <moritz_> aye

[09:55] <masak> also, I agree with Andrei: "Please also implement :g for .subst :-)"

[09:55] <masak> :)

[09:56] <moritz_> [X] Patches welcome

[09:57] <moritz_> rakudo: say ['abcd'.split(/<before .>/)].perl

[09:58] <p6eval> rakudo 31254: No output (you need to produce output to STDOUT)

[09:58] <moritz_> so it loops

[09:59] <masak> shouldn't it?

[10:00] <moritz_> masak: no, it should bump along after each match, just like in perl 5, and split into characters (I hope so, at least)

[10:00] <masak> ah. reasonable.

[10:00] <masak> actually, what's the shortest way to write // in perl 6?

[10:01] <moritz_> /''/

[10:01] <masak> oki

[10:01] <moritz_> but if you want to split into characters, no need for a regex

[10:01] <moritz_> rakudo: say ['abcd'.split('')].perl

[10:01] <p6eval> rakudo 31254: OUTPUT[sh: ./parrot: No such file or directory␤]

[10:01] <masak> oops :)

[10:01] <moritz_> it's 12:01, rebuild time ;)

[10:02] <moritz_> rakudo: say ['abcd'.split('')].perl

[10:02] <p6eval> rakudo 31254: OUTPUT[sh: ./parrot: No such file or directory␤]

[10:02] *** Ontolog left
[10:02] <masak> speaking of errors: on http://www.november-wiki.org/cgi-bin/w?action=recent_changes how do I change "[no address given]" into some email address?

[10:02] <moritz_> takes a few minutes on that server, it's not the fastest

[10:03] <eternaleye> Is there an operator which takes a List on the left and an Int on the right and returns a slice containing the list repeated Int times?

[10:03] <eternaleye> so <a b c d> OP 2 would return [a,b,c,d ; a,b,c,d]

[10:04] <moritz_> infix:<xx>

[10:04] <moritz_> in slice context

[10:04] <moritz_> (but no implementation does slice context yet)

[10:05] <eternaleye> Ah, that's why it didn't work. It assumed array context, and nothing does slice context yet

[10:05] <eternaleye> Dang

[10:05] <eternaleye> (I tried it in seevral incaarntions on p6eval but it died every time)

[10:05] <moritz_> as a workaround you can use map {[@list]}, ^$x

[10:05] <eternaleye> *several (cursed key-reordering bug

[10:05] <moritz_> rakudo: say ['abcd'.split('')].perl

[10:05] <p6eval> rakudo 31254: OUTPUT[Parrot VM: Can't stat languages/perl6/perl6.pbc, code 2.␤main: Packfile loading failed␤]

[10:06] <moritz_> rebuild still in progress :(

[10:06] <eternaleye> ooh, that map trick looks cool

[10:06] <moritz_> rakudo: say [map {[1, 2, 3]}, ^3].perl

[10:06] <p6eval> rakudo 31254: OUTPUT[Parrot VM: Can't stat languages/perl6/perl6.pbc, code 2.␤main: Packfile loading failed␤]

[10:07] <moritz_> (slow servers)--

[10:07] <moritz_> masak: can I register an account online yet?

[10:07] <moritz_> rakudo: say [map {[1, 2, 3]}, ^3].perl

[10:08] <p6eval> rakudo 31254: OUTPUT[[[1, 2, 3], [1, 2, 3], [1, 2, 3]]␤]

[10:08] <moritz_> rakudo: say (map {[1, 2, 3]}, ^3).perl

[10:08] <p6eval> rakudo 31254: OUTPUT[[[1, 2, 3], [1, 2, 3], [1, 2, 3]]␤]

[10:12] <masak> moritz_: not quite there yet

[10:12] <masak> I'll bump it up in priority, just for you

[10:12] <moritz_> masak: no need, I was just curious

[10:13] <masak> I have this wild idea about honeypotting people so that they can edit everything and see their changes, but all they do is queued up for moderation

[10:13] <masak> until they are approved, then everything goes in

[10:13] <moritz_> like the wikipedia did it?

[10:14] <masak> they did?

[10:14] <moritz_> (at least the German did, I think)

[10:14] <masak> and here I thought I had an original idea :)

[10:14] <masak> they don't anymore?

[10:15] <moritz_> no

[10:16] <masak> was it a bad idea?

[10:16] * masak is curious

[10:16] <moritz_> I think it discouraged contributions

[10:18] <moritz_> and it expresses that you don't trust people

[10:18] <moritz_> (which is generally not a bad idea on the internet, but people don't want to hear that anyway)

[10:19] <masak> hm

[10:19] <masak> makes sense

[10:19] <masak> I guess it's one of those ideas that seems technologically cool, but that turns people off

[10:26] *** alanhaggai joined
[10:30] *** Bzek left
[10:30] *** smg left
[10:33] <eternaleye> masak: also, it doesn't scale well - it requires that mod_hours/editor_hours remain near-constant, meaning that either moderators must do nothing but mod, or more (possibly unreliable) moderators must be added

[10:33] <masak> eternaleye: aye.

[10:33] <masak> so, for a small-size wiki engine, what's common practice?

[10:34] <moritz_> don't worry about abuse until it becomes a problem

[10:34] <masak> moritz_: hm. :/

[10:34] <masak> I like thinking ahead...

[10:34] <masak> also, I've had problems on my home wiki of this kind

[10:35] <masak> they started after I began publishing addresses to it on mailing lists

[10:35] <masak> and they are very real, and time-consuming once they've begun

[10:35] * masak hates wiki spammers

[10:36] * moritz_ hates all kind of spammers

[10:38] *** clintongormley joined
[10:57] *** wknight8111 joined
[11:02] *** Ontolog joined
[11:05] *** alanhaggai left
[11:13] *** iblechbot left
[11:17] *** FreshCat left
[11:39] *** BinGOs left
[11:39] *** BinGOs joined
[11:53] *** alanhaggai joined
[12:00] *** smg joined
[12:08] *** ruoso joined
[12:11] *** m0kn1 joined
[12:12] *** m0kn1 left
[12:14] *** iblechbot joined
[12:40] *** abra joined
[12:40] *** omichael joined
[12:41] *** BinGOs left
[12:45] *** ashizawa left
[12:48] * ruoso had just received a mail that points out that Lehman Brothers was one of the cases in the Get The Facts series of Microsoft... and now...

[12:48] * ruoso Get The Facts, it broke!

[12:49] <moritz_> ruoso b0rked the Lehman Brothers, we blame him

[12:49] <moritz_> oh, wait ;-)

[12:49] <rakudo_svn> r31263 | pmichaud++ | [rakudo]: spectest-progress.csv update: 166 files, 3399 passing tests

[12:56] *** alanhaggai_ joined
[13:00] *** BinGOs joined
[13:01] *** alanhaggai left
[13:01] *** alanhaggai_ is now known as alanhaggai

[13:42] *** smg left
[13:48] *** araujo left
[13:56] <moritz_> rakudo: ['a1b23dc'.split(/\d+/)].join('|')

[13:56] <p6eval> rakudo 31264: RESULT["a|b|dc"]

[14:05] *** Lorn_ joined
[14:18] *** Lorn left
[14:22] *** jhorwitz joined
[14:34] *** alanhaggai left
[15:11] *** pmichaud joined
[15:12] *** smg joined
[15:12] *** hercynium joined
[15:19] *** justatheory joined
[15:20] <Ontolog> moritz_: could you apply the latest patch I sent? it fixes the split function

[15:21] <moritz_> Ontolog: looking...

[15:22] *** tcliou joined
[15:23] *** araujo joined
[15:23] <moritz_> Ontolog: is that against the newest version of rakudo?

[15:23] <moritz_> Ontolog: it doesn't apply cleanly

[15:24] <Ontolog> oh?

[15:24] <Ontolog> let me seesee

[15:24] <moritz_> patching file src/builtins/any-str.pir

[15:24] <moritz_> Reversed (or previously applied) patch detected!  Assume -R? [n] n

[15:25] <Ontolog> hm?

[15:26] *** kanru left
[15:26] <moritz_> that's what I got when trying to apply your patch

[15:26] <moritz_> maybe I'm looking at the wrong patch...

[15:27] <moritz_> the one from p6c about 40min ago

[15:27] *** kanru joined
[15:27] <Ontolog> yeah i sent one about 40 min ago

[15:27] <Ontolog> let me try something

[15:28] <Ontolog> what's the command to patch?

[15:28] <moritz_> patch -p0 < patch_file

[15:30] <Ontolog> no problems here

[15:30] <moritz_> I'm currently testing what pmichaud has written on the list

[15:30] <moritz_> Ontolog: which svn revision?

[15:31] <moritz_> that seems to work

[15:31] <Ontolog> Revision: 31264

[15:31] <Ontolog> Last Changed Rev: 31263

[15:31] <moritz_> weird, same here

[15:31] *** ashleyb joined
[15:33] *** [particle]1 joined
[15:35] *** masak` joined
[15:35] *** baest_ joined
[15:36] *** aindilis` joined
[15:37] *** tcliou left
[15:37] *** Ontolog left
[15:37] *** masak left
[15:37] *** Patterner left
[15:37] *** aindilis left
[15:37] *** baest left
[15:37] *** c1sung left
[15:37] *** rakudo_svn left
[15:37] *** yves left
[15:37] *** [particle] left
[15:37] *** pasteling left
[15:37] *** simcop2387 left
[15:37] *** gbacon left
[15:38] *** tcliou joined
[15:38] *** Psyche^ joined
[15:38] *** Psyche^ is now known as Patterner

[15:38] *** c1sung joined
[15:38] *** masak` is now known as masak

[15:40] *** simcop2387 joined
[15:40] *** iblechbot left
[15:40] *** kanru left
[15:42] *** Ontolog joined
[15:42] *** aindilis joined
[15:42] *** yves joined
[15:42] *** [particle] joined
[15:42] *** gbacon joined
[15:42] *** pasteling joined
[15:42] *** rakudo_svn joined
[15:44] *** tcliou left
[15:44] *** aindilis left
[15:44] *** tcliou joined
[15:45] *** mberends left
[15:47] *** simcop2387 left
[15:47] <Ontolog> i did this: svn update; svn revert src/builtins/any-str.pir; svn revert src/classes/Str.pir;  patch -p0 < split.diff 

[15:47] <Ontolog> and my result is: patching file src/builtins/any-str.pir

[15:47] <Ontolog> patching file src/classes/Str.pir

[15:47] <Ontolog> with on errors

[15:47] <Ontolog> maybe you need to revert yours too

[15:48] <moritz_> I thought I had a clean working tree

[15:48] <moritz_> ok, I'll try again

[15:49] <moritz_> ah, I guess stored it in the wrong directory, and tried to apply an old version of a patch

[15:50] *** rakudo_svn left
[15:50] *** [particle] left
[15:50] *** simcop2387 joined
[15:55] <moritz_> that one works

[15:56] <pmichaud> it would be good to make sure we have spectests for all of the edge cases being discussed on november-wiki

[15:56] <lambdabot> pmichaud: You have 2 new messages. '/msg lambdabot @messages' to read them.

[15:57] <masak> indeed.

[15:58] *** rakudo_svn joined
[15:59] *** tcliou is now known as tcliouAway

[16:02] * moritz_ feels very frustrated by the inaccessability of the current split test

[16:07] <Ontolog> what's the url to that wiki?

[16:08] <Ontolog> i googled for it but just get references to it not the wiki itself

[16:08] *** Exodist joined
[16:08] <pmichaud> oh, the discussions are on the november-wiki mailing list

[16:09] <pmichaud> november-wiki is a wiki being written in Rakudo

[16:09] <Ontolog> ahh

[16:09] <Ontolog> you are talking about split.t in the pugs tests?

[16:10] <moritz_> yes

[16:10] <Ontolog> i see it's a bit complicated at the top

[16:10] <Ontolog> i don't know what all the is_deeply stuff is either :p

[16:10] <pmichaud> moritz_: I think I may able to get an 'eqv' operator working this weekend, at least for lists.

[16:11] <pmichaud> afk, lunch.

[16:16] *** ashleyb left
[16:17] *** iblechbot joined
[16:22] *** masak left
[16:28] *** meppl joined
[16:41] <TimToady> pmichaud: eqv on a hash could be optimized greatly over naive comparison of serializations

[16:41] <TimToady> first of all, you can reject if the number of keys differs

[16:42] <TimToady> it would also be relatively easy for the hash header to maintain an XOR of all hash values for existing keys

[16:43] *** alanhaggai joined
[16:43] <TimToady> and comparing those would give you an almost instantaneous rejection of hash equality most of the time

[16:43] <TimToady> and for the situation where they are equal, you're just wanting to make sure that all keys in one are also in the other

[16:45] <TimToady> and since the keys are identical, when the hash bucket layout is the same, you can just walk the buckets in parallel, and make sure each pair of buckets contains the same keys

[16:50] <TimToady> and in general, for more complicated data structures, there's something to be said for checking all the components for easy falsifiability before checking any of them for trueness, if there is any way to compute such a traversal cheaply

[16:51] <TimToady> or lazily

[16:52] <TimToady> for immutable values a hash of the .perl of everything might be lazily cached the first time we use a value in an eqv

[16:53] <TimToady> anyway, just some random premature optimizations :)

[16:54] <TimToady> oh, wait, eqv requires the hash values to be eqv too, so a hash-wide key xor only tells you if the keys are unequal; you still have to walk the buckets for both keys and values if the keys hash equally

[17:04] *** wknight8111 left
[17:13] *** mberends joined
[17:26] *** zamolxes left
[17:40] <pmichaud> also, hash keys aren't constrained to be strings :-)

[17:40] <pmichaud> but yes, I get the idea.  :-)

[17:40] *** meppl left
[17:42] *** Chillance joined
[18:12] *** ashizawa joined
[18:16] *** ashizawa left
[18:20] *** Lorn joined
[18:26] *** cjfields joined
[18:28] *** meteorjay joined
[18:28] *** Lorn_ left
[18:33] *** aindilis` is now known as aindilis

[18:33] *** omichael left
[18:33] *** Lorn_ joined
[18:40] *** r0bby is now known as r0bbyarrr

[18:45] *** cjfields left
[18:48] *** sri_work joined
[18:49] *** Lorn left
[19:02] *** wknight8111 joined
[19:35] *** Lorn joined
[19:38] *** clintongormley left
[19:44] *** wknight8111 left
[19:47] *** abra left
[19:48] *** Lorn_ left
[20:25] *** wknight8111 joined
[20:53] <rakudo_svn> r31278 | particle++ | [rakudo] add some cleanups to the makefile

[20:58] <pugs_svn> r22284 | bacek++ | [spec] Explicitly stringify .WHAT result to avoid 'use uninitialised variable' warnings

[21:06] *** hercynium left
[21:10] *** alanhaggai_ joined
[21:20] <pugs_svn> r22285 | bacek++ | [spec] Drop second declaration of same variable

[21:23] <pugs_svn> r22286 | bacek++ | [spec] Explicitly stringify .WHAT result to avoid 'use uninitialised variable' warnings

[21:31] *** jhorwitz left
[21:32] *** iblechbot left
[21:32] *** alanhaggai left
[21:34] *** Lunchy left
[21:36] *** zamolxes joined
[21:38] <pugs_svn> r22287 | ruoso++ | [smop] starting to put map in place...

[21:47] *** Lorn left
[21:58] *** wknight8111 left
[22:16] *** jiing left
[22:30] *** Exodist left
[22:58] <ruoso> pugs: say false.defined();

[22:58] <p6eval> pugs: OUTPUT[*** No such subroutine: "&false"␤    at /tmp/kOAzrSNDfE line 1, column 5-20␤]

[22:58] <ruoso> pugs: say Bool::False.defined();

[22:58] <p6eval> pugs: OUTPUT[1␤]

[23:04] <pugs_svn> r22288 | ruoso++ | [smop] YAY! SMOP now supports lazy map, for now there is only map in Void context, which means eager evaluation...

[23:12] *** zamolxes left
[23:15] <ruoso> heh... although the above statement might look weird, it actually means that at the moment a generic lazy list is implemented, it can be used with map...

[23:15] <ruoso> it's still missing the map in item context, which provides a flattened iteration, independent of the number of items returned in each iteration...

[23:43] <[particle]1> that ci comment is indeed confusing then :)

[23:43] <[particle]1> ruoso++

[23:43] *** [particle]1 is now known as [particle]

[23:44] *** ispy_ joined
[23:44] <ruoso> [particle], the thing is that as smop have late context propagation... and all the implicit things that happen by syntax are visible in the low-level...

[23:45] <ruoso> [particle], you can see test/30 in the smop sources :)

[23:46] <[particle]> i'll have a look after errands &

