[00:08] <samcv> \x[298F]\x[2990]\x[298D]\x[298E] ok

[00:08] <samcv> these two are switched

[00:09] <samcv> i just checked all of our delimiters we currently have in nqp's bracket file. and these two sets of brackets are the only that are incorrect with their matcher

[03:03] <dalek> nqp: cd8973d | samcv++ | src/HLL/Grammar.nqp:

[03:03] <dalek> nqp: Fix two bracket pairs which had each others closing delimiters

[03:03] <dalek> nqp:

[03:03] <dalek> nqp: Per BidiBrackets.txt Unicode 9.0:

[03:03] <dalek> nqp:

[03:03] <dalek> nqp: 298D; 2990; o # LEFT SQUARE BRACKET WITH TICK IN TOP CORNER

[03:03] <dalek> nqp: 298E; 298F; c # RIGHT SQUARE BRACKET WITH TICK IN BOTTOM CORNER

[03:03] <dalek> nqp:

[03:03] <dalek> nqp: Previously the Left Top Corner was paired with right bottom corner and

[03:03] <dalek> nqp: the Left Bottom Corner was paired with Right Top Corner which was

[03:03] <dalek> nqp: incorrect.

[03:03] <dalek> nqp:

[03:03] <dalek> nqp: IRC log: https://irclog.perlgeek.de/perl6/2017-01-03#i_13839721

[03:03] <dalek> nqp: review: https://github.com/perl6/nqp/commit/cd8973d8c0

[03:04] <dalek> roast: 3044240 | samcv++ | S02-literals/quoting-unicode.t:

[03:04] <dalek> roast: Fix two bracket pairs which had each others closing delimiters

[03:04] <dalek> roast:

[03:04] <dalek> roast: Per BidiBrackets.txt Unicode 9.0:

[03:04] <dalek> roast:

[03:04] <dalek> roast: 298D; 2990; o # LEFT SQUARE BRACKET WITH TICK IN TOP CORNER

[03:04] <dalek> roast: 298E; 298F; c # RIGHT SQUARE BRACKET WITH TICK IN BOTTOM CORNER

[03:04] <dalek> roast:

[03:04] <dalek> roast: Previously the Left Top Corner was paired with right bottom corner and

[03:04] <dalek> roast: the Left Bottom Corner was paired with Right Top Corner which was

[03:04] <dalek> roast: incorrect.

[03:04] <dalek> roast:

[03:04] <dalek> roast: IRC log: https://irclog.perlgeek.de/perl6/2017-01-03#i_13839721

[03:04] <dalek> roast: review: https://github.com/perl6/roast/commit/30442400f2

[03:11] <dalek> rakudo/nom: 76283f6 | samcv++ | tools/build/NQP_REVISION:

[03:11] <dalek> rakudo/nom: Bump NQP: Fix two bracket pairs which had each others closing delimiters

[03:11] <dalek> rakudo/nom:

[03:11] <dalek> rakudo/nom: Per BidiBrackets.txt Unicode 9.0:

[03:11] <dalek> rakudo/nom:

[03:11] <dalek> rakudo/nom: 298D; 2990; o # LEFT SQUARE BRACKET WITH TICK IN TOP CORNER

[03:11] <dalek> rakudo/nom: 298E; 298F; c # RIGHT SQUARE BRACKET WITH TICK IN BOTTOM CORNER

[03:11] <dalek> rakudo/nom:

[03:11] <dalek> rakudo/nom: Previously the Left Top Corner was paired with right bottom corner and

[03:11] <dalek> rakudo/nom: the Left Bottom Corner was paired with Right Top Corner which was

[03:11] <dalek> rakudo/nom: incorrect.

[03:11] <dalek> rakudo/nom:

[03:11] <dalek> rakudo/nom: IRC log: https://irclog.perlgeek.de/perl6/2017-01-03#i_13839721

[03:11] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/76283f6e16

[03:16] <dalek> roast/6.c-errata: e82c278 | samcv++ | S02-literals/quoting-unicode.t:

[03:16] <dalek> roast/6.c-errata: Fix two bracket pairs which had each others closing delimiters

[03:16] <dalek> roast/6.c-errata:

[03:16] <dalek> roast/6.c-errata: Per BidiBrackets.txt Unicode 9.0:

[03:16] <dalek> roast/6.c-errata:

[03:16] <dalek> roast/6.c-errata: 298D; 2990; o # LEFT SQUARE BRACKET WITH TICK IN TOP CORNER

[03:16] <dalek> roast/6.c-errata: 298E; 298F; c # RIGHT SQUARE BRACKET WITH TICK IN BOTTOM CORNER

[03:16] <dalek> roast/6.c-errata:

[03:16] <dalek> roast/6.c-errata: Previously the Left Top Corner was paired with right bottom corner and

[03:16] <dalek> roast/6.c-errata: the Left Bottom Corner was paired with Right Top Corner which was

[03:16] <dalek> roast/6.c-errata: incorrect.

[03:16] <dalek> roast/6.c-errata:

[03:16] <dalek> roast/6.c-errata: IRC log: https://irclog.perlgeek.de/perl6/2017-01-03#i_13839721

[03:16] <dalek> roast/6.c-errata: review: https://github.com/perl6/roast/commit/e82c278a05

[03:25] <dalek> roast: 5b8fb62 | samcv++ | S02-literals/quoting-unicode.t:

[03:25] <dalek> roast: Fix a typo and make it fit 80 column width

[03:25] <dalek> roast: review: https://github.com/perl6/roast/commit/5b8fb62449

[03:26] <dalek> roast/6.c-errata: ae13900 | samcv++ | S02-literals/quoting-unicode.t:

[03:26] <dalek> roast/6.c-errata: Fix a typo and make it fit 80 column width

[03:26] <dalek> roast/6.c-errata: review: https://github.com/perl6/roast/commit/ae13900437

[03:35] <dalek> roast: 5a6fe25 | samcv++ | S02-lexical-conventions/unicode.t:

[03:35] <dalek> roast: Correct unicode.t as well so for the ticked brackets

[03:35] <dalek> roast: review: https://github.com/perl6/roast/commit/5a6fe25d1e

[03:35] <dalek> roast/6.c-errata: 785cc71 | samcv++ | S02-lexical-conventions/unicode.t:

[03:35] <dalek> roast/6.c-errata: Correct unicode.t as well so for the ticked brackets

[03:35] <dalek> roast/6.c-errata: review: https://github.com/perl6/roast/commit/785cc719cd

[03:37] <samcv> ok i think that's it

[07:18] <[Tux]> last night:

[07:18] <[Tux]> This is Rakudo version 2016.12-187-g61887712e built on MoarVM version 2016.12-50-g9a9f2d46

[07:18] <[Tux]> csv-ip5xs        3.054

[07:18] <[Tux]> test            12.655

[07:18] <[Tux]> test-t           5.213

[07:18] <[Tux]> csv-parser      13.303

[07:18] <[Tux]> this morning:

[07:18] <[Tux]> This is Rakudo version 2016.12-190-g76283f6e1 built on MoarVM version 2016.12-50-g9a9f2d46

[07:18] <[Tux]> csv-ip5xs        3.096

[07:18] <[Tux]> test            13.906

[07:18] <[Tux]> test-t           5.675

[07:18] <[Tux]> csv-parser      14.553

[07:22] <samcv> yeye speedz

[07:24] <timotimo> it noised upwards quite a bit

[07:24] <timotimo> buggable: speed

[07:24] <buggable> timotimo, ▅▅▅▅▅█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▂▁▂▃▁▁▂▁▂▁▂▁▃▃ data for 2016-12-12–2017-01-03; variance: 5.137s–7.592s

[07:26] <[Tux]> timotimo: both pates were the fastest of two consecutive runs. the alternative for -190 was 5.9 :(

[07:26] <timotimo> oof

[07:34] <masak> wait, the variance is given as an interval?

[07:35] <masak> isn't that a confience interval or something?

[07:35] <timotimo> it's not like a standard deviation, it's just the minmax, i believe

[07:35] <masak> variance is usually taken to mean the square of the standard deviation

[07:35] <timotimo> right

[07:48] <nine> I'm quite sure it's just minmax

[07:51] <arnsholt> In that case, I suggest s/variance/range/

[08:02] <[Tux]> jnthn, got a new one :(

[08:03] <[Tux]> # expected: Buf.new(61,125,17,108,54,202,12,120,39,225,91,9,125,124,163,24,100,110,156,192,137)

[08:03] <[Tux]> #      got: Buf.new(61,125,17,108,54,202,12,120,39,225,91,9,125,124,163,24,100,110,156,9)

[08:03] <[Tux]> # expected: Buf.new(61,57,204,118,97,221,164,168,63,30,168,197,108,198,67,28,111,192,161,122,96)

[08:03] <[Tux]> #      got: Buf.new(61,57,204,118,97,221,164,168,63,30,168,197,108,198,67,28,111,33,122,96)

[08:03] <[Tux]> # expected: Buf.new(61,180,192,142,191,171,181,101,4,238,122,232,11,194,77,144,221,109,108,228,192)

[08:03] <[Tux]> #      got: Buf.new(61,180,14,191,171,181,101,4,238,122,232,11,194,77,144,221,109,108,228,192)

[08:03] <[Tux]> looks like they all have 192 in them

[08:08] <arnsholt> This Unicode shenanigans?

[08:14] <arnsholt> If those are supposed to be UTF-8 byte sequences, 192 followed by 137, 161 and 142 are all invalid

[08:14] <arnsholt> Those can all be replaced by shorter sequences (in this case, 9, 33 and 14)

[08:21] <[Tux]> arnsholt, utf8-c8

[08:22] <[Tux]> the underlying idea is that one can store real binary data (JPEG images) as utf8-c8

[08:22] <[Tux]> that way string functions can be used instead of Buf

[08:23] <samcv> 8 bit clean is just like utf-8 but like with 7 bytes?

[08:23] <samcv> or some bs? like that

[08:41] <arnsholt> [Tux]: Right. So what are the underlying bytes in those cases?

[08:44] <arnsholt> 'Cause those expected bytes are very iffy as UTF-8, but I don't know if utf8-c8 relaxes the UTF-8 constraints in some way to let you store arbitrary bytes

[08:51] <timotimo> the whole point of utf8-c8 is to let you store arbitrary bytes as utf8 and have the non-valid parts at least round-trip through encoding as utf8-c8 again

[08:56] <arnsholt> Right. So you read bytes in, and the bits that happen to be valid UTF-8 codepoints get decoded as such, and the ones that aren't just get read in as bytes?

[08:57] <timotimo> they get synthetics created for them

[08:57] <timotimo> m: say Buf.new(^255 .roll(32)).decode('utf8-c8')

[08:57] <camelia> rakudo-moar 76283f: OUTPUT«􏿽xE0􏿽xEFP#/􏿽xA8􏿽xE6􏿽x98Ԩ#k-􏿽x8E􏿽xF3􏿽x9Bb􏿽xB9􏿽xBCek2􏿽xBB􏿽xB3􏿽xC4␤»

[08:58] <arnsholt> Right

[08:59] <arnsholt> In that case, it's probably the decoder not recognizing that 192 is an invalid UTF-8 leader byte

[09:03] <timotimo> m: say 0x7f

[09:03] <camelia> rakudo-moar 76283f: OUTPUT«127␤»

[09:03] <timotimo> it compares > 0x7f

[09:06] <arnsholt> In utf8_c8.c:classify right?

[09:06] <timotimo> oh, i totally glanced past that

[09:07] <arnsholt> Heh!

[09:07] <arnsholt> First hit for 7f in the file =D

[09:08] <arnsholt> Anyways, I think classify needs to consider that 1100 0000, 1110 0000, etc. are invalid

[09:09] <timotimo> oooh

[09:09] <timotimo> well

[09:10] <timotimo> there's EXPECT_CONTINUATION

[09:10] <timotimo> if the continuation byte doesn't have its first two bits 10, it'll "process_bad_bytes"

[09:13] <arnsholt> Yeah, that's the code I think

[09:13] <timotimo> note also that what came after the 192 was not a null byte

[09:13] <arnsholt> If the byte is exactly 0b11000000 it's invalid

[09:14] <arnsholt> Similarly for 0b11100000 and friends

[09:14] <arnsholt> Or wait

[09:14] <arnsholt> This is more complicated, I think

[09:14] <arnsholt> 0b11100000 is actually valid I *think*

[09:15] <arnsholt> But only if the next two bytes are sufficiently full of bits

[09:16] <timotimo> oh you're so full of bits :P

[09:16] <arnsholt> I guess process_ok_codepoint needs to account for this, or something

[09:16] <nwc10> good UGT, #perl6-dev

[09:16] <arnsholt> o/

[09:16] <timotimo> m: say Buf.new(110,156,192,137).decode('utf8-c8').encode('utf8-c8)

[09:16] <camelia> rakudo-moar 76283f: OUTPUT«===SORRY!=== Error while compiling <tmp>␤Unable to parse expression in single quotes; couldn't find final "'" ␤at <tmp>:1␤------> 7).decode('utf8-c8').encode('utf8-c8)⏏<EOL>␤    expecting any of:␤        argument list␤        …»

[09:16] <timotimo> m: say Buf.new(110,156,192,137).decode('utf8-c8').encode('utf8-c8').perl

[09:16] <camelia> rakudo-moar 76283f: OUTPUT«Blob[uint8].new(110,156,9)␤»

[09:16] <timotimo> m: say Buf.new(156,192,137).decode('utf8-c8').encode('utf8-c8').perl

[09:16] <camelia> rakudo-moar 76283f: OUTPUT«Blob[uint8].new(156,9)␤»

[09:17] <timotimo> that's enough to trigger the problem

[09:17] <timotimo> m: say Buf.new(156,192).decode('utf8-c8').encode('utf8-c8').perl

[09:17] <camelia> rakudo-moar 76283f: OUTPUT«Blob[uint8].new(156,192)␤»

[09:17] <timotimo> that isn't

[09:17] <timotimo> m: say Buf.new(156,192, 0).decode('utf8-c8').encode('utf8-c8').perl

[09:17] <camelia> rakudo-moar 76283f: OUTPUT«Blob[uint8].new(156,192,0)␤»

[09:17] <timotimo> m: say Buf.new(156,192, 1).decode('utf8-c8').encode('utf8-c8').perl

[09:17] <camelia> rakudo-moar 76283f: OUTPUT«Blob[uint8].new(156,192,1)␤»

[09:17] <timotimo> m: say Buf.new(156,192, 129).decode('utf8-c8').encode('utf8-c8').perl

[09:17] <camelia> rakudo-moar 76283f: OUTPUT«Blob[uint8].new(156,1)␤»

[09:19] <arnsholt> m: say Buf.new(192, 129).decode('utf8-c8').encode('utf8-c8').perl # And this, I guess?

[09:19] <camelia> rakudo-moar 76283f: OUTPUT«Blob[uint8].new(1)␤»

[09:19] <timotimo> seems like

[09:19] <nine> j: say $*PERL.compiler

[09:19] <camelia> rakudo-jvm 8ca367: OUTPUT«rakudo (2016.11.71.g.8.ca.367.d)␤»

[09:19] <arnsholt> And probably...

[09:19] <arnsholt> *scribblescribble*

[09:20] <arnsholt> m: say Buf.new(192, 128).decode('utf8-c8').encode('utf8-c8').perl

[09:20] <camelia> rakudo-moar 76283f: OUTPUT«Blob[uint8].new(0)␤»

[09:20] <timotimo> that's also wrong, yeah

[09:20] <arnsholt> m: say Buf.new(0xe0, 128, 128).decode('utf8-c8').encode('utf8-c8').perl

[09:20] <camelia> rakudo-moar 76283f: OUTPUT«Blob[uint8].new(0)␤»

[09:21] <arnsholt> m: say Buf.new(0xf0, 128, 128, 128).decode('utf8-c8').encode('utf8-c8').perl

[09:21] <camelia> rakudo-moar 76283f: OUTPUT«Blob[uint8].new(0)␤»

[09:23] * arnsholt makes an issue

[09:24] <timotimo> at least the thing doesn't asplode any more due to bad memory reads :)

[09:25] <nwc10> yep. ASAN does not consider your bugs worthy of comment.

[09:25] <nwc10> jnthn++

[09:44] <|Tux|> arnsholt, there already is/was an issue

[09:44] <nwc10> am I right in thinking than m-spectest5 is only able to run in parallel on *nix, whereas m-spectest6 can also run in parallel on Win32?

[09:46] <timotimo> i think that's what it is, yeah

[09:46] <timotimo> though i think it isn't 100% reliable yet

[09:47] <arnsholt> [Tux]: For MoarVM?

[09:47] <arnsholt> Too late anyways. I've written it up as MoarVM#481

[09:48] <|Tux|> I couldn't find it anyway

[09:48] <nwc10> yes, not 100% reliable. ASAN occasionally triggers. jnthn knows why (but I forget why)

[09:48] <arnsholt> Me neither, when I searched just now

[09:50] <arnsholt> m: say Buf.new(0b1100_0001, 0b0000_0000).decode('utf8-c8').encode('utf8-c8').perl # Maybe this one too?

[09:50] <camelia> rakudo-moar 76283f: OUTPUT«Blob[uint8].new(193,0)␤»

[09:51] <arnsholt> Apparently not

[09:51] <arnsholt> Oh, derp

[09:51] <arnsholt> m: say Buf.new(0b1100_0001, 0b1000_0000).decode('utf8-c8').encode('utf8-c8').perl # Maybe *this* one too?

[09:51] <camelia> rakudo-moar 76283f: OUTPUT«Blob[uint8].new(64)␤»

[09:51] <arnsholt> There we go =D

[10:24] <bartolin> yesterday we had a discussion about division by zero on nqp-j vs. nqp-m: https://irclog.perlgeek.de/perl6-dev/2017-01-01#i_13833581

[10:24] <bartolin> use nqp; say nqp::div_In($_,0) for -1,0,2

[10:24] <bartolin> r: use nqp; say nqp::div_In($_,0) for -1,0,2

[10:24] <camelia> rakudo-jvm 8ca367: ( no output )

[10:24] <camelia> ..rakudo-moar 76283f: OUTPUT«-Inf␤NaN␤Inf␤»

[10:25] <bartolin> this is a request for comments on the following change to nqp::div_In for nqp-j: https://github.com/usev6/nqp/commit/be4b51425a

[10:26] <bartolin> I *think* that patch makes sense, but I'm not really sure -- so I'd like to get some feedback

[10:51] <dalek> nqp: 81c0e83 | jnthn++ | tools/build/MOAR_REVISION:

[10:51] <dalek> nqp: Bump MOAR_REVISION for Unicode improvements.

[10:51] <dalek> nqp: review: https://github.com/perl6/nqp/commit/81c0e83c89

[10:54] <dalek> rakudo/nom: ee38721 | jnthn++ | tools/build/NQP_REVISION:

[10:54] <dalek> rakudo/nom: Get latest MoarVM with Unicode improvements.

[10:54] <dalek> rakudo/nom:

[10:54] <dalek> rakudo/nom: * Catch some further invalid sequences in utf8-c8 decoding (jnthn++)

[10:54] <dalek> rakudo/nom: * Secondary/tertiary Unicode collation support (samcv++)

[10:54] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/ee38721ca5

[10:55] <dalek> roast: 1c42eea | jnthn++ | S32-str/utf8-c8.t:

[10:55] <dalek> roast: Some further utf8-c8 tests.

[10:55] <dalek> roast:

[10:55] <dalek> roast: We didn't have any that covered invalid/over-length representations.

[10:55] <dalek> roast: review: https://github.com/perl6/roast/commit/1c42eea5ea

[11:07] <notviki> bartolin: the results make sense to me.

[11:07] <notviki> No idea about the rest. I don't know java

[11:09] <notviki> buggable: speed

[11:09] <buggable> notviki, ▅▅▅▅▅█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▂▁▂▃▁▁▂▁▂▁▂▁▃▃ data for 2016-12-12–2017-01-03; range: 5.137s–7.592s

[11:11] <bartolin> I wonder whether there is a better place to do the checks for division by zero. but it seems to be a good thing to do it in nqp::div_In, so that that operator behaves the same as on MoarVM

[11:13] <bartolin> however, if noone suggests something better, I'll commit my patch later today. thanks for looking

[11:20] <psch> bartolin: i'd say that's exactly where the check should go

[12:08] <lizmat> m: class A { method sink { say "goodbye" } }; A  # shouldn't this just need to say "goodbye" ???

[12:08] <camelia> rakudo-moar ee3872: OUTPUT«WARNINGS for <tmp>:␤Useless use of constant value A in sink context (line 1)␤»

[12:13] <psch> we don't really seem to be using method sink for the sink warning, actually

[12:14] <lizmat> hmmm... I seem to remember a time when it was

[12:14] <psch> as in, the actual text appears in the Optimizer, and i don't see any spot where .sink is called explicitly

[12:14] <psch> yeah, might be a regression, it certainly makes sense that it should be called

[12:15] <lizmat> I was thinking about using this feature for the repl-here functionality

[12:15] <lizmat> m: REPL

[12:15] <camelia> rakudo-moar ee3872: OUTPUT«WARNINGS for <tmp>:␤Useless use of constant value REPL in sink context (line 1)␤»

[12:15] <lizmat> you want a repl for debugging your code: just add a line with REPL  :-)

[12:16] <lizmat> or something like:

[12:16] <psch> hide that behind a pragma maybe?  'cause the constant as such seems a bit too magical

[12:16] <lizmat> m: REPL if %*ENV<REPL>

[12:16] <camelia> rakudo-moar ee3872: OUTPUT«WARNINGS for <tmp>:␤Useless use of constant value REPL in sink context (line 1)␤»

[12:16] <psch> well, assuming the .sink stuff works out in the first place :)

[12:17] <lizmat> bisectable: help

[12:17] <bisectable6> lizmat, Like this: bisectable6: old=2015.12 new=HEAD exit 1 if (^∞).grep({ last })[5] // 0 == 4 # RT128181

[12:17] <synopsebot6> Link:  https://rt.perl.org/rt3//Public/Bug/Display.html?id=128181

[12:18] <lizmat> bisectable: old=2015.12 new=HEAD class A { method sink { say "goodbye" } }; A

[12:18] <bisectable6> lizmat, On both starting points (old=2015.12 new=ee38721) the exit code is 0 and the output is identical as well

[12:18] <bisectable6> lizmat, Output on both points: WARNINGS for /tmp/6YLL2XBaEU:␤Useless use of constant value A in sink context (line 1)

[12:18] <lizmat> hmmm...

[12:18] <lizmat> bisectable: old=2014.12 new=HEAD class A { method sink { say "goodbye" } }; A

[12:18] <bisectable6> lizmat, Bisecting by output (old=2014.12 new=ee38721) because on both starting points the exit code is 0

[12:18] <bisectable6> lizmat, bisect log: https://gist.github.com/cd8cd01db69a8b084c34fd7eedfcae0f

[12:18] <bisectable6> lizmat, (2015-12-17) https://github.com/rakudo/rakudo/commit/0021601502978a3946634da0f7aff71883a6f15c

[12:19] <psch> committable6: v6.c class A { method sink { say "sunk" } }; A

[12:19] <psch> committable6: help

[12:19] <committable6> psch, ¦«2015.12,2016.02,2016.03,2016.04,2016.05,2016.06,2016.07.1,2016.08.1,2016.09,2016.10,2016.11,2016.12,HEAD»: WARNINGS for /tmp/3olyApeBtW:␤Useless use of constant value A in sink context (line 1)

[12:19] <committable6> psch, Like this: committable6: f583f22,HEAD say ‘hello’; say ‘world’

[12:19] <psch> well, that fits with a pre 2015.12 commit at least

[12:20] <psch> oh, yeah, the bisect commit definitely looks right too

[12:20] <lizmat> yeah

[12:20] <lizmat> I guess we would need to add checking for a .sink method if it is a class

[12:21] <psch> that's gonna be somewhat annoying i guess, considering we're adding the worry in the optimizer

[12:30] <lizmat> hmmm... even before that patch, .sink didn't get called

[12:30] <lizmat> perhaps jnthn moritz TimToady can shine their light on this

[12:31] <lizmat> m: class A {}; A.sink  # this assumes there's a .sink somewhere

[12:31] <camelia> rakudo-moar ee3872: ( no output )

[12:31] <psch> committable6: 2015.11 class A { method sink { say "sunk" } }; A

[12:31] <committable6> psch, ¦«2015.11»:

[12:32] <psch> well, Mu has .sink

[12:32] <psch> m: Any.^lookup('sink').perl

[12:32] <camelia> rakudo-moar ee3872: ( no output )

[12:32] <psch> m: Any.^lookup('sink').perl.say

[12:32] <camelia> rakudo-moar ee3872: OUTPUT«method sink (Mu $: *%_ --> Nil) { #`(Method|64799696) ... }␤»

[12:33] <dalek> nqp: 6105446 | niner++ | src/vm/jvm/ModuleLoader.nqp:

[12:33] <dalek> nqp: Always add JVM class paths, even when --module-path is used

[12:33] <dalek> nqp:

[12:33] <dalek> nqp: It's counter intuitive to leave out standard search paths just because a

[12:33] <dalek> nqp: custom path is specified. Especially since --module-path takes only a

[12:33] <dalek> nqp: single path and can only be used once.

[12:33] <dalek> nqp: review: https://github.com/perl6/nqp/commit/610544619c

[12:33] <dalek> nqp: 4b1c72c | niner++ | src/vm/jvm/ModuleLoader.nqp:

[12:33] <dalek> nqp: Add support for NQP_LIB environment variable in JVM ModuleLoader

[12:33] <dalek> nqp:

[12:33] <dalek> nqp: This is needed so the Perl 6 main.nqp can run with a custom "blib" search path.

[12:33] <dalek> nqp: Otherwise it would fail on the use statements when trying to compile the

[12:33] <dalek> nqp: setting because it would try to load the installed libraries instead of the

[12:33] <dalek> nqp: ones created during the build.

[12:34] <dalek> rakudo/nom: directory to the front of the search path. Fixes setting compilation when

[12:34] <dalek> rakudo/nom: there are already Perl6:: NQP modules installed.

[12:34] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/fb4f16166c

[12:34] <nine> ^^^ Fixes the infamous "Missing or wrong version of dependency

[12:34] <nine> 'gen/jvm/stage2/QRegex.nqp'" when compiling Perl6::World

[12:34] <nine> bartolin: ^^^

[12:34] <nine> psch: ^^^

[12:34] <psch> wow

[12:34] <psch> nine++

[12:34] <psch> that's honestly great

[12:34] <psch> i guess that might've been fallout from my bootclasspath removal, in hindsight

[12:35] <nine> I finally got fed up enough cleaning camelia's build to have a look at where it goes wrong

[12:36] <nine> The fix could have been much easier but I do want to get rid of the hard coded . and blib search paths which is now possible

[12:36] <lizmat> psch: if I add nqp::say("sunk") to Mu.sink, it *does* get called instead of A.sink

[12:38] <psch> lizmat: with --optimize=off too?

[12:38] <lizmat> yup

[12:39] <psch> huh.  well, we do call .sink explicitly in main.nqp...

[12:39] <psch> on the final result though.  not sure that explains Mu.sink instead of A.sink though

[12:48] <arnsholt> What do we think about a test file (for stresstest, for obvious reasons) with 2^32-1 tests? =)

[12:49] <arnsholt> It's the obvious way to smoke out any further bugs like the on [Tux] found earlier: make sure that all possible byte sequences up to length 4 round-trip correctly

[12:49] <arnsholt> Which would make it more than 2^23, come to think of it

[12:50] <lizmat> do you have an estimate for its runtime ?

[12:50] <lizmat> I mean, if it's going to take an hour, that might not sit well with the release manager

[12:50] <arnsholt> Nope. But I suspect it's a bit overkill, even for stresstest, yeah

[12:51] <arnsholt> In my defence, I meant it mostly in jest =)

[12:51] <lizmat> I'm only against it because of the runtime, I like the idea

[12:51] <arnsholt> Yeah, thus the mostly in jest

[12:51] <arnsholt> I'll see how long it takes if and when I get around to hacking on that stuff

[12:52] <arnsholt> It might smoke out bugs in the test harnesses too, come to think of it =)

[12:52] <lizmat> yeah, so like I said, the only reason in my view not to do it, would be at release time

[12:53] <lizmat> even if it does run an hour, I wouldn't mind running it every now and then

[12:53] <lizmat> also, you could maybe split it up and have them test in parallel ?

[12:53] <arnsholt> Yeah, that could work

[12:53] <arnsholt> At least for the four-byte (and maybe three-byte sequences)

[12:55] <arnsholt> Mmmmmm. 4.3 billion tests

[12:56] <lizmat> perhaps only emitting an ok for every X values checked ?

[12:56] <arnsholt> Yeah, that's an idea too

[12:56] <lizmat> or maybe keep the number of tests open ended, and only emit a not-ok for every failure ?

[12:57] <lizmat> RT #130493  # A.sink not being called, but Mu.sink is

[12:57] <arnsholt> Oh, that's a neat idea!

[12:57] <synopsebot6> Link:  https://rt.perl.org/rt3//Public/Bug/Display.html?id=130493

[12:58] <arnsholt> Or even "plan 1", "pass 'done'" at the end and output nok for each failure

[12:59] <lizmat> yup, also an idea  :-)

[12:59] <lizmat> afk for a bit&

[12:59] <|Tux|> is it correct that I heard some rumours about panda being deprecated?

[13:03] <timotimo> i don't know if you have heard some rumours

[13:05] <notviki> |Tux|: panda is being replaced for zef in Rakudo Star. That's about it.

[13:06] <notviki> And they aren't rumours; there's blog post about it: http://blogs.perl.org/users/steve_mynott/2017/01/rakudo-star-past-present-and-future.html

[13:09] <|Tux|> would you advice panda users to switch to zef?

[13:09] <|Tux|> This is Rakudo version 2016.12-193-gfb4f16166 built on MoarVM version 2016.12-55-gfe110d60

[13:09] <|Tux|> csv-ip5xs        3.042

[13:09] <|Tux|> test            13.044

[13:09] <|Tux|> test-t           5.251

[13:09] <|Tux|> csv-parser      13.860

[13:09] <|Tux|> # expected: Buf.new(61,1,251,34,193,152,7,136,253,183,136,13,116,113,248,143,176,217,172,177,121)

[13:09] <|Tux|> #      got: Buf.new(61,1,251,34,88,7,136,253,183,136,13,116,113,248,143,176,217,172,177,121)

[13:10] <|Tux|> 193,152 => 88

[13:10] <notviki> Yes, for the same reasons the blog post says zef's gonna be used in R*

[13:12] <arnsholt> [Tux]: Yeah, that's the same bug as the one we discussed earlier today (a leader of 193 being a two-byte sequence but only seven bits of codepoint)

[13:12] <arnsholt> If that's with the updated MoarVM from earlier today, looks like jnthn's bugfix isn't fixy enough =)

[13:13] <notviki> m: Buf.new(0b1100_0001,0b1000_0000).decode('utf8-c8').encode('utf8-c8').perl

[13:13] <camelia> rakudo-moar fb4f16: ( no output )

[13:13] <|Tux|> it is with a new git fetch

[13:13] <notviki> m: Buf.new(0b1100_0001,0b1000_0000).decode('utf8-c8').encode('utf8-c8').perl.say

[13:13] <camelia> rakudo-moar fb4f16: OUTPUT«Blob[uint8].new(193,128)␤»

[13:13] <notviki> m: for ^1000_000 { Buf.new(0b1100_0001,0b1000_0000).decode('utf8-c8').encode('utf8-c8') === Blob[uint8].new(193,128) }; say now - INIT now

[13:14] <camelia> rakudo-moar fb4f16: OUTPUT«(timeout)WARNINGS for <tmp>:␤Useless use of "===" in expression ".encode('utf8-c8') === Blob[uint8].new(193,128)" in sink context (line 1)␤»

[13:14] <notviki> m: for ^500_000 { $ = Buf.new(0b1100_0001,0b1000_0000).decode('utf8-c8').encode('utf8-c8') === Blob[uint8].new(193,128) }; say now - INIT now

[13:14] <camelia> rakudo-moar fb4f16: OUTPUT«(timeout)»

[13:14] <notviki> m: for ^1000 { $ = Buf.new(0b1100_0001,0b1000_0000).decode('utf8-c8').encode('utf8-c8') === Blob[uint8].new(193,128) }; say now - INIT now

[13:14] <camelia> rakudo-moar fb4f16: OUTPUT«0.1303087␤»

[13:14] <notviki> m: say 130308000/3600

[13:14] <camelia> rakudo-moar fb4f16: OUTPUT«36196.666667␤»

[13:15] * |Tux| installed new kernel. must reboot now. bbs

[13:15] <notviki> arnsholt: so it'd be a test that'd take 36196 hours to run on a single core? :}

[13:16] <arnsholt> Surely not a problem! =)

[13:18] <nine> Seems like it'd be worth investing a day or 200 into optimization before starting that test...

[13:19] <arnsholt> Yup.

[14:03] <bartolin> nine++

[14:13] <bartolin> Oh, dalek is absent. I just pushed my nqp::div_In patch: https://github.com/perl6/nqp/commit/0b055b9266

[14:19] <notviki> cool

[14:33] <cognominal> hi, what are synthetics and pseudotiles in MoarVM branch even-moar-jit ?

[14:36] <lizmat> cognominal: synthetics usually refer artificial codepoints generated for characters sequence for which there is no composed version

[14:37] <lizmat> pseudotiles feels more like a thing that brrt might be able to answer

[14:37] <notviki> cognominal: we're starting a business producing poor quality synthetic construction materials to fund Perl 6 development ;)

[14:38] <notviki> cognominal: here's some writing on the tiles stuff: https://perl6advent.wordpress.com/2016/12/09/a-preview-of-the-hackable-jit-compiler/

[14:38] <jnthn> lizmat: In the context of the JIT, they mean something else. (I don't know how to explain it, alas. :))

[14:38] <brrt> cognominal: a pseudotile is a tile that doesn't have a 'proper' emit function

[14:39] <brrt> the terminology 'tile' comes from the procedure that selects instructions (via 'tiling' by which the original tree is 'covered')

[14:39] <samcv> <notviki> cognominal: we're starting a business producing poor quality synthetic construction materials to fund Perl 6 development ;)

[14:39] <samcv> good idea

[14:39] <cognominal> thx

[14:40] <brrt> so the way that works is that we generate a list of objects that can write machine code to the assembler

[14:40] <brrt> and then we loop over that list and ouptut machine code

[14:40] <brrt> and a pseudotile is the name for a 'placeholder' of some sort

[14:41] <jnthn> brrt: What's a case where we need a pseudotile?

[14:41] <brrt> a 'synthetic' tile is a tile (object) that is not created by the tiling process but afterwards during register allocation (or other things)

[14:41] <brrt> well, for one thing, for resolving multiple value paths in IF (in fact, PHI) to one

[14:42] <brrt> another one is for setting up the arguments to a function call (that's called an ARGLIST node)

[14:42] <brrt> there are a bunch of these examples

[14:42] <brrt> historically, 'pseudotile' included tiles that were introduced *during* tiling, e.g. jumps and labels to handle within-procedure conditional jumps

[14:43] <brrt> but that's not really a good way to refer to these

[14:43] <brrt> if i had to call them anything, i'd call them 'structural' tiles, but there is no reason to distinguish these from 'natural' tiles anymore

[14:49] <brrt> also, recently, tiles that resolve to a simple register declaration (i.e. the MVMThreadContext always resides in register r14)

[14:50] <jnthn> Yes, a setdispatcherfor op seems to nicely resolve the original issue I was hunting down

[14:50] <brrt> \o/

[14:53] <jnthn> Unfortunately, the changes invalidate the JIT of the op

[14:53] <jnthn> Some small changes might make it easy to update though

[14:54] * brrt will be happy to take a look

[14:54] <brrt> once i understand what's going on, anyway

[15:00] <jnthn> oops, I mis-channeled the last bit ;)

[15:01] <brrt> no worries :-)

[15:32] <lizmat> m: my str @a = <a b c d e>.pick(*); @a.sort  # :-(

[15:32] <camelia> rakudo-moar fb4f16: OUTPUT«compare requires a concrete string, but got null␤  in block <unit> at <tmp> line 1␤␤»

[15:32] <lizmat> m: my int @a = (1,2,3,4,5).pick(*); say @a.sort

[15:32] <camelia> rakudo-moar fb4f16: OUTPUT«3 4 5 1 0␤»

[15:33] <lizmat> hmmm

[15:33] * lizmat will look at this later today or tomorrow

[15:33] <lizmat> this was not caught by spectests  :-(

[15:34] <notviki> dalek \o/

[16:23] <dalek> nqp: 41f8d8b | jnthn++ | tools/build/MOAR_REVISION:

[16:23] <dalek> nqp: MoarVM bump for setdispatcherfor op.

[16:23] <dalek> nqp: review: https://github.com/perl6/nqp/commit/41f8d8b2f1

[16:23] <dalek> nqp: 5f40147 | jnthn++ | src/vm/moar/QAST/QASTOperationsMAST.nqp:

[16:23] <dalek> nqp: Map setdispatcherfor on MoarVM backend.

[16:23] <dalek> nqp: review: https://github.com/perl6/nqp/commit/5f4014787d

[16:25] <dalek> rakudo/setdispatcherfor: dc34413 | jnthn++ | src/vm/moar/ops/perl6_ops.c:

[16:25] <dalek> rakudo/setdispatcherfor: Missing MVMROOT around try_get_lexical.

[16:25] <dalek> rakudo/setdispatcherfor:

[16:25] <dalek> rakudo/setdispatcherfor: It may vivify it on demand.

[16:25] <dalek> rakudo/setdispatcherfor: review: https://github.com/rakudo/rakudo/commit/dc344139dc

[16:25] <dalek> rakudo/setdispatcherfor: 1c3999a | jnthn++ | src/Perl6/Metamodel/Dispatchers.nqp:

[16:25] <dalek> rakudo/setdispatcherfor: Use the new setdispatcherfor op.

[16:25] <dalek> rakudo/setdispatcherfor:

[16:25] <dalek> rakudo/setdispatcherfor: In a branch for now, needs MoarVM HEAD, still need to fix up JVM.

[16:25] <dalek> rakudo/setdispatcherfor: review: https://github.com/rakudo/rakudo/commit/1c3999ab73

[16:55] <dalek> nqp: 918cdb3 | jnthn++ | src/vm/jvm/ (3 files):

[16:55] <dalek> nqp: Introduce setdispatcherfor op on JVM backend.

[16:55] <dalek> nqp:

[16:55] <dalek> nqp: So that Rakudo can start using it. Should mean we also get the same

[16:55] <dalek> nqp: set of bug fixes that use of the new op provides for MoarVM also.

[16:55] <dalek> nqp: review: https://github.com/perl6/nqp/commit/918cdb3f38

[17:02] <jnthn> Hmm, if I build a fresh Rakudo JVM then run it I get

[17:02] <jnthn> java.nio.file.NoSuchFileException: /home/jnthn/dev/rakudo/nqp/jvm-install/share/nqp/lib/Perl6/BOOTSTRAP.jar

[17:03] <bartolin> jnthn: does it work after 'make install'?

[17:03] <jnthn> That's what I'm trying

[17:04] <jnthn> (waiting for install-core-dist to complete)

[17:05] <bartolin> https://irclog.perlgeek.de/perl6-dev/2016-12-31#i_13828563

[17:05] <jnthn> bartolin: Yes, it helps

[17:05] <jnthn> Ah, you already notified nine about it

[17:05] <bartolin> jnthn: nine suggested an untested patch here: https://irclog.perlgeek.de/perl6-dev/2016-12-31#i_13828633

[17:05] <jnthn> OK

[17:05] <jnthn> I don't have time to look into that issue

[17:06] <jnthn> Good news is that my patch to fix up nextsame and friends works on JVM too

[17:06] <bartolin> yeah, I hope, I'll find some time soon-ish

[17:06] <bartolin> \o/

[17:06] <jnthn> So we get the fix on Moar and JVM and don't have to fudge/#?if :)

[17:06] <bartolin> sounds very good, jnthn++ :-)

[17:08] * notviki just booked all Mondays until end of February off o/

[17:08] <notviki> Hopefully could get some quality time hacking on Perl 6

[17:10] <dalek> rakudo/nom: 8d5fe1a | jnthn++ | src/vm/moar/ops/perl6_ops.c:

[17:10] <dalek> rakudo/nom: Missing MVMROOT around try_get_lexical.

[17:10] <dalek> rakudo/nom:

[17:10] <dalek> rakudo/nom: It may vivify it on demand.

[17:10] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/8d5fe1a977

[17:10] <dalek> rakudo/nom: fe34aa8 | jnthn++ | tools/build/NQP_REVISION:

[17:10] <dalek> rakudo/nom: Bump to get new setdispatcher op.

[17:10] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/fe34aa8988

[17:14] <dalek> rakudo/nom: 0c0dd82 | jnthn++ | src/Perl6/Metamodel/Dispatchers.nqp:

[17:14] <dalek> rakudo/nom: Use the new setdispatcherfor op.

[17:14] <dalek> rakudo/nom:

[17:14] <dalek> rakudo/nom: This corrects various bugs arising from the wrong block picking up the

[17:14] <dalek> rakudo/nom: dispatcher, by setting the target that it should be captured by. This

[17:14] <dalek> rakudo/nom: fixes a number of issues, including use of nextsame in conjunction

[17:14] <dalek> rakudo/nom: with multi subs with `where` clauses, and the spooky issue reported

[17:14] <dalek> rakudo/nom: as an OO::Monitors bug (which uses callsame) where occasionally the

[17:14] <dalek> rakudo/nom: callsame would not, in fact, call anything. That was due to the

[17:14] <dalek> rakudo/nom: finalizers being run post-GC, and the finalizer stole the dispatcher,

[17:14] <dalek> rakudo/nom: thus why any code that used Failure was more likely to tickle this.

[17:14] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/0c0dd826e0

[17:23] <dalek> roast: d667dda | jnthn++ | S12-methods/defer-next.t:

[17:23] <dalek> roast: Add test to cover RT #123989.

[17:23] <dalek> roast: review: https://github.com/perl6/roast/commit/d667ddadf0

[17:23] <synopsebot6> Link:  https://rt.perl.org/rt3//Public/Bug/Display.html?id=123989

[17:54] <lizmat> jnthn: HARNESS_TYPE=6 make spectest now has a lot of tests out of order and one test hanging

[17:54] <lizmat> *and* the same kind of failure like before :-(

[17:54] <lizmat> so in that regard, things haven't gotten better  :-(

[17:55] <lizmat> ah, another NQP bump: trying that now

[17:56] <jnthn> lizmat: I'm not even working on it.

[17:57] <jnthn> Or any concurrency stuff in the last days

[17:57] <jnthn> So if it's gotten worse it's likely something else.

[17:58] <jnthn> (Last couple of days were Unicode and a deferral bug and a regex engine bug, which feel rather distant from anything harness6 does)

[17:59] <jnthn> It'd be interesting to work out when the new failures were introduced.

[17:59] <jnthn> About the original failure, do have some clues what it's about.

[17:59] <jnthn> (Still deciding how to fix that)

[18:00] <jnthn> But if it's regressed in some other way that will only help so much :(

[18:04] <dalek> roast: cd43168 | jnthn++ | integration/failure-and-callsame.t:

[18:04] <dalek> roast: Add a test to cover failure + callsame issue.

[18:04] <dalek> roast:

[18:04] <dalek> roast: See comment in the test for details.

[18:04] <dalek> roast: review: https://github.com/perl6/roast/commit/cd43168706

[18:04] <dalek> rakudo/nom: 4b68d30 | jnthn++ | t/spectest.data:

[18:04] <dalek> rakudo/nom: Run integration/failure-and-callsame.t.

[18:04] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/4b68d30f22

[18:08] <jnthn> That took nearly all day to find/fix/write tests for...

[18:08] <jnthn> At least it nailed an RT or two also

[18:08] <jnthn> Nasty.

[18:12] <jnthn> dogbert2: I've tagged https://rt.perl.org/Ticket/Display.html?id=125135 as testneeded; we can close it up once your test is in :)

[18:31] <jnthn> m: https://gist.github.com/jnthn/2c8d09f38aadfd72a572ce7a79ca718d

[18:31] <camelia> rakudo-moar 4b68d3: OUTPUT«not ok 1 - Can put multi-line Pod on a role␤␤# Failed test 'Can put multi-line Pod on a role'␤# at <tmp> line 3␤# Error: Method 'connect' must be implemented by Test::Antenna because it is required by roles: Test::Antenna.␤»

[18:33] <dalek> roast: 13403ee | dogbert17++ | S12-meta/ (2 files):

[18:33] <dalek> roast: Test for RT 125135

[18:33] <dalek> roast: review: https://github.com/perl6/roast/commit/13403eee42

[18:33] <dalek> roast: 3e2015d | dogbert17++ | S12-meta/ (2 files):

[18:33] <dalek> roast: Merge pull request #213 from dogbert17/test-rt-125135

[18:33] <dalek> roast:

[18:33] <dalek> roast: Test for RT 125135

[18:33] <dalek> roast: review: https://github.com/perl6/roast/commit/3e2015dc85

[18:37] <jnthn> dogbert2: You got RT perms to close it, or shall i?

[18:41] <dogbert2> jnthn: plz close it

[18:42] <dogbert2> I don't have perms, need to get hold of [Coke] first I guess

[18:43] <dogbert2> hmm, t/spec/S02-types/mixhash failed one test

[18:45] <jnthn> done. thanks

[18:45] <dalek> rakudo/nom: d487657 | jnthn++ | src/Perl6/Metamodel/BOOTSTRAP.nqp:

[18:45] <dalek> rakudo/nom: Fix putting Pod onto a role with requirements.

[18:45] <dalek> rakudo/nom:

[18:45] <dalek> rakudo/nom: Previously, this led to the role being punned, which is not wanted in

[18:45] <dalek> rakudo/nom: the case of attaching/retrieving documentation.

[18:45] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/d487657c8b

[18:45] <dalek> roast: 4031e22 | jnthn++ | S26-documentation/block-leading.t:

[18:45] <dalek> roast: Test for RT #130208.

[18:45] <dalek> roast: review: https://github.com/perl6/roast/commit/4031e22f95

[18:45] <synopsebot6> Link:  https://rt.perl.org/rt3//Public/Bug/Display.html?id=130208

[18:47] <jnthn> There, an easier bug. :)

[18:48] <dogbert2> how many of those are there I wonder

[18:48] <notviki> heh... they're always easy when you know what to look for :P

[18:49] <dogbert2> :)

[18:50] <dogbert2> I've found, at $work, that seemingly easy problems can be incredibly hard to solve and vice versa

[18:52] <jnthn> Time for some rest. :)

[18:53] <jnthn> Might be back later, though I slept awfully last night, so mebbe not. :)

[18:57] <notviki> cpan@perlbuild2~/CPANPRC/rakudo (nom)$ grep -R 'hack' src/ | wc -l

[18:57] <notviki> 10

[18:57] <notviki> cpan@perlbuild2~/CPANPRC/rakudo (nom)$ grep -ER 'evil.*hack' src/ | wc -l

[18:57] <notviki> 2

[18:57] * notviki laughs

[18:57] <notviki> and two matches for 'shoddy' :}

[19:08] <notviki> hm... t/spec/S32-io/socket-host-port-split.t ............................ seems to hang on my VM

[19:23] <DrForr> "Did you sleep good?" "No, I made a few mistakes."

[19:23] <dalek> roast: b3d3a73 | (Zoffix Znet)++ | S32-io/socket-host-port-split.t:

[19:23] <dalek> roast: Fudge IPv6 test

[19:23] <dalek> roast:

[19:23] <dalek> roast: The test seems to hang on boxes without ipv6 support

[19:23] <dalek> roast: review: https://github.com/perl6/roast/commit/b3d3a736ee

[19:28] <dalek> rakudo/nom: c13e67b | (Zoffix Znet)++ | src/core/ (2 files):

[19:28] <dalek> rakudo/nom: Replace heuristic type detection with actual type check

[19:28] <dalek> rakudo/nom:

[19:28] <dalek> rakudo/nom: Seems to also be 3x faster

[19:28] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/c13e67b3e9

[19:31] <lizmat> notviki:  good catch

[19:31] <timotimo> neat.

[19:56] <dalek> rakudo/nom: f9ed730 | lizmat++ | src/core/ (2 files):

[19:56] <dalek> rakudo/nom: Remove unnecessary stubs

[19:56] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/f9ed7300fc

[19:57] <notviki> \o/

[20:16] * bartolin sent a CLA in order to get a commit bit for rakudo (cc'd lizmat and [Coke])

[20:16] <lizmat> bartolin==

[20:16] <lizmat> ++

[20:16] <bartolin> *g*

[20:16] <lizmat> grrr

[20:16] <lizmat> :-)

[20:42] <notviki> bartolin＋＋

[20:49] <nine> bartolin: about time :)

[21:01] <dalek> roast: 0a7b6c5 | usev6++ | S32-num/rat.t:

[21:01] <dalek> roast: Unfudge passing test on JVM (RT #128264)

[21:01] <dalek> roast: review: https://github.com/perl6/roast/commit/0a7b6c5cbd

[21:01] <synopsebot6> Link:  https://rt.perl.org/rt3//Public/Bug/Display.html?id=128264

[21:34] <dalek> roast: fed7442 | usev6++ | S32-array/adverbs.t:

[21:34] <dalek> roast: Unfudge passing test on JVM (RT #128123)

[21:34] <dalek> roast: review: https://github.com/perl6/roast/commit/fed74429d8

[21:34] <synopsebot6> Link:  https://rt.perl.org/rt3//Public/Bug/Display.html?id=128123

[22:27] <cognominal> m: grammar A { token TOP { :my $*T; <t> {say $*T}}; token t { $<t>=t { $*T=$<t> }}}; A.parse('t');

[22:27] <camelia> rakudo-moar f9ed73: OUTPUT«｢t｣␤»

[22:28] <cognominal> m: grammar A { token TOP { :my $*T; <t> {say $*T}}; token t { $*T=t }}; A.parse('t');

[22:28] <camelia> rakudo-moar f9ed73: ( no output )

[22:31] <cognominal> hum probably not a good idea.

[22:32] <cognominal> I wanted an idiom for a environment variable to double as an hypothetic.

[22:40] <cognominal> more exactly I wanted the hypothetic implicit and the dynvar set when the whole rule matched

[22:40] <cognominal> s/environment variable/dynvar/ btw

[22:41] <cognominal> probably too much magic here
