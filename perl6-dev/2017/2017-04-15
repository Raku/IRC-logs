[00:01] * TimToady admits to a certain amount of design aphasia in the area of IO...

[00:02] <Zoffix> Hmmm... Was stresstesting on this box all day and on this run t/spec/S32-io/IO-Socket-INET.t started taking ages. So I killed the stresstest, tried to run the file alone, it complained about adress in use. I killed the process using the address, run the file again, it got a bunch of failures, now after 10 minutes went back to that terminal, and the test passes normally :|

[00:02] <ugexe> its nice like how its nice push doesnt return boolean

[00:02] <ugexe> not that i really care strongly about this

[00:04] <TimToady> with mkdir, it does fit a little more strongly into the category of "you really oughta be checking that the OS didn't fail you"

[00:04] <timotimo> so why not have it fail when it fails?

[00:04] <Zoffix> ATM sub and method mkdirs work exactly the same, and IO::Path.mkdir return value is consistent with other... "making"... methods, like .link, .symlink: True on success; Failure on failure

[00:04] <TimToady> with push, one kind of expects it to work till you run out of memory

[00:06] <Zoffix> And all IO subs are same as methods, except for &chmod, &unlink, and &rmdir that do take a list of things to work on and return stuff that succeeded; the change for mkdir was mostly due to it taking a $mode arg, so the sig was: ($path, $mode) + ($mode, *@paths)

[00:07] <TimToady> well, that never bothered P5 :)

[00:07] <TimToady> but showing failure by leaving things out of a list is not a great interface

[00:08] * Zoffix reads perldoc -f mkdir

[00:08] <TimToady> interspersing failures would just end up pushing failures into the @delete-me array for later

[00:08] <Zoffix> Doesn't look like it can create multiple dirs at a time

[00:08] <TimToady> I could be misremembering

[00:09] <TimToady> anyway, if zef is the only casualty (and that's a big "if"), I'm probably okay with a little more accountabiilty out of mkdir

[00:10] <TimToady> as in, encouraging people to assume it might return failure as easily as success

[00:11] <TimToady> not that Laziness is a bad thing, but maybe here's a spot to encourage a bit more Cleanliness

[00:11] <mst> TimToady: it might not have bothered *you*

[00:12] <mst> I would suggest if we're going to default to 'works like perl5' then it should be 'works like the stuff perl5 devs use to avoid the core routines'

[00:12] <TimToady> well, certainly Cleanliness is sort of an acquired skill for some of us :)

[00:12] <mst> which probably means Path::Tiny atm

[00:13] <mst> yes, well, for me cleanliness isn't so much a skill at all as a thing my default configurations (strictures.pm etc.) enforce to save me from myself ;)

[00:13] * TimToady also maintains a great deal of CPAN aphasia :)

[00:13] <Zoffix> looks like samcns/uzu/lib/Uzu.pm6 is another causaulti

[00:15] <TimToady> well, "" is an invalid(ish) filename, and the file "0" is no longer false, so if you just something that can evaluate to true, rather than True, a filename still works, though encourages the sort of shortcuts we see

[00:15] <Zoffix> maybe ugexe/Perl6-PathTools/lib/PathTools.pm6 too

[00:16] <TimToady> and presumably they'd still catch the Failure when they try to delete it...

[00:17] <TimToady> so I do think it would be okay to return the filename for True, at the expense of a bit of hobgoblinness

[00:17] <Zoffix> OK, I'll do that

[00:18] <TimToady> I'm also fine with return Failure when it ain't true :)

[00:18] <TimToady> *ing

[00:18] <Zoffix> ugexe: so leave it then. It'll unbreak once I make it return the filename again. Note: it'll be an IO::Path object tho

[00:19] <TimToady> and we can talk about clamping down a bit more for 6.d, if there's a groundswell of support for that position :)

[00:19] <ugexe> too late! :P Its just cleanup code for tests anyway

[00:20] <TimToady> I love it when everyone shoots past each other trying to be accomodating... :)

[00:20] <TimToady> *accommo

[00:21] * TimToady never could accomodate to the correct spelling of that word...

[00:27] <Geth> ¦ nqp/uncurse: a44e6dedc5 | TimToady++ | src/QRegex/Cursor.nqp

[00:27] <Geth> ¦ nqp/uncurse: reduce old match object to a singleton

[00:27] <Geth> ¦ nqp/uncurse:

[00:27] <Geth> ¦ nqp/uncurse: Still can't get it quite down to a boolean, but at least we can avoid

[00:27] <Geth> ¦ nqp/uncurse: allocating every time MATCH is called.

[00:27] <Geth> ¦ nqp/uncurse: review: https://github.com/perl6/nqp/commit/a44e6dedc5

[00:28] <Geth> ¦ rakudo/uncurse: 63e76d7afe | TimToady++ | 2 files

[00:28] <Geth> ¦ rakudo/uncurse: reuse NQP's singleton "did match" type

[00:28] <Geth> ¦ rakudo/uncurse:

[00:28] <Geth> ¦ rakudo/uncurse: (though for the moment we allocate our own singleton)

[00:28] <Geth> ¦ rakudo/uncurse: review: https://github.com/rakudo/rakudo/commit/63e76d7afe

[00:28] <Geth> ¦ rakudo/uncurse: 13 commits pushed by MasterDuke17++, (Zoffix Znet)++, TimToady++

[00:28] <Geth> ¦ rakudo/uncurse: review: https://github.com/rakudo/rakudo/compare/63e76d7afe...fbf19d88da

[00:34] <Geth> ¦ rakudo/nom: d46e8df4cb | (Zoffix Znet)++ | src/core/IO/Pipe.pm

[00:34] <Geth> ¦ rakudo/nom: [io grant] Add IO::Pipe .path and .IO methods

[00:34] <Geth> ¦ rakudo/nom:

[00:34] <Geth> ¦ rakudo/nom: That return an IO::Path type object. This fixes LTA error

[00:34] <Geth> ¦ rakudo/nom: of .IO/.path crashing, since the inherited methods from IO::Handle

[00:34] <Geth> ¦ rakudo/nom: try to instantiate an IO::Path from an empty string.

[00:34] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/d46e8df4cb

[00:34] <Geth> ¦ roast: 637500da24 | (Zoffix Znet)++ | S32-io/pipe.t

[00:34] <Geth> ¦ roast: [io grant] Spec IO::Pipe.path/.IO returns IO::Path type object

[00:34] <Geth> ¦ roast:

[00:34] <Geth> ¦ roast: Rakudo impl: https://github.com/rakudo/rakudo/commit/d46e8df4cb

[00:34] <Geth> ¦ roast: review: https://github.com/perl6/roast/commit/637500da24

[00:47] <Geth> ¦ rakudo/nom: c01ebea0a0 | (Zoffix Znet)++ | src/core/IO/Path.pm

[00:47] <Geth> ¦ rakudo/nom: [io grant] Make IO::Path.mkdir return invocant on success

[00:47] <Geth> ¦ rakudo/nom:

[00:47] <Geth> ¦ rakudo/nom: Per discussion[^1], to ameliorate possible fallout from changes to

[00:47] <Geth> ¦ rakudo/nom: &mkdir[^2], make the method return the invocant instead of True.

[00:47] <Geth> ¦ rakudo/nom:

[00:47] <Geth> ¦ rakudo/nom: Since all IO::Path:Ds are True, the method's success can still be

[00:47] <Geth> ¦ rakudo/nom: judged in boolean context, and this way &mkdir returns its old

[00:47] <Geth> ¦ rakudo/nom: <…commit message has 5 more lines…>

[00:47] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/c01ebea0a0

[01:16] <Geth> ¦ rakudo/uncurse: d46e8df4cb | (Zoffix Znet)++ | src/core/IO/Pipe.pm

[01:16] <Geth> ¦ rakudo/uncurse: [io grant] Add IO::Pipe .path and .IO methods

[01:16] <Geth> ¦ rakudo/uncurse:

[01:16] <Geth> ¦ rakudo/uncurse: That return an IO::Path type object. This fixes LTA error

[01:16] <Geth> ¦ rakudo/uncurse: of .IO/.path crashing, since the inherited methods from IO::Handle

[01:16] <Geth> ¦ rakudo/uncurse: try to instantiate an IO::Path from an empty string.

[01:16] <Geth> ¦ rakudo/uncurse: review: https://github.com/rakudo/rakudo/commit/d46e8df4cb

[01:16] <Geth> ¦ rakudo/uncurse: c01ebea0a0 | (Zoffix Znet)++ | src/core/IO/Path.pm

[01:16] <Geth> ¦ rakudo/uncurse: [io grant] Make IO::Path.mkdir return invocant on success

[01:16] <Geth> ¦ rakudo/uncurse:

[01:16] <Geth> ¦ rakudo/uncurse: Per discussion[^1], to ameliorate possible fallout from changes to

[01:16] <Geth> ¦ rakudo/uncurse: &mkdir[^2], make the method return the invocant instead of True.

[01:16] <Geth> ¦ rakudo/uncurse:

[01:16] <Geth> ¦ rakudo/uncurse: Since all IO::Path:Ds are True, the method's success can still be

[01:17] <Geth> ¦ rakudo/uncurse: judged in boolean context, and this way &mkdir returns its old

[01:17] <Geth> ¦ rakudo/uncurse: <…commit message has 5 more lines…>

[01:17] <Geth> ¦ rakudo/uncurse: review: https://github.com/rakudo/rakudo/commit/c01ebea0a0

[01:17] <Geth> ¦ rakudo/uncurse: 762c63ce64 | TimToady++ | 2 files

[01:17] <Geth> ¦ rakudo/uncurse: Merge branch 'nom' into uncurse

[01:17] <Geth> ¦ rakudo/uncurse: review: https://github.com/rakudo/rakudo/commit/762c63ce64

[01:55] <Geth> ¦ rakudo/nom: 1f689a94e1 | (Zoffix Znet)++ | src/core/IO/Handle.pm

[01:55] <Geth> ¦ rakudo/nom: [io grant] Fix up IO::Handle.Str

[01:55] <Geth> ¦ rakudo/nom:

[01:55] <Geth> ¦ rakudo/nom: Ensure we coerce $!path to .Str before returning it, since it can

[01:55] <Geth> ¦ rakudo/nom: be a bunch of different things. Also use $.path, so that IO::Pipe

[01:55] <Geth> ¦ rakudo/nom: uses its `method path` instead of the :path arg given to new.

[01:55] <Geth> ¦ rakudo/nom:

[01:55] <Geth> ¦ rakudo/nom: The :path attr in IO::Pipe might need more thinking; should it be

[01:55] <Geth> ¦ rakudo/nom: just ignored by .new and set to empty string?

[01:55] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/1f689a94e1

[01:58] <Geth> ¦ roast: 64ff572916 | (Zoffix Znet)++ | 2 files

[01:58] <Geth> ¦ roast: [io grant] Cover IO::Path/IO::Pipe's .Str/.path/.IO

[01:58] <Geth> ¦ roast: review: https://github.com/perl6/roast/commit/64ff572916

[01:58] <ugexe> mkdir("lib").child("MyModule.pm6").spurt(q|class MyModule { say 1; }|); # i like this better than the previous "lib".IO.mkdir.IO.child.....

[02:01] <Zoffix> The previous looks broken; .mkdir used to return True on success until 2 hours ago

[02:03] <ugexe> then it was even worse

[02:03] <ugexe> i probably did "lib".IO.mkdir andthen {...}

[02:17] <Zoffix> Have been getting 8s longer stresstests the last few hours :/ I'm hoping that's Google ripping me off with my VM rather than something I added today :\

[02:19] <Geth> ¦ rakudo/nom: 490ffd1562 | (Zoffix Znet)++ | src/core/IO/Path.pm

[02:19] <Geth> ¦ rakudo/nom: [io grant] Do not use self.Str in IO::Path errors

[02:19] <Geth> ¦ rakudo/nom:

[02:19] <Geth> ¦ rakudo/nom: Use $!abspath instead. Since .Str does not take $!CWD into account,

[02:19] <Geth> ¦ rakudo/nom: we might be producing very confusing error messages for paths that

[02:19] <Geth> ¦ rakudo/nom: were created with CWDs that aren't the current $*CWD

[02:19] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/490ffd1562

[02:41] <Geth> ¦ rakudo/nom: 40217edfb1 | (Zoffix Znet)++ | 8 files

[02:41] <Geth> ¦ rakudo/nom: [io grant] Swap .child to .concat-with in all the guts

[02:41] <Geth> ¦ rakudo/nom:

[02:41] <Geth> ¦ rakudo/nom: We want the old .child's behaviour that .concat-with now provides,

[02:41] <Geth> ¦ rakudo/nom: instead of the much more expensive and throwy new .child that's

[02:41] <Geth> ¦ rakudo/nom: about to be implemented.

[02:41] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/40217edfb1

[02:41] <Zoffix> s/throwy/faily/;

[02:53] <Zoffix> oh boy...

[02:53] <Zoffix> method resolve (IO::Path:D: :$completely) {

[02:53] <Zoffix> # XXXX: Not portable yet; assumes POSIX semantics

[02:54] <Zoffix> And I need it for .child(). Wonder what's broken in .resolve()...

[02:56] <Zoffix> At least 184 instances of .child() in ecosystem...

[02:57] <Zoffix> I think I'll leave it as is for release, and make it "secure" after it, to give it a chance to boil a bit in bleed code, and maybe submit some PRs to ecosystem to swap .child to .concat-with or something.

[02:57] <Zoffix> Kinda having second thoughts about changing it with so much usage...

[02:58] <Zoffix> Is there some better short name for .child() ?

[02:58] <Zoffix> biggest problem: swapping existing code to .concat-with means forcing users to have 2017.04 compiler. So it's kinda crappy

[03:02] * Zoffix calls it a day for today

[04:23] * BenGoldberg wonders when is a day not a day?

[04:57] <Zoffix> When it isn't full :)

[05:03] * BenGoldberg was kinda thinking of, "when it's tomorrow"

[05:04] <BenGoldberg> m: say "today" ~~ "day"

[05:04] <camelia> rakudo-moar 40217e: OUTPUT: «False␤»

[05:04] <BenGoldberg> m: say "today" ~~ /day/

[05:04] <camelia> rakudo-moar 40217e: OUTPUT: «｢day｣␤»

[05:04] <BenGoldberg> m: say "tomorrow" ~~ /day/

[05:04] <camelia> rakudo-moar 40217e: OUTPUT: «Nil␤»

[05:10] * samcv cracks knuckles and decideds to try and fix the s:g { } issue with atom-language-perl6 which has been around a while

[05:14] <Zoffix> \o/

[05:14] <samcv> another part of the codebase i've been planning on automatically generating

[05:14] <samcv> but have not gotten around to that yet

[05:14] <samcv> since that really creates consistency between delimiters and such like it did for the different kinds of quotes. much less bugs

[05:22] <samcv> there's like... way way too many regex definitions in here

[05:22] <samcv> which is why i have not automated this part yet becuase usually if remove one something breaks :P

[05:23] <geekosaur> also re when is a day not a day? when it's a night

[05:23] <geekosaur> hm, why "also". furrfu. speaking of night...

[05:23] <geekosaur> (only awake because sinuses)

[05:33] <samcv> ok i fixed it yay

[05:43] <samcv> Zoffix, will release as soon as travis/appveyor complete for Atom + Atom Beta

[05:55] <Zoffix> No rush.

[05:55] <Zoffix> I'm going to bed as soon as this commit passes stresstest...

[05:56] <samcv> well it's released. i have hated this bug for a while

[05:56] <samcv> glad it's fixed finally

[06:05] <Zoffix> *phew* and it finally does

[06:06] <Geth> ¦ rakudo/nom: 0e36bb26ba | (Zoffix Znet)++ | src/core/IO/Spec/Win32.pm

[06:06] <Geth> ¦ rakudo/nom: [io grant] Make IO::Spec::Win32!canon-cat 2.3x faster

[06:06] <Geth> ¦ rakudo/nom:

[06:06] <Geth> ¦ rakudo/nom: Should make a bunch of IO::Path stuff faster on Windows

[06:06] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/0e36bb26ba

[06:06] <Zoffix> NOW I can sleep

[06:06] * Zoffix drops to bed

[06:13] <samcv> canon cat

[06:14] * samcv envisions a cat next to a cannon

[06:14] <samcv> nice. it exists http://resources0.news.com.au/images/2012/04/18/1226331/410540-cat-in-a-cannon.jpg

[06:48] <lizmat> Files=1190, Tests=56701, 199 wallclock secs (12.03 usr  4.75 sys + 1184.86 cusr 115.21 csys = 1316.85 CPU)

[06:50] <[Tux]> This is Rakudo version 2017.03-254-g0e36bb26b built on MoarVM version 2017.03-128-gc9ab59c6

[06:50] <[Tux]> csv-ip5xs        3.234

[06:50] <[Tux]> test            13.329

[06:50] <[Tux]> test-t           5.269 - 5.456

[06:50] <[Tux]> csv-parser      13.146

[06:51] <samcv> i should bump nqp so that the m:i speedup gets in

[06:57] <RabidGravy> Zoffix++ cheers for the PR on XDG::BaseDirectory - I've not been testing everything frequently enough recently (boo to day job,)

[06:58] <Geth> ¦ rakudo/nom: 822566f1ad | (Samantha McVey)++ | tools/build/NQP_REVISION

[06:58] <Geth> ¦ rakudo/nom: Bump NQP for case insensitive regex 2x speed boost

[06:58] <Geth> ¦ rakudo/nom:

[06:58] <Geth> ¦ rakudo/nom: 1b3f6cf4 Merge pull request #350 from samcv/foldcase

[06:58] <Geth> ¦ rakudo/nom: 7d9f43c9 Make sure to push in the sval node before the indexic_s op

[06:58] <Geth> ¦ rakudo/nom: fbd18cc6 Merge pull request #352 from MasterDuke17/make_errors_in_QASTCompilerMAST_more_awesome

[06:58] <Geth> ¦ rakudo/nom: 66dfddd2 Make errors in QASTCompilerMAST more awesome

[06:58] <Geth> ¦ rakudo/nom: a70dabf2 s/two/2/

[06:58] <Geth> ¦ rakudo/nom: 7194ff46 Merge pull request #351 from MasterDuke17/make_errors_in_QASTOperationsMAST_more_awesome

[06:58] <samcv> [Tux], can you try re-running the test after this nqp bump?

[06:58] <Geth> ¦ rakudo/nom: 513d4ebf Make errors in QASTOperationsMAST more awesome

[06:58] <Geth> ¦ rakudo/nom: ec856126 [moar] Use foldcase in QASTRegexCompilier

[06:58] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/822566f1ad

[06:58] <Geth> ¦ rakudo/nom: version bump brought these changes: https://github.com/perl6/nqp/compare/2017.03-72-ga29b818...2017.03-80-g1b3f6cf4

[06:59] <samcv> as long as it's not burdensome

[07:01] <[Tux]> $ rakud

[07:01] <[Tux]> (alias for running all of it. takes a while to finish)

[07:03] <samcv> i'm fearful that we've reached a plataue in the test-t timings

[07:06] <[Tux]> samcv: we'll make time-travel-blasting speedup's if "next" is optimized to not being an exception where possible

[07:09] <[Tux]> This is Rakudo version 2017.03-255-g822566f1a built on MoarVM version 2017.03-128-gc9ab59c6

[07:09] <[Tux]> csv-ip5xs        3.068

[07:09] <[Tux]> test            12.810

[07:09] <[Tux]> test-t           4.994 - 5.037

[07:09] <[Tux]> csv-parser      12.812

[07:10] <[Tux]> 2017.03-254 → 2017.03-255

[07:13] <samcv> it's smaller right

[07:13] <samcv> it look ssmaller

[07:25] <RabidGravy> it's smaller :)

[07:25] <RabidGravy> the range was all above five the other day

[07:26] <samcv> yey

[07:26] <samcv> cause i saw it does use m:i in the module

[07:26] <samcv> so hoped it would make it faster

[07:26] <samcv> since 1.8x to 3x speedup worst vs best case

[10:20] <Geth> ¦ nqp/master: 11 commits pushed by (Pawel Murias)++

[10:20] <Geth> ¦ nqp/master: review: https://github.com/perl6/nqp/compare/1b3f6cf40d...7b7e2c1a16

[10:27] <jnthn> Hm, I'm guessing uncurse didn't get merged yet?

[10:27] <jnthn> I was going to pin the regression in https://github.com/jnthn/grammar-debugger/issues/34 on it

[10:28] <jnthn> But if uncurse ain't merged it must be something else :S

[10:29] <nine> jnthn: could it be that an EVAL's computation unit references the dynamic call chain somehow? That would explain why with the compile time EVAL, the Staging repo gets referenced in the byte code.

[10:30] <nine> jnthn: and no, I don't think uncurse is merged

[10:31] <jnthn> OK

[10:32] <jnthn> I'm liable to have to fix that module once it is, so I'll look at the two together.

[10:33] <jnthn> References the dynmaic callchain - it could be happening

[10:33] <nine> I guess the more important question is: can I somehow prevent it from happening?

[10:33] <jnthn> Though I can't think of where it might happen purposefully

[10:33] <jnthn> So I'm suspecting "accident"

[10:34] <jnthn> Well, find out what's doing it and stop it doing so, I guess :)

[10:35] <nine> Nothing a couple 100 hours of work can't fix :D

[10:35] <jnthn> :P

[10:35] <jnthn> Having hunted many of our concurrency bugs, I can empathize :)

[10:36] <jnthn> Did you try instrumenting the serialization code in Moar that adds dependencies?

[10:37] <nine> I have started on that

[10:37] <jnthn> https://github.com/MoarVM/MoarVM/blob/master/src/6model/serialization.c#L275

[10:37] <jnthn> That can at least tell you the kind of object indirectly referencing the parent

[10:37] <jnthn> gah, that was all the wrong words

[10:38] <nine> Ok, will continue in that direction. Thanks! :)

[10:38] <jnthn> That can at least tell you the kind of object that's being serialized and the type of the referring object

[10:38] <jnthn> You can use debug_name in gdb to get the names

[10:38] <jnthn> That may be enough of a clue

[10:39] <nine> Yeah, debug_name can be a life safer :)

[11:03] <jnthn> I guess if that isn't a powerful enough debugging approach, the next step would be to try and make something that can data-dump an SC

[11:04] <jnthn> So we can see what's in it

[12:07] <Zoffix> No, uncurse wasn't merged.

[12:08] <Zoffix> "test-t           5.269 - 5.456"... so it wasn't just my VM running the stresstest 8s slower :/ something I commited last night sucks.

[12:40] <dogbert17> jnthn: a good example to showcase the progress made by 'better-fsa' is the example code in RT #129779

[12:40] <synopsebot6> Link:  https://rt.perl.org/rt3/Public/Bug/Display.html?id=129779

[12:42] <timotimo> how much better is it?

[12:42] <dogbert17> on my system, with two cores available I get:

[12:43] <dogbert17> (bad-fsa): Counting to 2000000; Non-promise iteration: 1.3932086; One iteration: 3.0489264 (setup: 0.0030221); 16 iterations: 86.9051643 (setup: 0.008308)

[12:44] <dogbert17> (better-fsa): Counting to 2000000; Non-promise iteration: 1.35415227; One iteration: 2.9348096 (setup: 0.0033342); 16 iterations: 31.4008981 (setup: 0.0030857)

[12:45] <timotimo> what does "one iteration" mean?

[12:47] <dogbert17> looks as if the author is using a Promise do to the same calc as the non-promise iteration

[12:47] * dogbert17 could of course be totally wrong

[12:47] <timotimo> i'm not sure i understand these measurements. with 16 iterations it takes 15x as much time?

[12:48] <timotimo> hm, no, more like 10x as much

[12:49] <dogbert17> which is better than the 86 it took before

[12:49] <timotimo> it is, yeah

[12:49] <dogbert17> m: say 86.9 / 3.05

[12:49] <camelia> rakudo-moar 822566: OUTPUT: «28.491803␤»

[12:49] <dogbert17> m: say 31.4 / 2.93

[12:49] <camelia> rakudo-moar 822566: OUTPUT: «10.716724␤»

[12:50] <jnthn> That's a pretty dramatic improvement :)

[12:51] <jnthn> m: say 16 * 2.93

[12:51] <camelia> rakudo-moar 822566: OUTPUT: «46.88␤»

[12:51] <timotimo> ah, it doesn't divide work, it does as much work in each thread as it would do in a single thread

[12:51] <jnthn> Right

[12:51] <jnthn> m: say 16 * 1.35

[12:51] <camelia> rakudo-moar 822566: OUTPUT: «21.6␤»

[12:51] <jnthn> I suspect it's still hugely over-subscribing the CPU though

[12:51] <jnthn> And even then probably the GC sync-up is killing it

[12:52] <jnthn> Will need to work some at that now the much larger FSA issue is out of the way

[12:52] <timotimo> it'd be nice to graph it for every n between 1 and 16

[12:55] <jnthn> The fibonaci one looks much nicer now

[12:55] <jnthn> No thread: 12.2610092

[12:55] <jnthn> Parallel: 4.05580449

[12:55] <jnthn> Single: 12.6727114

[12:55] <jnthn> No thread: 12.760576269

[12:56] <timotimo> cool

[12:56] <dogbert17> nice

[12:56] <jnthn> That's on a quad-core box

[12:56] * dogbert17 must upgrade soon, system is from 2010

[12:57] <jnthn> Also note the slow-down for simply having threads even if you're only actually using one of them is also down to very little now

[12:57] <jnthn> In theory I get new hardware next week :)

[12:57] <dogbert17> please elaborate :)

[12:57] <jnthn> Will go 4 core -> 6 core (so, 8 virtual to 12 virtual)

[12:58] <jnthn> Plus 32 GB RAM, and far faster/larger SSD

[12:58] <dogbert17> ohh, you'll be able to run spectests and compiles in seconds

[12:59] * dogbert17 have been eyeing the recently released Ryzen CPU's

[13:00] <timotimo> huh. i must be doing something wrong

[13:00] <dogbert17> ?

[13:00] <timotimo> because here i get 0.6005177, 1.6591586, 63.5066597

[13:00] <timotimo> m: say 63.5066597 / 1.6591586

[13:00] <camelia> rakudo-moar 822566: OUTPUT: «38.27642499␤»

[13:01] <timotimo> and like 80% spent in fixed_size_allocator

[13:01] * Zoffix updates https://perl6.vip/ to not promise deliverables today

[13:01] <Zoffix> eek... that was overoptimistic to say the least :}

[13:01] <timotimo> but i did rebase my stuff on top of the new_fsa branch (because i rebased it on top of origin/master)

[13:01] <dogbert17> you didn't turn on FSA_DEBUG (or whatever its name is) by any chance

[13:02] <timotimo> nah, it spends all its time in some atomic op in there

[13:02] <timotimo> that wouldn't exist if fsa_debug was turned on

[13:02] <jnthn> Also double the amount of CPU cache, and from Sandy Bridge (32nm) to Broadwell (14nm)

[13:03] <jnthn> So hopefully I'll be getting faster builds and spectests :)

[13:03] <dogbert17> you definitely will, am stuck on Westmere if I remember the name correctly

[13:04] <timotimo> for 8 iterations: 0.5527264 , 1.7122354 , 17.5421605

[13:04] <timotimo> for 4 iterations: 0.553683 , 1.68850254 , 4.67553810

[13:07] <dogbert17> timotimo: maybe you're running the 'bad-fsa' branch :)

[13:07] <timotimo> i'm running whatever's in master

[13:07] * timotimo tries re-configuring, realclean, rebuild

[13:09] <timotimo> have to rebuild rakudo, also

[13:10] * dogbert17 my machine has served me well, still remember the immense boost my system got when I switched a my boot drive (5400 rpm HDD) for an SSD (Intel 80 Gig)

[13:10] <dogbert17> I had to rebould Rakudo

[13:11] <dogbert17> *rebuild rather

[13:11] <timotimo> um

[13:11] <timotimo> yeah, that changed things

[13:11] <timotimo> dramatically

[13:12] <timotimo> 16 iterations: 0.5407265, 1.4378239, 7.6077481

[13:12] <timotimo> m: say 7.607 / 1.438

[13:12] <camelia> rakudo-moar 822566: OUTPUT: «5.289986␤»

[13:12] <timotimo> i have 4 logical cores

[13:12] <timotimo> so it's basically just 25% to 30% overhead on top of that

[13:13] * Zoffix wonders which part of IO work caused this commit https://github.com/jonathanstowe/p6-Linux-Fuser/commit/60758fa557debbe4e37bdc5184208f90dd168aaa

[13:13] * Zoffix looks at RabidGravy inquisitly

[13:13] <timotimo> you mean IO wprk

[13:14] <dogbert17> timotimo: those are nice numbers

[13:16] * timotimo tries a plot

[13:18] <timotimo> it's kind of hard to get a good result when it already switches directions at 4

[13:19] <RabidGravy> YOU LOOKING AT ME!

[13:20] <timotimo> hmm, hack also has only 4 cores available

[13:20] <timotimo> it'd be interesting to test this on 6-core and 8-core machines

[13:21] <timotimo> hm, so if i have 4 cores, and i do 16x as much work, it should take 4x as long, right?

[13:22] <timotimo> that was my idea behind the 5.289 number being "25% to 30% overhead"

[13:22] <Zoffix> RabidGravy: and yeah, it's now $target.symlink: $linkname.

[13:23] <Zoffix> Target is the target the link points to. I don't know why so many people call the link target :/

[13:23] <RabidGravy> yeah it makes more sense

[13:23] <timotimo> dogbert17: do you want to post an update on the bug? i'll be afk for a bit, if you don't want to, i'll do it later on

[13:23] <robertle> timotimo: if you want something run on a many-core machine and on't have one around, let me know...

[13:24] <timotimo> can you get an absolutely-up-to-date rakudo with very-newest nqp and very-newest moarvm?

[13:24] <Zoffix> RabidGravy: what was the problem in https://github.com/jonathanstowe/p6-Linux-Fuser/commit/60758fa557debbe4e37bdc5184208f90dd168aaa ? Doesn't look like any of the IO changes I made.

[13:25] <timotimo> https://gist.github.com/timo/a3a405f977840e8336f50234715e9cd4 - it'd be cool if you could run this and give me the output :)

[13:25] <RabidGravy> Zoffix, it appears to be the .append didn't like an Int

[13:25] <Zoffix> RabidGravy: also, you're coercing a Str basename to Int here, just to coerce it back to Str on the next line: https://github.com/jonathanstowe/p6-Linux-Fuser/commit/60758fa557debbe4e37bdc5184208f90dd168aaa#diff-e41272ca664df2b6db9d6f783a8d3817R50

[13:25] <timotimo> robertle: ^

[13:26] <robertle> timotimo: if you tell me how to build it! I have only used rakudobrew so far...

[13:27] <Zoffix> m: my $x = "foo".IO; $x.append: 'X'

[13:27] <camelia> rakudo-moar 822566: OUTPUT: «Cannot resolve caller append(IO::Path: Str); none of these signatures match:␤    (Any:U \SELF: |values is raw)␤  in block <unit> at <tmp> line 1␤␤»

[13:27] <Zoffix> m: my $x = "foo".IO; $x.append: 42

[13:27] <camelia> rakudo-moar 822566: OUTPUT: «Cannot resolve caller append(IO::Path: Int); none of these signatures match:␤    (Any:U \SELF: |values is raw)␤  in block <unit> at <tmp> line 1␤␤»

[13:27] <Zoffix> Doesn't look like there's append for it?

[13:28] <Zoffix> Above is just the autoviv candidate

[13:29] <RabidGravy> er, it was throwing something about unboxing

[13:29] * Zoffix shrugs

[13:29] <RabidGravy> up to my armpits in OpenSSL right now

[13:29] <Zoffix> :)

[13:34] <Zoffix> timotimo: the first 6 iterations on my 24-core box: https://gist.github.com/zoffixznet/4e0fd3e352fbf9115d63186d5dc47340

[13:34] <Zoffix> (got bored with it and aborted it)

[13:45] <MasterDuke_> timotimo: results from my "quad" core laptop https://gist.github.com/MasterDuke17/bf5c05123bf8504dfef90ca126957bb7

[13:46] <Zoffix> m: say 43.4275427/7.0786173

[13:46] <camelia> rakudo-moar 822566: OUTPUT: «6.135031866␤»

[13:46] <Zoffix> Interesting that it's 6x faster on your box :|

[13:47] <MasterDuke_> and this is just a dell xps 13, also gonna run it on my older, but "eight" core desktop

[13:49] <MasterDuke_> the laptop does have a haswell gen cpu, while the desktop is nehalem gen, so the beefier desktop isn't always faster

[13:50] <MasterDuke_> Zoffix: were your numbers from a laptop or desktop? if laptop, on battery or ac?

[13:51] <Zoffix> MasterDuke_: Google Compute Engine VM

[13:51] <timotimo> Zoffix: your moarvm is before the better-fsa branch got merged

[13:51] <Zoffix> Oh :)

[13:52] <timotimo> .tell robertle you can use "rakudobrew triple nom master master"

[13:52] <yoleaux> timotimo: I'll pass your message to robertle.

[13:53] <timotimo> Zoffix: would you re-run it with a more up-to-date moar?

[13:56] <MasterDuke_> desktop results https://gist.github.com/MasterDuke17/7e261e4a2eb41327d5b895c78144f709

[13:56] <Zoffix> In a bit. Trying to hunt down the commit that brought the slowness last night.

[13:56] <timotimo> OK!

[13:58] <Zoffix> Well, that was pointless.

[13:58] <MasterDuke_> it was rounded instead?

[13:58] <Zoffix> Built as far as Apr 11th rakudo and checkout that time's roast and still getting 121s stresstest runs. Even though I had 111s runs about 24hrs ago, as posted in #MoarVM

[13:59] <timotimo> MasterDuke_: that has a really strange bump near the beginning

[13:59] <Zoffix> ZofBot: must be solar flares!

[13:59] <ZofBot> Zoffix, These are used to initialize superclasses

[13:59] * timotimo always initializes superclasses with solar flares

[13:59] <Zoffix> timotimo: was the merge version bumped or do I need to build moar master myself?

[13:59] <MasterDuke_> i usually use supernovas for superclasses

[13:59] <robertle> timotimo: https://gist.github.com/anonymous/755aea8c68876bdc215a885ffdc74bb8

[13:59] <yoleaux> 13:52Z <timotimo> robertle: you can use "rakudobrew triple nom master master"

[14:00] <robertle> timotimo: will trt that, back in a sec

[14:01] <Zoffix> guess not

[14:01] <timotimo> the before/after will be interesting to see here.

[14:01] <timotimo> nope, the last bumped moar_revision was right before the better-fsa brahc

[14:01] <timotimo> branch

[14:01] <MasterDuke_> (timotimo: what do you mean strange bump? looks kind of linear to me (assuming you're referring to my desktop results)

[14:02] <timotimo> the eight-core one

[14:02] <timotimo> http://imgur.com/a/ItCBX

[14:03] <MasterDuke_> hm, yeah

[14:05] <Zoffix> wtf

[14:06] <Zoffix> How is this even possible? https://gist.github.com/zoffixznet/7c7728e0eb62973d257e10138d786ce3

[14:06] <MasterDuke_> just ran it again and added those to the gist, but they look pretty similar

[14:06] <Zoffix> Built HEAD rakudo after nuking nqp/MoarVM... and it's missing nqp/MoarVM :S yet works

[14:07] <timotimo> why would nqp/MoarVM missing be a problem?

[14:07] <timotimo> i'm pretty sure it'd take its stuff from the install/ folder

[14:07] <robertle> timotimo: rakudobrew triple ... seems broken for me, need to head to the playground. guess it's sorted anyway, let me know if you need more later

[14:07] <Zoffix> I dunno, because it was there for me every time for the past year?

[14:07] <timotimo> robertle: can you tell me in what way triple is broken?

[14:08] <Zoffix> guess as good a time as any to nuke my rakudo dir: cpan@perlbuild2~/CPANPRC/rakudo (nom)$ du -sh

[14:08] <Zoffix> 1.3G    .

[14:09] <robertle> timotimo: first like this: https://github.com/tadzik/rakudobrew/issues/63

[14:10] <robertle> with the patch it gets a bit further, but does not finish

[14:10] <robertle> will look into it when I get back

[14:10] * timotimo mumbles something about rakudobrew not being recommended

[14:11] <robertle> is there an alternative

[14:11] <timotimo> yeah, just checkout rakudo and perl Configure.pl --gen-moar=master or what it is

[14:11] <Zoffix> No?

[14:11] <Zoffix> Why do people recommend others to use random dev commits -_-

[14:12] <timotimo> Zoffix: i want robertle to run moarvm master

[14:12] <Zoffix> I see

[14:12] <timotimo> that's why i recommend using moar master, so they can get moar master?

[14:12] <timotimo> :\

[14:12] <timotimo> rakudobrew is useful if you want to switch between 10 different versions of rakudo installed at the same time and have your bin scripts easily switchable

[14:12] <Zoffix> Well, I also see Ulti recommending rakudobrew to users today: https://irclog.perlgeek.de/perl6/2017-04-15#i_14431467

[14:12] <timotimo> yeah, i was surprised by that

[14:13] <timotimo> maybe ulti's a bit out of the loop, or i'm just hallucinating the demise of rakudobrew

[14:14] * timotimo sees perl6.org/downloads recommending rakudobrew

[14:17] <timotimo> i suppose it'd be best to just bump moar and nqp

[14:19] <Geth> ¦ nqp: 6432a25e6e | (Timo Paulssen)++ | tools/build/MOAR_REVISION

[14:19] <Geth> ¦ nqp: bump moarvm for better multithreading performance

[14:19] <Geth> ¦ nqp: review: https://github.com/perl6/nqp/commit/6432a25e6e

[14:19] <Geth> ¦ nqp: version bump brought these changes: https://github.com/MoarVM/MoarVM/compare/2017.03-128-gc9ab59c...2017.03-138-g40881cd

[14:19] <Geth> ¦ rakudo/nom: 20af51fef9 | (Timo Paulssen)++ | tools/build/NQP_REVISION

[14:19] <Geth> ¦ rakudo/nom: bump nqp and moarvm for better multithreading performance

[14:19] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/20af51fef9

[14:19] <Geth> ¦ rakudo/nom: version bump brought these changes: https://github.com/perl6/nqp/compare/2017.03-80-g1b3f6cf4...2017.03-92-g6432a25

[14:23] <Zoffix> wow, what a difference

[14:23] <Zoffix> timotimo: https://gist.github.com/zoffixznet/783f0293d65300419549321f24e5ea6a

[14:23] <Zoffix> that's my 24core box

[14:24] <timotimo> nice

[14:24] <MasterDuke_> hot damn!

[14:24] <timotimo> could you turn the number up to 32 perchance?

[14:24] <timotimo> so we can see the point where it starts going up?

[14:24] <timotimo> once it goes past the core count?

[14:25] <Zoffix> Which number? the number of cores?

[14:25] <timotimo> there's a for loop that goes from 2 to 16

[14:25] <Zoffix> Ah

[14:25] <Zoffix> 1 sec. I nuked everything and building the new HEAD

[14:25] <timotimo> might also have to tell the scheduler that it's okay to make that many threads

[14:33] <MasterDuke_> timotimo: btw, what sort of information could one get out of your telemeh_try branch?

[14:33] <timotimo> good question

[14:33] <timotimo> nobody knows for sure

[14:34] <timotimo> BBIAB

[14:38] <Zoffix> timotimo: https://gist.github.com/zoffixznet/b4dcb14de782d200e2e45fcf68399aee

[14:42] <timotimo> Zoffix: two runs for improved precision?

[14:43] <Zoffix> timotimo: one had the default 16 max threads, the other 40

[14:43] <timotimo> oh of course

[14:44] <timotimo> thank you, i shall put that into a gnuplot soon-ish

[14:44] <timotimo> MasterDuke_: it ought to be able to tell you what kind of stuff moarvm spends its time with

[14:44] <MasterDuke_> in a different way than perf?

[14:45] <timotimo> yeah

[14:45] <Zoffix> ZOFVM: Files=1240, Tests=133707, 115 wallclock secs (22.60 usr  3.15 sys + 2387.36 cusr 130.95 csys = 2544.06 CPU)

[14:45] <MasterDuke_> how so?

[14:45] <timotimo> perf is probabilistic, whereas telemeh is precise

[14:46] <MasterDuke_> ah

[14:47] <Geth> ¦ roast: 925e6f03fe | (Zoffix Znet)++ | S05-modifier/ignorecase.t

[14:47] <Geth> ¦ roast: Un-todo now-passing tests

[14:47] <Geth> ¦ roast:

[14:47] <Geth> ¦ roast: The ligatures in the haystack of case insensensitive regex don't work ones

[14:47] <Geth> ¦ roast: review: https://github.com/perl6/roast/commit/925e6f03fe

[14:47] <timotimo> perf is based around telling you what exact instruction it hit when it randomly sampled

[14:47] <timotimo> telemeh has a concept of "intervals"

[14:47] <timotimo> and it'll also give you specific info about which thread is doing what

[14:47] <timotimo> because i added output for stuff like "trying to take a lock" you can see how lock-ownership passes on between different threads, for example

[14:48] <timotimo> though of course you can't "see" it until i build a visualizer for all this

[14:48] <MasterDuke_> so would help understand the difference in the benchmark we've just been trying, especially before better-fsa and after?

[14:49] <timotimo> the fsa doesn't have any telemeh commands yet

[14:50] <timotimo> so it's unlikely that we'd be able to point at the fsa for our issues

[14:53] <MasterDuke_> btw, with all the recent benchmarking and chatting with tadzik about viewing profiles, i realized i still haven't implemented those changes to the sql output you suggested

[14:54] <MasterDuke_> maybe can find some time to chat about what could be done to make it better?

[14:55] <timotimo> yeah

[14:55] <timotimo> i should have some time right now, for example

[14:56] <MasterDuke_> i have time now as well

[14:57] <timotimo> cool

[14:58] <MasterDuke_> so i think the one thing was putting 0s instead of NULLs?

[15:01] <timotimo> yeah, that should be easy

[15:01] <MasterDuke_> it looks like right now NULLs can end up in the 'gcs', 'callee's, and 'allocations' tables

[15:01] <MasterDuke_> they can all be 0s?

[15:02] <timotimo> i think we only had NULL because i optimized the profiler output to not have anything if the value is 0

[15:02] <timotimo> so we should be able to just output 0 instead

[15:06] <MasterDuke_> timotimo: https://github.com/MasterDuke17/nqp/commit/31ee14fe7efaeaf3057455c45de4475e446d5ddb

[15:07] <timotimo> hm, maybe push "0" instead of 0

[15:07] <timotimo> that might save us a tiny bit of stringification later on

[15:11] <timotimo> wanna have a look at a telemetry log from the threading thingie?

[15:13] <Geth> ¦ rakudo/nom: fd503f89ed | (Zoffix Znet)++ | 5 files

[15:13] <Geth> ¦ rakudo/nom: Revert "[io grant] Remove `role IO` and its .umask method"

[15:13] <Geth> ¦ rakudo/nom:

[15:13] <Geth> ¦ rakudo/nom: This reverts commit 87987c2dcbe6ca607ef623c4eb4b1a9f40d6af78.

[15:13] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/fd503f89ed

[15:13] <Geth> ¦ rakudo/nom: c95c4a75d1 | (Zoffix Znet)++ | 5 files

[15:13] <Geth> ¦ rakudo/nom: [io grant] Make IO::Path/IO::Special do IO role

[15:13] <Geth> ¦ rakudo/nom:

[15:13] <Geth> ¦ rakudo/nom: - Brought back the removed role in previous commit

[15:13] <Geth> ¦ rakudo/nom: - Make IO::Path and IO::Special do it

[15:13] <Geth> ¦ rakudo/nom: - It don't got no methods; we do it so that when we make our coercers

[15:13] <Geth> ¦ rakudo/nom:     type-check the return values all our IO() coercers that coerce

[15:13] <Geth> ¦ rakudo/nom:     to IO::Path don't explode.

[15:13] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/c95c4a75d1

[15:15] <MasterDuke_> timotimo: yeah, have a gist or something?

[15:16] <timotimo> i just uploaded it to the whateverable server

[15:16] <timotimo> it's a .txt.gz file in the home folder

[15:18] <MasterDuke_> heh, the third column looks like the vines in the original marios

[15:19] <MasterDuke_> what was the perl6 code run?

[15:20] <timotimo> that's the script we've been using but instead of 2..16 it's 2, 4, 8, 16

[15:22] <MasterDuke_> i thought maybe so, i didn't see any moarvm functions that looked like anything interesting was happening

[15:22] <timotimo> you can see it spawn the additional threads

[15:23] <MasterDuke_> is `~($gc{$f} // "0")` faster than `~($gc{$f} // 0)`?

[15:23] <timotimo> i think stringifying a string is cheaper than stringifying an int, even though it's one in the intification cache

[15:24] <timotimo> it's probably a micro-optimization that doesn't contribute much to overall profile enerating performance

[15:26] <timotimo> i find it a little strange that after each thread gets created it'll do a gc run first

[15:30] <MasterDuke_> 0s stringified

[15:32] <MasterDuke_> timotimo: is that done deliberately?

[15:33] <timotimo> what exactly?

[15:34] <timotimo> the gc thing?

[15:35] <MasterDuke_> yeah

[15:36] <timotimo> btw, using native ints here makes the whole thing a boatload faster

[15:37] <timotimo> Non-promise iteration: 0.023987, One iteration: 0.10999810, 16 iterations: 0.8526233

[15:38] <MasterDuke_> did you change to `$i = $i + 1` also?

[15:38] <timotimo> yes

[15:39] <timotimo> makes only a small difference, it seems

[15:41] <timotimo> could also be thermal throttling kicking in

[15:41] <MasterDuke_> not as much as switching to natives, no. but noticeable

[15:41] <timotimo> right

[15:41] <timotimo> we still don't recognize the variable as being native in the optimizer ,i think

[15:42] <timotimo> hm, no, we do that

[15:45] <MasterDuke_> we were chatting with jnthn about that a little while ago. i don't remember the exact reason $i++ couldn't be turned in to $i=$i+1, but i think it had something to do with outer blocks

[15:46] <MasterDuke_> and if they had a variable with the same name. i dunno

[15:47] <timotimo> huh

[15:55] <MasterDuke_> maybe here https://irclog.perlgeek.de/perl6/2017-03-25#i_14322350

[15:56] <timotimo> that's about automatically turning a for loop into a while loop

[15:56] <timotimo> well, a loop loop

[15:57] <timotimo> m: loop (my $i = 0; $i < 10; $i++) { }; say $i

[15:57] <camelia> rakudo-moar c95c4a: OUTPUT: «10␤»

[15:58] <timotimo> mhh, the scoping is different from a for loop, yeah

[16:07] <MasterDuke_> m: loop (my int $i = 0; $i < 10_000_000; ++$i) { }; say now - INIT now

[16:07] <camelia> rakudo-moar c95c4a: OUTPUT: «0.0637503␤»

[16:07] <MasterDuke_> m: loop (my int $i = 0; $i < 100_000_000; ++$i) { }; say now - INIT now

[16:07] <camelia> rakudo-moar c95c4a: OUTPUT: «0.6624194␤»

[16:07] <MasterDuke_> m: loop (my int $i = 0; $i < 100_000_000; $i = $i + 1) { }; say now - INIT now

[16:07] <camelia> rakudo-moar c95c4a: OUTPUT: «0.6310619␤»

[16:07] <MasterDuke_> not a huge difference there

[16:07] <MasterDuke_> m: loop (my $i = 0; $i < 100_000_000; ++$i) { }; say now - INIT now

[16:08] <camelia> rakudo-moar c95c4a: OUTPUT: «15.92080205␤»

[16:08] <MasterDuke_> m: loop (my $i = 0; $i < 100_000_000; $i = $i + 1) { }; say now - INIT now

[16:08] <camelia> rakudo-moar c95c4a: OUTPUT: «15.13526735␤»

[16:09] <MasterDuke_> or there. nice, i remembered it being larger than that

[16:10] <TimToady> jnthn: I had not planned on merging uncurse till after the release, since the IO work is already a fairly big perturbation, but I could probably be argued into merging it for this release

[16:10] <TimToady> I suspect nine's serialization deps are coming through the language braid, because braids are trying to be fairly agressive in what participates in the "current language"

[16:11] <TimToady> so we might need to break a language braid dep somewhere strategically to get things not to serialize

[16:14] <TimToady> though, in fact, EVAL is still using %?LANG, not $?LANG, so maybe that's not what's really happening

[16:17] <timotimo> MasterDuke_: sorry, i don't seem to have been actually helping with the profiler stuff?

[16:17] <jnthn> TimToady: Ah, OK. I'm not in a hurry, just tied for time as usual so trying to be efficient. ;)

[16:17] <MasterDuke_> heh, well i'm down to one hand right now anyway

[16:18] <timotimo> oh, you got a cat? :D

[16:18] <MasterDuke_> but what were your other ideas?

[16:19] <timotimo> the sql version of the profiler still doesn't give us enough data to construct the full call graph

[16:19] <MasterDuke_> heh, tiny humans are just as hand-consuming

[16:19] <timotimo> oh, hah

[16:19] <timotimo> i totally forgot you mentioned that recently

[16:19] <Geth> ¦ nqp/uncurse: 14 commits pushed by (Pawel Murias)++, (Timo Paulssen)++, TimToady++

[16:19] <Geth> ¦ nqp/uncurse: review: https://github.com/perl6/nqp/compare/a44e6dedc5...005a2b7a20

[16:19] <MasterDuke_> hm, i thought it had all the data the json version did?

[16:20] <Geth> ¦ rakudo/uncurse: 9 commits pushed by (Zoffix Znet)++, (Samantha McVey)++, (Timo Paulssen)++, TimToady++

[16:20] <Geth> ¦ rakudo/uncurse: 1f689a94e1 | [io grant] Fix up IO::Handle.Str

[16:20] <Geth> ¦ rakudo/uncurse: 490ffd1562 | [io grant] Do not use self.Str in IO::Path errors

[16:20] <Geth> ¦ rakudo/uncurse: 40217edfb1 | [io grant] Swap .child to .concat-with in all the guts

[16:20] <Geth> ¦ rakudo/uncurse: 0e36bb26ba | [io grant] Make IO::Spec::Win32!canon-cat 2.3x faster

[16:20] <Geth> ¦ rakudo/uncurse: 822566f1ad | Bump NQP for case insensitive regex 2x speed boost

[16:20] <Geth> ¦ rakudo/uncurse: 20af51fef9 | bump nqp and moarvm for better multithreading performance

[16:20] <Geth> ¦ rakudo/uncurse: fd503f89ed | Revert "[io grant] Remove `role IO` and its .umask method"

[16:20] <Geth> ¦ rakudo/uncurse: c95c4a75d1 | [io grant] Make IO::Path/IO::Special do IO role

[16:20] <Geth> ¦ rakudo/uncurse: 89fd91c1ea | Merge branch 'nom' into uncurse

[16:20] <Geth> ¦ rakudo/uncurse: review: https://github.com/rakudo/rakudo/compare/762c63ce64...89fd91c1ea

[16:44] <timotimo> MasterDuke_: it has all the data, but a sql table is flat, the json data is nested

[16:44] <timotimo> if you don't put in something to represent how the json data was nested, you'll lose data even though all the fields are still there

[16:45] <MasterDuke_> aren't there ids that refer to each other?

[16:45] <timotimo> yeah, but something about them was wrong

[16:45] <timotimo> i had a hard time figuring out exactly how it was wrong

[16:45] <timotimo> didn't help that the id fields were all rather nebulously named

[16:46] <MasterDuke_> hm..i tested with a tiny profile and thought it was right, but it's not easy

[16:47] <timotimo> yeah, it's rather difficult to make sense of the whole thing

[16:47] <nine> I've got my Ryzen CPU + board + 32 GB RAM at home since Tuesday. But I'm short a CPU cooler, Delivery problems :/

[16:48] <nine> Ironically the cooler is the only part built in Austria and the only part that's hard to get in Austria...

[16:48] <MasterDuke_> nine: nice, i've been lusting after one of those. which cpu?

[16:48] <MasterDuke_> timotimo: suggestions for the id names?

[16:49] <nine> R7 1800X

[16:49] <MasterDuke_> or some code that will generate a good (small!) test profile?

[16:50] <TimToady> uncurse does seem to be 1-2% faster compiling the setting, and it does seem to be in a stable state, or at least a metastable state, and it does pass one TODO for Match.perl, so maybe it's worth merging earlier

[16:51] <MasterDuke_> nine: good deal. will probably go 1700 myself. want to reduce the heat generated in my office

[16:51] <RabidGravy> speaking of new computers what's the biggest bang for the buck I can get in a microATX/NUC form factor?  I'm thinking of getting a bunch more Gigabyte Brix to run continuous testing of my modules on

[16:51] <RabidGravy> but don't know what the state of the art of that stuff is

[16:54] <dogbert17> nine: interesting, what MB and memory did you get?

[16:54] <nine> MasterDuke_: the 1700 is also much more cost efficient. I just figured it's time for AMD to earn some real cash and I can afford it

[16:55] * dogbert17 is pondering the 1600 or 1700

[16:56] <ugexe> you can build some mean 32+ thread systems pretty cheap from used v2/v3 xeons

[16:56] <timotimo> MasterDuke_: ideally it'd point out what the "target" table and field are

[16:57] <timotimo> no clue what code would give a good profile :\  maybe something from rosettacode as examples? there was a github repository that had rosettacode data in it for easy running

[16:59] <dogbert17> 32+ threads, impressive, that would crush Zoffix puny 24 core setup :)

[17:00] <dogbert17> the cooler nine is mentioning sounds suspiciously like some Noctua model

[17:14] <robertle> timotimo: https://gist.github.com/anonymous/650ff6b00a0f8dc34b9e358992e572b4

[17:15] <robertle> looks quite flat even after it matches the number of cores

[17:15] <timotimo> there's also a variable that limits the number of threads the thread pool scheduler will even create

[17:17] <timotimo> Int :$!max_threads = (%*ENV<RAKUDO_MAX_THREADS> // 16).Int

[17:17] <timotimo> so we'd expect the graph to become steeper after 16

[17:17] <Zoffix> dogbert17: 32 cores is a click away for me. I'm just not seeing the benefit from them on stresstest. Also google recently added 64-core boxes :) if only I could figure out how to launch them

[17:19] <nine> dogbert17: Gigabyte AX370-Gaming 5 and Corsair Vengance LPX CMK32GX4M2B3000C15

[17:20] <nine> dogbert17: and yes, the cooler is supposed to be a Noctua NH-D15 SE-AM4

[17:22] <robertle> timotimo: I don't think that limits to 16 threads! and thge graph doesn't look it either...

[17:25] <robertle> timotimo: http://imgur.com/a/2d7q4

[17:25] <timotimo> huh, interesting

[17:26] <robertle> doesn't // just say "if not defined use the other"?

[17:26] <timotimo> yup

[17:27] <MasterDuke_> robertle: what if you set MAX_THREADS to a small number? e.g., 4

[17:29] <robertle> a moment

[17:30] <MasterDuke_> timotimo: in `"allocations": [ { "id": "11", count": 1 } ]` from a json profile, what is that id?

[17:31] <MasterDuke_> there are a bunch of those, all with id=11 (and some with other ids)

[17:32] <MasterDuke_> for this code: sub a($b) { say $b }; a($_) for ^2

[17:39] <MasterDuke_> ugh, and the regular profile allocations tab is busted so i don't have anything to compare with

[17:40] <MasterDuke_> maybe need to fix that first

[17:41] <MasterDuke_> is it a problem with the raw data? or the html/js that's meant to display the data?

[17:49] <robertle> MasterDuke_: https://gist.github.com/anonymous/f0afc0007a1c36985bb388ba3fbd898d http://imgur.com/a/PKl7n

[17:50] <robertle> lighter blue is with RAKUDO_MAX_THREADS=4

[17:50] <timotimo> MasterDuke_: i think that points at the name of the thing allocated

[17:51] <MasterDuke_> `"11": "List"` so  maybe this? from the very beginning of the json

[17:52] <MasterDuke_> robertle: 4 definitely makes it worse

[17:52] <timotimo> yup

[17:52] <timotimo> tthat ought to be the one

[17:53] <MasterDuke_> oh ha, i stick those in the 'allocators' table already

[17:53] <timotimo> another id-to-thing connection is the way we re-use filename and line number

[17:54] <timotimo> can that table be called "types" or "classes" maybe?

[17:54] <MasterDuke_> sure

[17:54] <MasterDuke_> re-use filename and line number?

[17:55] <timotimo> yeah, instead of putting those into every json object we just refer to a big list at the beginning

[17:56] <MasterDuke_> right, same list i get the allocators from

[17:57] <MasterDuke_> if hash, filename and line number, else allocator

[17:57] <timotimo> oh, ok

[17:58] <MasterDuke_> filename and line number go in the routines table

[18:00] <MasterDuke_> which i join with the callees table to replicate the info in the routines tab of the regular profile (and the qt viewer)

[18:00] <timotimo> right, the routines tab is a join and aggregate of all routines with the same filename/line number/routine name

[18:01] <MasterDuke_> select case when r.name = "" then "<anon>" else r.name end as name, r.file, r.line, sum(entries) as entries, sum(case when rec_depth = 0 then inclusive_time else 0 end) as inclusive_time, sum(exclusive_time) as exclusive_time from callees c, routines r where c.id = r.id group by c.id order by exclusive_time desc;

[18:03] <timotimo> hm

[18:03] <timotimo> i'm not sure i really understand how rec_depth works

[18:05] <timotimo> i'm not sure we can just write the inclusive time thing as sql

[18:05] <timotimo> as we have to take times from any routine we find in the call graph below this

[18:05] <timotimo> and every given routine can occur as many times as it wants

[18:06] <AlexDaniel> Zoffix: remember I told you that I use my laptop on my long bus rides?

[18:06] <AlexDaniel> Zoffix: turns out somebody took a picture of me a few months ago

[18:06] <MasterDuke_> i think that's what rec_depth is supposed to do

[18:06] <AlexDaniel> Zoffix: and by pure luck that picture got to me…

[18:06] <AlexDaniel> Zoffix: https://files.progarm.org/bus.jpg

[18:08] <timotimo> hah

[18:10] <ugexe> hmm zef's testers.p6c.org reporter should work (it sends the same data as panda reporter). but panda doesnt send reports properly now either

[18:15] <timotimo> ah, interesting

[18:15] <timotimo> i think i should be able to find something out by going to www.p6c.org

[18:16] <timotimo> is FlightRecorder what gathers the data up?

[18:16] <ugexe> im not sure what happens after the data gets posted lol

[18:16] <MasterDuke_> timotimo: i believe, but couldn't swear to, that i hacked nqp to write both json and sql profiles and that query gave the same numbers for inclusive and exclusive as the qt viewer showed

[18:17] <timotimo> do the reports reach the server at a specific port?

[18:17] <ugexe> 80

[18:18] <timotimo> hm, ok, then i'll have to look at the apache conf

[18:18] <timotimo> what's the hostname and path?

[18:19] <ugexe> https://gist.github.com/ugexe/f69ba589ef2057d5426eb054feea9309

[18:19] <timotimo> OK, that's port 3000

[18:19] <ugexe> my $sock    = IO::Socket::INET.new(:host<213.95.82.53>, :port(80));

[18:19] <timotimo> i mean it gets proxied to port 3000

[18:21] <timotimo> nothing in the apache errors log

[18:21] <timotimo> unsurprisingly

[18:23] <ugexe> (HTTP/1.1 400 Bad Request Date: Sat, 15 Apr 2017 18:20:37 GMT Server: Apache/2.4.10 (Debian) Content-Length: 301 Connection: close Content-Type: text/html; charset=iso-8859-1  <!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN"> <html><head> <title>400 Bad Request</title> </head><body> <h1>Bad Request</h1> <p>Your browser sent a request that this server could not understand.<br /> </p> <hr>

[18:23] <ugexe> <address>Apache/2.4.10 (Debian) Server at perl6.org Port 80</address> </body></html>)

[18:23] <timotimo> Apr 15 06:10:02 www starman[474]: Use of uninitialized value in subroutine entry at /usr/local/share/perl/5.20.1/Dancer

[18:23] <timotimo> /FileUtils.pm line 34

[18:24] <ugexe> hmm

[18:24] <timotimo> could that have anything to do with anything?

[18:25] <ugexe> long ago things like how you representing null would break it

[18:25] <timotimo> https://gist.github.com/timo/d321ee22531c2c7a9822459b03bf6b72 - this is the execution part of the report thingie

[18:34] <timotimo> MasterDuke_: i don't actually really know how recdepth works :)

[18:35] <MasterDuke_> neither do i anymore. but if it gives correct results...

[18:36] <timotimo> heh.

[18:42] <AlexDaniel> s: 'sprintf', \('<%#B>', 12)

[18:42] <SourceBaby> AlexDaniel, Something's wrong: ␤ERR: Cannot resolve caller sourcery(Str, Capture); none of these signatures match:␤    ($thing, Str:D $method, Capture $c)␤    ($thing, Str:D $method)␤    (&code)␤    (&code, Capture $c)␤  in block <unit> at -e line 6␤␤

[18:42] <AlexDaniel> s: 'sprintf', '<%#B>', 12

[18:42] <SourceBaby> AlexDaniel, Something's wrong: ␤ERR: Cannot resolve caller sourcery(Str, Str, Int); none of these signatures match:␤    ($thing, Str:D $method, Capture $c)␤    ($thing, Str:D $method)␤    (&code)␤    (&code, Capture $c)␤  in block <unit> at -e line 6␤␤

[18:43] <timotimo> hm? sourcery can only do methods?

[18:43] <MasterDuke_> s: &sprintf, \('<%#B>', 12)

[18:43] <SourceBaby> MasterDuke_, Sauce is at https://github.com/rakudo/rakudo/blob/c95c4a7/src/core/Cool.pm#L291

[18:43] <timotimo> ah, yes

[18:43] <AlexDaniel> right!!

[18:43] <timotimo> was about to try that

[18:44] <AlexDaniel> dammit, I'll never learn that. I guess I have to fix the bot itself instead…

[18:48] <MasterDuke_> timotimo: does this look like reasonable allocation numbers for a random profile i had lying around? https://gist.github.com/MasterDuke17/b2145327aeeaa17936c5f08fb5ea4eaa

[18:50] <timotimo> hmm, perhaps

[18:52] <MasterDuke_> gist updated with results from the profile of `sub a($b) { say $b }; a($_) for ^2`

[19:03] <timotimo> dinner now

[19:16] <Geth> ¦ roast: 71034737d1 | (Pawel Murias)++ | S02-lexical-conventions/unicode-whitespace.t

[19:16] <Geth> ¦ roast: [js] Fudge around EN QUAD/EM QUAD vertical white-space matching weirdness

[19:16] <Geth> ¦ roast: review: https://github.com/perl6/roast/commit/71034737d1

[19:19] <Geth> ¦ rakudo/js: 5 commits pushed by (Pawel Murias)++

[19:19] <Geth> ¦ rakudo/js: 631468e79f | [js] Implement p6decontrv

[19:19] <Geth> ¦ rakudo/js: 06069f2605 | [js] Implmenent p6recont_ro

[19:19] <Geth> ¦ rakudo/js: a7eb035d80 | [js] Add some js specific precompilation constants

[19:19] <Geth> ¦ rakudo/js: 18c5ee84d0 | [js] Fix nqp::p6stateinit

[19:19] <Geth> ¦ rakudo/js: 71c942832b | [js] Disable debuging helper on hack

[19:19] <Geth> ¦ rakudo/js: review: https://github.com/rakudo/rakudo/compare/bf1d35f8d2...71c942832b

[19:23] <MasterDuke_> pmurias: as someone who obviously knows more JS than nothing i know, are you familiar with angular.js at all?

[19:24] <pmurias> I have used the version 1 angular.js before

[19:25] <MasterDuke_> pretty sure that's what our profile output uses

[19:26] <MasterDuke_> how easy is it to debug? our profiles currently have some empty sections, even though the raw data is present

[19:27] <pmurias> I could give a try at fixing that, what should I checkout/look into?

[19:27] <timotimo> if you don't have the angular batarang installed, you can forget about debugging it

[19:29] <MasterDuke_> the "Allocations" section is definitely wrong (nothing shown, raw data present)

[19:40] * pmurias is looking into it

[19:41] <MasterDuke_> pmurias++

[19:47] <pmurias> it seems to be bitrot from an dependency upgrade, I'll take a shower to freshen up and look into fixing it

[19:51] <MasterDuke_> nice, that's been broken for a while now, it'll be good to get it working again (and will let me verify my sql numbers)

[20:18] <Geth> ¦ nqp: 211b0f2ba3 | (Pawel Murias)++ | src/vm/moar/profiler/template.html

[20:18] <Geth> ¦ nqp: Fix bitrot in moarvm profiler

[20:18] <Geth> ¦ nqp: review: https://github.com/perl6/nqp/commit/211b0f2ba3

[20:18] <Geth> ¦ nqp: 30a965887f | (Pawel Murias)++ | src/vm/js/Compiler.nqp

[20:18] <Geth> ¦ nqp: [js] Stuff to fix nqp::p6initied

[20:18] <Geth> ¦ nqp: review: https://github.com/perl6/nqp/commit/30a965887f

[20:18] <pmurias> MasterDuke_: I fixed that

[20:26] <MasterDuke_> pmurias: cool, trying now

[20:30] <MasterDuke_> pmurias++ working for me. nice to get that in before the release

[20:31] <MasterDuke_> .tell lizmat fyi, since i think you've mentioned this before, pmurias just fixed the allocations tab in the profiler output

[20:31] <yoleaux> MasterDuke_: I'll pass your message to lizmat.

[20:48] <MasterDuke_> timotimo: the allocation names and numbers match between my sql output and the allocations tab on a regular profile (now that pmurias fixed it)

[20:58] <MasterDuke_> over in #perl6 Xliff is trying to compile script that's just a large (the whole file is 191k lines) hash of hashes, but gets `===SORRY!=== Frame 2 local access out of range` during the mbc stage

[20:58] <MasterDuke_> anybody have any idea?

[21:06] <jnthn> Yes. A hash constructor is just a call, and there's an upper limit of allowed arguments

[21:06] <lizmat> mbc stage?

[21:06] <yoleaux> 20:31Z <MasterDuke_> lizmat: fyi, since i think you've mentioned this before, pmurias just fixed the allocations tab in the profiler output

[21:06] <jnthn> It's actually waaay higher on MoarVM than on the JVM

[21:06] <jnthn> By a factor 256 or so :)

[21:06] <lizmat> but but mbc, isn't that Parrot ?

[21:07] <jnthn> mbc = MoarVM Bytecode

[21:07] <jnthn> The Parrot one was pbc :)

[21:07] <lizmat> ah

[21:07] <lizmat> ok :-)

[21:07] <lizmat> ah, yes

[21:07] <MasterDuke_> jnthn: src/mast/compiler.c:627: `if (l->index < 0 || l->index > 32768)                 DIE(vm, "Frame %u local access out of range", ws->current_frame_idx);`

[21:07] <lizmat> *phew*

[21:07] <jnthn> Yup, that code's just correctly doing its job

[21:07] <jnthn> The generated code really did spit out an out-of-range index

[21:08] <jnthn> It's probably the case that there's some kind of code-generator tweak we can do

[21:09] <jnthn> But I suspect that only makes the problem happen later

[21:09] <MasterDuke_> splitting it up into a hash create and then add?

[21:10] <jnthn> That would work...but seriously, why not just use something that's designed to be a serialization format?

[21:11] <timotimo> pmurias: how on earth did you figure out that change was needed?

[21:11] <MasterDuke_> well, it's not my code or use case, so i don't really care. if it's expected behavior that's fine

[21:14] <jnthn> MasterDuke_: It's an implementation limitation, and it's certainly not something with an easy fix.

[21:15] <jnthn> There may be semi-easy ways of making it not blow up until the data gets even bigger

[21:15] <MasterDuke_> think it's worth mentioning the max size of type literals in the docs ?

[21:16] <jnthn> May be worth a note, yeah

[21:16] <jnthn> And point people to things like %?RESOURCES

[21:16] <MasterDuke_> or fail faster/earlier? took almost 4min to die for him

[21:16] <jnthn> o.O

[21:17] <MasterDuke_> though most of that was parsing

[21:19] <timotimo> pmurias++

[21:19] <lizmat> does pmurias++ fix need a bump, or should I see the result in HEAD already ?

[21:26] <MasterDuke_> jnthn: what exactly is the limitation on hash literals? number of top level keys? total number of keys?

[21:26] <timotimo> each hash gets its own limited number of entries it can have

[21:27] <timotimo> nested hashes count as just one entry

[21:28] <jnthn> This is true, but it may also be the case that the whole hash counts as a single expression, meaning any temporary registers may not be freed up

[21:28] <jnthn> Since that happens at statement level in some cases

[21:28] <jnthn> So it may run into exhaustion there also

[21:28] <timotimo> oh, oof

[21:28] <MasterDuke_> lizmat: his fix is in nqp HEAD, but not rakudo

[21:29] <jnthn> Anyways, I don't actually know, and we'd need to look at the code we're producing

[21:30] <MasterDuke_> well, is there a limit to the top level of entries? i could add that info and say literals can't be that big

[21:30] <MasterDuke_> s/entries/keys/

[21:40] <lizmat> whee.... pmurias++

[21:40] <lizmat> running a spectest now, if clean will bump nqp

[21:44] <Geth> ¦ rakudo/nom: c16cdb2ce7 | (Elizabeth Mattijsen)++ | tools/build/NQP_REVISION

[21:44] <Geth> ¦ rakudo/nom: Bump NQP version for Allocations tab in profile fix

[21:44] <Geth> ¦ rakudo/nom:

[21:44] <Geth> ¦ rakudo/nom: pmurias++

[21:44] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/c16cdb2ce7

[21:44] <Geth> ¦ rakudo/nom: version bump brought these changes: https://github.com/perl6/nqp/compare/2017.03-92-g6432a25...2017.03-94-g30a9658

[21:47] <Geth> ¦ rakudo/nom: 354a4dbbda | (Elizabeth Mattijsen)++ | docs/ChangeLog

[21:47] <Geth> ¦ rakudo/nom: Update ChangeLog for latest NQP bump

[21:47] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/354a4dbbda

[21:48] <lizmat> good night, #perl6-dev!

[21:49] <timotimo> good night lizmat!

[21:55] <jnthn> 'night, lizmat

[21:56] <timotimo> it's really not necessary for an enum value to check for isnanorinf when trying to ACCEPTS another enum value …

[21:56] <timotimo> i wonder when and how that changed

[21:59] <timotimo> benchable6: releases enum Foo <Bar Baz Quux>; my int $foo; for Foo.roll(10_000) { when Quux { $foo = $foo + 1 } };

[21:59] <benchable6> timotimo, starting to benchmark the 17 given commits

[22:00] <benchable6> timotimo, benchmarked the given commits, now zooming in on performance differences

[22:00] <benchable6> timotimo, https://gist.github.com/2f470878dd2668e383ddbc11bcc3d67a

[22:03] <AlexDaniel> benchable6: 94780d7,2c552d9 enum Foo <Bar Baz Quux>; my int $foo; for Foo.roll(10_000) { when Quux { $foo = $foo + 1 } };

[22:03] <benchable6> AlexDaniel, starting to benchmark the 2 given commits

[22:03] <benchable6> AlexDaniel, benchmarked the given commits, now zooming in on performance differences

[22:03] <benchable6> AlexDaniel, ¦94780d7: «0.2110» ¦2c552d9: «0.1821»

[22:03] <Geth> ¦ rakudo/nom: 17d34cdc91 | (Timo Paulssen)++ | src/core/Enumeration.pm

[22:03] <Geth> ¦ rakudo/nom: allow for faster Enum ~~ Enum

[22:03] <Geth> ¦ rakudo/nom:

[22:03] <Geth> ¦ rakudo/nom: it used to go through Numeric's ACCEPTS, which first checks

[22:03] <Geth> ¦ rakudo/nom: isnanorinf, and also has a nested scope in it.

[22:03] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/17d34cdc91

[22:04] <AlexDaniel> notice how it actually found which commit caused the speedup

[22:04] <AlexDaniel> amazing…

[22:04] <AlexDaniel> benchable6 is probably more reliable than I thought

[22:04] <AlexDaniel> (although the graphs suck)

[22:05] <timotimo> wow, this accepts i made in there is a whole bunch faster

[22:07] <timotimo> i don't see how those commits it's got there are actually relevant here?!

[22:08] <AlexDaniel> timotimo: benchable is effectively bisectable

[22:08] <timotimo> right

[22:08] <timotimo> but how do these commits have anything to do with my code? :D

[22:08] <AlexDaniel> timotimo: ¦2016.02: «0.2214» ¦2016.03: «0.1780»

[22:08] <AlexDaniel> timotimo: you asked for releases, that's what it got ↑

[22:08] <AlexDaniel> timotimo: then it realized that the difference is actually significant

[22:09] <AlexDaniel> timotimo: so it tried one more commit between 2016.02 and 2016.03

[22:09] <timotimo> yeah

[22:09] <timotimo> i realize that much

[22:09] <timotimo> but the commits it pointed out

[22:09] <AlexDaniel> and again and again, until it actually figured which commit caused the speedup

[22:09] <timotimo> they are for eqv on signature and parameter

[22:09] <timotimo> don't think i use either of those in my code?

[22:09] <AlexDaniel> ah

[22:09] <timotimo> anyway

[22:09] <timotimo> this new accepts method is super fantastic

[22:09] <AlexDaniel> benchable6: 94780d7,2c552d9,HEAD enum Foo <Bar Baz Quux>; my int $foo; for Foo.roll(10_000) { when Quux { $foo = $foo + 1 } };

[22:09] <benchable6> AlexDaniel, starting to benchmark the 3 given commits

[22:10] <benchable6> AlexDaniel, benchmarked the given commits, now zooming in on performance differences

[22:10] <AlexDaniel> come on benchable, I know which commit it is :)

[22:10] <benchable6> AlexDaniel, https://gist.github.com/1e21854ada69394ea7d42825c0b233ea

[22:11] <AlexDaniel> timotimo: actually… yes…

[22:11] <AlexDaniel> timotimo: looks like noise :|

[22:11] <AlexDaniel> benchable6: 94780d7,2c552d9 enum Foo <Bar Baz Quux>; my int $foo; for Foo.roll(10_000) { when Quux { $foo = $foo + 1 } };

[22:11] <benchable6> AlexDaniel, starting to benchmark the 2 given commits

[22:11] <benchable6> AlexDaniel, benchmarked the given commits, now zooming in on performance differences

[22:11] <benchable6> AlexDaniel, ¦94780d7: «0.2092» ¦2c552d9: «0.1793»

[22:11] <timotimo> it's probably not the best idea to use roll there

[22:11] <AlexDaniel> benchable6: 94780d7,2c552d9 enum Foo <Bar Baz Quux>; my int $foo; for Foo.roll(10_000) { when Quux { $foo = $foo + 1 } };

[22:11] <benchable6> AlexDaniel, starting to benchmark the 2 given commits

[22:11] <benchable6> AlexDaniel, benchmarked the given commits, now zooming in on performance differences

[22:11] <benchable6> AlexDaniel, ¦94780d7: «0.2122» ¦2c552d9: «0.1785»

[22:11] <AlexDaniel> benchable6: 94780d7^,2c552d9^ enum Foo <Bar Baz Quux>; my int $foo; for Foo.roll(10_000) { when Quux { $foo = $foo + 1 } };

[22:11] <benchable6> AlexDaniel, starting to benchmark the 2 given commits

[22:11] <benchable6> AlexDaniel, benchmarked the given commits, now zooming in on performance differences

[22:11] <benchable6> AlexDaniel, ¦94780d7^: «0.2119» ¦2c552d9^: «0.2114»

[22:12] <AlexDaniel> whatever…

[22:12] <timotimo> benchable6: releases: enum Foo <Bar Baz Quux>; my int $foo; for ^100_000 { $_ = Baz; when Quux { $foo = $foo + 1 } }

[22:12] <benchable6> timotimo, ¦releases:: «Cannot find this revision (did you mean “releases”?)»

[22:12] <timotimo> benchable6: releases enum Foo <Bar Baz Quux>; my int $foo; for ^100_000 { $_ = Baz; when Quux { $foo = $foo + 1 } }

[22:12] <benchable6> timotimo, starting to benchmark the 17 given commits

[22:12] <benchable6> timotimo, benchmarked the given commits, now zooming in on performance differences

[22:13] * AlexDaniel slaps benchable6

[22:15] <AlexDaniel> Cannot coerce NaN to an Int  in method y-ticks at /home/bisectable/.rakudobrew/moar-nom/install/share/perl6/site/sources/F589ED5005168E0E2A09F070DB83A3AB0EAA38BC (SVG::Plot) line 436

[22:15] <AlexDaniel> /o\

[22:15] <timotimo> o_O

[22:15] <timotimo> yikes

[22:15] <AlexDaniel> benchable6: releases enum Foo <Bar Baz Quux>; my int $foo; for ^100_000 { $_ = Baz; when Quux { $foo = $foo + 1 } }

[22:15] <benchable6> AlexDaniel, starting to benchmark the 17 given commits

[22:16] <benchable6> AlexDaniel, benchmarked the given commits, now zooming in on performance differences

[22:16] <AlexDaniel> same thing again

[22:16] <AlexDaniel> benchable6: HEAD^,HEAD enum Foo <Bar Baz Quux>; my int $foo; for ^100_000 { $_ = Baz; when Quux { $foo = $foo + 1 } }

[22:16] <benchable6> AlexDaniel, starting to benchmark the 2 given commits

[22:16] <benchable6> AlexDaniel, benchmarked the given commits, now zooming in on performance differences

[22:16] <benchable6> AlexDaniel, ¦HEAD^: ««run failed, exit code = 1, exit signal = 0»» ¦HEAD: ««run failed, exit code = 1, exit signal = 0»»

[22:17] <AlexDaniel> timotimo: “Cannot assign to an immutable value”?

[22:18] <AlexDaniel> benchable6: releases enum Foo <Bar Baz Quux>; my int $foo; for ^100_000 { given Baz { when Quux { $foo = $foo + 1 } } }

[22:18] <benchable6> AlexDaniel, starting to benchmark the 17 given commits

[22:19] <benchable6> AlexDaniel, benchmarked the given commits, now zooming in on performance differences

[22:20] <timotimo> oh

[22:20] <benchable6> AlexDaniel, https://gist.github.com/997b48f9b614f23634c1196f736e93e5

[22:21] <timotimo> is that HEAD the right-now-HEAD?

[22:21] <AlexDaniel> say 42

[22:21] <timotimo> like, the commit i just pushed a minute or two ago?

[22:21] <evalable6> AlexDaniel, rakudo-moar 17d34cdc9: OUTPUT: «42»

[22:22] <AlexDaniel> yes

[22:22] <timotimo> nice

[22:22] <timotimo> you see how it's a little faster than it used to be?

[22:22] <timotimo> but it also was faster a while ago

[22:23] <timotimo> right, that commit where it does the pretty big spike upwards ..

[22:23] <timotimo> that's when Numeric.ACCEPTS got a nested scope

[22:25] <timotimo> i might want to also make Numeric.ACCEPTS faster now

[22:32] <AlexDaniel> Unhandled exception in code scheduled on thread 27

[22:32] <AlexDaniel> Unhandled exception in code scheduled on thread 30

[22:32] <AlexDaniel> too many open files

[22:32] <AlexDaniel> :|

[22:34] <timotimo> ;(

[22:37] <timotimo> m: say 4.7 / 5.5

[22:37] <camelia> rakudo-moar 17d34c: OUTPUT: «0.854545␤»

[22:37] <timotimo> an acceptable improvement.

[22:43] <timotimo> the new accepts method won't get jitted it seems, let's see why

[22:45] <timotimo> huh. it claims it can jit it

[22:45] <timotimo> perhaps only when it's profiling? :\

[22:50] <Geth> ¦ rakudo/nom: 89457f8d57 | (Timo Paulssen)++ | src/core/Numeric.pm

[22:50] <Geth> ¦ rakudo/nom: make Numeric.ACCEPTS(Any) about 15% faster

[22:50] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/89457f8d57

[22:50] <Geth> ¦ rakudo/nom: e0e0800897 | (Timo Paulssen)++ | src/core/Numeric.pm

[22:50] <Geth> ¦ rakudo/nom: accidentally committed wrong version

[22:50] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/e0e0800897

[23:28] <timotimo> maybe there's another few percent to be had by rewriting in nqp, or by adding a new candidate that's tighter
