[01:04] <Zoffix_> huggable, IO kills

[01:04] <huggable> Zoffix_, [XXXX] (doc test suite[fixed]; Text::CSV[fixed]; XML.pm6[PR to fix https://github.com/supernovus/exemel/pull/43 ], Zef [fixed in https://github.com/ugexe/zef/commit/e2deb25 ])

[01:04] <Zoffix_> huggable, IO kills :is: [XXXXX] (doc test suite[fixed]; Text::CSV[fixed]; Zef [fixed]; XML.pm6[PR to fix https://github.com/supernovus/exemel/pull/43 ], Crust.pm6[ PR to fix https://github.com/tokuhirom/p6-Crust/pull/89 ])

[01:04] <huggable> Zoffix_, Added IO kills as [XXXXX] (doc test suite[fixed]; Text::CSV[fixed]; Zef [fixed]; XML.pm6[PR to fix https://github.com/supernovus/exemel/pull/43 ], Crust.pm6[ PR to fix https://github.com/tokuhirom/p6-Crust/pull/89 ])

[01:05] <Zoffix_> Looks like I should switch to a gist :/

[01:06] <Zoffix_> There's another way to describe the breakage: this software was using entirely untested features.

[01:06] <Zoffix_> And on that happy note....

[01:06] * Zoffix_ drops to bed

[01:06] <Zoffix_> ZofBot, night!

[01:06] <ZofBot> Zoffix_, That is, you're specifying the abstract operation, which may be used by various shallow operators

[01:06] * Zoffix_ &

[01:17] <timotimo> gnite Zoffix_!

[01:17] <timotimo> i'll try sleep, too

[01:18] <timotimo> moritz: i have a reason to look at perl6-all-modules again; feel like updating it? :)

[02:51] <ugexe> https://github.com/CurtTilmes/perl6-dbi-async this is kinda interesting, although should maybe use a different name

[06:38] <Ulti> samcv out of curiosity why are you using a different string match for a given OS, is there a tangible difference in perf given the platform?

[06:39] <samcv> there is a bit of difference. and it's because linux has glibc and freebsd's libc has another

[06:39] <samcv> and the freebsd one is portable and i got it working on windows and macos

[06:41] <Ulti> oh thats interesting, I would have guessed they'd be the same

[06:46] <samcv> and it's only used when the strings are either both 8bit or both 32bit string representations

[06:46] <samcv> but that is most of them

[06:47] <samcv> eventually we may be able to adapt the FreeBSD code to also skip x number of bytes because 32bit strings have 4 bytes, so it searches the same on 8 bit as 32bit. but can be optimized more if it's able to skip more often

[06:47] <moritz> timotimo: sure, will do

[06:47] <samcv> instead of each byte considered seperate

[06:48] <moritz> I did want to automate that

[06:48] <moritz> (updating perl6-all-modules)

[06:49] <Ulti> samcv is this all low level or accessible higher up to swap out?

[06:49] <samcv> it's all low level

[06:49] <samcv> the nqp::index op is what has been changed

[06:49] <Ulti> I've been considering implementing in a module bitap but for buf so I can do DNA/RNA searches efficiently since they have really small alphabets where each character can be 2bits

[06:49] <samcv> https://github.com/MoarVM/MoarVM/commit/e8231a303e7646e2e79b2ea6f489230240272851 if you want to see the merge that pulled it all in. i've added a fair number of comments if you scroll past the bsd source file (though that's really interesting too)

[06:50] <samcv> hm

[06:50] <Ulti> cool thanks

[06:50] <samcv> you should look then

[06:50] <samcv> but memmem is basically searches for memory inside a memory

[06:50] <samcv> which is just the same as string search, just. i mean that's what it really is anyway

[06:51] <Ulti> yeah

[06:51] <samcv> and our strings aren't null terminated and are 32bit or 8bit

[06:52] <samcv> also https://github.com/MoarVM/MoarVM/pull/574 this may be interesting. and i have a link to the PDF of the paper that describes freebsd's algorithm (which also compares it to boyer-moore and also kruth-morris-pratt (glibc uses this)

[06:57] <Ulti> so what was there before you made your changes?

[06:58] <samcv> just brute force search

[06:58] <samcv> which grabs graphemes out of the each string and compares them

[06:58] <moritz> and I assume that was due to our interesting string format?

[06:59] <samcv> Ulti, https://github.com/MoarVM/MoarVM/blob/master/src/strings/ops.c#L265

[07:00] <samcv> this is the fallback still in case the strings are different bit widths

[07:03] <samcv> i still haven't been able to trigger this https://github.com/MoarVM/MoarVM/blob/master/src/strings/ops.c#L240 at least doesn't show it on coverage reports. even when i forced both strings to 32bit by converting them in the function beforehand

[07:03] <samcv> if anybody can help me with that, it would be cool

[07:03] <samcv> https://github.com/perl6/nqp/blob/master/t/nqp/107-index.t#L10

[07:04] <samcv> the comments big endian and little endian there are reversed by accident but both of them (i'm pretty certain) contain 4 bytes of null in their 32bit string represetations

[07:04] <samcv> depending on the endianess

[07:06] <samcv> camelia, https://gist.githubusercontent.com/samcv/a2b4593259f315c7464f7f195a3de6fc/raw/27182fc2f3c6f2a0401b8389deca482752a646b6/endian.p6

[07:06] <samcv> evalable6, https://gist.githubusercontent.com/samcv/a2b4593259f315c7464f7f195a3de6fc/raw/27182fc2f3c6f2a0401b8389deca482752a646b6/endian.p6

[07:06] <evalable6> samcv, Successfully fetched the code from the provided URL.

[07:06] <evalable6> samcv, rakudo-moar b6838ee4d: OUTPUT: «1048576 base 10␤Padding 11 extra 0's␤11␤21␤Big: (00000000 00010000 00000000 00000000)␤Little: (00000000 00000000 00010000 00000000)»

[07:08] <samcv> if anybody can confirm if that is correct that'd be great

[07:09] <samcv> since that's the script i used to decide which codepoints to use in the test

[07:23] <lizmat> good *, #perl6-dev!

[07:23] <samcv> hi lizmat :-)

[07:24] <lizmat> Files=1189, Tests=56681, 201 wallclock secs (12.08 usr  4.86 sys + 1195.44 cusr 116.20 csys = 1328.58 CPU)

[07:25] <samcv> hey lizmat :)

[07:25] <samcv> oh i said that already. i think i'm tired

[07:25] <lizmat> samcv  o/

[07:25] <lizmat> yeah, it's way past  midnight for you, no ?

[07:25] <samcv> 25 mins past

[07:25] <samcv> i got travis pushing rakudo builds now

[07:25] <samcv> pushing appimages

[07:25] <lizmat> :-)

[07:26] <samcv> https://github.com/samcv/rakudo-appimage/tree/gh-pages all these 4 were commited by travis

[07:26] <lizmat> cool

[07:26] <samcv> got a 4 matrix heh

[07:26] <samcv> so hopefully we will be able to have nightly appimages or maybe other things. now that i've figured out how the fuck to get travis to behave

[07:26] <lizmat> Zoffix_: MacOs apparently fails S16-filehandles/filetest.t test 48: .z can be called on directories

[08:00] <Ulti> samcv++ from all the people who do lots of string match :D

[08:02] <samcv> :D

[08:03] <samcv> Ulti, i'll probably convert 8 bit needles to 32bit if the haystack is 32bit and the haystack is long enough and needles not too long

[08:03] <samcv> so it can use the optimized not the brute force

[08:03] <samcv> but still very big improvement so far. but i'm not sure what the next most used function is to speed improve

[08:03] <samcv> for string search that is

[08:04] <Ulti> I guess one thing is for the code to be portable, but SSE4 instructions for strings would be a cool thing

[08:04] <samcv> yeah. qt has that

[08:04] <Ulti> it amazes me how few if any string libs actually use them despire it being a huge boost

[08:04] <samcv> wait maybe. idk

[08:04] <samcv> they have optimized UTF-8 decoding though

[08:04] <samcv> i was eying that a month ago

[08:05] <samcv> but it seems pretty integrated

[08:05] <Ulti> its kind of mental strings are this complicated

[08:05] <samcv> what?

[08:07] <samcv> also we may want to use the freebsd memmem on linux for some things, i'm not sure yet though. if performance shows it's faster. because it might be faster at searching for a 32bit single character in a 32bit string because it has a fourbyte_memmem function

[08:07] <samcv> https://github.com/MoarVM/MoarVM/blob/master/3rdparty/freebsd/memmem.c#L46

[08:10] <chansen_> http://www-igm.univ-mlv.fr/~lecroq/string/node13.html#SECTION00130

[08:11] <chansen_> Works well and memcmp() is usally very optimized in any libc

[08:18] <samcv> hmm maybe that can be altered to take advantage of knowing 4 byte width per char not 1 byte

[08:18] <samcv> bookmarking

[08:18] <samcv> but what license is that code under

[08:21] <chansen_> It's a book, did you see the index? http://www-igm.univ-mlv.fr/~lecroq/string/index.html

[08:23] <samcv> nope not yet

[09:13] <Zoffix_> lizmat, what does perl6 -e 'dd ".".IO.z; dd ".".IO.s' give on MacOS?

[09:14] <samcv> Zoffix_, where do i edit rakudo's source to have it change directory before running a script

[09:14] <samcv> based on an ENV var

[09:14] <samcv> for my appimages

[09:15] <Zoffix_> samcv, anywhere, I guess.

[09:15] <Zoffix_> samcv, the sub for changing process's chdir is here https://github.com/rakudo/rakudo/blob/nom/src/core/io_operators.pm#L149-L150

[09:15] <samcv> uh. where do we process command line arguments

[09:15] <samcv> i'd like to hack that

[09:15] <Zoffix_> Oh, no idea.

[09:16] <samcv> i have opened the source file at least once months ago

[09:16] <Zoffix_> Somewhere in https://github.com/rakudo/rakudo/blob/nom/src/Perl6/Compiler.nqp

[09:16] <samcv> oh yes

[09:17] <samcv> though i hope if i change directory there it doesn't screw up things

[09:17] <samcv> like if i chdir inside the perl6 shell script before launching all the relative links break

[09:28] <samcv> Zoffix_, i tried doing -M module_that_chdirs

[09:28] <samcv> works on my normal perl 6 but with the appimage it enters a dependency loop

[09:29] <Zoffix_> samcv, chdirs with what tho?

[09:29] <samcv> probably due to relative paths or something weird

[09:29] <samcv> chdir's to the directory the appimage was started from

[09:29] <Zoffix_> What are you calling to chdir?

[09:29] <samcv> well it doesn't matter what is in the module. it can be empty

[09:29] <samcv> but it fails in the appimage because the appimage uses relative paths or something

[09:30] <samcv> -I lib and then `use foo:bar` works though. but module PRE loading doesn't work

[09:38] <Zoffix_> It's curious how common misused of IO routines is in the ecosystem... I hope improved docs will help.

[09:38] <Zoffix_> "return False unless $pid-file.IO.abspath.IO.e;" in UNIX::Daemonize

[09:40] <samcv> it can just be $pid-file.IO.e right?

[09:40] <samcv> so is abspath getting deprecated with a warning? cause it's used a lot of places

[09:41] <Zoffix_> Another one in OpenSSL: "$*SPEC.catfile( IO::Path.new($*PROGRAM.dirname).absolute, "cacert.pem" )"

[09:41] <Zoffix_> m: say WHAT $*PROGRAM.dirname

[09:41] <camelia> rakudo-moar b6838e: OUTPUT: «(Str)␤»

[09:41] <Zoffix_> m: say $*PROGRAM.dirname

[09:41] <camelia> rakudo-moar b6838e: OUTPUT: «/tmp␤»

[09:41] <Zoffix_> samcv, it's already gone.

[09:42] <samcv> oh

[09:42] <samcv> m: say ".".IO.abspath

[09:42] <camelia> rakudo-moar b6838e: OUTPUT: «No such method 'abspath' for invocant of type 'IO::Path'␤  in block <unit> at <tmp> line 1␤␤»

[09:42] <samcv> m: say ".".IO.absolute

[09:42] <camelia> rakudo-moar b6838e: OUTPUT: «/home/camelia␤»

[09:43] <Zoffix_> m: say $*PROGRAM.parent.child('cacert.pem')

[09:43] <camelia> rakudo-moar b6838e: OUTPUT: «"/tmp/cacert.pem".IO␤»

[09:43] <Zoffix_> Hm. I think I will steal `.sibling` from Mojolicious

[09:43] <samcv> m: say '.'.IO.Str.IO.Str.IO.absolute.Str

[09:43] <camelia> rakudo-moar b6838e: OUTPUT: «/home/camelia␤»

[09:47] <Zoffix_> Details on what I wanna steal: https://metacpan.org/pod/Mojo::File#sibling

[09:47] <samcv> m: my $str = ".IO.Str.IO.Str.IO.absolute.Str"; “'.'{$str x 10000}”.EVAL.say

[09:47] <camelia> rakudo-moar b6838e: OUTPUT: «(timeout)»

[09:47] <Zoffix_> 0.o what are you doing...

[09:49] <samcv> m: my $str = ".IO.Str.IO.Str.IO.absolute.Str"; “'.'{$str x 1000}”.EVAL.say

[09:49] <camelia> rakudo-moar b6838e: OUTPUT: «/home/camelia␤»

[09:49] <samcv> only what must be done

[09:49] <Zoffix_> .Str.IO is wrong

[09:50] <samcv> it works though?

[09:50] <samcv> can't you call .IO on a string?

[09:50] <Zoffix_> Doesn't

[09:50] <samcv> i call IO on all the strings which have filenames or directories in them i want to do operations

[09:50] <Zoffix_> m: my $orig = '.'.IO; $orig.dir.say; chdir '/tmp'; $orig.Str.IO.dir.say

[09:50] <camelia> rakudo-moar b6838e: OUTPUT: «(".cpanm".IO ".local".IO ".npm".IO ".perl6".IO ".perlbrew".IO ".rcc".IO ".ssh".IO "Perlito".IO "evalbot".IO "log".IO "nqp-js".IO "p1".IO "p2".IO "perl5".IO "std".IO ".bash_history".IO ".bashrc".IO "mbox".IO ".lesshst".IO "evalbot.log".IO ".cpan".IO "dale…»

[09:50] <Zoffix_> m: my $orig = '.'.IO; $orig.dir[0].say; chdir '/tmp'; $orig.Str.IO.dir[0].say

[09:50] <camelia> rakudo-moar b6838e: OUTPUT: «".cpanm".IO␤"y2yamldata-M2wvA1".IO␤»

[09:50] <Zoffix_> m: my $orig = '.'.IO; $orig.dir[0].say; chdir '/tmp'; $orig.absolute.IO.dir[0].say

[09:50] <camelia> rakudo-moar b6838e: OUTPUT: «".cpanm".IO␤"/home/camelia/.cpanm".IO␤»

[09:50] <samcv> m: "blah".^methods.pick.say

[09:50] <camelia> rakudo-moar b6838e: OUTPUT: «comb␤»

[09:51] <Zoffix_> samcv, .Str.IO on an IO::Path object is wrong, because .Str doesn't take $!CWD into account. The proper way to stringify IO::Path while preserving path correctness is with .absolute or .relative

[09:51] <Zoffix_> m: my $orig = '.'.IO; $orig.dir[0].say; chdir '/tmp'; $orig.relative.IO.dir[0].say

[09:51] <camelia> rakudo-moar b6838e: OUTPUT: «".cpanm".IO␤"../home/camelia/.cpanm".IO␤»

[09:51] <samcv> ok that is wrong

[09:52] <samcv> yeah

[09:52] <samcv> agree

[10:00] <Zoffix_> "$remote = $remoteio.abspath() ~ '/' ~ $path.IO.basename();" another one heh

[10:14] <samcv> my $p = Promise.in(1); sub rec (Mu $b) { my $m; my $e = False; repeat while $e { $m = $b.^methods.pick.gist; try { "$b.$m".EVAL }; CATCH {$e = True; }; }; return !$p ?? rec("$b.$m") !! "$b.$m"; }; rec("'hi'").say

[10:14] <samcv> m: my $p = Promise.in(1); sub rec (Mu $b) { my $m; my $e = False; repeat while $e { $m = $b.^methods.pick.gist; try { "$b.$m".EVAL }; CATCH {$e = True; }; }; return !$p ?? rec("$b.$m") !! "$b.$m"; }; rec("'hi'").say

[10:14] <camelia> rakudo-moar b6838e: OUTPUT: «'hi'.indent.encode.trim.substr-eq.Str.chars.Stringy.parse-names.parse-base.indices.BUILD.Str.chop.NFC.match.ords.contains.contains.samespace.encode.match.parse-base.samecase.tc.trim.Stringy.uc.Bool.Int.codes.lc.starts-with.ords.samemark.subst-mutate.code…»

[10:14] <samcv> heh

[10:14] <samcv> m: my $p = Promise.in(1); sub rec (Mu $b) { my $m; my $e = False; repeat while $e { $m = $b.^methods.pick.gist; try { "$b.$m".EVAL }; CATCH {$e = True; }; }; return !$p ?? rec("$b.$m") !! "$b.$m"; }; rec("'hi'".IO).say

[10:14] <camelia> rakudo-moar b6838e: OUTPUT: «'hi'.x.uc.subst-mutate.chars.words.ords.rindex.chars.DUMP.lc.samespace.Num.samespace.uc.trim-leading.Num.BUILD.index.WHY.index.NFD.gist.DUMP.ord.chars.BUILD.lc.ord.word-by-word.trim-trailing.contains.NFC.subst.tclc.subst.trans.parse-base.samecase.Int.tri…»

[10:14] <samcv> m: my $p = Promise.in(1); sub rec (Mu $b) { my $m; my $e = False; repeat while $e { $m = $b.^methods.pick.gist; try { "$b.$m".EVAL }; CATCH {$e = True; }; }; return !$p ?? rec("$b.$m") !! "$b.$m"; }; rec("'hi'.IO").say

[10:14] <camelia> rakudo-moar b6838e: OUTPUT: «'hi'.IO.words.Str.samecase.words.chomp.samemark.gist.WHICH.lc.gist.Str.substr-eq.WHICH.Str.contains.uc.index.contains.Int.match.DUMP.contains.trim.chomp.comb.flip.ord.flip.chomp.trim-leading.starts-with.ACCEPTS.chop.wordcase.index.Num.tclc.indent.subst.N…»

[10:15] <samcv> m: my $p = Promise.in(1); sub rec (Mu $b) { my $m; my $e = False; repeat while $e { $m = $b.^methods.pick.gist; try { "$b.$m".EVAL }; CATCH {$e = True; }; }; return !$p ?? rec("$b.$m") !! "$b.$m"; }; rec("'hi'.IO").say

[10:15] <camelia> rakudo-moar b6838e: OUTPUT: «'hi'.IO.fc.substr-eq.subst-mutate.NFKD.comb.ends-with.trim-leading.flip.comb.gist.NFD.BUILD.samecase.Numeric.Int.rindex.chars.encode.Str.starts-with.NFC.chomp.NFKC.tc.DUMP.ords.index.trim-trailing.contains.pred.subst.ord.Bool.samemark.Int.words.Numeric.s…»

[10:15] <samcv> only does methods that eval shows don't throw.

[10:16] <samcv> m: my $p = Promise.in(1); sub rec (Mu $b) { my $m; my $e = False; repeat while $e { $m = $b.^methods.pick.gist; try { "$b.$m".EVAL }; CATCH {$e = True; }; }; return !$p ?? rec("$b.$m") !! "$b.$m"; }; rec("Promise.new").say

[10:16] <camelia> rakudo-moar b6838e: OUTPUT: «Promise.new.trans.word-by-word.ACCEPTS.lines.tclc.indices.ord.indices.subst-mutate.codes.tclc.NFKD.WHY.subst-mutate.starts-with.NFKD.perl.ords.flip.Stringy.substr-eq.wordcase.substr-eq.trim-leading.tclc.rindex.ord.starts-with.word-by-word.chomp.words.pre…»

[10:16] <samcv> m: my $p = Promise.in(1); sub rec (Mu $b) { my $m; my $e = False; repeat while $e { $m = $b.^methods.pick.gist; try { "$b.$m".EVAL }; CATCH {$e = True; }; }; return !$p ?? rec("$b.$m") !! "$b.$m"; }; rec("Promise.new").EVAL.say

[10:16] <camelia> rakudo-moar b6838e: OUTPUT: «No such method 'parse-base' for invocant of type 'Promise'␤  in block <unit> at EVAL_67 line 1␤  in block <unit> at <tmp> line 1␤␤»

[10:16] <samcv> oh. i guess it doesn't work that well

[10:20] <Zoffix_> <timotimo> moritz: i have a reason to look at perl6-all-modules again; feel like updating it? :)

[10:20] <Zoffix_> timotimo, FWIW, I sent PRs for the .abspath that were in the current perl6-all-modules: https://gist.github.com/zoffixznet/0ea1f4db792fc674abdde73f8dd11cc1

[10:20] <Zoffix_> huggable, IO kills

[10:20] <huggable> Zoffix_, [XXXXX XXXXX XXXXX XXX]: See https://gist.github.com/zoffixznet/0ea1f4db792fc674abdde73f8dd11cc1

[10:42] <timotimo> Zoffix_: sha1-native already has my pullrequest merged :)

[10:43] <Zoffix_> timotimo, I see neither commits nor other PRs: https://github.com/bduggan/p6-digest-sha1-native/commits/master

[10:45] * lizmat clickbaits https://p6weekly.wordpress.com/2017/04/10/2017-15-kaboom/

[10:45] <lizmat> oops, wrong chan

[10:47] * Zoffix_ looks up why the upcoming Good Friday is Good....

[10:47] <Zoffix_> Creepy :|

[10:47] <Zoffix_> At least we get a day off up in Canukistan \o/

[10:47] <samcv> night everybody o/

[10:47] <Zoffix_> night

[10:48] <samcv> also thanks Zoffix_ for sending PR to the modules :) very awesome

[10:48] <samcv> 'break it you fix it'?

[10:48] <samcv> heheh

[10:49] * lizmat just spent a day trying to optimize creating a sorted list of keys of a hash

[10:49] <lizmat> turns out, just creating a list_s and sorting that, is the fastest way to do this

[10:50] <lizmat> and not an approach with a binary search, building the list on the fly from the iterator

[10:50] <lizmat> *sigh*

[10:53] <lizmat> https://gist.github.com/lizmat/5ce4c4963e860f7adc4dba0ff932611c  # for those interested

[10:54] <samcv> lizmat, also is there a reason for nqp::stmts, when i was coding nqp it didn't change execution time using stmts versu just (exp 1; exp2; exp3)

[10:54] <samcv> when compiled

[10:54] <samcv> argh it's way too late

[10:55] <lizmat> samcv: I try to mix nqp-like code and HLL code as little as possible

[10:55] <samcv> see you all tomorrow

[10:55] <lizmat> good night!

[10:55] <samcv> kk :)

[10:55] <lizmat> 4am is a good time to go and get some rest!

[10:55] <samcv> it was a good time 2 hours ago

[10:55] <samcv> and now it's still a good time

[10:55] <samcv> but not a better time

[10:55] <samcv> o/

[10:55] <lizmat> o/

[11:00] * lizmat will be mostly away on Wed / Thu and possibly Fri, so stops doing commits now as to not more problems for the release

[11:00] <lizmat> *create

[11:00] <timotimo> Zoffix_: damn, i looked at closed pullrequests and there's actually only one "use abspath"

[11:01] <timotimo> i just got out of bed, so that's probably why i derped that

[11:01] <timotimo> looks like i made the change and somehow didn't pullrequest it?

[11:02] <Zoffix_> lizmat, what does perl6 -e 'dd ".".IO.z; dd ".".IO.s' give on MacOS?

[11:21] <Zoffix> .tell lizmat FWIW, I'm delaying the release by 1.5-2 days to cram all the IO stuff into it. You said .z test fails on MacOS... it's testing for Bool; what does it get on MacOS?

[11:21] <yoleaux> Zoffix: I'll pass your message to lizmat.

[12:15] <Zoffix> good grief...

[12:16] <Zoffix> I'm using Molases ISP

[12:16] <timotimo> :<

[12:40] <Zoffix> ehehe. I found a way to test out code on mac.

[12:40] <Zoffix> It's very slow though. Takes 8.5 minutes to do 1 test :)

[12:41] <Zoffix> .tell lizmat managed to run .z on Mac. Seems to work fine. Is it possible you ran the test without pulling and building HEAD for rakudo? https://travis-ci.org/zoffixznet/mactest/jobs/220938858

[12:41] <yoleaux> Zoffix: I'll pass your message to lizmat.

[12:41] <timotimo> oh yeah, travis :\

[13:00] <Zoffix> NeuralAnomaly: status

[13:00] <NeuralAnomaly> Zoffix, [✘] Next release will be in 3 days and 15 hours. Since last release, there are 24 new still-open tickets (14 unreviewed and 0 blockers) and 222 unreviewed commits. See http://perl6.fail/release/stats for details

[13:00] <Zoffix> lotsa commits :o

[13:02] <Zoffix> m: my int @b = 1, 2, 3, 4, 5; say @b[-2 ^ 0];

[13:02] <camelia> rakudo-moar b6838e: OUTPUT: «one(4, 1)␤»

[13:02] <Zoffix> m: my int @b = 1, 2, 3, 4, 5; say @b[-10 ^ 0];

[13:02] <camelia> rakudo-moar b6838e: OUTPUT: «MVMArray: Index out of bounds␤  in block <unit> at <tmp> line 1␤␤»

[13:02] <Zoffix> neat :D

[13:04] <timotimo> oh, that's fun

[13:04] <timotimo> because it's checking for bounds, and *one* of those satisfies the bounds

[13:04] <timotimo> that check needs to happen after the junction fans out

[13:05] * timotimo BBIAB

[13:05] <Zoffix> m: my int @b = 1, 2, 3, 4, 5; say @b[-2 ^ -1];

[13:05] <camelia> rakudo-moar b6838e: OUTPUT: «one(4, 5)␤»

[13:09] <lizmat> .

[13:09] <yoleaux> 11:21Z <Zoffix> lizmat: FWIW, I'm delaying the release by 1.5-2 days to cram all the IO stuff into it. You said .z test fails on MacOS... it's testing for Bool; what does it get on MacOS?

[13:09] <yoleaux> 12:41Z <Zoffix> lizmat: managed to run .z on Mac. Seems to work fine. Is it possible you ran the test without pulling and building HEAD for rakudo? https://travis-ci.org/zoffixznet/mactest/jobs/220938858

[13:09] <lizmat> Zoffix: indeed, cannot reproduce it now, so sorry for the false alarm

[13:09] <lizmat> afk again&

[13:09] <Zoffix> \o/

[14:09] <Zoffix> Hmmm

[14:10] <Zoffix> <ZofBot> Zoffix, The "subparse" method does not add anchors, and will match substrings against the rule

[14:10] <Zoffix> m: grammar { token TOP { "foo" } }.subparse("meowfoobar").say

[14:10] <camelia> rakudo-moar b6838e: OUTPUT: «#<failed match>␤»

[14:10] <Zoffix> But it doesn't actually. It's anchored to the start of the string.

[14:10] <Zoffix> Did the bot find a bug?

[14:17] <Geth> ¦ roast/6.c-errata: ae9c63cf27 | (Zoffix Znet)++ | integration/advent2011-day23.t

[14:17] <Geth> ¦ roast/6.c-errata: Fix typo in code

[14:17] <Geth> ¦ roast/6.c-errata:

[14:17] <Geth> ¦ roast/6.c-errata: The previous fix[^1] to the test to accomodate Rakudo's changes[^2]

[14:17] <Geth> ¦ roast/6.c-errata: removed one-too-many characters. Fix by re-adding it. Also amend test's

[14:17] <Geth> ¦ roast/6.c-errata: description to describe actual code run.

[14:17] <Geth> ¦ roast/6.c-errata:

[14:17] <Geth> ¦ roast/6.c-errata: [1] https://github.com/perl6/roast/commit/5f7613eb72cc843b75530f359541dea3b70e102b

[14:17] <Geth> ¦ roast/6.c-errata: [2] https://github.com/rakudo/rakudo/commit/7ea0f66189c03b27c9815966b274638dcaa4989e

[14:17] <Geth> ¦ roast/6.c-errata: review: https://github.com/perl6/roast/commit/ae9c63cf27

[14:19] <Geth> ¦ roast: 6546a54cae | (Zoffix Znet)++ | integration/advent2011-day23.t

[14:19] <Geth> ¦ roast: Update test description

[14:19] <Geth> ¦ roast:

[14:19] <Geth> ¦ roast: To reflect the actual code being run.

[14:19] <Geth> ¦ roast: review: https://github.com/perl6/roast/commit/6546a54cae

[14:36] <Zoffix> Should roast even be accessible to default perl6 users? Basically anyone who's part of perl6 org has perms to alter The Official Perl 6 Specification™

[14:36] <Zoffix> I just went to GitHub and it suggested me I pull and merge 6.c-errata to master.

[14:37] <Zoffix> Which might be quite damaging if actually done..

[14:38] <Zoffix> ZofBot: I'm all alone, talking in this room, am I not? It's just you and me.

[14:38] <ZofBot> Zoffix, Default "multi"s should be marked with ""is default""

[14:38] <moritz> Zoffix: we also gave everybody write access to perl6/specs when that was considered "The Official Perl 6 Specification™"

[14:39] <Zoffix> Before it was solidified tho

[14:40] <Zoffix> And made immutable

[14:40] <jnthn> Trusting people has, so far, worked out pleasantly well

[14:42] <Zoffix> This isn't about trust. This is about someone accidentally deleting 6.c-errata, for example. That won't be even reported by Geth. And with 270 people accidents are more likely than with 30-50.

[14:42] <moritz> then one of us who has 6.c-errata checked out pushes it again

[14:42] <moritz> when we notice it's gone

[14:42] <Geth> ¦ roast/6.c-errata: fe1aef1688 | (Elizabeth Mattijsen)++ | integration/advent2013-day07.t

[14:42] <Geth> ¦ roast/6.c-errata: Make bogus .WHICH test less bogus

[14:42] <Geth> ¦ roast/6.c-errata: review: https://github.com/perl6/roast/commit/fe1aef1688

[14:43] <moritz> most mistakes in git land are simple to recover from (if sometimes painful, through a force-push), so mistakes typically aren't that fatal

[14:45] <Zoffix> OK. can't merge 6.cerrata anyway

[14:50] <Geth> ¦ roast/6.c-errata: fe1aef1688 | (Elizabeth Mattijsen)++ commited by Geth::GitHub::Hooks::Event::Push::Commit<140152101270048>.commiter | integration/advent2013-day07.t

[14:50] <Geth> ¦ roast/6.c-errata: Make bogus .WHICH test less bogus

[14:50] <Geth> ¦ roast/6.c-errata: review: https://github.com/perl6/roast/commit/fe1aef1688

[14:50] <Zoffix> uhhh...

[14:52] <Geth> ¦ roast/6.c-errata: fe1aef1688 | (Elizabeth Mattijsen)++ (committed by Zoffix Znet) | integration/advent2013-day07.t

[14:52] <Geth> ¦ roast/6.c-errata: Make bogus .WHICH test less bogus

[14:52] <Geth> ¦ roast/6.c-errata: review: https://github.com/perl6/roast/commit/fe1aef1688

[14:52] <dogbert17_> o/

[14:52] <Zoffix> That's better.

[14:53] <Geth> ¦ geth: 43aa2970ab | (Zoffix Znet)++ | lib/Geth/Plugin/GitHub.pm6

[14:53] <Geth> ¦ geth: Report committer when it differes from author

[14:53] <Geth> ¦ geth:

[14:53] <Geth> ¦ geth: - e.g. in cherry picks

[14:53] <Geth> ¦ geth: review: https://github.com/perl6/geth/commit/43aa2970ab

[14:53] <dogbert17_> is it reasonable that running 'perl6 htmlify.p6' should take 20 minutes to execute (on a dual core i5)?

[14:53] <Zoffix> That sounds about what my experience with it was.

[14:53] <dogbert17_> that's annoyingly slow

[14:54] * dogbert17_ wonders what it might be doing behind the scenes

[14:54] <timotimo> dogbert17_: yeah, it's pretty slow :(

[14:55] <timotimo> oh, did you get the faster highlighter?

[14:55] <Zoffix> Interesting....

[14:55] <dogbert17_> any idea what causes this slowness?

[14:55] <Zoffix> 6.c-errata stresstest takes: Files=1149, Tests=125720, 121 wallclock secs (20.15 usr  3.22 sys + 2247.16 cusr 122.38 csys = 2392.91 CPU)

[14:55] <timotimo> is that still optional?

[14:55] <Zoffix> dogbert17_: doing lots of work

[14:55] <dogbert17_> it uses some node thingie I belive

[14:55] <Zoffix> I think it gets faster if you turn off highlighting and image generation

[14:56] <Zoffix> the node stuff is highlighting

[14:56] <timotimo> OK, good

[14:56] <timotimo> it used to do it by exec ing a python instance if you didn't have Inline::Python, but those days are probably long gone

[14:56] <timotimo> can you run it with --parallel or what it's called? are we stable enough for that yet?

[14:56] <dogbert17_> well, today the NDA's are lifted on AMD's Ryzen 5 series CPU's, maybe it's time to upgrade ...

[14:56] <Zoffix> yeah, python's ded :}

[14:58] <dogbert17_> https://www.youtube.com/watch?v=HO20mmQjY40 # review of the new CPU's

[14:59] <Zoffix> timotimo: BTW the :s doesn't stop you from key-lookup or index-look or method call for your scalars. Just like you can still use %hash<foo>[42] with just :h. The most permissive option I found is :c and using codeblocks for all interpolation, but that still sucks for CSS interpolation :/

[15:00] <Zoffix> TimToady: showed some trick that I now forget

[15:00] <Zoffix> m: my $foo = 42; say q|qq\\$foo|

[15:00] <camelia> rakudo-moar b6838e: OUTPUT: «qq\$foo␤»

[15:01] <Zoffix> It looked somethign like that

[15:01] <Zoffix> m: my $foo = 42; say q|qq//$foo|

[15:01] <camelia> rakudo-moar b6838e: OUTPUT: «qq//$foo␤»

[15:01] * Zoffix shrugs

[15:01] <Zoffix> m: my $foo = 42; say q|qq{$foo}|

[15:01] <camelia> rakudo-moar b6838e: OUTPUT: «qq{$foo}␤»

[15:02] <Zoffix> m: my $foo = 42; say q|\qq[$foo]|

[15:02] <camelia> rakudo-moar b6838e: OUTPUT: «42␤»

[15:02] <Zoffix> Therewego

[15:03] <Zoffix> m: my $foo = 42; say '\qq[$foo](42)'

[15:03] <camelia> rakudo-moar b6838e: OUTPUT: «42(42)␤»

[15:03] <Zoffix> \o/

[15:05] <Zoffix> m: my $foo = 42; say 'the $foo is \Qs[$foo]'

[15:05] <camelia> rakudo-moar b6838e: OUTPUT: «the $foo is \Qs[$foo]␤»

[15:05] <Zoffix> I guess \Q don't work

[15:06] <Zoffix> too much risk for false positives

[15:07] <Zoffix> tho \q gets interpreted vOv

[15:13] <MasterDuke> dogbert17_: i just ran `htmlify.p6 --no-highlight --parallel=10` and it took maybe 2-3min, but there were two errors

[15:13] <MasterDuke> Use of uninitialized value $node of type Any in string context. Methods .^name, .perl, .gist, or .say can be used to stringify it to something meaningful.   in sub node2rawtext at /home/dan/Source/perl6/doc/../modules/Pod-To-HTML/lib/Pod/To/HTML.pm (Pod::To::HTML) line 599

[15:14] <MasterDuke> ..No such method 'contents' for invocant of type 'Any'   in block  at htmlify.p6 line 936   in sub write-kind at htmlify.p6 line 916   in sub MAIN at htmlify.p6 line 232   in block <unit> at htmlify.p6 line 1013

[15:15] <Zoffix> Here. Summed it all up in a screenshot: https://twitter.com/zoffix/status/851815881852284929

[15:17] <timotimo> MasterDuke: sounds like it's having some kind of concurrency related issue :(

[15:18] <MasterDuke> timotimo: yup. much better than it used to be, but still not perfect

[15:20] <Zoffix> Have you checked that the problem is not actually in the htmlify.p6 script?

[15:21] <Zoffix> This type of stuff you'd get when you have more than one thread changing the same variable

[15:21] <timotimo> yeah, the crossthreadwrite log might give a clue, but not necessarily

[15:21] <jnthn> The problem I know about in htmlify is that the NEXT phaser mis-compiles into something not thread safe

[15:21] <jnthn> In the while loop case

[15:21] <jnthn> Or something like that

[15:21] <Zoffix> Ah

[15:21] <jnthn> Many of the others I fixed

[15:22] <jnthn> But the script really wasn't written in a concurrency-thoughtful way

[15:22] <jnthn> So I'd not be surprised if there are some further issues after fixing that one

[15:22] <timotimo> yeah :|

[15:24] <jnthn> Though other than that issue it seemed to be getting relatively into things

[15:24] <jnthn> *relatively far

[15:28] <jnthn> I'd love to say I'd look at it soon, but my Perl 6 time these days is...pretty limited.

[15:29] <[Coke]> Zoffix: I didn't see this explicitly mentioned in backscroll, but the 6.c-errata branch is protected, on github.

[15:30] <[Coke]> we can protect it further if needs be, but it can't be deleted, and can't be force-pushed.

[15:31] <dogbert17_> MasterDuke: have you ever managed to profile htmlify?

[15:32] <[Coke]> nope.

[15:32] <Zoffix> [Coke]: cool

[15:33] <[Coke]> It's doing a lot, and it does it all in one script (instead of in several make-composable chunks). If you're using it locally, you can pass "--sparse=40" to do a fraction of the pages (this may also help with profiling)

[15:33] <dogbert17_> [Coke]: thx, I'll try that when I get home from work

[15:37] <b2gills> Zoffix: Windows reserves the filename "NUL" (/dev/null) in every directory, along with CON (STDOUT) LPT1 and COM1 etc

[15:38] <Zoffix> BTW, now that more people are here, I'm planning to add IO::Path.sibling($x) that will function like .parent.concat-with($x).

[15:38] <Zoffix> It's shorter to type. I've seen some uses of it in ecosystem. Mojo::File has it and their team bikesheds everything to death.

[15:38] <b2gills> That sounds useful

[15:38] <Zoffix> So if anyone wants to protest, do so now :D)

[15:55] <Zoffix> b2gills: TIL. Out of them all, the 'CON' file does get created with perl6 -e "'COM1'.IO.spurt('test')"

[15:55] <Zoffix> And LPT1 fails with "Failed to open file C:\temp\LPT1: no such file or directory" even though it's a writing open :S

[15:55] <Zoffix> The rest silently succeed with no file left.

[15:56] <Zoffix> Oh, it's CON not COM! Yeah, also failed to open.

[15:56] <Zoffix> Cool.

[15:56] <b2gills> One of my earliest Perl programs was directly controlling an Epson Dot matrix printer by sending bytes to LPT1

[15:58] <b2gills> I think it was in DOS 1.0 which was before it had directories, so to be backwards compatible in DOS 2.0 it worked in all directories.

[16:00] * Zoffix is pretty sure he wasn't yet born at the time...

[16:02] <Zoffix> A time when computing products were advertised with stone and chizzels lulz: https://upload.wikimedia.org/wikipedia/en/1/1a/Msdosad.jpg

[16:02] <[Coke]> do we want to restrict the actual github ids that can even push to 6.c-errata? that's possible with github.

[16:04] <Zoffix> [Coke]: I'd say yes. Simply because otherwise we're relying on people noticing a commit announced via a bot. It shouldn't be easy to change something that's supposedly immutable.

[16:05] <Zoffix> After 6.d release, would be nice to have some stricter rules, or more like concrete checklist for identifying stuff that can be changed in erratas.

[16:05] <perlpilot> b2gills: I'm a wee bit skeptical that you had Perl running on DOS 1.0 or 2.0  :)

[16:06] <b2gills> I didn't say that, I said that is why CON and NUL are in every directory

[16:06] <perlpilot> oh, I conflated your two statements in my head.

[16:07] <b2gills> I think I was using Windows 98 (SE)? when I first found out about Perl

[16:08] <Zoffix> And maybe a separate branch where errata-breaking stuff gets pushed, until the test is changed. I noticed at least 1 time where a change went in and a discussion about whether errata is wrong and should be changed never properly took place, because people couldn't connect together. This way, the change can exist elsewhere until everything is properly decided.

[16:11] <Zoffix> And more bots to watch stuff. After all the grant stuff, gonna add a bot that stresstests nightly.

[16:11] <Zoffix> Will track all the flappers too.

[16:13] <Zoffix> And improve the release bot to also cut Perl6.VIP and also make distro packages.

[16:14] <Zoffix> And improve the release app a bit. Too much typing when doing logs. Gonna add boxes for each commit and a toggle for which section to log it. It'll assemble it at the end automagically.

[16:14] <Zoffix> ZofBot: replace all the things with robots.

[16:14] <ZofBot> Zoffix, ^ *>5 # means 0, 1, 2, 3, 4, 5 [Conjecture: it is possible that, for most of the above operators that take "*" to mean "Inf", we could still actually return a closure that defaults that particular argument to "Inf"

[16:14] <Geth> ¦ rakudo/uncurse: cdd625b68c | TimToady++ | 11 files

[16:14] <Geth> ¦ rakudo/uncurse: unify Match with Cursor

[16:14] <Geth> ¦ rakudo/uncurse:

[16:14] <Geth> ¦ rakudo/uncurse: This just follows the same changes that nqp does for unification.

[16:14] <Geth> ¦ rakudo/uncurse: review: https://github.com/rakudo/rakudo/commit/cdd625b68c

[16:14] <Geth> ¦ rakudo/uncurse: b123ab223b | TimToady++ | 2 files

[16:14] <Geth> ¦ rakudo/uncurse: move Match code from Cursor.pm to Match.pm

[16:14] <Geth> ¦ rakudo/uncurse: review: https://github.com/rakudo/rakudo/commit/b123ab223b

[16:14] <Zoffix> m: say ^ *>5

[16:14] <camelia> rakudo-moar b6838e: OUTPUT: «{ ... }␤»

[16:15] <Zoffix> m: say eager ^ *>5

[16:15] <camelia> rakudo-moar b6838e: OUTPUT: «({ ... })␤»

[16:15] <Zoffix> m: say eager 1..^*>5

[16:15] <camelia> rakudo-moar b6838e: OUTPUT: «(True)␤»

[16:15] <Zoffix> m: say eager 1...^*>5

[16:15] <camelia> rakudo-moar b6838e: OUTPUT: «(1 2 3 4 5)␤»

[16:16] <Zoffix> \o/

[16:18] <Geth> ¦ nqp: 7f949d31f6 | TimToady++ | 11 files

[16:18] <Geth> ¦ nqp: rebootstrap to get constant declarator

[16:18] <Geth> ¦ nqp: review: https://github.com/perl6/nqp/commit/7f949d31f6

[16:18] <Geth> ¦ nqp: 98601ba688 | TimToady++ | 11 files

[16:18] <Geth> ¦ nqp: Revert "rebootstrap to get constant declarator"

[16:18] <Geth> ¦ nqp:

[16:18] <Geth> ¦ nqp: This reverts commit 7f949d31f691fe862dc962d9ab9bff4239f20cac.

[16:18] <Geth> ¦ nqp:

[16:18] <Geth> ¦ nqp: Accidentally did this in master when I intended to do it in a branch.

[16:18] <Geth> ¦ nqp: review: https://github.com/perl6/nqp/commit/98601ba688

[16:20] <TimToady> progress report: the uncurse branch now successfully parses the setting, but blows up somewhere in the precompiler

[16:21] <TimToady> without having done any benchmarks, it appears to run at about the same speed, or possibly a hair faster, but large speedups are not yet expected

[16:21] <TimToady> since it's still doing most of the work that the old MATCH method is doing

[16:22] <TimToady> in any case, not intending to merge this till after release

[16:23] <TimToady> since it may impact downstream modules that have gotten overly chummy with the current internals

[16:26] <Zoffix> It's possible the release will be delayed by 2 days and be cut on April 17th (around noon on Monday, EST time)

[16:26] <TimToady> yes, I picked up the distress call earlier :)

[16:26] <Zoffix> :)

[16:39] <Geth> ¦ nqp/uncurse: 17 commits pushed by (Samantha McVey)++, (Pawel Murias)++, TimToady++

[16:39] <Geth> ¦ nqp/uncurse: review: https://github.com/perl6/nqp/compare/e32ad16b0e...6439b08a94

[16:40] <Zoffix> t/spec/S17-supply/syntax.t flopped

[16:40] <Geth> ¦ rakudo/uncurse: 30 commits pushed by (Zoffix Znet)++, (Julien Simonet)++, (Elizabeth Mattijsen)++, (Samantha McVey)++, (Daniel Green)++, (David Warring)++, lizmat++, TimToady++

[16:40] <Geth> ¦ rakudo/uncurse: review: https://github.com/rakudo/rakudo/compare/b123ab223b...3dbd05631d

[16:46] <MasterDuke> dogbert17_: i had profiled htmlify.p6 a while ago, but i don't have it anymore (and it probably wouldn't be useful by now anyway)

[16:47] <MasterDuke> i just tried now, with --parallel=1 so there wasn't any concurrency, but it immediately segfaults

[16:52] <MasterDuke> valgrind output fwiw https://gist.github.com/MasterDuke17/cdf5793ea077a2dd4dc33503efb29c35

[16:55] <Zoffix> Oh hah. Un-inteded side effect: Geth fix above now also identifies commits that were pushed using GitHub's web interface :)

[16:59] <Geth> ¦ rakudo/uncurse: 6d04acf7dc | TimToady++ | src/core/Attribute.pm

[16:59] <Geth> ¦ rakudo/uncurse: get rid of hacky read of .HOW

[16:59] <Geth> ¦ rakudo/uncurse:

[16:59] <Geth> ¦ rakudo/uncurse: (It was a mystery why we ever needed it in the first place, but for

[16:59] <Geth> ¦ rakudo/uncurse: a while the following method call to .generate_accessor would not

[16:59] <Geth> ¦ rakudo/uncurse: work without it.)

[16:59] <Geth> ¦ rakudo/uncurse: review: https://github.com/rakudo/rakudo/commit/6d04acf7dc

[17:05] <[Coke]> suggested restricted list of committers for 6.c-errata? lizmat, zoffix, jnthn, timtoady?

[17:05] <Zoffix> rakudo's repo members?

[17:06] <Geth> ¦ geth: 7844afdbf1 | (Zoffix Znet)++ | lib/Geth/Plugin/GitHub.pm6

[17:06] <Geth> ¦ geth: Identify when a commit is made using GitHub's web editor

[17:06] <Geth> ¦ geth:

[17:06] <Geth> ¦ geth: Because we can.

[17:06] <Geth> ¦ geth: review: https://github.com/perl6/geth/commit/7844afdbf1

[17:06] <[Coke]> Zoffix: that would have to be coordinated manually, and I can't see that list.

[17:08] <[Coke]> we could create a perl 6 team called "core" or something and give that team privs.

[17:08] <[Coke]> (then we use team management to manage it instead of a list of users in one repo's settings.)

[17:09] <Zoffix> Then I guess yeah, that list is good.    + samcv + usev6 (bartolin) + MasterDuke17 + pmurias + FCO (SmokeMachine) + niner + arnsholt

[17:10] <Zoffix> + stmuck

[17:10] <Zoffix> * stmuk

[17:10] <Zoffix> ZofBot: is that all?

[17:10] <ZofBot> Zoffix, 14159265358979323846264338327950288 Context * Perl still has the three main contexts: sink (aka void), item (aka scalar), and list

[17:12] <Zoffix> Yeah, the core perl6 team sounds good.

[17:13] <MasterDuke> fyi, i'm not a rakudo repo member

[17:13] <[Coke]> as long as your a perl6 org member, 'sfine.'

[17:14] <[Coke]> adding myself to list as well.

[17:16] <MasterDuke> k, just didn't want to slide in under an incorrect assumption. btw, what about moritz and masak also?

[17:17] <[Coke]> sure.

[17:17] <Zoffix> oh yeah

[17:18] <Zoffix> Oh and AlexDaniel

[17:18] <MasterDuke> timotimo?

[17:18] <[Coke]> there, push to 6.c-errata is now restricted to the probably inappropriately named 'core' team.

[17:18] <Zoffix> [Coke]++

[17:18] <Zoffix> Thanks.

[17:18] <Zoffix> Oh, this for for 6.c-errata. Cool.

[17:19] <[Coke]> yup. any perl6 owner/admin can update the "core" team to add more members as needed.

[17:19] <[Coke]> but this should prevent potential thinkos.

[17:19] <Zoffix> OK. Thanks.

[17:38] <[Tux]> This is Rakudo version 2017.03-219-gb6838ee4d built on MoarVM version 2017.03-115-ge8231a30

[17:38] <[Tux]> csv-ip5xs        3.052

[17:38] <[Tux]> test            12.593

[17:38] <[Tux]> test-t           4.942 - 4.996

[17:38] <[Tux]> csv-parser      12.679

[17:40] <Zoffix> buggable: speed 5

[17:40] <buggable> Zoffix, ▁▃▁▁▂ data for 2017-04-10–2017-04-11; range: 4.921s–5.031s; 1% slower

[17:40] <Zoffix> bah

[17:41] <Zoffix> buggable: speed 10

[17:41] <buggable> Zoffix, █▁▇▄█▁▃▁▁▂ data for 2017-04-08–2017-04-11; range: 4.921s–5.413s; 8% faster

[17:41] <Zoffix> There are lies, damned lies, and statistics :)

[17:42] <Zoffix> buggable: speed 4

[17:42] <buggable> Zoffix, ▃▁▁▂ data for 2017-04-10–2017-04-11; range: 4.921s–5.031s; 1% faster

[17:42] <Zoffix> buggable: speed 4000

[17:42] <buggable> Zoffix, Refusing to do more than 100 last entries

[17:42] <Zoffix> buggable: speed 100

[17:42] <buggable> Zoffix, ▁▁▁▁▁▂▁▂▁▁▂▂▁▂▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▁▃▃▂▂▂▂▁▂█▂▂▃▂▁▁▁▁▁▂▁▁▁▁▂▂▂▁▂▁▂▂▁▁▁▁▁▁▆▂▁▁▁▁▁▁▁▂▁▃▁▂▁▁▁▁▁▁▂▃▁▂▂▂▁▂▁▁▂ data for 2017-02-25–2017-04-11; range: 4.788s–7.664s; 4% slower

[17:42] <Zoffix> :(

[17:43] <Zoffix> Well, don't mean much, as far as entire Rakudo is concerned.

[17:57] <dogbert17> some htmlify stats from my home machine: running with --no-highlight takes a bit over 7 minutes, running with highlighting takes 20 !

[17:58] * dogbert17 wonders of node v 4.5 is too old

[18:01] <dogbert17> and 'perl6 --profile htmlify.p6 --no-highlight --sparse=10' segfaults

[18:11] <MasterDuke> dogbert17: i believe the segfaulting is the same as this https://github.com/MoarVM/MoarVM/issues/571

[18:37] <Geth> ¦ roast: a8a968499e | (Daniel Green)++ | S02-types/native.t

[18:37] <Geth> ¦ roast: Too big argument for a native param should throw

[18:37] <Geth> ¦ roast: review: https://github.com/perl6/roast/commit/a8a968499e

[18:46] <dogbert17> Program received signal SIGSEGV, Segmentation fault.

[18:46] <dogbert17> 0xb7c157d5 in MVM_interp_run (tc=0x804c458, initial_invoke=0xb7cee5e9 <toplevel_initial_invoke>, invoke_data=0x80b8b20) at src/core/interp.c:5328

[18:46] <dogbert17> 5328                 tc->cur_frame->params.named_used[GET_UI16(cur_op, 0)] = 1;

[18:47] <dogbert17> MasterDuke: looks familiar?

[18:50] <dogbert17> here's the gist, perhaps something for timotimo: https://gist.github.com/dogbert17/82fd4cb9ce3dafc5f93d63b39f7223d0

[18:51] <MasterDuke> dogbert17: yep

[18:54] <[Coke]> perl6 -MApp::Uni -e 'say uni-gist $_ for qx/tput cuu 1/.comb' # should be able to make this awesomer.

[18:55] <[Coke]> ... wrong window!

[19:01] <MasterDuke> dogbert17: btw, 6m30s no highlighting, 24m20s with highlighting

[19:03] <[Coke]> there is a highlighting -- option to speed things up, not sure if it's the default.

[19:25] <Zoffix> ZofBot: what are your options to speed things up

[19:25] <ZofBot> Zoffix, typename'" !! "No such method '$

[19:26] <Zoffix> m: sub (int $x) { dd $x }(99999999999999999999)

[19:26] <camelia> rakudo-moar b6838e: OUTPUT: «7766279631452241919␤»

[19:26] <Zoffix> MasterDuke: seems it's a failing test you added

[19:26] <Zoffix> c: 2017.03 sub (int $x) { dd $x }(99999999999999999999)

[19:26] <committable6> Zoffix, ¦2017.03: «Cannot unbox 67 bit wide bigint into native integer␤  in sub  at /tmp/LAM1jd3FFL line 1␤  in block <unit> at /tmp/LAM1jd3FFL line 1␤ «exit code = 1»»

[19:27] * Zoffix hopes for a fix before release :)

[19:28] <MasterDuke> Zoffix: whoops, the fix was merged to moar this monring

[19:28] <Zoffix> Ah, we just need a bump https://github.com/MoarVM/MoarVM/pull/578

[19:28] <Zoffix> MasterDuke++

[19:28] <Zoffix> Imma do it

[19:31] <Zoffix> That's another thing I'm gonne make a bot do: version bumps, with stressting stuff first

[19:38] <Zoffix> Might be too slow tho; since I don't have a 24-core VM running 24-7

[19:38] <Zoffix> Hm... I could teach it to power on a VM to do the bump...

[19:39] <Zoffix> Probably takes like half an hour on a 2-core VM

[19:44] <Zoffix> ZOFVM: Files=1238, Tests=133657, 113 wallclock secs (21.17 usr  3.40 sys + 2323.35 cusr 156.45 csys = 2504.37 CPU)

[19:44] <Geth> ¦ nqp: a29b8187e2 | (Zoffix Znet)++ | tools/build/MOAR_REVISION

[19:44] <Geth> ¦ nqp: Bump MoarVM version

[19:44] <Geth> ¦ nqp:

[19:44] <Geth> ¦ nqp: Brings these commits:

[19:44] <Geth> ¦ nqp: https://github.com/MoarVM/MoarVM/compare/2017.03-115-ge8231a30...2017.03-128-gc9ab59c

[19:44] <Geth> ¦ nqp:

[19:44] <Geth> ¦ nqp: c9ab59c Remove arbitrary and small length range check.

[19:44] <Geth> ¦ nqp: 66dd8c9 Merge pull request #578 from MasterDuke17/fix_mp_get_int64_and_mp_get_uint64_for_realz

[19:44] <Geth> ¦ nqp: <…commit message has 11 more lines…>

[19:45] <Geth> ¦ nqp: review: https://github.com/perl6/nqp/commit/a29b8187e2

[19:45] <Geth> ¦ nqp: version bump brought these changes: https://github.com/MoarVM/MoarVM/compare/2017.03-115-ge8231a30...2017.03-128-gc9ab59c

[19:45] <Geth> ¦ rakudo/nom: d0924f1a28 | (Zoffix Znet)++ | tools/build/NQP_REVISION

[19:45] <Geth> ¦ rakudo/nom: Bump NQP Version

[19:45] <Geth> ¦ rakudo/nom:

[19:45] <Geth> ¦ rakudo/nom: NQP version bump brought these commits:

[19:45] <Geth> ¦ rakudo/nom: https://github.com/perl6/nqp/compare/2017.03-59-gcfd1b9a4...2017.03-72-ga29b818

[19:45] <Geth> ¦ rakudo/nom:

[19:45] <Geth> ¦ rakudo/nom: 98601ba Revert "rebootstrap to get constant declarator"

[19:45] <Geth> ¦ rakudo/nom: 7f949d3 rebootstrap to get constant declarator

[19:45] <Geth> ¦ rakudo/nom: <…commit message has 27 more lines…>

[19:45] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/d0924f1a28

[19:45] <Geth> ¦ rakudo/nom: version bump brought these changes: https://github.com/perl6/nqp/compare/2017.03-59-gcfd1b9a4...2017.03-72-ga29b818

[19:45] <timotimo> dogbert17: that might be another thing where disabling INLINE might help?

[19:46] <Zoffix> It's kinda weird that master stresstest runs in 113 secs, but 6.c-errata stresstest—that complains about 20-30 missing files—runs in 121secs

[19:47] <MasterDuke> timotimo: same as the experimenting we did before. disabling jit and spesh get it a tiny bit farther and more info, but stiff immediate segfaults

[19:48] <timotimo> wait, huh, did i just see something else?

[19:48] <timotimo> i saw one where paramnamesused segfaulted

[19:49] <MasterDuke> timotimo: i think that was something you were doing, maybe yesterday?

[19:49] <timotimo> long, long ago

[19:51] <Geth> ¦ roast: e3ce53a142 | (Zoffix Znet)++ (using GitHub Web editor) | S02-types/native.t

[19:51] <Geth> ¦ roast: Don't use non-standard features in tests

[19:51] <Geth> ¦ roast: review: https://github.com/perl6/roast/commit/e3ce53a142

[20:01] <dogbert17> timotimo: you're right setting MVM_SPESH_INLINE_DISABLE=1 seems to fix things

[20:09] <timotimo> i wonder what it is about named arguments that breaks inlines sometimes

[20:09] <MasterDuke> you can profile htmlify.p6 with MVM_SPESH_INLINE_DISABLE=1?

[20:17] <MasterDuke> i've never seen a backtrace like this before: https://gist.github.com/MasterDuke17/dd93c8c57821d3cc16ce8fd98075b2ba

[20:32] <Geth> ¦ rakudo/nom: acaeb367f3 | usev6++ | src/vm/jvm/runtime/org/perl6/rakudo/Binder.java

[20:32] <Geth> ¦ rakudo/nom: [JVM] Fix X::TypeCheck::Binding::Parameter

[20:32] <Geth> ¦ rakudo/nom:

[20:32] <Geth> ¦ rakudo/nom: In order to make the recently (with 0f9f00082b) introduced exception

[20:32] <Geth> ¦ rakudo/nom: X::TypeCheck::Binding::Parameter work, the CallSiteDescriptor had

[20:32] <Geth> ¦ rakudo/nom: to contain the additional argument. This makes a couple of tests

[20:32] <Geth> ¦ rakudo/nom: from roast pass again.

[20:32] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/acaeb367f3

[20:36] <timotimo> MasterDuke: fascinating!

[20:36] <dogbert17> I'm trying to profile now but the profiles get rather big so I'm commenting out some steps

[20:36] <timotimo> MasterDuke: can you give us what thread 1 has in its backtrace?

[20:37] <timotimo> it might be at the end of gc and waiting for other threads to report finished

[20:40] <dogbert17> am a bit confused with how to interpret the 'Routines' page of profiler output

[20:42] <dogbert17> the top few entries all have 'Inclusive time' equal to 100% after that it slowly starts to drop off until there's a big jump

[20:42] <timotimo> yeah

[20:42] <timotimo> you know that inclusive counts not only the routine itself but also all time spent in routines they call?

[20:43] <timotimo> so imagine you have a "main"

[20:43] <timotimo> 99.9% of the program's run time is spent inside of main or something main calls

[20:43] <dogbert17> e.g. I have 'sink' at 97.85% followed by 'process-pod-dir' at 75.78%

[20:43] <timotimo> right, that sink is most likely a very top-level for loop that does most of the work in total

[20:44] <dogbert17> aha, do I then have to drill down that call to see whats's happening

[20:45] <MasterDuke> timotimo: gist updated

[20:46] <MasterDuke> dogbert17: are you using the qt profile viewer? much better for large profiles

[20:46] <dogbert17> haven't tried that

[20:47] <timotimo> i generally just sort by exclusive time, honestly

[20:47] <MasterDuke> https://github.com/tadzik/p6profiler-qt

[20:48] <MasterDuke> i pretty much use it exclusively, until the profile get too big even for it and then switch to SQL

[20:49] <dogbert17> cool, will have to try that

[20:49] <dogbert17> so 'sink' might then refer to a loop

[20:50] <MasterDuke> dogbert17: are you in a 32-bit OS? how old is your rakudo?

[20:50] <tadzik> MasterDuke: since you use it a lot, could I get all possible feedback on what'd you like improved?

[20:50] <tadzik> especially how big is "too big"

[20:51] <tadzik> it's one of the things I'd like to polish a little over the not-qa-hackathon next month

[20:51] <MasterDuke> tadzik: well, i know QT imposes a somewhat arbitrary limit of ~120mb, iirc

[20:51] <timotimo> too big is when the json parser says "i can't deal with files this big"

[20:52] <tadzik> yeah, a move to sql is probably unavoidable

[20:52] <timotimo> yeah

[20:52] <MasterDuke> tadzik: one thing is resizing the columns doesn't always work well

[20:53] <MasterDuke> actually you can't resize at all

[20:54] <MasterDuke> so sometimes even full screen i can't read the file+linenumber in the "Routine" column

[20:56] <timotimo> i wish we had something clever for these looooong hash filenames

[20:56] <timotimo> in the html one

[20:56] <MasterDuke> yeah, those are where it really breaks down

[20:59] <MasterDuke> tadzik: another small thing. the bar in the inclusive and exclusive columns adjusts adjusts its width to fit the percentage+time

[21:01] <MasterDuke> but it just looks a little funny that sometimes the bar's total width differs from one row to the next

[21:01] <timotimo> i wanted to add info about GCs to the qtprofiler some time ago, but handling the model/view stuff qt has come up with is ... annoying

[21:01] <timotimo> and also trying to build a progressbar that renders in three colors ...

[21:01] <tadzik> hmm

[21:01] * tadzik notes

[21:02] <MasterDuke> timotimo: do the regular profiles still lack allocation info and such?

[21:03] <timotimo> yeah :(

[21:03] <timotimo> well, the info is there, but the html app doesn't let you look

[21:04] <timotimo> MasterDuke: do can you figure out how the instrumented_mark_data function crashes exactly?

[21:05] <MasterDuke> tadzik: see what i mean here? http://i.imgur.com/khj3FAU.png

[21:05] <timotimo> wat?

[21:05] <tadzik> yeah, silly indeed :)

[21:05] <timotimo> that's not how i remember the profiler looking

[21:05] <tadzik> though it looks much different here, must be styling

[21:05] <MasterDuke> i'm using KDE fwiw

[21:05] <MasterDuke> on Arch

[21:06] <MasterDuke> timotimo: how do i figure that out?

[21:06] <timotimo> MasterDuke: start by doing "print" on all the local variables

[21:06] <timotimo> tc->prof_data is already null-checked, but maybe it's just a totally invalid pointer somehow?

[21:06] <MasterDuke> does it matter what thread?

[21:07] <timotimo> it should be the one that crashed

[21:09] <MasterDuke> timotimo: gist updated

[21:10] <timotimo> could you also print the foo[0] for each of these so it dereferences?

[21:10] <timotimo> except the null pointer of course

[21:12] <timotimo> hum. zef somehow failed to fetch OO::Monitors

[21:13] <timotimo> *shrug*, i git cloned and locally installed it

[21:14] <MasterDuke> gist updated

[21:16] <timotimo> m: say DateTime.new(1033699633629796)

[21:16] <camelia> rakudo-moar acaeb3: OUTPUT: «+32758607-05-21T23:23:16Z␤»

[21:16] <timotimo> what.

[21:16] <timotimo> hm, might be msec

[21:16] <timotimo> m: say DateTime.new(1033699633629796 / 1000)

[21:16] <camelia> rakudo-moar acaeb3: OUTPUT: «+34726-08-22T03:07:09.796000Z␤»

[21:17] <timotimo> .....

[21:17] <Zoffix> Well, this is unpleasant :| Coming in home to find pieces of drywall all over the hall and half the bathroom wall missing :S

[21:17] <timotimo> :o

[21:17] <timotimo> what kind of ghetto repair job are they doing there

[21:18] <Zoffix> Note: I had no idea anyone would come at all :/

[21:18] <timotimo> MasterDuke: i'm surprised it crashed at that point ... but maybe gcc just totally inlined the other function and therefor you can't properly see it in the debugger?

[21:18] <Zoffix> And I was supposed to work from home tomorrow; now I wonder if I should turn in to the office, so I wouldn't get annoyed by all the banging.

[21:19] <timotimo> MasterDuke: does it crash early enough so that you could run it under valgrind? it usually gives a bit better errors when a segfault happens

[21:23] <MasterDuke> yeah, just a sec

[21:26] <timotimo> otherwise maybe --optimize=1 could help? i can't really see in what way that code is supposed to crash

[21:26] <MasterDuke> would compiling with --optimize=0 be useful at all?

[21:26] <timotimo> usually not much better than 1, i believe

[21:26] <MasterDuke> oh interesting, it just got past the part it always crashes in in valgrind

[21:30] <timotimo> updating zef helped with installing stuff

[21:30] <timotimo> maybe it was an .abspath thing or something

[21:31] <MasterDuke> gist updated with valgrind output, now i'll try recompiling with --optimize=1

[21:32] <timotimo> ouch

[21:33] <timotimo> Pod::To::BigPage is failing tests with an internal-ish error

[21:35] <dogbert17> not something about MAST I hope

[21:35] <timotimo> exactly that

[21:35] <timotimo> mast frame expected but not gotted

[21:36] <dogbert17> https://github.com/perl6/perl6-pod-to-bigpage/issues/1

[21:36] <timotimo> oh, that's when it tries to install

[21:36] <MasterDuke> timotimo: gist updated, filename '--optimize=1' is the new one

[21:37] <timotimo> that makes a lot more sense

[21:37] <MasterDuke> oh, also: (gdb) p node $6 = (MVMProfileCallNode *) 0x0

[21:38] <MasterDuke> oh, could already see that

[21:38] <timotimo> yeah, but only via another pointer deref

[21:38] <timotimo> and nothing in the line that was highlighted did that

[21:39] <timotimo> well, not sure why that'd happen, but i've just put a "&& tc->prof_data->call_graph" into the if guarding that part

[21:40] <MasterDuke> src/profiler/instrument.c:541 ?

[21:41] <timotimo> yu

[21:41] <timotimo> yup

[21:42] <MasterDuke> oh, i tried that and it doesn't die right away

[21:42] <MasterDuke> yeah, just finished normally

[21:43] <timotimo> that's better.

[21:43] <MasterDuke> still dies if i leave off MVM_SPESH_INLINE_DISABLE=1 though

[21:43] <timotimo> yeah

[21:43] <timotimo> that's an entirely different thing :)

[21:48] <MasterDuke> dinner &

[21:54] <tadzik> hmm, I wonder if a profiler could be ported to perl 6 %)

[21:54] <tadzik> and to gtk, probably

[21:55] <timotimo> could be, yeah

[21:55] <tadzik> it'd be pretty cool if it turned out that perl 6 is performant enough where JS wasn'ot

[21:55] <timotimo> DBIish can do sqlite

[21:56] <timotimo> well, it'd also work completely differently

[21:56] <tadzik> yup

[21:56] <tadzik> is there an ncurses module? :)

[21:58] <dogbert17> timotimo: here's an odd thing with the 'perl6' shell script. On my machine it looks like this:

[21:58] <dogbert17> #!/bin/sh

[21:58] <dogbert17> exec /home/dogbert/repos/rakudo/install/bin/moar  --execname="$0" --libpath="/home/dogbert/repos/rakudo/install/share/nqp/lib" --libpath="/home/dogbert/repos/rakudo/install/share/nqp/lib" --libpath="." /home/dogbert/repos/rakudo/perl6.moarvm --nqp-lib=blib "$@"

[21:59] <dogbert17> there are two --libpath's pointing to the same directory

[22:07] <timotimo> that seems fun

[22:39] <MasterDuke> dogbert17: same here

[22:45] <Geth> ¦ geth: 19e44a4a42 | (Zoffix Znet)++ | lib/Geth/Plugin/GitHub.pm6

[22:45] <Geth> ¦ geth: Reword with `when` to avoid duplication

[22:45] <Geth> ¦ geth:

[22:45] <Geth> ¦ geth: And to look cool.

[22:45] <Geth> ¦ geth:

[22:45] <Geth> ¦ geth: Also add word "committed" to message about GitHub editor.

[22:45] <Geth> ¦ geth: review: https://github.com/perl6/geth/commit/19e44a4a42

[22:47] <Geth> ¦ geth: a9df0ea59c | (Zoffix Znet)++ | lib/Geth/Plugin/GitHub.pm6

[22:47] <Geth> ¦ geth: Remove another useless duplication of var

[22:47] <Geth> ¦ geth: review: https://github.com/perl6/geth/commit/a9df0ea59c

[22:50] <Zoffix> huggable: IO kills

[22:50] <huggable> Zoffix, 14 x [✔]; 4 x [✘]: See https://gist.github.com/zoffixznet/0ea1f4db792fc674abdde73f8dd11cc1

[22:50] <Zoffix> Much better outlook on breakage than 12 hours ago :)

[22:51] <Zoffix> Oh, I even missed one merge. It's now 15 vs 3

[22:52] <MasterDuke> (IO Grant)++

[23:01] <Geth> ¦ rakudo/nom: 184d499961 | (Zoffix Znet)++ | src/core/IO/Handle.pm

[23:01] <Geth> ¦ rakudo/nom: [io grant] Make IO::Handle.Supply respect handle's mode

[23:01] <Geth> ¦ rakudo/nom:

[23:01] <Geth> ¦ rakudo/nom: - Use bin mode when then handle is in bin mode

[23:01] <Geth> ¦ rakudo/nom: - Remove :bin argument

[23:01] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/184d499961

[23:03] <Geth> ¦ roast: a4c53b01be | (Zoffix Znet)++ | S16-io/supply.t

[23:03] <Geth> ¦ roast: [io grant] Use bin IO::Handle to test its .Supply

[23:03] <Geth> ¦ roast:

[23:03] <Geth> ¦ roast: As part of the IO Action Plan it was deemed the test was erroneous.

[23:03] <Geth> ¦ roast:

[23:03] <Geth> ¦ roast: .Supply was made to respect the handle's mode[^1], which requires

[23:03] <Geth> ¦ roast: the test to be amended.

[23:03] <Geth> ¦ roast:

[23:03] <Geth> ¦ roast: [1] https://github.com/rakudo/rakudo/commit/184d499961

[23:03] <Geth> ¦ roast: review: https://github.com/perl6/roast/commit/a4c53b01be

[23:05] <Geth> ¦ roast/6.c-errata: b83882bf8e | (Zoffix Znet)++ | S16-io/supply.t

[23:05] <Geth> ¦ roast/6.c-errata: [io grant] Use bin IO::Handle to test its .Supply

[23:05] <Geth> ¦ roast/6.c-errata:

[23:05] <Geth> ¦ roast/6.c-errata: As part of the IO Action Plan it was deemed the test was erroneous.

[23:05] <Geth> ¦ roast/6.c-errata:

[23:05] <Geth> ¦ roast/6.c-errata: .Supply was made to respect the handle's mode[^1], which requires

[23:05] <Geth> ¦ roast/6.c-errata: the test to be amended.

[23:05] <Geth> ¦ roast/6.c-errata:

[23:05] <Geth> ¦ roast/6.c-errata: [1] https://github.com/rakudo/rakudo/commit/184d499961

[23:05] <Geth> ¦ roast/6.c-errata: review: https://github.com/perl6/roast/commit/b83882bf8e

[23:06] <samcv> m: say '\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[\qq[testing]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]

[23:06] <camelia> rakudo-moar acaeb3: OUTPUT: «5===SORRY!5=== Error while compiling <tmp>␤Couldn't find terminator ] (corresponding [ was at line 1)␤at <tmp>:1␤------> 3ting]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]7⏏5<EOL>␤    expecting any of:␤        ]␤»

[23:06] <samcv> ]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]'

[23:06] <samcv> damn cut ofgf

[23:06] <samcv> that apparently works

[23:07] * Zoffix doesn't see why it wouldn't :)

[23:07] <samcv> m: '\q[\q[\q[\q[\q[\q[\q[\q[\q[\q[\q[testing]]]]]]]]]]]'

[23:07] <camelia> rakudo-moar acaeb3: ( no output )

[23:07] <samcv> m: say '\q[\q[\q[\q[\q[\q[\q[\q[\q[\q[\q[testing]]]]]]]]]]]'

[23:07] <camelia> rakudo-moar acaeb3: OUTPUT: «testing␤»

[23:07] <samcv> it's insane though

[23:07] <Zoffix> m: say '\qq[\q[\qq[\q[this works too!]]]]'

[23:07] <camelia> rakudo-moar acaeb3: OUTPUT: «this works too!␤»

[23:07] <samcv> how many levels until i use up all my memory though

[23:08] <samcv> m: my $head = Q{\q[}; my $tail = ']'; my $b = 10; my $i = 0; sub funct ($in) { ++$i > $b ?? $head ~ $in ~ $tail !! funct($head ~ $in ~ $tail) }; say "'" ~ funct("testing") ~ "'"

[23:08] <camelia> rakudo-moar acaeb3: OUTPUT: «'\q[\q[\q[\q[\q[\q[\q[\q[\q[\q[\q[testing]]]]]]]]]]]'␤»

[23:08] <samcv> that is the question

[23:08] <samcv> m: my $head = Q{\q[}; my $tail = ']'; my $b = 10000; my $i = 0; sub funct ($in) { ++$i > $b ?? $head ~ $in ~ $tail !! funct($head ~ $in ~ $tail) }; say ("'" ~ funct("testing") ~ "'").EVAL

[23:08] <camelia> rakudo-moar acaeb3: OUTPUT: «testing␤»

[23:09] <samcv> for some reason i find that very amusing

[23:10] <timotimo> samcv: are you going to add some html to the gh-pages of the rakudo-appimage project?

[23:10] <Zoffix> m: say $*DEFAULT-READ-ELEMS

[23:10] <camelia> rakudo-moar 184d49: OUTPUT: «65536␤»

[23:10] <samcv> maybe

[23:10] <Zoffix> So, are we making that part of the language?

[23:11] <Zoffix> The $*DEFAULT-READ-ELEMS var

[23:11] <samcv> well yes eventually

[23:11] <samcv> what is that...

[23:11] <Zoffix> Reworded: Are we making $*DEFAULT-READ-ELEMS part of the language and make it default to 65536?

[23:11] <Zoffix> It's used in a bunch of places in IO. I'm documenting stuff. So, should I document $*DEFAULT-READ-ELEMS or not.

[23:12] <samcv> but.. what dose it do

[23:12] <Zoffix> $ grep -FR '$*DEFAULT-READ-ELEMS' src/

[23:12] <Zoffix> src/core/IO/Handle.pm:    method readchars(Int(Cool:D) $chars = $*DEFAULT-READ-ELEMS) {

[23:13] <Zoffix> src/core/IO/Handle.pm:    method Supply(IO::Handle:D: :$size = $*DEFAULT-READ-ELEMS --> Supply:D) {

[23:13] <Zoffix> src/core/IO/Handle.pm:Rakudo::Internals.REGISTER-DYNAMIC: '$*DEFAULT-READ-ELEMS', {

[23:13] <Zoffix> src/core/IO/Socket.pm:            my $r := nqp::readfh($!PIO, nqp::decont(buf8.new), $*DEFAULT-READ-ELEMS);

[23:13] <samcv> hmm interesting

[23:14] <samcv> m: say $*DEFAULT_READ_ELEMS.^methods

[23:14] <camelia> rakudo-moar 184d49: OUTPUT: «(DESTROY AT-POS AT-KEY defined handled Int Num Numeric mess sink CALL-ME FALLBACK STORE new Bool Str gist perl exception backtrace AT-POS AT-KEY BIND-KEY ASSIGN-KEY STORE iterator sink unshift chrs gist BIND-POS Numeric Str new ords chomp push FALLBACK c…»

[23:14] <Zoffix> Looking at that... I'm gonna go with "no" as the answer to my question.

[23:14] <samcv> seems internalish

[23:14] <Zoffix> And we should nix it to not pay the dynamic price.

[23:14] <Zoffix> I think it was sorta meant as a macro or something.

[23:16] <samcv> ok 100000 levels gets to 5GB of ram then gets killed cause my ulimit setting

[23:16] <Zoffix> :o

[23:16] <samcv> but 10000 levels is much less ram maybe 750MB

[23:16] <timotimo> samcv: i wonder if .^ will neglect to vivify the dynamic var there

[23:16] <timotimo> m: say $*DEFAULT_READ_ELEMS; say $*DEFAULT_READ_ELEMS.^methods

[23:16] <camelia> rakudo-moar 184d49: OUTPUT: «Dynamic variable $*DEFAULT_READ_ELEMS not found␤  in block <unit> at <tmp> line 1␤␤Actually thrown at:␤  in block <unit> at <tmp> line 1␤␤»

[23:17] <timotimo> m: say $*DEFAULT-READ-ELEMS; say $*DEFAULT-READ-ELEMS.^methods

[23:17] <camelia> rakudo-moar 184d49: OUTPUT: «65536␤(Int Num Rat FatRat abs Bridge chr sqrt base polymod expmod is-prime floor ceiling round lsb msb narrow Range atanh sign asech sin tan atan2 acosech truncate asinh conj acosh pred asec cosec acotan cosh acos acosec sech unpolar log exp roots cota…»

[23:17] <timotimo> that's why

[23:17] <timotimo> samcv: your .^methods was equivalent to $*WHAT_EVEN_IS_THIS.^methods

[23:17] <samcv> heh

[23:17] <samcv> m: $*WHAT_EVEN_IS_THIS.^methods.say

[23:17] <camelia> rakudo-moar 184d49: OUTPUT: «(DESTROY AT-POS AT-KEY defined handled Int Num Numeric mess sink CALL-ME FALLBACK STORE new Bool Str gist perl exception backtrace AT-POS AT-KEY BIND-KEY ASSIGN-KEY STORE iterator sink unshift chrs gist BIND-POS Numeric Str new ords chomp push FALLBACK c…»

[23:18] <timotimo> i.e. Failure.^methods

[23:18] <samcv> do we have a max variable name length

[23:18] <samcv> probably not right

[23:18] <timotimo> i'm not aware of one

[23:18] <samcv> good

[23:19] <timotimo> m: use MONKEY-SEE-NO-EVAL; EVAL 'my $' ~ "foo" x 10000 ~ ' = 1';

[23:19] <camelia> rakudo-moar 184d49: ( no output )

[23:19] <timotimo> m: use MONKEY-SEE-NO-EVAL; EVAL 'my $' ~ "foo" x 10000 ~ ' = 1; say $' ~ "foo" x 10000;

[23:19] <camelia> rakudo-moar 184d49: OUTPUT: «1␤»

[23:19] <timotimo> 10k graphs ought to be enough for anybody

[23:20] <Zoffix> Bill Gates said that!

[23:20] <Zoffix> Oh wait, that was memory :}

[23:20] <samcv> graphemes, memory. same thing

[23:21] <timotimo> only for people with photographic memory

[23:22] <samcv> well 100k graphs works

[23:22] <timotimo> that ought to be enough

[23:23] <samcv> naw not even

[23:23] <samcv> 10 million works too

[23:23] <timotimo> do we want an easter egg for when you use a very specific number of some significance?

[23:23] <samcv> heh

[23:23] <samcv> timotimo, if the name is long enough the name is the variable ;)

[23:23] <samcv> well stores more data

[23:23] <samcv> ha

[23:24] <timotimo> you can grab the name via .VAR.name

[23:24] <timotimo> so, yeah, probably!

[23:25] <samcv> ok 100_000_000 million is like

[23:25] <samcv> taking a realllyyy long time

[23:25] <samcv> brb

[23:25] <timotimo> hahaha

[23:25] <samcv> maybe will be done when i'm back

[23:25] <timotimo> well, it's a few megabytes, so ... :)

[23:25] <samcv> xoh wait it finished already

[23:25] <timotimo> what's its maxresidentk: )

[23:25] <samcv> going for 1_000_000_000 then

[23:25] <samcv> oh. no.

[23:25] <samcv> MoarVM panic: Memory allocation failed; could not allocate 8000000076 bytes

[23:25] <samcv> T_T T_T

[23:25] <timotimo> okay!

[23:26] <timotimo> get some swap on a very big disk

[23:26] <samcv> k

[23:26] <samcv> we should make moarvm more efficient

[23:26] <samcv> to enable longer variable names

[23:26] <samcv> brb actually tho

[23:26] <timotimo> that's clearly very important

[23:29] <MasterDuke> "we should make moarvm more efficient" - can't argue with that

[23:29] <MasterDuke> "to enable longer variable names" - eh

[23:32] <samcv> maybe it will be a side effect

[23:32] <samcv> brb

[23:32] <MasterDuke> ooo, but can your variable name be an actual Perl 6 program when EVALed?

[23:34] <timotimo> m: my ::('oh lord why is this variable so crazy') = 10

[23:34] <camelia> rakudo-moar 184d49: OUTPUT: «5===SORRY!5=== Error while compiling <tmp>␤Malformed my␤at <tmp>:1␤------> 3'oh lord why is this variable so crazy')7⏏5 = 10␤»

[23:34] <MasterDuke> what's the word i'm looking for? when a problem prints out it's own source code

[23:34] <timotimo> quine

[23:34] <MasterDuke> right

[23:34] <timotimo> named after mister quine, all he could ever say was his whole genome sequence

[23:35] <MasterDuke> heh

[23:44] <MasterDuke> timotimo: now that you've solved that one bug, any idea on the spesh bug?

[23:44] <timotimo> nah, it's probably a whole bit different flavour to it

[23:46] <MasterDuke> if i do a profile with MVM_SPESH_INLINE_DISABLE=1, is that at all useful?

[23:46] <timotimo> yeah

[23:46] <timotimo> performance will differ a bit

[23:46] <timotimo> you can check what percentage difference it makes by running it without profiling

[23:47] <samcv> why does travis have the HAS_JOSH_K_SEAL_OF_APPROVAL env var

[23:47] <timotimo> like, not profiling but timing. once with and once without inline

[23:47] <timotimo> samcv: monkey see no env var?

[23:47] <samcv> can't avoid it with travis

[23:48] <MasterDuke> huh. i profile with MVM_SPESH_INLINE_DISABLE=1, --no-highlight, and --sparse=50, which created a 19mb .json profile, but the qt viewer gets killed when i try to open it

[23:49] <timotimo> oh, now here's something interesting

[23:49] <timotimo> you can definitely debug that though

[23:50] <MasterDuke> with what?

[23:50] <timotimo> well, gdb i guess?

[23:50] <MasterDuke> huh, only 308486 lines in the sql profile output

[23:51] <timotimo> well, turning off inlining doesn't make there be any fewer routines

[23:51] <timotimo> and we record functions post-inline as a different piece either way

[23:52] <timotimo> i.e. a normal call differs only from an inlined call by having a "it was inlined" bit set

[23:52] <timotimo> so the call graphs should be the same size

[23:52] <MasterDuke> i'm just surprised the qt viewer can't do such a small file

[23:53] <timotimo> well, it might be choking on some value? null pointer dereference or something?

[23:53] <timotimo> i don't think you've told us what way it actually dies in?

[23:53] <MasterDuke> will gdb help if the OOM killer is what's killing it?

[23:54] <MasterDuke> yep, it's the OOM killer

[23:54] <mst> perhaps it's time to provision some swap?

[23:55] <timotimo> oh, haha

[23:55] <timotimo> well, in that case try a memory debugger or something

[23:55] <MasterDuke> i'm using this as just one part of the justification to upgrade my system

[23:55] <timotimo> like, what was it, heaptrack?

[23:57] <MasterDuke> mst: i've run without swap for a long time now. adds a sense of danger and excitement to my life

[23:57] <timotimo> hah

[23:58] <timotimo> i have zram swap and it's nice

[23:58] <mst> I tend to provision my dev systems to look as much like production as possible

[23:58] <mst> 'danger and excitement' are not geatures

[23:58] <mst> nor, indeed, are they features

[23:58] <MasterDuke> heaptrack overview: http://i.imgur.com/IdwUa0E.png

[23:58] <timotimo> wow

[23:59] <timotimo> i don't think it should generate that much data

[23:59] <MasterDuke> mst: in complete agreement at work. at home i'm more freewheeling
