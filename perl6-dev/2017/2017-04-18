[00:00] <MasterDuke_> don't think i tried just removing that check altogether though...

[00:01] <samcv> do i need qt5-base

[00:01] <MasterDuke_> i think? it was a while ago i was messing around with that

[00:01] <samcv> ok. i checked it out of the svn

[00:02] <samcv> just search for 1<<27?

[00:03] <MasterDuke_> it's line 639 of some file

[00:03] <samcv> that's very specific

[00:04] <MasterDuke_> going off of what timotimo pasted, i assume he grabbed the line number from vim

[00:04] <samcv> oh

[00:04] <samcv> ok i found 1<<27

[00:04] <samcv> on exactly that line. heh

[00:05] <timotimo> here comes the hang

[00:07] <timotimo> cpu usage has drastically decreased, unsurprisingly

[00:07] <samcv> nice

[00:07] <timotimo> what's nice about that? :D

[00:07] <samcv> the cpu usage decreased

[00:07] <timotimo> well ... yeah ... because it's waiting for data to be shoveled in from swap and back again

[00:08] <samcv> oh. lol.

[00:08] <samcv> !

[00:08] <timotimo> d'oh, it's reaching the amount of swap i have soon

[00:08] <timotimo> 6.7g of 8.25g

[00:08] <samcv> uh oh. you need more swap

[00:08] <timotimo> i do

[00:08] <samcv> i used up 16GB maybe more

[00:08] <samcv> no more than 18GB tho

[00:08] <timotimo> writing profiler output!!!

[00:09] <samcv> yep :)

[00:21] <samcv> MasterDuke_, gonna try removing all the checks that seem sane to remove

[00:21] <samcv> cause some things like failure to realloc or malloc can trigger documenttoolarge errors, so i didn't touch those ones though

[00:21] <MasterDuke_> in qt?

[00:21] <samcv> yes

[00:21] <samcv> but commented out a few places that seemed arbitrary

[00:22] <MasterDuke_> interested to see what you find

[00:22] <timotimo> i want to go to bed soon ... but the thing is still running :|

[00:22] <samcv> go to bed. it might be done in an hour

[00:22] <timotimo> hah.

[00:23] <timotimo> in theory it'd be faster because i'm throwing out list items and hash keys/values while creating the json

[00:23] <timotimo> so consecutive gc runs will have slightly less work

[00:23] <timotimo> oh, huh, the json file is still at 0 bytes?

[00:23] <MasterDuke_> if it's better can do the same for to_sql

[00:24] <samcv> argh still too large document

[00:24] <timotimo> samcv: one idea is to switch from a JSONDocument-like API to a stream-like API

[00:24] <timotimo> where the size of the document is practically irrelevant

[00:24] <samcv> yeah

[00:25] <samcv> let's just do a memory dump

[00:25] <samcv> like microsoft word does

[00:25] <samcv> sorry that made only 1/4 of sense. ignore that

[00:25] <timotimo> kch kch kch

[00:27] <geekosaur> word hasn't done that in a while

[00:27] <geekosaur> I am pretty sure the xml-ish format they use now is not what they have in memory :)

[00:27] <samcv> yeah they don't anymore

[00:27] <timotimo> nah, they still dump the memory, but they put some random xml tags around pieces of it :P

[00:28] <samcv> hahaha

[00:28] <geekosaur> also they've actually been addressing the "but it doesn't behave the same on windows vs. mac"

[00:30] <geekosaur> (I still suspect it's because they switched to the mac version as the main one... because the old one was a horrid trainwreck that derailed development of windows 8 because some of their streamlining uncovered bugs that had been patched around in the OS during the "office is our cash cow, office devs an do anything they want" phase.)

[00:31] <timotimo> i think swap usage is slowly dropping

[00:31] <samcv> just wait

[00:31] <timotimo> it'll end up being at like 0.05% cpu usage

[00:31] <samcv> i had that happen then after it went down for a while it went back up. has it actually started outputting the json?

[00:31] <timotimo> let's see.

[00:31] <timotimo> nah, still 0 bytes

[00:32] <timotimo> doesn't help that i'm also creating a new swapfile on one of the disks where there's already an active swapfile

[00:34] <timotimo> oh wow

[00:34] <timotimo> why not update my laptop's packages on the side

[00:34] <timotimo> just a download of 1.3 gigs

[00:40] <timotimo> Disk Requirements:

[00:40] <timotimo> At least 169MB more space needed on the / filesystem.

[00:44] <timotimo> i've got so much swap now

[00:58] <MasterDuke_> .tell pmurias i think NQP_VERBOSE_EXCEPTIONS=1 is what gives better jvm errors

[00:58] <yoleaux> MasterDuke_: I'll pass your message to pmurias.

[00:58] <MasterDuke_> .tell [Coke] i think NQP_VERBOSE_EXCEPTIONS=1 is what gives better jvm errors

[00:58] <yoleaux> MasterDuke_: I'll pass your message to [Coke].

[00:59] <MasterDuke_> .tell TimToady i think NQP_VERBOSE_EXCEPTIONS=1 is what gives better jvm errors

[00:59] <yoleaux> MasterDuke_: I'll pass your message to TimToady.

[01:01] <samcv> well i got it to 14% of my mem usage (qt)

[01:01] <samcv> and then i get too large document error

[03:21] <MasterDuke_> m: say 1:

[03:21] <camelia> rakudo-moar 241831: OUTPUT: «HERE:␤- sym: :␤- O: ␤␤1␤»

[03:21] <MasterDuke_> bisectable6: say 1:

[03:21] <bisectable6> MasterDuke_, Bisecting by output (old=2015.12 new=241831e) because on both starting points the exit code is 0

[03:21] <bisectable6> MasterDuke_, bisect log: https://gist.github.com/32e2abe320c388f3c43338b23eafa2b7

[03:21] <bisectable6> MasterDuke_, There are 20 candidates for the first “new” revision. See the log for more details

[03:22] <MasterDuke_> bisectable6: old=2017.03 say 1:

[03:22] <bisectable6> MasterDuke_, Bisecting by output (old=2017.03 new=241831e) because on both starting points the exit code is 0

[03:22] <bisectable6> MasterDuke_, bisect log: https://gist.github.com/8ec0603f10e4f5573e85f8dc4ca9c07e

[03:22] <bisectable6> MasterDuke_, There are 20 candidates for the first “new” revision. See the log for more details

[03:23] <MasterDuke_> c: 2017.03,HEAD say 1:

[03:23] <committable6> MasterDuke_, ¦2017.03: «1» ¦HEAD(241831e): «HERE:␤- sym: :␤- O: ␤␤1»

[03:25] <MasterDuke_> this ^^^ was talked about over in #perl6, https://github.com/rakudo/rakudo/blob/nom/src/Perl6/Grammar.nqp#L4504 introduced in https://github.com/rakudo/rakudo/commit/cdd625b68c24fd68789be2890a418ca1c4018b7b

[03:35] <Geth> ¦ nqp: e843d339bc | MasterDuke17++ | docs/ops.markdown

[03:35] <Geth> ¦ nqp: Alphabetize the ops and use consistent wording

[03:35] <Geth> ¦ nqp: review: https://github.com/perl6/nqp/commit/e843d339bc

[03:46] <Geth> ¦ rakudo/nom: c9ebfc2023 | TimToady++ | src/Perl6/Grammar.nqp

[03:46] <Geth> ¦ rakudo/nom: remove inadvertent debugging line

[03:46] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/c9ebfc2023

[03:53] * TimToady guesses that probably snuck in at some point due to hitting 'u' one too many times in vim, since it certainly wasn't part of the uncurse effort...

[03:53] <yoleaux> 02:42Z <MasterDuke_> TimToady: if you backlog here https://irclog.perlgeek.de/perl6/2017-04-18#i_14443061, was this intended?

[03:55] <TimToady> probably one of the earlier 'useless use' thingies that I backed into

[03:56] <TimToady> course, I'm starting to get to the age where I can just blame brainrot...

[05:37] <nine> YEAH, YEAH, YEAH, YEAH! I just managed for the first time to run Inline::Perl5's test suite using moarvm, nqp, rakudo _and_ Inline::Perl5 installed from RPM packages.

[05:37] <nine> This is it! The culmination of 16 months of working on precomp stuff

[05:38] <nine> Yesterday evening I was already so close. I got the RPM to work with my manually compiled rakudo but not with the one installed from the RPM. Turns out I had a workaround in that package that deleted the precomp files for CompUnit::Repository::Staging itself.

[05:39] <nine> Looks like I don't need that workaround anymore :)

[05:43] <nine> Now the work on packaging Perl 6 modules and submitting to openSUSE can start in earnest. And now that deployment is sorted out we can start using Perl 6 and Inline::Perl5 in production at work.

[05:44] <samcv> yay!

[05:44] <samcv> nine, yay

[05:46] <bartolin> very nice, nine++

[05:59] <TimToady> do we need a point release?  prolly need one for my debugging flub anyway...

[06:00] <TimToady> people are likely to have used 'method $obj: @args' in the ecosystem

[06:02] * TimToady is a little surprised no test caught this, but I guess the harness just tends to ignore stderr

[06:04] <samcv> ok so i got my appimage build attempting to install every module

[06:04] <samcv> into an appimage

[06:04] <nine> TimToady: no, I'm lucky. The workaround was in my .spec file :)

[06:05] <samcv> still going https://travis-ci.org/samcv/rakudo-appimage/jobs/223029739#L2701 not sure how long will take to finish or the best way to record which were uninstallable.

[06:05] <TimToady> darn, I was hoping I wouldn't be the only reason for a point release :)

[06:05] <samcv> so i can make some sort of uh. ecosystem warning system idk

[06:05] <bartolin> .tell Zoffix unfortunatly 9d8e391f3b (rakudo) does not work on JVM: Unknown encoding 'utf8-c8'. One option would be to add a workaround for JVM there ...

[06:05] <yoleaux> bartolin: I'll pass your message to Zoffix.

[06:06] <samcv> it installs them not as an appimage but before it's made btw. so that affects the results not

[06:06] <samcv> i guess i can make it a gh-pages thing like i did for the appimages and for moarvm coverage

[06:06] <samcv> hopefully travis ci doesnn't stop the build before everything is installed. if it does i'll probably have to split the build up or something

[06:14] <samcv> also nine you know about modules. is there a file that would be best to look at after i have tried to install all the modules, so i can get a list of what actualy installed and compare it to the full list?

[06:28] <TimToady> .tell Zoffix We'll probably need a point release before doing Star, 'cuz I screwed up the 'new Foo: ...' syntax by leaving a debugging line in (after worrying about all the heavy stuff, wouldn'tchya know it'd be something stupid)

[06:28] <yoleaux> TimToady: I'll pass your message to Zoffix.

[06:29] <samcv> ruh roh

[06:31] <samcv> TimToady, what's a good percentage of eco modules acceptable to be failing

[06:31] <samcv> out of the total

[06:31] <samcv> i mean 0 would be nice but seems a bit unrealistic

[06:31] <TimToady> um, 0 would be good :0

[06:31] <TimToady> I suppose it depends on why they're failing

[06:32] <samcv> well they shouldn't fail. i mean

[06:32] <samcv> not a good thing

[06:32] <TimToady> if they're failing due to extraneous debugging info, well, I know where that came from :)

[06:32] <samcv> hm

[06:32] <TimToady> if they don't like the new I/O for some reason, that's something else

[06:32] <samcv> so far IO::Prompter, Math::ContinuedFractions, List::Utils, Text::Diff, BioInfo:ver('0.4.3'):auth('Matt Oates'), Math::PascalTriangle:ver('0.1.0'), DateTime::Math Flower, Hinges

[06:33] <TimToady> if they happen to think Cursor and Match are different types, well...

[06:33] <samcv> are failing. out of those travis has tested

[06:33] <samcv> https://travis-ci.org/samcv/rakudo-appimage/jobs/223029739#L3524 what is this. possibly recent change?

[06:34] <samcv> t/math.t ..1/17Ambiguous call to 'infix:<->'; these signatures all match:

[06:34] <samcv> :(DateTime:D \a, DateTime:D \b)

[06:34] <samcv> :(DateTime:D $a, DateTime:D $b)

[06:34] <samcv> that doesn't sound that great

[06:36] <TimToady> dunno, but if DateTime is malfing, that could easily take down a number of other modules

[06:36] <samcv> yea

[06:36] <[Tux]> This is Rakudo version 2017.04-2-gc9ebfc202 built on MoarVM version 2017.04

[06:36] <[Tux]> csv-ip5xs        3.182

[06:36] <[Tux]> test            12.651

[06:36] <[Tux]> test-t           5.111 - 5.118

[06:36] <[Tux]> csv-parser      13.127

[06:36] <RabidGravy> BTW, I testted all of mine on Saturday so that's about 7% passing :)

[06:36] <samcv> hehehe you have 7% of all modules?

[06:37] <samcv> o.O

[06:37] <TimToady> well, we could've broken them since Saturday :)

[06:38] <samcv> some of the have no plan in tap output

[06:38] <samcv> list::util has t/08-combinations.t ....42/?Type check failed in binding; expected Positional but got Seq ((["a", "b", "c"],

[06:38] <RabidGravy> yeah 7.63% it appears ;-)

[06:38] <samcv> heh my job has now been terminated X|

[06:39] <samcv> will have to randomize which modules go each time. or maybe split them up between two jobs idk

[06:39] <RabidGravy> it was over 10% at some point last year, but I slowed down

[06:43] <TimToady> well, maybe we'd better see the downstream fallout over the next day or two; a lot of people hacked on a lot of things over the last month

[06:43] <TimToady> RabidGravy: did yours all work, or did you have to tweak 'em?

[06:46] <RabidGravy> a couple of tweaks, the symlink semantics bit in one place and there was something with IO::Path.append that needed more coercing

[06:46] <TimToady> Math::ContinuedFractions appears not to download from github

[06:46] <RabidGravy> nothing like "lexical import" though

[06:47] <TimToady> huh, can't get IO::Prompter either, maybe my zef is screwed up or too old

[06:49] <TimToady> or maybe github is screwy at the moment

[06:56] <samcv> well it installed or tried to install 95 modules

[06:56] <samcv> so that's not bad for one travis run. we have 700 right?

[06:56] <samcv> just gonna need at least 7 travis builds XD

[06:59] <samcv> 86 pass and 11 fail. so

[06:59] <samcv> that's not good statistics so far :O

[07:03] <nine> samcv: I'm not sure I understood your question

[07:03] <samcv> uhm. there's a json file that keeps track of what's installed right. as far as modules goes?

[07:03] <samcv> here's the test results https://gist.github.com/samcv/835b0640ef91c3f3617f34771e230b6e

[07:04] <RabidGravy> 812

[07:04] <samcv> so that's an 8.8% failure rate out of the modules it had time to install

[07:04] <samcv> RabidGravy, modules total?

[07:06] <RabidGravy> yeah

[07:06] <RabidGravy> phew, none of mine in the FAIL list

[07:06] <RabidGravy> ;-)

[07:07] <samcv> time to uhm. i guess. split it into 10 builds

[07:07] <samcv> i'll sort the modules alphabetically and then choose 1/10 of a section to try and install

[07:07] <nine> samcv: Well there's a dist's meta data that's stored in the repo. But I'm not sure what exactly you're after. What do you mean by "full list"?

[07:07] <samcv> what is installed

[07:08] <samcv> a list of everything installed i can process programically

[07:08] <samcv> though i could do zef list --installed i guess. maybe that's the best way? but i do want to know the file it's stored in too. since that with help with other things

[07:09] <nine> m: say $*REPO.next-repo.installed>>.meta

[07:09] <camelia> rakudo-moar c9ebfc: OUTPUT: «({auth => github:niner, author => github:niner, authors => [Stefan Seifert], depends => [LibraryMake], description => Use Perl 5 code in a Perl 6 program, files => {resources/libraries/p5helper => 2F6B236B77BC9D0E77C1B73DBAFA53E81D238E83.so}, license => …»

[07:09] <nine> samcv: ^^^

[07:12] <samcv> thx

[07:12] <TimToady> IO::Prompter is using ancient syntax ('as') in a signature

[07:13] <TimToady> Math::ContinuedFractions appears to just be producing wrong results

[07:14] <TimToady> Text::Diff is failing with: No such method 'succ' for invocant of type 'List'

[07:15] <TimToady> so seems to be a variety of reasons

[07:16] <samcv> yeah

[07:39] <Zoffix> .

[07:39] <yoleaux> 06:05Z <bartolin> Zoffix: unfortunatly 9d8e391f3b (rakudo) does not work on JVM: Unknown encoding 'utf8-c8'. One option would be to add a workaround for JVM there ...

[07:39] <yoleaux> 06:28Z <TimToady> Zoffix: We'll probably need a point release before doing Star, 'cuz I screwed up the 'new Foo: ...' syntax by leaving a debugging line in (after worrying about all the heavy stuff, wouldn'tchya know it'd be something stupid)

[07:40] <Zoffix> Cool. I don't think NeuralAnomaly knows how to do point releases, so I get to keep my skills sharp by doing it... *dun-tun-tun*... by hand!

[07:42] <Zoffix> .tell AlexDaniel something's wrong with committable6. Doesn't respond. I tried running ./verify-and-unfuck but it seems to just sit there; I tried deleting the "deleteme" file; but nothign helped

[07:42] <yoleaux> Zoffix: I'll pass your message to AlexDaniel.

[07:44] <nine> Oh and once we've got all Perl 6 modules in the Open Build Service, we could use that for smoke testing the whole ecosystem. Because the build service will rebuild packages on changes to their dependencies.

[07:44] <Zoffix> Heh. Google doesn't want us to do a point release apparently: "Starting VM instance "perlbuild2" failed. Error: The zone 'projects/perl6-build/zones/us-east1-b' does not have enough resources available to fulfill the request. Try a different zone, or try again later."

[07:47] <Zoffix> AlexDaniel: you have a robomessage

[07:47] <AlexDaniel> .

[07:47] <yoleaux> 07:43Z <Zoffix> AlexDaniel: something's wrong with committable6. Doesn't respond. I tried running ./verify-and-unfuck but it seems to just sit there; I tried deleting the "deleteme" file; but nothign helped

[07:48] <Zoffix> And it pinged out like 1 min ago

[07:48] <AlexDaniel> hmm these aren't the files you should use for such situation, actually XD

[07:48] <Zoffix> AlexDaniel: also, is there a ./stop-all ?

[07:48] <AlexDaniel> dammit I have to clean it up

[07:48] <Zoffix> :}

[07:49] <AlexDaniel> Zoffix: yes, it is ｢rakudobrew build moar｣

[07:50] <Zoffix> :o

[07:50] <AlexDaniel> hm, it failed it on HEAD

[07:50] <AlexDaniel> which was 4 hours ago

[07:51] <AlexDaniel> e: say 42

[07:51] <AlexDaniel> ah-ha

[07:53] <samcv> i can't report issues here https://github.com/colomon/io-prompter

[07:53] <samcv> there's no issues tab X|

[07:54] <Zoffix> hm... I see no option to switch zone for my VM... :S

[07:54] <AlexDaniel> c: HEAD^ say 42

[07:54] <committable6> AlexDaniel, ¦HEAD^: «42»

[07:54] <AlexDaniel> c: HEAD say 42

[07:54] <committable6> AlexDaniel, ¦HEAD(c9ebfc2): «No build for this commit»

[07:54] <Zoffix> samcv: just make a fake PR and describe issue there, along with saying Issues tab is disabled

[07:55] <AlexDaniel> alright, this should fix itself ≈3 minutes

[07:55] <Zoffix> c: 2017.04 class Foo {}; $ = new Foo:

[07:55] <committable6> Zoffix, ¦2017.04: «HERE:␤- sym: :␤- O: ␤»

[07:55] <AlexDaniel> oh noes

[07:55] <Zoffix> ehehe. This is so funny :)

[07:55] <AlexDaniel> this is… horrible actually

[07:56] <Zoffix> It's a new feature, to... um... discourage people from using that notation :P

[07:57] <AlexDaniel> are we going to have a 2017.04.01 to fix that?

[07:58] <Zoffix> Yup. As soon as manage to power on a VM

[07:59] <Zoffix> It's 4AM, I guess everyone's running nightly stuff, which is why the zone is too busy :|

[08:00] * Zoffix tries creating a new VM in another zone, hoping to hook up the same drive to it

[08:03] <Zoffix> Don't see an option. Stupid google

[08:07] <samcv> omg this module is so bad

[08:07] <samcv> Type check failed in binding to parameter '$in'; expected IO but got <anon|94140617225856> (<anon|94140617225856>...)

[08:08] <samcv> io::prompter. with `:d(:$default) as Str = "",` as a parameter

[08:09] <samcv> at least fixing that parameter makes more than 0 tests pass?

[08:10] <AlexDaniel> e: say 42

[08:10] <evalable6> AlexDaniel, rakudo-moar c9ebfc202: OUTPUT: «42»

[08:10] <AlexDaniel> alright

[08:10] <AlexDaniel> Zoffix: thanks!

[08:13] <Zoffix> ugh, this is really annoying.

[08:14] <Zoffix> No easy way to move to new zone or even make the VM non-ephemeral.

[08:15] <Zoffix> or detach a drive from one VM to use on another

[08:17] <samcv> ok will have to fix some IO related stuff in this module

[08:19] <samcv> arghhh

[08:19] <Zoffix> ... "Starting VM instance "perlbuild2-non-preemptive" failed. Error: A required resource is not available."

[08:19] <Zoffix> And it deleted the VM I was trying to create.. wtf :(

[08:19] <samcv> class StubIO is IO

[08:20] <samcv> ok. i think i can safely change these to IO::Handle's too

[08:23] <samcv> now all but one test file works

[08:26] <Zoffix> YEY! I'm in :) Had to bump down the CPUs to 8

[08:30] <samcv> checked another one off. https://gist.github.com/samcv/835b0640ef91c3f3617f34771e230b6e

[08:31] <samcv> of failing modules

[08:31] <samcv> can we get an intern

[08:31] <Zoffix> samcv: what's this stuff?

[08:31] <samcv> failing modules :X

[08:31] <samcv> just made a PR due to IO breakage from that one module

[08:32] <Zoffix> samcv: but what's with the selection of modules? How were they selected?

[08:33] <samcv> uh. not purposefully.

[08:33] <samcv> they are just only the ones that completed/failed before travis ended the build

[08:33] <samcv> i tried to install every single module

[08:33] <samcv> Zoffix, can you or somebody write me some code to divide an array holding all 700 or so module names into sections?

[08:34] <samcv> so i can set an ENV variable to a number (number of builds) and another to which build it is.

[08:34] <Zoffix> m: my @a = 1..10; dd @a.rotor: @a/5, :partial

[08:34] <camelia> rakudo-moar c9ebfc: OUTPUT: «((1, 2), (3, 4), (5, 6), (7, 8), (9, 10)).Seq␤»

[08:34] <samcv> so NUM_BUILDS=10 then it splits the array into 10 sections

[08:34] <Zoffix> m: my @a = 1..10; dd @a.rotor: @a/3, :partial

[08:34] <camelia> rakudo-moar c9ebfc: OUTPUT: «((1, 2, 3), (4, 5, 6), (7, 8, 9), (10,)).Seq␤»

[08:34] <samcv> and BUILD_NUM=2 then it needs the 2nd section of that array

[08:35] <samcv> and only build that section. and also make sure that the 10th or last one will get ones that are in addition to the divisor

[08:35] <samcv> err remainder type things

[08:35] <samcv> hm

[08:35] <samcv> that seems good

[08:35] <samcv> thank you kindly. :partial is critical :) did not know that one. was trying to hack something and it ended up being error prone

[08:36] <Zoffix> m: %*ENV<NUM_BUILDS BUILD_NUM> = 10, 2; my @a = 1..100; dd (@a.rotor: @a/(%*ENV<NUM_BUILDS>-1), :partial)[%*ENV<BUILD_NUM>]

[08:36] <camelia> rakudo-moar c9ebfc: OUTPUT: «(23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33)␤»

[08:37] <samcv> m: %*ENV<NUM_BUILDS BUILD_NUM> = 10, 10; my @a = 1..100; dd (@a.rotor: @a/(%*ENV<NUM_BUILDS>-1), :partial)[%*ENV<BUILD_NUM>]

[08:37] <camelia> rakudo-moar c9ebfc: OUTPUT: «Nil␤»

[08:37] <samcv> m: %*ENV<NUM_BUILDS BUILD_NUM> = 9, 10; my @a = 1..100; dd (@a.rotor: @a/(%*ENV<NUM_BUILDS>-1), :partial)[%*ENV<BUILD_NUM>]

[08:37] <camelia> rakudo-moar c9ebfc: OUTPUT: «Nil␤»

[08:38] <samcv> m: %*ENV<NUM_BUILDS BUILD_NUM> = 10, 9; my @a = 1..100; dd (@a.rotor: @a/(%*ENV<NUM_BUILDS>-1), :partial)[%*ENV<BUILD_NUM>]

[08:38] <camelia> rakudo-moar c9ebfc: OUTPUT: «(100,)␤»

[08:38] <samcv> m: %*ENV<NUM_BUILDS BUILD_NUM> = 10, 8; my @a = 1..100; dd (@a.rotor: @a/(%*ENV<NUM_BUILDS>-1), :partial)[%*ENV<BUILD_NUM>]

[08:38] <camelia> rakudo-moar c9ebfc: OUTPUT: «(89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99)␤»

[08:38] <samcv> m: %*ENV<NUM_BUILDS BUILD_NUM> = 10, 1; my @a = 1..100; dd (@a.rotor: @a/(%*ENV<NUM_BUILDS>-1), :partial)[%*ENV<BUILD_NUM>]

[08:38] <camelia> rakudo-moar c9ebfc: OUTPUT: «(12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22)␤»

[08:38] <samcv> m: %*ENV<NUM_BUILDS BUILD_NUM> = 10, 0; my @a = 1..100; dd (@a.rotor: @a/(%*ENV<NUM_BUILDS>-1), :partial)[%*ENV<BUILD_NUM>]

[08:38] <camelia> rakudo-moar c9ebfc: OUTPUT: «(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11)␤»

[08:39] <Geth> ¦ rakudo/nom: 88a6facc81 | (Zoffix Znet)++ | src/core/IO/Path.pm

[08:39] <Geth> ¦ rakudo/nom: Undo IO::Path.resolve fix on JVM

[08:39] <Geth> ¦ rakudo/nom:

[08:39] <Geth> ¦ rakudo/nom: Seems it doesn't know about ut8-c8 yet, so swap JVM to use

[08:39] <Geth> ¦ rakudo/nom: the pre-fix code.

[08:39] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/88a6facc81

[09:00] <Geth> ¦ roast: 6fc4cf833d | (Zoffix Znet)++ | integration/weird-errors.t

[09:00] <Geth> ¦ roast: Test there is no unwanted output with `new Foo:`

[09:00] <Geth> ¦ roast: review: https://github.com/perl6/roast/commit/6fc4cf833d

[09:00] <Geth> ¦ rakudo/nom: c8cb6a61fa | (Zoffix Znet)++ | docs/ChangeLog

[09:00] <Geth> ¦ rakudo/nom: Log 2017.04.1 changes

[09:00] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/c8cb6a61fa

[09:02] <Geth> ¦ rakudo/nom: 7eb37996a3 | (Zoffix Znet)++ | docs/announce/2017.04.1.md

[09:02] <Geth> ¦ rakudo/nom: Add 2017.04.1 Release Announcement

[09:02] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/7eb37996a3

[09:03] <Geth> ¦ rakudo/nom: e49b3728a8 | (Zoffix Znet)++ | VERSION

[09:03] <Geth> ¦ rakudo/nom: [release] bump VERSION to 2017.04.1

[09:03] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/e49b3728a8

[09:18] <Zoffix> Does changelog in emailed release announcements always looks this messed up? http://www.nntp.perl.org/group/perl.perl6.compiler/2017/04/msg15215.html

[09:18] <Zoffix> Seems multi-line entries have the 1..* lines flush to left margin instead of indented :S

[09:19] <Zoffix> Looks fine in my email reader :/

[09:24] <Zoffix> awww...

[09:24] <Zoffix> Looks like the http://rakudo.org/downloads/rakudo/ script doesn't know how to handle point releases either...

[09:26] <Zoffix> Hope I can fix it in time... I need to wake up for work in 35 minutes

[09:27] <Zoffix> I guess it's 'cause PHP's glob sorts it that way :|

[09:55] <Zoffix> Done.

[09:58] <Geth> ¦ rakudo/nom: 7e826f434d | (Zoffix Znet)++ (committed using GitHub Web editor) | docs/announce/2017.04.1.md

[09:58] <Geth> ¦ rakudo/nom: It's not the future yet.

[09:58] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/7e826f434d

[09:58] <Zoffix> "You had one job" :)

[09:58] <Zoffix> And that file made it into the tarball. Brilliant.

[09:59] <Zoffix> At least the filename is right

[10:01] <Zoffix> Annndd cut

[10:01] * Zoffix celebrates with appropriate amount of fun

[10:03] <Zoffix> .tell bartolin Thanks. Fixed by undoing the bugfix for JVM: https://github.com/rakudo/rakudo/commit/88a6facc81e95d2bcc3ada5f5bfbf701e97181f4

[10:03] <yoleaux> Zoffix: I'll pass your message to bartolin.

[10:03] <Zoffix> .tell TimToady point release cut. We also discovered a bug on our downloads page that didn't sort point releases correctly. So this was all beneficial :)

[10:03] <yoleaux> Zoffix: I'll pass your message to TimToady.

[10:06] <jnthn> nine: On Rakudo latest I'm seeing:

[10:06] <jnthn> An exception occurred while evaluating a constant

[10:06] <jnthn> at /home/travis/build/edumentab/rmtly/site#sources/F6A76DDBC4B3F739D1B0D02B0403CF4AEB0CBC07 (Digest::SHA1::Native):5

[10:06] <jnthn> Exception details: No such method 'absolute' for invocant of type '<anon|863819600>'

[10:06] <jnthn> That line is https://github.com/bduggan/p6-digest-sha1-native/blob/master/lib/Digest/SHA1/Native.pm6#L5

[10:07] <jnthn> I think you changed something in this area recently?

[10:08] <samcv> jnthn, i'm getting all the eco modules tested

[10:09] <samcv> well trying. i split it into 10 pieces to have travis ci do

[10:09] <samcv> so hopefully then we can get numbers for every single module

[10:10] <samcv> thanks Zoffix for helping me with rotor, it's working beautifully so far

[10:12] <jnthn> Sounds nice

[10:13] <samcv> very slow. but. will be a good starting point. and hopefully can get it so all builds complete

[10:13] <samcv> and then maybe upload the logs or something somewhere, or process them idk

[10:13] <samcv> one step at a time

[10:15] <samcv> though it seems impossible to install every module within 50 minute time frame for travis :( though i could hack it and commit a tar.gz to a branch, then trigger another build by commiting it

[10:15] <samcv> until they're all actually intstalled.

[10:22] <Zoffix> "...On Rakudo latest I'm seeing..."

[10:22] <Zoffix> Sounds like it's a good thing I ensured the download page works right even when there's more than one point release :}

[10:33] <Zoffix> Oh cool. The last 3 releases all happened on the same day of the month (if we assume today's point release is the release for this month)

[10:33] <Geth> ¦ rakudo/nom: 41bb79c9ea | (Zoffix Znet)++ (committed using GitHub Web editor) | docs/release_guide.pod

[10:33] <Geth> ¦ rakudo/nom: List 2017.04.1 in past releases list

[10:33] <Geth> ¦ rakudo/nom:

[10:33] <Geth> ¦ rakudo/nom: - Also, fix the date for 2017.04 release

[10:33] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/41bb79c9ea

[10:35] <nine> jnthn: indeed, that's caused by https://github.com/rakudo/rakudo/commit/d4d6a9976403c7a8339aaf44d3fb9e9656c28232 :/

[10:38] <jnthn> That very line was changed some days back from .abspath :)

[10:38] <nine> Wouldn't have mattered. Fix coming up

[10:39] <Zoffix> \o/

[10:39] <nine> Do we have something like Moose's "handles" for delegating a whole bunch of methods?

[10:40] <nine> Zoffix: that's definitely something for the point release

[10:40] <Zoffix> no problem

[10:40] <nine> TimToady will be happy that he now has company :)

[10:40] <Zoffix> :)

[10:41] <jnthn> nine: yes, it's called handles :)

[10:41] <nine> Or...maybe I should just mixin the Callable stuff. That way we stay very close to the original IO::Path object

[10:42] <nine> Ah, no that's not possible as the point of the exercise is to defer creating the path in the first place

[10:43] <nine> Haha, "handles" is excruciatingly well documented ;) https://docs.perl6.org/language/glossary#index-entry-handles

[10:44] <Zoffix> nine: https://docs.perl6.org/language/typesystem#index-entry-handles_trait-handles

[10:48] <nine> Ok, I will delegate these method calls: Str gist perl absolute is-absolute relative is-relative parts volume dirname basename extension open resolve slurp lines comb split words copy

[10:49] <nine> I.e. everything that handles the path name itself or does read access on the file. I better not delegate anything related to permissions or modification of the file.

[10:53] <nine> Now how can I lazily initialize this attribute?

[10:54] <Zoffix> = do {}      ?

[10:54] <Zoffix> Ah no

[10:57] <Zoffix> m: use nqp; class Foo { my $def;  nqp::bindattr($def, Scalar, '$!whence', {say "inited"}); has $.foo := $def; }.new.foo

[10:57] <camelia> rakudo-moar 41bb79: OUTPUT: «5===SORRY!5=== Error while compiling <tmp>␤Cannot use := to initialize an attribute␤at <tmp>:1␤------> 3nce', {say "inited"}); has $.foo := $def7⏏5; }.new.foo␤»

[10:57] * Zoffix shrugs

[10:58] <nine> I guess I have to use a Proxy?

[10:58] * Zoffix leaves for work

[10:59] <Zoffix> ping me when it's time to cut the point release

[11:01] <nine> m: class Foo { has $.foo handles <bar>; method BUILD() { $!foo = Proxy.new(FETCH => method () { note "initing foo"; class :: { method bar() { "bar" } }.new }, STORE => method () { die }) } }; my $foo = Foo.new; say $foo.bar; say $foo.foo;

[11:01] <camelia> rakudo-moar 41bb79: OUTPUT: «initing foo␤bar␤<anon|60446032>.new␤»

[11:01] <Zoffix> m: use nqp; class Foo { has $.foo is rw; submethod TWEAK { nqp::bindattr($!foo, Scalar, '$!whence', {say "inited"});  } }.new.foo = 42

[11:01] <camelia> rakudo-moar 41bb79: OUTPUT: «inited␤»

[11:01] <Zoffix> hm, assignment works, but not reading

[11:02] <Zoffix> m: use nqp; class Foo { has $.foo; method foo { $!foo //= do {say "inited"; 42} } }; my $n = Foo.new; say "started"; dd $n.foo; dd $n.foo

[11:02] <camelia> rakudo-moar 41bb79: OUTPUT: «started␤inited␤42␤42␤»

[11:04] <nine> But methods delgated by "handles" won't go through the accessor

[11:04] <Zoffix> nine: BTW, I've seen some comments in IO source about not being able to use `handles` in core. So you might want to test it out first

[11:04] <nine> on it

[11:16] <AlexDaniel> hm, interesting

[11:16] <AlexDaniel> c: releases say 42

[11:16] <committable6> AlexDaniel, ¦releases (18 commits): «42»

[11:16] <AlexDaniel> … that's not what I meant!

[11:16] <AlexDaniel> c: releases say rand

[11:17] <committable6> AlexDaniel, https://gist.github.com/be6a6a39422634b94f2f73d94b2a8c8b

[11:17] <AlexDaniel> oh, what a good bot!

[11:17] <AlexDaniel> picked up 2017.04.1 automatically

[11:17] * AlexDaniel pets committable6

[11:26] <AlexDaniel> 11 seconds… that's getting slow

[11:27] <AlexDaniel> .oO( can we stop making releases so that I don't have to fix committable6? :P )

[11:27] <Zoffix> nine, looking at that error message; perhaps that class should have some name. And we should document its methods, so people would know what they can and can't call on the %?RESOURCES stuff

[11:28] <samcv> ok we're at at 18 failed modules now https://gist.github.com/samcv/835b0640ef91c3f3617f34771e230b6e

[11:28] <samcv> i have links for all 18 of them to logs of the failures

[11:28] <samcv> for convenience

[11:29] <samcv> more often used ones i moved to the top like datetime::utils datetime::math, list::Utils, then there's several math ones too

[11:30] <samcv> i gotta go to bed. all the travis builds have not completed yet. and looks like i'm going to have to make more than 10 builds to build all modules or maybe calculate dependencies some way to split them up differently...

[11:36] <samcv> anddd. why the hell not split it up into 20 builds! https://travis-ci.org/samcv/rakudo-appimage/builds/223119055 so will find out when i wake up what happened with that hahahaha

[11:36] <samcv> 20? why not 100! abuse travis for all it's got!

[11:39] <AlexDaniel> Zoffix: by the way, can I do 2017.06 release? (that is, a release after the next one) I'm just thinking that the current situation with you doing every release doesn't affect the bus factor positively… what do you think?

[11:40] <samcv> also is it ok to have an issue open at https://github.com/perl6/ecosystem with failed modules so others can also edit it with updates?

[11:40] <samcv> discussion etc etc

[11:40] <AlexDaniel> samcv: why not?

[11:40] <samcv> very yes

[11:40] <samcv> will open issue

[11:41] <AlexDaniel> I've noticed that if you explicitly say that people are encouraged to edit your post, people will actually do it

[11:41] <Zoffix> samcv: the amusing part is you were also the person complaining about travis aborting builds, presumably because it was under heavy load :)

[11:41] <samcv> yeah well. if it does 50 minutes that's fine. it tried hard

[11:41] <samcv> but i have seen it abort after like 27 minutes before

[11:42] <samcv> but also ;)

[11:42] <samcv> if they want they can throttle my builds or whatever :\ i mean

[11:44] <samcv> i'm seeing the same modules in like all 10 builds failing. so things must depend o nthem

[11:44] <samcv> well at least one thing from each part of the alphabet

[11:44] <Zoffix> AlexDaniel: not a fan of the idea TBH.

[11:45] <samcv> i mean it needs to go somewhere.

[11:45] <nine> Holy crap. Seems like I've even broken Inline::Perl5's test suite when it's _not_ installed from an RPM package

[11:45] <samcv> :X

[11:45] <AlexDaniel> Zoffix: sure, why?

[11:45] <Zoffix> nine, pretty sure it installed fine with zef when I cut 2017.04.1

[11:46] <nine> Ok, only when I apply the change that should fix it for packaging.

[11:48] <samcv> ok well here we go. https://github.com/perl6/ecosystem/issues/318 i'm fine to remove it if there's somewhere that it can go instead that people might actually participate in it

[11:49] <samcv> maybe someday i can scrape git's email addresses and mass email the most recent commiters :X

[11:50] <samcv> might be annoying. haha. probably not gonna reort to that yet

[11:56] <samcv> o/ night

[11:57] <Zoffix> AlexDaniel: sort of "aint broke don't fix it thing." I got into routine with releases; it works. Not a single release issue in 9 nonths. So why change it? There is no bus factor, as the entire process is documented in step by step. So when I die, exact same proceedure would need to be followed as right now for you to learn to release.

[12:03] <Zoffix> + we've been using the same key to sign releases, now it'd have to be different? Since I can't give you passphrase for mine; or was the plan to have me poweron the VM and kick the bot off safemode and you to just tell it to cut?

[12:04] <Zoffix> + it'd have to be a bot doing it with my github account, 'cause you don't have rakudo's commit bit

[12:05] <Zoffix> + I've seen some poor attention to detail in releases of other projects; if you happen to be the same type of person, it'd annoy me to have poor attention to detail in rakudo's releases

[12:05] <Zoffix> + I don't like change :)

[12:07] <Zoffix> + I don't like inconsistency

[12:07] <Zoffix> + I need to add stuff to perl6.fail to make changelog generation more automatic

[12:21] <Zoffix> Interesting... GCE still tells me not enough resources in zone to power on a 24-core box. First time it's like that during day hours :o

[12:22] <Zoffix> And what's really annoying: fine, there aren't any resources, I'll try again later... But it *deletes* the VM I've just created because it couldn't power it on after creation.

[12:26] <nine> Passing a Callable to the "is native" trait is a great way to defer the creation of the path to the shared lib till runtime. It just has one drawback: NativeCall's guess_library_name will use the result of calling this object as-is and will not apply the $*VM.platform-library-name transformation.

[12:27] <Zoffix> Guess a good time as any to try and find a zone that lets me poweron a 64-core VM...

[12:27] <nine> I.e. resources/libraries/p5helper will stay as-is and not be transformed into resources/libraries/libp5helper.so (on Linux)

[12:27] <Zoffix> ZofBot: I want a less-than-minute time for stresstest!

[12:27] <ZofBot> Zoffix, zip

[12:29] <nine> Now I've got 3 options: 1. change guess_library_name to do the transformation - thereby robbing the user of this escape hatch, 2. have the Callable do that transformation itself, thereby tying %?RESOURCES closer to NativeCall's needs or 3. do the transformation in CompUnit::Repository::Filesystem::resource

[12:30] <nine> 2 has the disadvantage of having to guess if the transformation is necessary (it isn't for Installation repositories for example), same as guess_library_name does right now.

[12:30] <nine> 3 may break other existing code as it really changes the result of %?RESOURCES<libraries/foo>

[12:30] <jnthn> maybe 4) Introduce a named type Resource or some such that is returned from %?RESOURCES lookups, and add a candidate for that in NativeCall's native trait?

[12:33] <nine> jnthn: aaah, that makes so much sense it almost hurts :)

[12:35] <nine> I guess "Distribution::Resource" is the obvious name

[12:36] <jnthn> Seems reasonable, yeah

[12:37] <jnthn> So after I thought about it, yeah, I *think* it's easy...

[12:38] <jnthn> oops, wrong window

[12:43] <nine> This also opens the door for moving the platform_library_name transformation into a repo-specific subclass of Distribution::Resource as it's only needed when the resource is loaded from a FileSystem repo.

[12:45] <Zoffix> .

[12:45] <yoleaux> 12:42Z <El_Che> Zoffix: Thx, I'll do that. I was just starting to create the pkgs, but indeed beter to wait

[12:46] <Geth> ¦ roast: cd94122a9a | usev6++ | S05-modifier/ignorecase.t

[12:46] <Geth> ¦ roast: [JVM] Re-fudge some tests for ligatures matching

[12:46] <Geth> ¦ roast: review: https://github.com/perl6/roast/commit/cd94122a9a

[12:52] <Zoffix> $ lscpu | grep 'CPU(s)'

[12:52] <Zoffix> CPU(s):                64

[12:52] <Zoffix> I did it :)

[12:53] <Zoffix> Had to use "increase quota" form, which apparently is handled by robot, because I got the increase right away

[12:55] <Zoffix> "Stage parse      :  53.006" lowest yet

[12:55] <Zoffix> A'right. Time to set some records \o/

[12:57] <Zoffix> Close, but no cigar: Files=1241, Tests=133745, 77 wallclock secs (21.38 usr  3.66 sys + 2072.16 cusr 186.73 csys = 2283.93 CPU)

[12:57] <Zoffix> m: say 111/77

[12:57] <camelia> rakudo-moar 41bb79: OUTPUT: «1.441558␤»

[12:57] <Zoffix> 1.5x faster than 24-core box

[12:58] <Zoffix> That's with TEST_JOBS=70

[12:59] <Zoffix> Google promised 128-core boxes later this year... So there's still hope for a sub-minute stresstests :)

[13:00] <nine> Unless there are test file which take longer than a minute by themselves?

[13:00] <Zoffix> Oh.. right. And there are probably are

[13:00] <Zoffix> harness6 result: Files=1241, Tests=133745,  137 wallclock secs

[13:01] <Zoffix> Well, this was good 3 minutes of fun :)

[13:01] <MasterDuke_> i just did a parse on AlexDaniel's whateverable server in 51s

[13:01] <MasterDuke_> i would have thought the GCE could do it even faster

[13:02] <Zoffix> Mine is with 2.2GHz cpus

[13:02] <Zoffix> And parse isn't affected much, if at all, but number of cores.

[13:02] <MasterDuke_> yeah, i just thought the individual cores would be a bit faster than that

[13:03] <MasterDuke_> his server has 3.4GHz cores

[13:04] <MasterDuke_> nine: you'll have to let us know the relevant numbers when you get your ryzen up and running

[13:07] <nine> MasterDuke_: will do :) I've now ordered the cooler from another merchant. Today I finally got an email where the one I ordered at initially admitted to not knowing when it can be delivered. While at the same time still claiming a 2 day delivery time on geizhals.at, just like they did a week ago.

[13:09] <MasterDuke_> you didn't want to use the stock amd one? i thought they got a serious upgrade a year or two ago?

[13:11] <nine> The 1800X doesn't come with a stock cooler. Also I just want the best (thus most silent) cooler I can get :)

[13:11] <MasterDuke_> huh, didn't realize that

[13:13] <MasterDuke_> and yes, silent is good. built a watercooling setup for the athlon 64 3400 i won from amd back in college and loved that i couldn't hear a thing

[13:14] <timotimo> the profiling job i let run over night errored out with a dumb error from me not being careful enough about nqp ...

[13:15] <nine> Oh how I hate the waiting. Ever since I decided to go for a really silent system, I notice the noise of my current one much more :)

[13:15] <timotimo> but it helped me figure out that the majority of time is spent in the graph node preparation step

[13:15] <timotimo> maybe i can find out how to make it nom less memory

[13:15] <MasterDuke_> post_process_call_graph_node?

[13:16] <timotimo> yup

[13:17] <timotimo> i wonder how big the id remap hash gets

[13:18] <MasterDuke_> line 122 could be moved down to 133, right?

[13:18] <MasterDuke_> for a micro-optimization

[13:19] <timotimo> ah, indeed, that's a good idea

[13:19] <timotimo> do you know if $node<id> is an int?

[13:19] <timotimo> because if it is, we should perhaps use a native int array instead of a hash for the remap

[13:19] <MasterDuke_> pretty sure all the ids are ints

[13:19] <timotimo> those are a thousand times more efficient when it comes to gc in memory-constrained environments

[13:20] <timotimo> hm, except we stringify the $new-id-counter into $node<id>

[13:20] <MasterDuke_> line 144. how good is the gc about throwing away newly created variables?

[13:21] <timotimo> it's very good

[13:21] <Geth> ¦ rakudo/nom: f4f1c42048 | (Stefan Seifert)++ | src/core/Distribution.pm

[13:21] <Geth> ¦ rakudo/nom: Support all appropriate IO::Path methods on Distribution::Resources

[13:21] <Geth> ¦ rakudo/nom:

[13:21] <Geth> ¦ rakudo/nom: %?RESOURCES<foo> used to return IO::Path objects. People started to

[13:21] <Geth> ¦ rakudo/nom: depend on that behavior which of course now fails as the object is no

[13:21] <Geth> ¦ rakudo/nom: longer an IO::Path but something that defers the creation of the path

[13:21] <Geth> ¦ rakudo/nom: as long as possible. Delegate calls to all of IO::Path's useful methods

[13:21] <Geth> ¦ rakudo/nom: (those dealing with the path name itself and for read access) to the

[13:21] <Geth> ¦ rakudo/nom: result of the deferred path assembly.

[13:21] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/f4f1c42048

[13:21] <Geth> ¦ rakudo/nom: 647abfea2d | (Stefan Seifert)++ | 2 files

[13:21] <Geth> ¦ rakudo/nom: Improve relations between %?RESOURCES and Native trait.

[13:21] <Geth> ¦ rakudo/nom:

[13:21] <Geth> ¦ rakudo/nom: %?RESOURCES<foo> now returns a Distribution::Resource object which the

[13:21] <Geth> ¦ rakudo/nom: Native trait will know how to deal with. This fixes the situation

[13:21] <Geth> ¦ rakudo/nom: where one could either have automatic shared library name transformation

[13:21] <MasterDuke_> `my $shared_data := nqp::hash(...); $id_to_thing{$node<id>} := $shared_data;`. would it be any better as `$id_to_thing{$node<id>} := nqp::hash(...)`?

[13:21] <Geth> ¦ rakudo/nom: by NativeCall _or_ deferred path setup of resources installed via the

[13:21] <Geth> ¦ rakudo/nom: Staging repo.

[13:21] <Geth> ¦ rakudo/nom: <…commit message has 5 more lines…>

[13:21] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/647abfea2d

[13:22] <nine> jnthn: many thanks for pointing out the issue and the help with the fix :)

[13:23] <timotimo> at most a small difference

[13:23] <jnthn> nine++ # yay, that should unbust my $dayjob app :)

[13:24] * Zoffix is reminded

[13:24] <nine> As that part of the commit message was cut, the recommended way to access functions in bundled native libraries is now:

[13:25] <nine> my constant $helper = %?RESOURCES<libraries/helper>; sub foo() is native($helper) { ... }

[13:25] <Zoffix> m: dd IO::Spec::Win32.is-absolute: '/'

[13:25] <camelia> rakudo-moar 41bb79: OUTPUT: «Bool::True␤»

[13:25] <Zoffix> Do we keep that ^ as true?

[13:25] <nine> Older suggestions like %?RESOURCES<libraries/helper>.Str or %?RESOURCES<libraries/helper>.absolute will still work (but not with the Staging repo)

[13:26] <timotimo> MasterDuke_: wait ... are those ids high numbers?

[13:26] <timotimo> i think they are ...

[13:26] <MasterDuke_> timotimo: line 132: how expensive is try? does that ever not succeed?

[13:27] <MasterDuke_> timotimo: i don't think so. don't they just start at 1 and count up?

[13:27] <timotimo> that's why i have a hash ...

[13:27] <timotimo> try is very cheap when it doesn't get hit

[13:27] <timotimo> no, those ids only start at 1 and count up because we have the id remap

[13:28] <timotimo> if i hadn't somehow broken the compile i'd just quickly toss a debug print in there ...

[13:29] <timotimo> i think moar internally uses memory addresses for the ids

[13:29] <timotimo> because those are, conveniently, unique

[13:29] <MasterDuke_> in a profile of a rakudo compile from feb the max id in any of the tables is 5487

[13:29] <MasterDuke_> ah. too big for ints?

[13:30] <timotimo> too big for "int", but they fit into int64

[13:30] <timotimo> except on 32bit where int is int32 and pointer is also int32

[13:31] <timotimo> just a quick debug output looks a whole lot like this:

[13:31] <timotimo> id was 28719360

[13:31] <timotimo> id was 41029576

[13:31] <timotimo> so at least i can div by 8 to get the sizes down, but it's still huge

[13:32] <timotimo> if i want to replace the hash with an array, it'll become the size of the ram you have, basically :P

[13:33] <timotimo> now if i put in a quick pass first that finds the lowest id, that'd help a whole lot

[13:33] <robertle> you could rely on alignment a bit ;)

[13:33] <timotimo> yeah, that's what i meant by divide by 8

[13:33] <Zoffix> nine: should I cut the release now or is there more commits coming? Any tests for the bug that was fixed?

[13:34] <timotimo> alternatively i'll build id_remap out of two lists that i keep in sync; one has all the befores, the other has all the afters, and i keep it sorted by inserting into the right positions

[13:35] <MasterDuke_> yeah, was thinking about the same thing

[13:35] <timotimo> hm, but if the max id is 5487, that is unlikely to be the culprit at all :|

[13:35] <timotimo> so maybe what we should try instead is to make the post_process_call_graph_node function iterative instead of recursive

[13:35] <MasterDuke_> annoying, but if it's much faster/uses less ram...

[13:37] <nine> Zoffix: the 1M$ question is if my commit broke the Staging repo stuff again. Now that I think of it, this could very well be. The fix would be trivial, but I have to go home to be able to test it.

[13:37] <Zoffix> nine: OK, well. I'm not in a rush. Test it when you can and let me know when to release.

[13:40] <timotimo> should be relatively easy, no?

[13:40] <nine> Just had another look and I guess it's fine, as I do not overwrite $!IO in the Proxy's FETCH. So it should run the code for every access. But a test would be good anyway.

[13:49] <Zoffix> [Coke]: recall in July, 2016 you said when making point releases, they should only include the bug fix and not whatever commits happened since previous release.

[13:49] <Zoffix> [Coke]: how to do that? Specically, how would the tag work?

[13:58] <timotimo> create a branch for the point release

[13:58] <timotimo> and when only the interestign commits have been cherry-picked into that branch

[13:58] <timotimo> tag the tip of that branch as the point release

[13:59] <Zoffix> And then what?

[14:00] <jnthn> Why does there need to be something else? :)

[14:00] <jnthn> Well, delete the branch I guess :)

[14:00] <Zoffix> So there'll always be a branch hanging out?

[14:00] <jnthn> Since the tag records what was releases

[14:00] <Zoffix> Um, but what will happen to the tag then? And there won't be a path from that tag in master

[14:01] <jnthn> That's normal enough, though?

[14:01] <timotimo> i'd assume other projects do it exactly like that

[14:01] <Zoffix> Is it? Last august that ruinined NQP

[14:01] <timotimo> you're allowed to delete the branch because the tag keeps all the commits alive

[14:02] <nine> I guess in the current case we want all commits anyway

[14:02] <timotimo> hm, what were the details? i don't remember

[14:04] <[Coke]> The issue was that some things are incorrectly expecting a simple linear commit history for rakudo, which is borked. we should fix whatever broke when we did that.

[14:04] <[Coke]> ... but knowing that something like that is out there, yes, be cautious.

[14:04] <timotimo> good idea. though maybe not now for the release :)

[14:05] <timotimo> like, make a faux not-really-release in between months just to shake out that

[14:05] <Zoffix> timotimo: details of august breakage? I tagged the dist, then git pull --rebased a recent commit on top of that and pushed. And the tag wasn't in the path for the commits in master

[14:06] <[Coke]> right. release tags don't have to be on master/nom

[14:06] <[Coke]> what was expecting it to be?

[14:07] <Zoffix> [Coke]: git describe

[14:09] * Zoffix just tested out the "branch tag delete" method

[14:09] <Zoffix> The tag stays, but yeah, git describe doesn't see it

[14:09] <Zoffix> The tag with the commits from released branch

[14:09] <Zoffix> s/released/deleted/;

[14:12] <Geth> ¦ rakudo/merge-post-2017.04.2-release: c6fd7361d2 | (Zoffix Znet)++ | src/core/IO/Spec/Win32.pm

[14:12] <Geth> ¦ rakudo/merge-post-2017.04.2-release: [io grant] Make IO::Spec::Win32.is-absolute about 63x faster

[14:12] <Geth> ¦ rakudo/merge-post-2017.04.2-release:

[14:12] <Geth> ¦ rakudo/merge-post-2017.04.2-release: - Use NQP ops instead of regexes

[14:12] <Geth> ¦ rakudo/merge-post-2017.04.2-release: - Toss UNC path check; if we didn't match the leading slash test,

[14:12] <Geth> ¦ rakudo/merge-post-2017.04.2-release:     we won't match UNC path anyway

[14:12] <Geth> ¦ rakudo/merge-post-2017.04.2-release: review: https://github.com/rakudo/rakudo/commit/c6fd7361d2

[14:12] <timotimo> oh, i get it

[14:13] <Zoffix> Well, if you commit non-release stuff before 2017.04.2, please try to use ^ that branch ( merge-post-2017.04.2-release ) instead of nom. I don't wanna go with "this should work, probably" road with the tags unless we really have to.

[14:13] <timotimo> you don't get 2017.01.1 in the versions because the point release is on a different branch entirely

[14:13] <timotimo> which is "correct", of course

[14:13] <timotimo> (the best kind of correct)

[14:16] <Zoffix> ^ that commit should give some sort of gravity boost on Windows. I see .is-absolute used in a bunch of places, like .absolute, .dir, .chdir, .slurp, .open. In fact, I think any method that actually accesses the file + some others

[14:17] <jnthn> Zoffix: ooh, sounds nice :)

[14:18] <MasterDuke_> bisectable6 has gotten confused before with weird history

[14:19] <MasterDuke_> but not sure how much we should take that into account for rakudo releases

[14:23] <Zoffix> Ah, no, only .dir, .chdir, and .parent. But never fear: all the read methods use another method that should get a sizeable boost as well some time later today. For absolute paths it should be in the same 60x range.

[14:27] <MasterDuke_> timotimo: any improvements so far?

[14:28] <timotimo> no, i ran a proflie-compile again in the background and it got OOM'd even though i have lots of swap remaining

[14:28] <timotimo> not quite sure why that'd happen

[14:30] <MasterDuke_> maybe need to come up with some script that creates a large profile, but doesn't take *quite* as much time/ram as profiling a rakudo compile

[14:30] <timotimo> heh.

[14:31] <timotimo> well, i got one tiny piece of information, i think

[14:31] <timotimo> it did get its memory growth before the post-process step started

[14:31] <timotimo> so perhaps the problem is already there inside the moarvm code that creates the profile datastructures in the first place

[14:31] <MasterDuke_> huh. did the post-process make it any worse?

[14:32] <Zoffix> Actually no, not today. I was planning to have an evening off today :}

[14:32] <Zoffix> Tomorrow! :)

[14:35] <timotimo> oh. i think i actually threw out the debug output that would actually have told me that

[14:35] <timotimo> no, i do have a print for whenever it puts a value into the id remap

[14:35] <timotimo> and that didn't get hit

[14:35] <timotimo> so it will have crashed before it reached the post processing step

[14:39] <timotimo> it looks like zef was using new-from-absolute-path

[14:40] <timotimo> oh

[14:40] <timotimo> no it wasn't

[14:40] <Zoffix> It was until recently

[14:40] <Zoffix> https://github.com/ugexe/zef/issues/149

[14:40] <Zoffix> Fixed 10 days ago

[14:40] <timotimo> yeah but i just pulled it and it won't install

[14:41] <Zoffix> :(

[14:41] <timotimo> it seems to call .IO on something that's already an IO::Path or something?

[14:41] <timotimo> hold on ...

[14:41] <timotimo> d'oh :)

[14:41] <timotimo> i was using the system-wide installed zef to try to install zef

[14:41] <timotimo> of course it was still using the old code

[14:42] <Zoffix> Calling .IO on IO::Path is identity

[14:42] <Zoffix> m: dd [ ".".IO.WHAT.IO, ".".IO.IO ]

[14:42] <camelia> rakudo-moar 647abf: OUTPUT: «[IO::Path, ".".IO(:SPEC(IO::Spec::Unix),:CWD("/home/camelia"))]␤»

[14:42] <timotimo> right

[14:42] <timotimo> the problem was i was looking at a newer source file than it was running

[14:43] <Zoffix> Ah

[14:43] <Zoffix> woooow

[14:44] <Zoffix> Spec::Win32.rel2abs is slow as hell. I had to drop down my bench to 500 iteration and it still took 14 seconds

[14:44] <Zoffix> Oh, 2500 iterations, but still that's slow AF

[14:44] <Zoffix> ZofBot: time to fix that!

[14:44] <ZofBot> Zoffix, in(10); my $timecalc = Promise

[14:45] <timotimo> <3

[14:53] <TimToady> I had to reinstall zef last night to get it to work

[14:53] <yoleaux> 10:03Z <Zoffix> TimToady: point release cut. We also discovered a bug on our downloads page that didn't sort point releases correctly. So this was all beneficial :)

[14:53] <TimToady> and no, I couldn't use the old zef to do it...

[14:55] <nine> That somehow doesn't sound like the backwards compatibility story we told after the 6.c release :/

[14:56] <Zoffix> It is though. I didn't have to modify any of 6.c tests to remove .abspath and .new-from-absolute-path

[14:57] <Zoffix> And .new-from-absolute-path wasn't even documented.

[14:57] <Zoffix> Just like zef uses Rakudo::Internals.from-json; if we nix it, the same breakage will occur.

[14:59] <TimToady> we did explicitly say "if it's not tested, it's not guaranteed"

[15:00] <Zoffix> ZofBot: but then users happened

[15:00] <ZofBot> Zoffix, 123 # 111111111111111111111111111111111111111111111

[15:01] <TimToady> ZofBot: Why can't you ever think of anything original to say?

[15:01] <ZofBot> TimToady, alternatively i'll build id_remap out of two lists that i keep in sync; one has all the befores, the other has all the afters, and i keep it sorted by inserting into the right positions

[15:03] <Zoffix> Would be sweet if the "Back" button worked in the profiler when looking through CallGraph ->  Callees

[15:04] * Zoffix looks at source

[15:04] <Zoffix> Oh, some sort of angular stuff :

[15:05] <Zoffix> Or an ".." link to go up a level, so you could actually nagivgate teh callee tree instead of restarting from scratch

[15:05] <jnthn> Zoffix: When I originally did it there was a breadcrumb trail at the top

[15:06] <jnthn> That let you go back to recent frames in the chain

[15:06] <Zoffix> Oh, awesome. yeah, it's still there. It's just at the top and I didn't see it :)

[15:08] <jnthn> That UI is like, the first *and* last thing I wrote in Angular JS :)

[15:15] <timotimo> the breadcrumb trail exists but it acts really strange when you skip multiple levels

[15:16] <timotimo> and i managed to somehow break labels in most of the boxes in the call graph >_<

[15:29] <nine> Darn....back to getting the wrong path for the shared lib again. Will have to look into this later on :/

[15:30] <Zoffix> Note to self: /Q'\'/ is not the same as /｢\｣/

[15:37] <Zoffix> samcv++ # updateing highlighter to latest fixed my Q'\' breakage \o/

[15:44] <Zoffix> What's the right way to use that anyway?

[15:44] <Zoffix> I mean.. how to uses Texas Q// in regex

[15:44] <Zoffix> m: say 'foo' ~~ /{Q'fo'}/

[15:44] <camelia> rakudo-moar 647abf: OUTPUT: «5===SORRY!5=== Error while compiling <tmp>␤Two terms in a row␤at <tmp>:1␤------> 3say 'foo' ~~ /{Q'fo7⏏5'}/␤    expecting any of:␤        infix␤        infix stopper␤        statement end␤        statement modifier␤        sta…»

[15:44] <Zoffix> TTIAR?

[15:45] <Zoffix> m: say 'foo' ~~ /{Q/fo/}/

[15:45] <camelia> rakudo-moar 647abf: OUTPUT: «｢｣␤»

[15:45] <Zoffix> dafuq

[15:45] <Zoffix> m: say 'foo' ~~ /<{Q/fo/}>/

[15:45] <camelia> rakudo-moar 647abf: OUTPUT: «｢fo｣␤»

[15:45] <Zoffix> m: say 'foo' ~~ /<{Q'fo'}>/

[15:45] <camelia> rakudo-moar 647abf: OUTPUT: «5===SORRY!5=== Error while compiling <tmp>␤Two terms in a row␤at <tmp>:1␤------> 3say 'foo' ~~ /<{Q'fo7⏏5'}>/␤    expecting any of:␤        infix␤        infix stopper␤        statement end␤        statement modifier␤        s…»

[15:45] <Zoffix> bug

[15:46] <Zoffix> m: say 'foo' ~~ /<{Q/.+/}>/

[15:46] <camelia> rakudo-moar 647abf: OUTPUT: «｢foo｣␤»

[15:46] <Zoffix> m: say 'f.+o' ~~ /"{Q/f.+/}"/

[15:46] <camelia> rakudo-moar 647abf: OUTPUT: «｢f.+｣␤»

[15:46] <Zoffix> aha \o/

[15:47] <Zoffix> m: say 'f.+o' ~~ /"{Q'f.+'}"/

[15:47] <camelia> rakudo-moar 647abf: OUTPUT: «5===SORRY!5=== Error while compiling <tmp>␤Unable to parse expression in single quotes; couldn't find final "'" ␤at <tmp>:1␤------> 3say 'f.+o' ~~ /"{Q'f.+'}"/7⏏5<EOL>␤    expecting any of:␤        dotty method or postfix␤        si…»

[15:47] <Zoffix> It's tripping on ' quotes there too tho

[15:49] <timotimo> MasterDuke_: i'll put some telemetry pings into the call graph creation code inside moarvm to see what its behavior is like

[16:12] <TimToady> ZofBot: Q'fo is a valid ident

[16:12] <ZofBot> TimToady, , are aliases into the $/ object

[16:13] <TimToady> m: say 'f.+o' ~~ /"{Q 'f.+'}"/

[16:13] <camelia> rakudo-moar 647abf: OUTPUT: «｢f.+｣␤»

[16:14] <TimToady> m: say 'f.+o' ~~ /"{Q‘f.+’}"/

[16:15] <camelia> rakudo-moar 647abf: OUTPUT: «｢f.+｣␤»

[16:16] <timotimo> we can give a "did you mean" error here

[16:17] <timotimo> i'm surprised we haven't stumbled over this a thousand times, though?

[16:17] <timotimo> m: say qq'blah'

[16:17] <camelia> rakudo-moar 647abf: OUTPUT: «5===SORRY!5=== Error while compiling <tmp>␤Two terms in a row␤at <tmp>:1␤------> 3say qq'blah7⏏5'␤    expecting any of:␤        infix␤        infix stopper␤        postfix␤        statement end␤        statement modifier␤   …»

[16:17] <timotimo> i suppose when you're already using Q and friends, you wouldn't use '?

[16:18] <Zoffix> m: say Q'blah'

[16:18] <camelia> rakudo-moar 647abf: OUTPUT: «5===SORRY!5=== Error while compiling <tmp>␤Two terms in a row␤at <tmp>:1␤------> 3say Q'blah7⏏5'␤    expecting any of:␤        infix␤        infix stopper␤        postfix␤        statement end␤        statement modifier␤    …»

[16:19] <Zoffix> Ok, definitely a regression, because that used to work

[16:19] <Zoffix> bisect: Q'blah'

[16:19] <Zoffix> c: 2017.03 Q'blah'

[16:19] <committable6> Zoffix, https://gist.github.com/af15992e4d4e449ad78d1be76a56c146

[16:20] <Zoffix> c: all say Q'blah'

[16:20] <Zoffix> ...

[16:20] <TimToady> it *shouldn't* work

[16:20] <Zoffix> hurry up, robot!

[16:21] <Zoffix> TimToady: really?

[16:21] <Zoffix> star: say Q'blah'

[16:21] <camelia> star-m 2016.10: OUTPUT: «5===SORRY!5=== Error while compiling <tmp>␤Two terms in a row␤at <tmp>:1␤------> 3say Q'blah7⏏5'␤    expecting any of:␤        infix␤        infix stopper␤        postfix␤        statement end␤        statement modifier␤        …»

[16:21] <Zoffix> OK

[16:21] <Zoffix> Maybe I'm misremembering

[16:21] <TimToady> m: my \Q'blah = 42; say Q'blah

[16:21] <camelia> rakudo-moar 647abf: OUTPUT: «42␤»

[16:21] <Zoffix> Ahhh

[16:21] <Zoffix> OOHHH

[16:21] <TimToady> as timotimo points out, we can have a better message though

[16:22] <Zoffix> star: say Q 'blah'

[16:22] <camelia> star-m 2016.10: OUTPUT: «blah␤»

[16:22] <Zoffix> Right, THAT used to work :D

[16:22] <TimToady> still duz

[16:22] <Zoffix> yeah :)

[16:22] <timotimo> now i have a segfault in gdb open where i can't figure out what did it ...

[16:29] <timotimo> aha!

[16:29] <timotimo> the call stack is too deep

[16:30] <timotimo> i mean ... that could be it

[16:30] <timotimo> the instruction it crashes on is a callq

[16:41] <Zoffix> Hm.. 40 minutes of rewriting it a routine in nqp = 8% speed gain...

[16:42] <Zoffix> A few weeks of this effort and rakudo will read the files before you even know you wanted to read them :P

[16:43] <Zoffix> Time to learn to make non-nqp fast.

[16:43] <Zoffix> Where do I start?

[16:45] <nine> m: class Foo { has $.IO; method BUILD() { $!IO = Proxy.new(FETCH => method () { note "FETCH"; "foo" }, STORE => method ($new) { die }) } }; my $foo = Foo.new; $foo.IO; $foo.IO;

[16:45] <camelia> rakudo-moar 647abf: OUTPUT: «FETCH␤»

[16:45] <nine> Why does this FETCH only once?!

[16:47] <Zoffix> need to bind the proxy

[16:47] <Zoffix> m: class Foo { has $.IO; method BUILD() { $!IO := Proxy.new(FETCH => method () { note "FETCH"; "foo" }, STORE => method ($new) { die }) } }; my $foo = Foo.new; $foo.IO; $foo.IO;

[16:47] <camelia> rakudo-moar 647abf: OUTPUT: «FETCH␤FETCH␤FETCH␤»

[16:47] <nine> oh, ok, thanks!

[16:47] <Zoffix> Why does it fetch it 3 times?

[16:48] <nine> m: class Foo { has $.IO; method BUILD() { $!IO := Proxy.new(FETCH => method () { note "FETCH"; "foo" }, STORE => method ($new) { die }) }; self }; my $foo = Foo.new; $foo.IO; $foo.IO;

[16:48] <camelia> rakudo-moar 647abf: OUTPUT: «5===SORRY!5=== Error while compiling <tmp>␤'self' used where no object is available␤at <tmp>:1␤------> 3o" }, STORE => method ($new) { die }) };7⏏5 self }; my $foo = Foo.new; $foo.IO; $fo␤    expecting any of:␤        term␤»

[16:48] <nine> m: class Foo { has $.IO; method BUILD() { $!IO := Proxy.new(FETCH => method () { note "FETCH"; "foo" }, STORE => method ($new) { die }) }; 1 }; my $foo = Foo.new; $foo.IO; $foo.IO;

[16:48] <camelia> rakudo-moar 647abf: OUTPUT: «WARNINGS for <tmp>:␤Useless use of constant integer 1 in sink context (line 1)␤FETCH␤FETCH␤FETCH␤»

[16:48] <nine> no idea then

[16:49] <Zoffix> oh, doh. Yeah, that's it

[16:49] <Zoffix> m: class Foo { has $.IO; method BUILD() { $!IO := Proxy.new(FETCH => method () { note "FETCH"; "foo" }, STORE => method ($new) { die }); 42 } }; my $foo = Foo.new;

[16:49] <camelia> rakudo-moar 647abf: ( no output )

[16:49] <Zoffix> m: class Foo { has $.IO; method BUILD() { $!IO := Proxy.new(FETCH => method () { note "FETCH"; "foo" }, STORE => method ($new) { die }); 42 } }; my $foo = Foo.new; Foo.IO

[16:49] <camelia> rakudo-moar 647abf: OUTPUT: «Cannot look up attributes in a Foo type object␤  in block <unit> at <tmp> line 1␤␤»

[16:50] <Zoffix> m: class Foo { has $.IO; method BUILD() { $!IO := Proxy.new(FETCH => method () { note "FETCH"; "foo" }, STORE => method ($new) { die }); 42 } }; my $foo = Foo.new; $foo.IO

[16:50] <camelia> rakudo-moar 647abf: OUTPUT: «FETCH␤»

[16:50] <Zoffix> cool

[16:50] <nine> Now with the proxy bound it ends with: Cannot invoke this object (REPR: Null; VMNull)

[16:52] <nine> --ll-exception does not actually give me a backtrace there

[16:57] <nine> Maybe I'll have to write 20 delegation methods manually after all

[16:58] <nine> I'd guess that it's the FETCH closure that doesn't survive serialization.

[16:59] <TimToady> .oO(serial killer?)

[17:00] <Zoffix> :D

[17:01] <nine> but dinner first

[17:02] <MasterDuke_> timotimo: get anything from the telemetry?

[17:03] <timotimo> MasterDuke_: it's not reached the point yet

[17:03] <timotimo> now i'm no longer at my desktop, so i'll have to ssh in to see what's up

[17:04] <MasterDuke_> at one point i had some code that very quickly produced a too-big profile, but i don't remember what it was

[17:04] <timotimo> ackermann should do it. alternatively, i'd think recursive fibonacci should also do it

[17:05] <MasterDuke_> i wonder if it was something with .combinations

[17:05] <Zoffix> What do you think of readability of rel2abs2 vs rel2abs3 here? https://gist.github.com/zoffixznet/1121ae5f906d05383a77a62c91848f06

[17:05] <timotimo> didn't we have a recursion-free combinations routine?

[17:05] <timotimo> desktop will most likely freeze in a minute or two

[17:05] <Zoffix> It only brings like 10% improvement... The real slowage is further down the pipeline. This method is called anytime a file on disc is accessed

[17:06] <Zoffix> Wondering if the mild perf boost is worth the poorer readability

[17:06] <MasterDuke_> timotimo: we do now, this may have been before that

[17:06] <Zoffix> ( I'll still need to rewrite ($path ~~ /^ <$UNCpath>/ in nqp, so there'd be another small nqp chunklet there)

[17:08] <MasterDuke_> Zoffix: do you know the slowest part of the non-nqp version? is there a hot part so you could re-write just a bit in nqp?

[17:08] <timotimo> https://gist.github.com/timo/1dab05a80811102a9437894adff39e87 - MasterDuke_, something similar to the function donw below would be what we do in post-processing

[17:08] <timotimo> well, that function is a bit wordy because of the whole C thing; in nqp-land we'd just be using a list

[17:09] <MasterDuke_> isn't malloc always on the heap?

[17:10] <Zoffix> MasterDuke_: good planm

[17:10] <MasterDuke_> Zoffix: but i wouldn't say the rel2abs3 is all that bad

[17:12] <timotimo> malloc is on the heap, but the structure i put there is on the stack

[17:13] <MasterDuke_> ah

[17:18] <MasterDuke_> recursive fibonacci of 30k only produced a 15mb profile, and up to 10k it runs pretty quickly, faster than i expected

[17:36] <timotimo> interesting

[17:36] <MasterDuke_> oops, i lied. recursive factorial is very fast. recursive fibonacci is not

[17:37] <MasterDuke_> bit of a difference

[17:38] <timotimo> ah, well :)

[17:38] <timotimo> factorial doesn't branch

[17:41] <DrForr> Ackermann FTW :)

[17:42] <DrForr> (though there are many more fun hyperexponentials out there)

[17:44] <MasterDuke_> can do fib(35), but fib(40) was taking a long time so i killed it. but it only produced a 100k profile

[17:44] <MasterDuke_> fib(37) produced a 25k profile

[17:46] <MasterDuke_> *250k

[17:48] <Geth> ¦ rakudo/nom: 4a560aa746 | (Stefan Seifert)++ | src/core/Distribution.pm

[17:48] <Geth> ¦ rakudo/nom: Fix "Cannot invoke this object (REPR: Null; VMNull)"

[17:48] <Geth> ¦ rakudo/nom:

[17:48] <Geth> ¦ rakudo/nom: A packaged Inline::Perl5 will throw the error about VMNull at runtime when

[17:48] <Geth> ¦ rakudo/nom: trying to access the Proxy's FETCH method. Presumably the method closure did

[17:48] <Geth> ¦ rakudo/nom: not survive serialization.

[17:48] <Geth> ¦ rakudo/nom: Use a less elegant, but ultimately working approach instead.

[17:48] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/4a560aa746

[17:50] <nine> Is there a way to run a spec test using an installed perl6 instead of from the source directory?

[17:50] <MasterDuke_> something with the --cmd option for fudgeandrun perhaps?

[17:53] <MasterDuke_> *--impl-cmd

[17:55] <nine> Ah, symlink the t directory in an otherwise empty directory and modify line 39 in t/harness5 ;)

[17:58] <nine> Zoffix: I'm seeing t/spec/S16-filehandles/filestat.t ................................. Dubious, test returned 1 (wstat 256, 0x100) Failed 1/11 subtests

[17:59] <nine> Zoffix: otherwise we're go for point release from me :)

[18:00] <nine> Zoffix: the failing test in filestat.t is 'IO.accessed should be updated when file content changes' and is kinda wrong as it just won't work on a file system mounted with noatime

[18:01] <timotimo> how do we figure that out?

[18:01] <nine> timotimo: probably checking if system tools detect the change and if they don't, skip the test

[18:02] <Geth> ¦ star: 5398118aa1 | (Steve Mynott)++ | 2 files

[18:02] <Geth> ¦ star: bump versions to 2017.04 and 04.1 for rakudo

[18:02] <Geth> ¦ star: review: https://github.com/rakudo/star/commit/5398118aa1

[18:03] <Zoffix> stmuk: that's the wrong version. It'll be 2017.04.2

[18:03] <Zoffix> nine: OK. I thought noatime would still update it on 1st access after write

[18:03] <stmuk> ah

[18:03] <timotimo> that's not a bad idea, except we have to have a system tool for every platform where that can happen :D

[18:04] <geekosaur> Zoffix, there's both soft-atime and hard no-atime, the latter you won;'t ever see an updated time

[18:04] <nine> timotimo: is there an atime on every platform?

[18:05] * nine just removed the noatime mount option from his fstab

[18:05] <timotimo> no clue :)

[18:05] <geekosaur> atime is usually present although its resolution varies (e.g. its granularity is 2 seconds on FAT/VFAT)

[18:05] <stmuk> relatime is best for linux

[18:05] <nine> I guess since I upgraded to an Intel SSD 750 400GB NVMe device, atime just won't make any difference anymore :)

[18:08] <Geth> ¦ roast: 715f602205 | (Zoffix Znet)++ (committed using GitHub Web editor) | S16-filehandles/filestat.t

[18:08] <Geth> ¦ roast: skip-fudge IO::Path.accessed test

[18:08] <Geth> ¦ roast:

[18:08] <Geth> ¦ roast: - Needs more through for noatime systems

[18:08] <Geth> ¦ roast: - Test was added 10 days ago and isn't part of 6.c-errata

[18:08] <Geth> ¦ roast: review: https://github.com/perl6/roast/commit/715f602205

[18:08] <Zoffix> Alright, I'll start cutting the 2017.04.2

[18:08] <Zoffix> s/through/thought/through

[18:08] <Zoffix> bah

[18:14] <Zoffix> .ask [Coke] I'm kinda way past the original grant due date, but I have a question: should I (a) complete the grant by end of April, making my final report on April 30th; or (b) throw in a bunch of performance improvements as part of the grant work and complete it mid-May. I'll make a short report this week and final and complete report mid-May

[18:14] <yoleaux> Zoffix: I'll pass your message to [Coke].

[18:19] <MasterDuke_> timotimo: 'use MONKEY-SEE-NO-EVAL; for ^10 { my &fs = EVAL q|sub f\qq[$_]($n) { if $n < 2 { return 1 } else { return $n * f\qq[$_]($n - 1) } }|; say &fs(30_000).chars };' produces a 150mb profile that the qt viewer can't open

[18:19] <MasterDuke_> Malformed input file, top level isn't an array: "too deeply nested document"

[18:20] <timotimo> OK

[18:20] <timotimo> ... too deeply?

[18:20] <timotimo> that's distinct from "too large", right?

[18:21] <MasterDuke_> think so

[18:21] <geekosaur> yes, that's a stack (not necessarily machine stack) issue

[18:21] <timotimo> it's machine stack if we have a json machine

[18:26] <MasterDuke_> but we don't necessarily need a profile that's actually too large right, just one that's pretty large and generates quickly?

[18:29] <[Coke]> .

[18:29] <yoleaux> 18:14Z <Zoffix> [Coke]: I'm kinda way past the original grant due date, but I have a question: should I (a) complete the grant by end of April, making my final report on April 30th; or (b) throw in a bunch of performance improvements as part of the grant work and complete it mid-May. I'll make a short report this week and final and complete report mid-May

[18:29] <Zoffix> nine: is this output from Inline::Perl5 normal? something about leaked scalars in t/use.t  https://gist.github.com/zoffixznet/e17ff7b7e41840c285f2824261824f2a

[18:29] <[Coke]> late completion is fine; missing reporting progress is not.

[18:30] <nine> Zoffix: yes :/ But maybe now that the packaging stuff works I'll find the time to track that down.

[18:30] <[Coke]> Either way is fine; if you want to throw extra stuff in as part of the grant report, I am not going to stop you. :)

[18:30] <Zoffix> [Coke]: OK. I'll have the report for April tomorrow \o/

[18:30] <Zoffix> :D

[18:30] <[Coke]> I can take .md for republishing.

[18:31] <Zoffix> OK

[18:38] <MasterDuke_> timotimo: 'use MONKEY-SEE-NO-EVAL; for ^500 { my &fs = EVAL q|sub f\qq[$_]($n) { if $n < 2 { return 1 } else { return $n * f\qq[$_]($n - 1) } }|; &fs(500) };' produces a 127mb profile that's "too large document"

[18:41] <Geth> ¦ rakudo/nom: f28044b8f7 | (Zoffix Znet)++ | docs/ChangeLog

[18:41] <Geth> ¦ rakudo/nom: Log 2017.04.2 changes

[18:41] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/f28044b8f7

[18:43] <Geth> ¦ rakudo/nom: 85da85002d | (Zoffix Znet)++ | docs/announce/2017.04.2.md

[18:43] <Geth> ¦ rakudo/nom: Add 2017.04.2 Release Announcement

[18:43] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/85da85002d

[18:53] <MasterDuke_> on my machine, the whole thing took 73s. of that, post_process_call_graph_node() took 14.0655379295349 and to_json() took 43.3250727653503

[18:55] <AlexDaniel> hhhhhmmmm

[18:55] <yoleaux> 18:39Z <Zoffix> AlexDaniel: re cutting releases: so, are we cool or is my reasoning unreasonable?

[18:56] <AlexDaniel> where's committable

[18:57] <AlexDaniel> c: 647abfea2d9 say 42

[18:57] <AlexDaniel> :|

[18:58] <AlexDaniel> c: 647abfea2d9 say 42

[18:58] <committable6> AlexDaniel, ¦647abfe: «No build for this commit»

[18:58] <AlexDaniel> ok that's better

[18:58] <AlexDaniel> c: HEAD 42

[18:59] <AlexDaniel> :|

[18:59] <AlexDaniel> c: HEAD 42

[18:59] <committable6> AlexDaniel, ¦HEAD(85da850): «No build for this commit»

[18:59] <AlexDaniel> c: HEAD^ 42

[18:59] <committable6> AlexDaniel, ¦HEAD^: «WARNINGS for /tmp/donFsm9Lfe:␤Useless use of constant integer 42 in sink context (line 1)»

[19:04] <AlexDaniel> Zoffix: we are cool, it's fine. I found your reasoning unreasonable, but at the same time I appreciate your work, so if it disturbs you too much then I think we can keep it this way.

[19:05] <AlexDaniel> c: HEAD 42

[19:05] <committable6> AlexDaniel, ¦HEAD(85da850): «No build for this commit»

[19:05] <AlexDaniel> c: 647abfea2d9 say 42

[19:05] <committable6> AlexDaniel, ¦647abfe: «42»

[19:05] <AlexDaniel> ok that's slightly better…

[19:07] <AlexDaniel> c: HEAD 42

[19:07] <committable6> AlexDaniel, ¦HEAD(85da850): «WARNINGS for /tmp/y84Bt4akEP:␤Useless use of constant integer 42 in sink context (line 1)»

[19:08] <AlexDaniel> if only I could figure out why whateverable does this…

[19:08] <AlexDaniel> c: releases say rand

[19:08] <committable6> AlexDaniel, https://gist.github.com/954b232a8967a2e8f14fe9fa6365c763

[19:10] <AlexDaniel> c: all say rand

[19:10] <committable6> AlexDaniel, https://gist.github.com/349e4b94e73202adefd031fdaf84225a

[19:10] <AlexDaniel> c: all say Q'blah'

[19:10] <committable6> AlexDaniel, https://gist.github.com/395a79533bdb3e09eacb4e26bc6b825f

[19:10] <timotimo> don't you mean Q'plah?

[19:11] * AlexDaniel shrug

[19:11] <Zoffix> AlexDaniel: well, OK. Once I'm done with the grant stuff, I plan on improving the bot and perl6.fail (they're both kinda in-beta-status). So the end-goal is for the bot to auto-start the VM and have an on-IRC safemode switch. Once that's done, you can cut a release. 'cause then you won't need any VMs, keys, or commit bits; the bot will handle all that

[19:12] <AlexDaniel> Zoffix: and if the bot is hit by a bus we're doomed, mhm…

[19:13] <MasterDuke_> timotimo: for that script, to_json takes 42s, but to_sql takes 53s

[19:13] <Zoffix> Not at all. (a) You can always follow manual instructions — it's painful and error-prone; (b) The final-state bot will have proper setup instructions, so all you'd need to do is find a new box to run it on and done.

[19:14] <Zoffix> I mean, I'm following manual instructions *as we speak* because the bot doesn't know how to cut point releases

[19:14] <AlexDaniel> I'd much rather run it myself. But again, if this is so big of a trouble, we don't *have* to do it

[19:14] <Zoffix> AlexDaniel: run what yourself? The bot?

[19:14] <AlexDaniel> yea

[19:15] <Zoffix> AlexDaniel: well, then submit a CLA to get commit bit for rakudo.

[19:15] <Zoffix> You need it to run the bot, 'cause I doubt anyone will give you their github credentials :P

[19:15] <AlexDaniel> sure, I know. This is why I brought it up ahead of time :)

[19:16] <Zoffix> And we also need to figure out the "group key" or whatever. So that multiple people can release and we'd still always use the same key

[19:17] <timotimo> MasterDuke_: that's kinda strange

[19:20] <MasterDuke_> 2202736maxresident)k for both

[19:21] <Geth> ¦ rakudo/nom: 052dfcddce | (Zoffix Znet)++ | VERSION

[19:21] <Geth> ¦ rakudo/nom: Bump version to 2017.04.2

[19:21] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/052dfcddce

[19:23] <MasterDuke_> timotimo: got anything from telemetry yet?

[19:31] <timotimo> only gc runs starting and such

[19:31] <MasterDuke_> it's still going?

[19:32] <timotimo> yeah

[19:32] <timotimo> of course it is :)

[19:32] <timotimo> 603b30  30636434259937 (-   "start minor collection" (2620)

[19:32] <timotimo> ^- the last output

[19:33] <timotimo> not every interval was a gc, but the vast majority

[19:33] <MasterDuke_> how long has it been running?

[19:33] <timotimo> real time or cpu time? :)

[19:34] <MasterDuke_> real

[19:34] <timotimo> hm

[19:34] <timotimo> good question actually

[19:34] <timotimo> 0 Epoch counter: 98516819482392

[19:34] <timotimo> that's not a unix timestamp

[19:35] <MasterDuke_> and you're profiling a rakudo compile?

[19:37] <timotimo> yeah

[19:37] <timotimo> i think with --target=ast

[19:38] <timotimo> it's spending most of its time doing nothing

[19:38] <MasterDuke_> swapping?

[19:38] <timotimo> yeah

[19:39] <MasterDuke_> how much ram do you have?

[19:40] <timotimo> eating now

[19:40] <timotimo> 15.6G says htop

[19:40] <timotimo> 10.9G is in my swap

[19:41] <MasterDuke_> ha. need to rent some 32 or 64gb aws or gce machine for an hour or so

[19:49] <Zoffix> good god we have a lot of branches

[19:49] <Zoffix> "2016.01-preparation"

[19:49] <Zoffix> heh

[19:49] <Geth> ¦ rakudo: zoffixznet++ created pull request #1062: [io grant] Make IO::Spec::Win32.is-absolute about 63x faster

[19:49] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/pull/1062

[19:50] <Geth> ¦ rakudo/nom: c6fd7361d2 | (Zoffix Znet)++ | src/core/IO/Spec/Win32.pm

[19:50] <Geth> ¦ rakudo/nom: [io grant] Make IO::Spec::Win32.is-absolute about 63x faster

[19:50] <Geth> ¦ rakudo/nom:

[19:50] <Geth> ¦ rakudo/nom: - Use NQP ops instead of regexes

[19:50] <Geth> ¦ rakudo/nom: - Toss UNC path check; if we didn't match the leading slash test,

[19:50] <Geth> ¦ rakudo/nom:     we won't match UNC path anyway

[19:50] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/c6fd7361d2

[19:50] <Geth> ¦ rakudo/nom: e1c086b7a7 | (Zoffix Znet)++ (committed using GitHub Web editor) | src/core/IO/Spec/Win32.pm

[19:50] <Geth> ¦ rakudo/nom: Merge pull request #1062 from rakudo/merge-post-2017.04.2-release

[19:50] <Geth> ¦ rakudo/nom:

[19:50] <Geth> ¦ rakudo/nom: [io grant] Make IO::Spec::Win32.is-absolute about 63x faster

[19:50] <Geth> ¦ rakudo/nom: review: https://github.com/rakudo/rakudo/commit/e1c086b7a7

[19:51] <Geth> ¦ star: a54b67f843 | (Zoffix Znet)++ (committed using GitHub Web editor) | tools/star/Makefile

[19:51] <Geth> ¦ star: Use correct Rakudo point release

[19:51] <Geth> ¦ star: review: https://github.com/rakudo/star/commit/a54b67f843

[19:51] <Zoffix> Alright

[19:51] <Zoffix> Release is done.

[19:51] <Zoffix> 2017.04.2 is the latest and greatest.

[19:51] <Zoffix> Commit to nom freely :)

[19:52] * Zoffix takes rest of the day off to relax

[19:55] <[Coke]> (group key) We've signed releases as individuals in the past, I don't think that's necessarily a problem to do in the future, is it

[19:55] <[Coke]> ?

[19:55] <[Coke]> (lot of branches) if the branches are merged to nom, we can probably kill them.

[19:56] <timotimo> MasterDuke_: it's not outputting anything into the telemetry log any more

[19:56] <timotimo> it might be that gcc stopped it

[19:58] <MasterDuke_> timotimo: is your branch up to date? if i check it out, build moar, and run my script will i get something useful?

[19:58] <timotimo> oh

[19:58] <timotimo> it's spittin'

[19:58] <samcv> .tell lizmat thank you :) got your package in the mail! so happy!

[19:58] <yoleaux> samcv: I'll pass your message to lizmat.

[19:58] <samcv> i now have perl 6 swag!

[20:00] <timotimo> samcv: yeah!!

[20:14] <timotimo> it seems like the process has ended

[20:18] <timotimo> aha. SIGKILL

[20:18] <timotimo> "the process no longer exists"

[20:30] <robertle> out of curiosity, what does "nom" stand for?

[20:31] <geekosaur> new object model

[20:31] <geekosaur> iirc

[20:33] <timotimo> yeah, from many, many, many years ago

[20:33] <timotimo> before nom rakudo used to compile the whole core setting from source every time you started it

[20:33] <timotimo> because we didn't have serialization yet

[20:34] <jnthn> The history is a little more involved than that :)

[20:35] <jnthn> We did compile the setting into bytecode, but the lack of serialization meant that we couldn't serialize meta-objects

[20:35] <jnthn> So we built up objects every time at startup

[20:35] <jnthn> Like adding all the methods to classes, etc.

[20:37] <timotimo> ah, ok

[20:38] <robertle> sounds slow

[20:39] <jnthn> It was, and CORE.setting was way smaller then

[20:41] <jnthn> By now we are even doing stuff like lazily deserializing parts of CORE.setting on-demand

[20:43] <jnthn> Which gave us a further startup time reduction and base memory reduction

[20:43] <jnthn> At the price of quite a few headaches

[20:47] <MasterDuke_> timotimo: i have a 3601 line telemetry log. anything i can glean from it?

[20:49] <timotimo> you don't have my local patch for it, right?

[20:49] <timotimo> oh

[20:49] <MasterDuke_> no, whatever was on github

[20:50] <timotimo> the patch that i linked you to that changes the marking for call graph nodes also includes the interesting intervals

[20:50] <timotimo> could you apply that patch?

[20:51] <MasterDuke_> doing that now

[20:54] <MasterDuke_> oh, now about 16k lines of log

[20:55] <timotimo> mhm

[20:56] <MasterDuke_> don't know what successors are, but there were 254238 of them

[20:56] <timotimo> that's how many children each call graph node has

[20:56] <timotimo> in theory we could graph the growth of the call graph with this

[20:57] <MasterDuke_> started with 103579

[21:42] <Zoffix> [Coke]: (group key) yes we did do them in the past and now there are a bunch of different keys in use and some are still unverified: https://github.com/rakudo/rakudo/tags?after=2016.01.1  So, I don't know of a way to verify those releases.

[21:43] <Zoffix> [Coke]: and if we use a bunch of different keys, users need to import them (or figure out how to very without importing)

[21:44] <Zoffix> + someone releases some users import key as trusted, user goes apeshit and now we have a bunch of users trusting a hostile key.

[21:44] <Zoffix> ZofBot: APOKEYLIPSE!

[21:44] <ZofBot> Zoffix, [Note: the name "FIRST" used to be associated with "state" declarations

[22:06] <Zoffix> OMG! I got the best hacking ice-cream! A fruity icepop on the outside; pop rocks on the inside!

[22:06] <Zoffix> These ones: https://www.madewithnestle.ca/sites/default/files/styles/product_main_image/public/popping_popz_8x50ml_3d_e.png?itok=cd_rn-0D

[22:06] <Zoffix> Wonder how they make the popping things not pop inside wet-ish icecream, yet pop in wet mouth

[22:15] <geekosaur> temperature?

[22:42] <Zoffix> Ah

[22:46] <samcv> and nucleation. you put it in your mouth and ice cream dissolves off, exposing the pitted groves off the poprocks which then have all those physical sites to react at

[23:07] <Zoffix> :o

[23:07] * Zoffix has another one

[23:07] <Zoffix> ZofBot: FOR SCIENCE

[23:07] <ZofBot> Zoffix, If it's being overly hungry

[23:10] <geekosaur> oh, yes, could well be threshold water level, if the ice cream is decent then it's got lipids that would wash away

[23:24] <Zoffix> "To make Pop Rocks, the hot sugar mixture is allowed to mix with carbon dioxide gas at about 600 pounds per square inch (psi). The carbon dioxide gas forms tiny, 600-psi bubbles in the candy"

[23:24] <Zoffix> 600-psi :o

[23:26] <samcv> not high enough

[23:26] <samcv> we need more bubbles
