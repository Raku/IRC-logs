[00:18] *** phkd6 joined
[00:18] *** phkd6 left
[00:41] <AlexDaniel> :) https://gist.github.com/AlexDaniel/dc18791fef0de7be556df0402dc34cbd

[00:42] *** ggoebel_ left
[00:43] <AlexDaniel> that was for HEAD^^ or something like that, not an issue anymore

[00:50] *** dct left
[01:09] *** Kaypie left
[01:17] *** Drawde23 joined
[01:18] *** Drawde23 left
[01:22] *** lizmat left
[01:28] *** jaagr3 joined
[01:28] *** jaagr3 left
[01:38] *** ggoebel_ joined
[01:38] *** p6bannerbot sets mode: +v ggoebel_

[01:51] <samcv> AlexDaniel: ok :) cool. will work on that releasing that tomorrow

[02:12] *** ZzZombo left
[02:23] *** nibbo_ joined
[02:25] *** nibbo_ left
[02:53] *** ZzZombo joined
[02:53] *** p6bannerbot sets mode: +v ZzZombo

[03:29] *** MasterDuke left
[04:22] *** ggoebel_ left
[04:50] *** Ven` joined
[04:51] *** p6bannerbot sets mode: +v Ven`

[04:55] *** Ven` left
[06:19] *** patrickb joined
[06:19] *** p6bannerbot sets mode: +v patrickb

[06:27] *** robertle joined
[06:28] *** p6bannerbot sets mode: +v robertle

[06:40] *** ggoebel left
[06:41] *** robertle left
[06:53] *** ggoebel joined
[06:54] *** p6bannerbot sets mode: +v ggoebel

[07:32] *** illuminated12 joined
[07:33] *** illuminated12 left
[07:33] *** brrt joined
[07:34] *** p6bannerbot sets mode: +v brrt

[07:39] *** ZzZombo_ joined
[07:39] *** p6bannerbot sets mode: +v ZzZombo_

[07:41] *** ZzZombo left
[07:41] *** ZzZombo__ joined
[07:41] *** ZzZombo__ is now known as ZzZombo

[07:41] *** p6bannerbot sets mode: +v ZzZombo

[07:44] *** ZzZombo_ left
[07:50] *** Ven` joined
[07:50] *** masak joined
[07:51] *** p6bannerbot sets mode: +v Ven`

[07:51] *** p6bannerbot sets mode: +v masak

[07:53] *** lizmat joined
[07:54] *** dogbert17 left
[07:54] *** p6bannerbot sets mode: +v lizmat

[07:54] <lizmat> Files=1253, Tests=76140, 338 wallclock secs (15.48 usr  5.60 sys + 2380.69 cusr 228.51 csys = 2630.28 CPU)

[08:00] *** awwaiid left
[08:14] *** exferenceBot28 joined
[08:19] *** exferenceBot28 left
[08:42] *** brrt left
[08:51] *** dogbert2 joined
[08:52] *** p6bannerbot sets mode: +v dogbert2

[08:56] *** brrt joined
[08:56] *** p6bannerbot sets mode: +v brrt

[09:00] *** haxxpop28 joined
[09:04] *** haxxpop28 left
[09:05] <samcv> [Tux]: you around?

[09:15] *** [TuxCM] joined
[09:16] *** p6bannerbot sets mode: +v [TuxCM]

[09:54] *** Ven` left
[09:55] *** ZzZombo left
[09:56] *** Ven` joined
[09:57] *** p6bannerbot sets mode: +v Ven`

[10:16] *** brrt left
[10:21] *** brrt joined
[10:21] *** p6bannerbot sets mode: +v brrt

[10:43] <Geth> ¬¶ nqp/nqp-mbc: 21 commits pushed by (Stefan Seifert)++

[10:43] <Geth> ¬¶ nqp/nqp-mbc: review: https://github.com/perl6/nqp/compare/a32e1ba79485...73b17eea2cc0

[11:03] *** Ven` left
[11:15] *** [TuxCM] left
[11:19] *** [Tux] joined
[11:19] *** [Tux] is now known as [TuxCM]

[11:20] *** p6bannerbot sets mode: +v [TuxCM]

[11:25] *** innovati joined
[11:27] *** ZzZombo joined
[11:27] *** p6bannerbot sets mode: +v ZzZombo

[11:30] *** innovati left
[11:31] <[TuxCM]> I was running a timing when my PC went out. I hope the two are not related

[11:31] <[TuxCM]> luckily my daughter was at home to reboot the box

[11:38] *** Ven` joined
[11:39] *** p6bannerbot sets mode: +v Ven`

[11:41] *** Kaiepi joined
[11:42] *** p6bannerbot sets mode: +v Kaiepi

[11:51] *** brrt left
[11:54] <Geth> ¬¶ rakudo/postrelease-opts: 5f55d76272 | (Jonathan Worthington)++ | src/Perl6/World.nqp

[11:54] <Geth> ¬¶ rakudo/postrelease-opts: Use a simple atkey in generated BUILDALL

[11:54] <Geth> ¬¶ rakudo/postrelease-opts: 

[11:54] <Geth> ¬¶ rakudo/postrelease-opts: We're already using the existskey op, so may as well go the whole hog

[11:54] <Geth> ¬¶ rakudo/postrelease-opts: and have simpler, faster code here.

[11:54] <Geth> ¬¶ rakudo/postrelease-opts: review: https://github.com/rakudo/rakudo/commit/5f55d76272

[11:59] <lizmat> jnthn: good catch!  

[11:59] <lizmat> maybe I should port that to the 2018.09 release ?

[12:00] <jnthn> No, not worth the risk

[12:01] <jnthn> And it's a win but not a massive one since the costs in construction are elsewhere (I'm looking into that)

[12:05] <lizmat> indeed, I don't see any difference in test-t performance: guess the AT-KEY was very quickly inlined already ?

[12:05] <jnthn> Yeah, it was these days

[12:06] <jnthn> I did see a difference in a construction benchmark

[12:06] <jnthn> But small

[12:15] *** ggoebel_ joined
[12:16] *** p6bannerbot sets mode: +v ggoebel_

[12:48] *** brrt joined
[12:48] *** p6bannerbot sets mode: +v brrt

[12:52] *** Guest52089 joined
[12:54] *** Guest52089 left
[12:54] <dogbert2> m: .contains: "meow" for ^10000_00; say now - INIT now

[12:54] <camelia> rakudo-moar 19edeafd1: OUTPUT: ¬´7.27520441‚ê§¬ª

[12:57] <AlexDaniel> 6c: .contains: "meow" for ^5000_00; say now - INIT now

[12:58] <committable6> AlexDaniel, https://gist.github.com/1d453ef107d4ce5a984340d861cf4e82

[12:59] <dogbert2> AlexDaniel: RT #132280

[12:59] <synopsebot> RT#132280 [new]: https://rt.perl.org/Ticket/Display.html?id=132280 [REGRESSION][PERF] Cool methods that take and pass a Capture are uber slower (.contains: 'meow' for ^10000_00)

[13:00] <AlexDaniel> I have to confess that I remember none of my tickets :)

[13:00] <dogbert2> btw, the RPi fix, alignment related, which went in a few days ago solved the build problems I had

[13:00] <AlexDaniel> dogbert2: good! Thanks

[13:19] <lizmat> m: my %h = <a b c>   # throws

[13:19] <camelia> rakudo-moar 19edeafd1: OUTPUT: ¬´Odd number of elements found where hash initializer expected:‚ê§Found 3 (implicit) elements:‚ê§Last element seen: "c"‚ê§  in block <unit> at <tmp> line 1‚ê§‚ê§¬ª

[13:20] <lizmat> m: my %h; %h.push( <a b c> ); dd %h   # just warns, that seems inconsistent to me

[13:20] <camelia> rakudo-moar 19edeafd1: OUTPUT: ¬´Trailing item in Hash.push‚ê§  in block <unit> at <tmp> line 1‚ê§Hash %h = {:a("b")}‚ê§¬ª

[13:20] <lizmat> m: my %h = <a b c>; dd %h   # doublechecking it throws

[13:20] <camelia> rakudo-moar 19edeafd1: OUTPUT: ¬´Odd number of elements found where hash initializer expected:‚ê§Found 3 (implicit) elements:‚ê§Last element seen: "c"‚ê§  in block <unit> at <tmp> line 1‚ê§‚ê§¬ª

[13:30] *** patrickb left
[13:36] *** [TuxCM] left
[14:03] <Geth> ¬¶ nqp/nqp-mbc: bbdb894fff | (Stefan Seifert)++ | src/vm/moar/QAST/QASTCompilerMAST.nqp

[14:03] <Geth> ¬¶ nqp/nqp-mbc: Fix write_uint32_at only writing to the first 2^16 bytes

[14:03] <Geth> ¬¶ nqp/nqp-mbc: review: https://github.com/perl6/nqp/commit/bbdb894fff

[14:03] *** AsciiWolf10 joined
[14:04] <diakopter> oops lol

[14:05] <diakopter> wait, what's nqp-mbc

[14:07] <nine> diakopter: a branch where I replace MoarVM's MAST compiler with an NQP implementation with the goal of merging that with QASTCompilerMAST to get rid of MAST (or the most expensive parts at least)

[14:08] <diakopter> oh neat. is that a significant bottleneck/stage?

[14:08] *** AsciiWolf10 left
[14:09] <nine> Creating the MAST causes lots of allocations

[14:21] <lizmat> diakopter: I understand it has the potential of halving the MAST stage in time

[14:21] <lizmat> + needing a lot less memory, so easier on the RPi's

[14:35] *** ggoebel_ left
[14:55] *** [Tux] joined
[14:55] *** p6bannerbot sets mode: +v [Tux]

[14:58] *** [Tux] left
[14:58] <AlexDaniel> yeah, canary is green, toaster looks alright, CI is green, releasable is happy

[14:59] <brrt> \o/

[14:59] *** [Tux] joined
[14:59] *** p6bannerbot sets mode: +v [Tux]

[15:00] *** radeek13 joined
[15:03] *** radeek13 left
[15:03] *** drawkula0 joined
[15:08] *** drawkula0 left
[15:12] *** [TuxCM] joined
[15:12] *** p6bannerbot sets mode: +v [TuxCM]

[15:16] *** ggoebel_ joined
[15:17] *** p6bannerbot sets mode: +v ggoebel_

[15:20] <Geth> ¬¶ rakudo: taboege++ created pull request #2291: Check for definedness of callframe.code when creating error message

[15:20] <Geth> ¬¶ rakudo: review: https://github.com/rakudo/rakudo/pull/2291

[15:22] * [Tux] waves

[15:25] <timotimo> in *theory* we can quickly reject .contains of strings that don't look numerical when called on .Int

[15:26] <timotimo> where did we get the "halving mast stage in time" number?

[15:26] <timotimo> just that we're now writing mast bytecode immediately instead of first building MAST nodes?

[15:27] <timotimo> i'd expect that only halve in the very best case, which is that qast -> MAST and MAST -> mbc both take exactly the same amount of time

[15:27] <timotimo> but the MAST -> mbc compiler is written in C and might be a bunch faster than the QAST -> MAST part

[15:28] <samcv> hey [Tux]!

[15:31] <samcv> any thoughts on whether you think "foo".encode('utf16') should add a BOM? i feel it should at least add it when we write to an actual file (start writing at position 0). but otherwise i don't know if .encode should add a BOM for utf16. here's what i said in #moarvm http://colabti.org/irclogger/irclogger_log/moarvm?date=2018-09-19#l69

[15:31] <[Tux]> "foo" being a file or a string? If string, no

[15:32] <samcv> yeah just foo is a string

[15:32] <samcv> m: "foo".encode('utf16').say

[15:32] <camelia> rakudo-moar 19edeafd1: OUTPUT: ¬´utf16:0x<66 6f 6f>‚ê§¬ª

[15:32] <samcv> [Tux]: what about to a file?

[15:32] <[Tux]> yes

[15:32] <[Tux]> :)

[15:32] <samcv> ok. that's what i was thinking of doing

[15:33] <[Tux]> üëçüèª

[15:34] <samcv> [Tux]: ok and so utf16le and utf16be as of yesterday in moarvm master will not handle BOM in files specially

[15:35] <samcv> like how perl 5 does (from my testing) and what the standard says. though many ignore that and treat it as a BOM (i.e. remove it from the file on read). do you think that is the right approach too?

[15:35] <timotimo> that ... is a 3 byte big utf16 string?!

[15:35] <timotimo> oh

[15:35] <timotimo> no, that's three 16bit numbers

[15:35] <timotimo> sorry

[15:37] <samcv> so reading "\x[FEFF]hello" from a file using 'utf16' encoding will pass through "hello" while reading it with "utf16le" will pass through "\x[FEFF]hello"

[15:38] <[Tux]> Rakudo version 2018.08-114-g19edeafd1 - MoarVM version 2018.08-92-g3e94a68f6

[15:38] <[Tux]> csv-test-xs-20      0.422 -  0.435

[15:38] <[Tux]> csv-ip5xs           0.898 -  0.923

[15:38] <[Tux]> test-t --race       0.902 -  0.910

[15:38] <[Tux]> test-t              2.119 -  2.188

[15:38] <[Tux]> csv-ip5xs-20        7.673 -  7.704

[15:38] <[Tux]> test                8.655 -  9.147

[15:38] <[Tux]> test-t-20 --race   11.940 - 12.554

[15:38] <[Tux]> csv-parser         24.215 - 25.013

[15:38] <samcv> also the question is. if we do .decode('utf16') on "\x[FEFF]hello" do we get "\c[FEFF]hello"? or "hello"?

[15:38] <[Tux]> test-t-20          36.757 - 38.287

[15:39] <timotimo> wow, quite a bounce-back

[15:39] <[Tux]> I have no answer to that last question. I'm open to arguments for either

[15:39] <samcv> if we don't encode the BOM except for *files* do we treat the BOM specially for .decode or do the same we do for encode (only in an actual file)

[15:39] <samcv> ok

[15:39] <samcv> same :P

[15:40] <[Tux]> timotimo, not really I guess. I rebooted after a crash and am working on the desktop, so it is maybe a bit more busy

[15:40] <timotimo> OK

[15:40] <timotimo> i suppose we just hope for the data to be good on average ;)

[15:40] <timotimo> the error can hardly be negative ;)

[15:43] *** inked-19 joined
[15:48] *** inked-19 left
[15:56] *** brrt left
[15:57] *** lizmat left
[16:12] <Geth> ¬¶ rakudo: f359fa9a26 | (Tobias Boege)++ | src/core/metaops.pm6

[16:12] <Geth> ¬¶ rakudo: Check for definedness of callframe.code when creating error message

[16:12] <Geth> ¬¶ rakudo: 

[16:12] <Geth> ¬¶ rakudo: This fixes #2222. The "non-dwimmy hyperop" hint uses callframe(‚Ä¶).code.name

[16:12] <Geth> ¬¶ rakudo: to detect if it recurses. In some cases callframe.code is Mu (unknown file)

[16:12] <synopsebot> RAKUDO#2222 [closed]: https://github.com/rakudo/rakudo/issues/2222 LTA error message with non-dwimmy hyper infix

[16:12] <Geth> ¬¶ rakudo: which leads to an error looking up .name. Inserting `andthen` solves this.

[16:12] <Geth> ¬¶ rakudo: review: https://github.com/rakudo/rakudo/commit/f359fa9a26

[16:12] <Geth> ¬¶ rakudo: e889d7ed68 | (Zoffix Znet)++ (committed using GitHub Web editor) | src/core/metaops.pm6

[16:12] <Geth> ¬¶ rakudo: Merge pull request #2291 from taboege/callframe-code-name-in-non-dwimmy-hyperop-message

[16:12] <Geth> ¬¶ rakudo: 

[16:12] <Geth> ¬¶ rakudo: Check for definedness of callframe.code when creating error message

[16:12] <Geth> ¬¶ rakudo: review: https://github.com/rakudo/rakudo/commit/e889d7ed68

[16:14] *** Ven` left
[16:15] *** AlexDaniel left
[16:17] *** Ven` joined
[16:18] *** p6bannerbot sets mode: +v Ven`

[16:19] *** AlexDaniel joined
[16:19] *** p6bannerbot sets mode: +v AlexDaniel

[16:19] *** Zoffix joined
[16:19] *** p6bannerbot sets mode: +v Zoffix

[16:20] <Zoffix> my MAST stage for core is 18s. Halving it would be a nice win :)

[16:22] <Geth> ¬¶ nqp: ee16e6c4ed | (Zoffix Znet)++ | tools/build/MOAR_REVISION

[16:22] <Geth> ¬¶ nqp: [MoarVM Bump] Brings 6 commits

[16:22] <Geth> ¬¶ nqp: 

[16:22] <Geth> ¬¶ nqp: MoarVM bump brought: https://github.com/MoarVM/MoarVM/compare/2018.08-86-gddde09508...2018.08-92-g3e94a68

[16:22] <Geth> ¬¶ nqp: 3e94a68 Pass through BOM with utf16le and utf16be

[16:22] <Geth> ¬¶ nqp: 24860d4 let spesh discover the type of hllbool[for]

[16:22] <Geth> ¬¶ nqp: 025b3cd Fix fprintf compiler warning in main.c

[16:22] <Geth> ¬¶ nqp: ff75050 Make sure MVM_string_utf16le/be_decodestream are predeclared

[16:22] <Geth> ¬¶ nqp: ad12d8e Fix some bugs with utf16* decodestream get_chars, and retain state

[16:22] <Geth> ¬¶ nqp: 792cdd5 Add support for utf16le and utf16be decodestream

[16:23] <Geth> ¬¶ nqp: review: https://github.com/perl6/nqp/commit/ee16e6c4ed

[16:23] <Geth> ¬¶ nqp: version bump brought these changes: https://github.com/MoarVM/MoarVM/compare/2018.08-86-gddde09508...2018.08-92-g3e94a68

[16:23] <Geth> ¬¶ rakudo: d275ea09bb | (Zoffix Znet)++ | tools/build/NQP_REVISION

[16:23] <Geth> ¬¶ rakudo: [NQP Bump] ee16e6c [MoarVM Bump] Brings 6 commits

[16:23] <Geth> ¬¶ rakudo: 

[16:23] <Geth> ¬¶ rakudo: NQP bump brought: https://github.com/perl6/nqp/compare/2018.08-65-g358dc6eab...2018.08-66-gee16e6c

[16:23] <Geth> ¬¶ rakudo: 

[16:23] <Geth> ¬¶ rakudo: MoarVM bump brought: https://github.com/MoarVM/MoarVM/compare/2018.08-86-gddde09508...2018.08-92-g3e94a68

[16:23] <Geth> ¬¶ rakudo: 3e94a68 Pass through BOM with utf16le and utf16be

[16:23] <Geth> ¬¶ rakudo: 24860d4 let spesh discover the type of hllbool[for]

[16:23] <Geth> ¬¶ rakudo: 025b3cd Fix fprintf compiler warning in main.c

[16:23] <Geth> ¬¶ rakudo: ff75050 Make sure MVM_string_utf16le/be_decodestream are predeclared

[16:23] <Geth> ¬¶ rakudo: ad12d8e Fix some bugs with utf16* decodestream get_chars, and retain state

[16:23] <Geth> ¬¶ rakudo: 792cdd5 Add support for utf16le and utf16be decodestream

[16:23] <Geth> ¬¶ rakudo: review: https://github.com/rakudo/rakudo/commit/d275ea09bb

[16:23] <Geth> ¬¶ rakudo: version bump brought these changes: https://github.com/perl6/nqp/compare/2018.08-65-g358dc6eab...2018.08-66-gee16e6c

[16:23] <Zoffix> ZOFVM: Files=1309, Tests=153183, 166 wallclock secs (26.66 usr  3.44 sys + 3587.26 cusr 162.45 csys = 3779.81 CPU)

[16:23] *** Zoffix left
[16:25] <Geth> ¬¶ roast: e55749a9f6 | (Zoffix Znet)++ | MISC/bug-coverage.t

[16:25] <Geth> ¬¶ roast: Cover hyper DWIM error

[16:25] <Geth> ¬¶ roast: 

[16:25] <Geth> ¬¶ roast: Closes https://github.com/rakudo/rakudo/issues/2222 R#2222

[16:25] <Geth> ¬¶ roast: Rakudo fix: https://github.com/rakudo/rakudo/pull/2291/files

[16:25] <Geth> ¬¶ roast: review: https://github.com/perl6/roast/commit/e55749a9f6

[16:25] <synopsebot> R#2222 [open]: https://github.com/rakudo/rakudo/issues/2222 [testneeded] LTA error message with non-dwimmy hyper infix

[16:51] *** Ven` left
[17:07] *** travis-ci joined
[17:07] *** p6bannerbot sets mode: +v travis-ci

[17:07] <travis-ci> Rakudo build failed. Zoffix Znet 'Merge pull request #2291 from taboege/callframe-code-name-in-non-dwimmy-hyperop-message

[17:07] <travis-ci> https://travis-ci.org/rakudo/rakudo/builds/430623589 https://github.com/rakudo/rakudo/compare/19edeafd1caf...e889d7ed6875

[17:07] *** travis-ci left
[17:07] <buggable> [travis build above] ‚ò† Did not recognize some failures. Check results manually.

[17:27] *** brrt joined
[17:28] *** p6bannerbot sets mode: +v brrt

[17:35] *** bisectable6 left
[17:35] *** bisectable6 joined
[17:36] *** p6bannerbot sets mode: +v bisectable6

[17:45] *** bisectable6 left
[17:45] *** bisectable6 joined
[17:45] *** ChanServ sets mode: +v bisectable6

[17:46] *** p6bannerbot sets mode: +v bisectable6

[17:50] *** lizmat joined
[17:51] *** p6bannerbot sets mode: +v lizmat

[17:56] <AlexDaniel> [Coke]: https://github.com/ugexe/zef/issues/272#issuecomment-422897511

[17:56] <AlexDaniel> [Coke]: can you explain what the issue is exactly?

[17:57] <AlexDaniel> and how to resolve that without rewriting the module

[17:57] *** brrt left
[18:03] *** brrt joined
[18:04] *** p6bannerbot sets mode: +v brrt

[18:17] *** Zoffix joined
[18:17] *** p6bannerbot sets mode: +v Zoffix

[18:19] <[Coke]> AlexDaniel: it says "I agree with [Coke]", but doesn't say what I said. 

[18:19] <[Coke]> oh.

[18:19] <[Coke]> the code that goes into rakudo is covered by the CLA.

[18:20] <[Coke]> the code that goes into "some module" isn't.

[18:20] <Zoffix> AlexDaniel: wouldn't we be able to get more speed by making a more limited version of JSON parser? (just a guess)

[18:20] <Zoffix> AlexDaniel: like, we don't have to be able to handle custom objects, for example

[18:20] <Zoffix> AlexDaniel: also, are we talking about making a publicly-available JSON parser in core, or are we only going to improve the private one?

[18:20] <AlexDaniel> [Coke]: so can't we just tell timotimo to contribute it to core?

[18:21] <[Coke]> *tell*? no

[18:21] <[Coke]> *ask*? sure.

[18:21] <AlexDaniel> ask

[18:21] <AlexDaniel> I didn't mean that, yes :)

[18:21] <[Coke]> Zoffix: isn't it already publicly available?

[18:21] <Zoffix> AlexDaniel: also, IIRC JSON::Fast creates Arrays, and it's likely more efficient to create Lists or Seqs instead (which can't be easily changed in JSON::Fast, without affecting stuff)

[18:21] <timotimo> if all other core devs are ok with that, sure

[18:21] <[Coke]> (as some helper routines?)

[18:21] <AlexDaniel> Zoffix: I don't think we want to make it publicly available, just improve the internal one

[18:21] <Zoffix> [Coke]: no, all Rakudo::Internal stuff is internal

[18:22] <Zoffix> [Coke]: I mean, you can still call it, but it'll be your fault if your code breaks.

[18:22] <timotimo> Zoffix: i'm not sure why a Seq would be better, but a List should be doable. perhaps an IterationBuffer

[18:22] <Zoffix> mhm

[18:23] <[Coke]> m: dd from-json("[1]");

[18:23] <camelia> rakudo-moar d275ea09b: OUTPUT: ¬´$[1]‚ê§¬ª

[18:23] <[Coke]> ^^ 

[18:23] <AlexDaniel> not really

[18:23] <AlexDaniel> e: dd from-json("[1]");

[18:23] <evalable6> AlexDaniel, rakudo-moar d275ea09b: OUTPUT: ¬´$[1]‚ê§Saw 1 occurrence of deprecated code.‚ê§================================================‚Ä¶¬ª

[18:23] <evalable6> AlexDaniel, Full output: https://gist.github.com/dca123a1d73ffa38b7952c5e4b44c73d

[18:23] <[Coke]> aren't we talking about updating that one?

[18:23] <AlexDaniel> yes

[18:23] <Zoffix> [Coke]: yeah, we area

[18:23] <Zoffix> *are

[18:24] <Zoffix> [Coke]: and yeah, you're right, it doesn't have Rakudo::Internal in it's name. But there is a deprecation warning that's been in place since Christmas

[18:24] <AlexDaniel> [Coke]: because it is used by rakudo and by zef, and in case of zef things are really slow and can be sped up over 6 times

[18:24] <[Coke]> ok, so once that hits, sure, private.

[18:25] <[Coke]> So instead of bundling with rakudo, bundle it with zef.

[18:25] <[Coke]> seems to avoid many of the logistic and maintenance issues.

[18:26] *** Zoffix left
[18:26] <timotimo> i'm hoping to be able to get a JSON::Fast version 2 on the API where we have fewer containers in the data structure

[18:26] <timotimo> also, perhaps basing the parser on unicode codepoints rather than actually strings

[18:28] <lizmat> timotimo: and drop support for synthetic graphemes ?

[18:28] *** BurningPrincess0 joined
[18:28] <[Coke]> Which makes me want to say even more, keep it in a module.

[18:28] <timotimo> not needed

[18:29] *** BurningPrincess0 left
[18:31] <AlexDaniel> [Coke]: I'm not following, what do you mean by that last message?

[18:34] <[Coke]> I would prefer we not dual home a module.

[18:34] <[Coke]> esp. one that is doing more than we need in core.

[18:34] <[Coke]> (esp if it's not going to be exposed to user-land anyway)

[18:35] <AlexDaniel> [Coke]: so in your mind what's the solution?

[18:36] <[Coke]> so, my recommendation is let this deprecation happen, remove the public interface; if zef needs json support, it can bundle the module as part of its own install.

[18:37] <AlexDaniel> [Coke]: and for stuff like this we do what? https://github.com/rakudo/rakudo/blob/d275ea09bb156d5a37076e272728628030dfacff/src/core/CompUnit/Repository/FileSystem.pm6#L24-L35

[18:42] <AlexDaniel> point is, both rakudo and zef currently use a json parser that is very slow

[18:42] <AlexDaniel> and I don't see this changing any time soon

[18:42] *** [Tux] left
[18:43] <AlexDaniel> ‚Äúzef needs to use the same JSON parser as rakudo internals for the CUR reasons‚Äù ‚Äì I don't know what these CUR reasons are, but if it's true, then there is a yet another reason to fix what we have now

[18:44] <AlexDaniel> it's not like we're committing to always have a copy of JSON::Fast in core, but right now it'd give an immediate, noticeable win

[18:44] <[Coke]> should zef be doing things with internals? Or should it be using CUR: and letting it handle it?

[18:45] <[Coke]> IMO zef should not be poking at Rakudo::Internals

[18:45] *** KombuchaKip7 joined
[18:46] <[Coke]> AlexDaniel: parsing meta6.json doesn't seem to require any internals knowlege.

[18:47] *** KombuchaKip7 left
[18:48] <[Coke]> if we did want to include the module in core but not expose it, how would we do that? would it impact build time, build requirements, disk footprint, etc.

[18:48] <AlexDaniel> [Coke]: yes? But that code is in rakudo, so what do you mean by internals knowlege?

[18:49] *** [Tux] joined
[18:49] <lizmat> JSON::Fast could live in lib perhaps ?

[18:49] <lizmat> to be loaded on demand?

[18:49] <AlexDaniel> same way we do it now

[18:49] *** p6bannerbot sets mode: +v [Tux]

[18:50] <AlexDaniel> I was thinking we just replace the current code with the code from JSON::Fast and call it a day :)

[18:50] <AlexDaniel> if timotimo agrees of course

[18:55] *** epony left
[18:58] <AlexDaniel> I mean, we can keep the bikeshedding on what should be done ideally go for as long as want

[18:59] <AlexDaniel> but it would be nice to have the speed improvement now-ish

[19:01] <[Coke]> if you're going to hide it so it's not exposed as a module to the users, and are just replacing from-json and to-json, and the copyright is fine, sure.

[19:02] <timotimo> i'm fine with having JSON::Fast be Artistic2, MIT, BSD3 or 2, WTFPL, LGPL, or something similar

[19:02] <timotimo> though there's a few contributions that i didn't make

[19:02] <timotimo> i "stole" a faster to-json (which is noted in the readme, of course)

[19:03] <lizmat> AlexDaniel: are you still ok with accepting commits in rakudo atm ?

[19:04] <[Coke]> (didn't write all the code, borrowed from tony-o), I would say this would need to be addressed before pulling the code into rakudo.

[19:16] *** brrt left
[19:16] *** epony joined
[19:16] *** p6bannerbot sets mode: +v epony

[19:25] *** belst3 joined
[19:29] *** belst3 left
[19:31] <Geth> ¬¶ rakudo: 12cfde2afd | (Elizabeth Mattijsen)++ | src/core/Hash.pm6

[19:31] <Geth> ¬¶ rakudo: Make Hash.push/append between 20% and 40% faster

[19:31] <Geth> ¬¶ rakudo: 

[19:31] <Geth> ¬¶ rakudo: Depending on whether the key in question already existed or not

[19:31] <Geth> ¬¶ rakudo: review: https://github.com/rakudo/rakudo/commit/12cfde2afd

[19:34] <AlexDaniel> lizmat: not really :D

[19:34] <AlexDaniel> but ok, I'll just start a release branch

[19:35] <AlexDaniel> done

[19:35] <AlexDaniel> releasable6: vars

[19:35] <releasable6> AlexDaniel, branch=master; timeout=10

[19:35] <lizmat> timotimo AlexDaniel: for zef we only need from-json, o ?

[19:36] <AlexDaniel> releasable6: branch=release-2018.09

[19:36] <releasable6> AlexDaniel, branch is now set to ‚Äúrelease-2018.09‚Äù (default value is ‚Äúmaster‚Äù)

[19:36] <AlexDaniel> releasable6: status

[19:36] <releasable6> AlexDaniel, No! It wasn't me! It was the one-armed man! Backtrace: https://gist.github.com/8d532938e688a2956a74b36c1824fe86

[19:36] <AlexDaniel> ‚Ä¶

[19:36] <AlexDaniel> releasable6: branch=reset

[19:36] <releasable6> AlexDaniel, branch is now set to its default value ‚Äúmaster‚Äù

[19:47] <AlexDaniel> lizmat: yes, seems so. But to-json is used in rakudo

[19:49] <lizmat> so, what is the bottleneck?  from-json or to-json ?

[19:49] <AlexDaniel> timotimo: if I'm not mistaken, that was from tony-o? And tony-o is currently willing to write a whole new parser from scratch‚Ä¶ So I guess they won't be against including it

[19:49] <AlexDaniel> lizmat: from-json

[19:49] <lizmat> I had an idea... probably stupid

[19:49] <AlexDaniel> lizmat: at least nobody complained about to-json yet

[19:50] <lizmat> most META6.json files are well formed

[19:50] <AlexDaniel> lizmat: this idea? http://colabti.org/irclogger/irclogger_log/perl6-dev?date=2018-09-19#l293

[19:50] <lizmat> so I was thinking of doing a very "words" based parser: if that fails, then fall back to the grammar based one

[19:51] <lizmat> yeah

[19:51] <AlexDaniel> JSON::Fast is not grammar based

[19:52] <AlexDaniel> probably not a bad idea, but JSON::Fast was already 6x as fast when I measured

[20:50] <tony-o> [Coke]: zef relies on the internal JSON to parse things for CUR's exactly the same way the internals would

[20:50] <yoleaux> 9 May 2018 15:56Z <Zoffix> tony-o: recall you had a tool that extracted versions from repos, based on commits to META file? Where is it? Were zef using it in the past (I thought it were)? If not, how come not? Using it would let github dists be versioned, no?

[20:51] <tony-o> .tell zoffix sure enough.  it's used on modules.zef.pm and i could probably integrate it into zef with some work, it would be slow on large repos but at least the functionality would be there i suppose

[20:51] <yoleaux> tony-o: I'll pass your message to zoffix.

[20:53] <tony-o> i talked to ugexe about bundling the json parser i wrote for JSON::Faster (before it merged into JSON::Fast) with zef and there were concerns about some edge cases of parsing JSON differently from internals having adverse effects

[20:58] <[Tux]> Rakudo version 2018.08-114-g19edeafd1 - MoarVM version 2018.08-92-g3e94a68f6

[20:58] <[Tux]> csv-test-xs-20      0.424 -  0.430

[20:58] <[Tux]> test-t --race       0.856 -  0.865

[20:58] <[Tux]> csv-ip5xs           0.900 -  0.906

[20:58] <[Tux]> test-t              2.087 -  2.116

[20:58] <[Tux]> csv-ip5xs-20        7.004 -  7.236

[20:58] <[Tux]> test                8.550 -  8.823

[20:58] <[Tux]> test-t-20 --race   11.233 - 11.341

[20:58] <[Tux]> csv-parser         23.714 - 24.240

[20:58] <[Tux]> test-t-20          35.796 - 37.024

[21:05] <AlexDaniel> tony-o: yeah, I'm worried about that too

[21:11] <tony-o> ugexe brought up exposing a (de)serialize method in CU to mitigate the issue and make the internal parser private

[21:12] <AlexDaniel> yeah, but that's a separate issue

[21:14] <tony-o> which part is a separate issue

[21:15] <tony-o> didn't realize we had irc logging again or i would've discussed here rather than GH issues :-)

[21:19] *** ggoebel_ left
[21:22] <lizmat> hmmm... my approach is 7x faster than the built-in R:I:JSON.from-jsonn

[21:22] <lizmat> that's disappointing

[21:24] <tony-o> 7 > 6 though :p

[21:33] <AlexDaniel> tony-o: well, it's related, but whether we hide the internal parser behind serialize/deserialize methods or not doesn't change the fact that the internal parser should be improved

[21:38] <lizmat> I got it up to 7.4x faster

[21:38] <timotimo> sorry, i was AFK for big parts of the day

[21:38] <timotimo> is JSON::Fast still on the table for replacing the internal parser?

[21:39] <lizmat> https://gist.github.com/lizmat/0454f034b9336673cea4fb31927ca164  # my take on a pretty braindead parser

[21:40] <timotimo> looks like it requires everything to be separated by spaces?

[21:41] <lizmat> yeah, it assumes a well formed JSON as can be expected from a META6.json made by e.g. App::Mi6

[21:41] <lizmat> the idea would be to put:

[21:41] <timotimo> oh

[21:41] <timotimo> fall back to the grammar based one

[21:41] <timotimo> only if needed

[21:42] <lizmat> .return with self.quick-from-json($meta)

[21:42] <lizmat> inside the "from-json" method

[21:43] <timotimo> there's still some things missing, but i expect you know that, too

[21:43] <lizmat> which things?  It worked on my sample META6.json

[21:43] <timotimo> \" inside strings

[21:44] <timotimo> i mean it has to know to abort to the safe parser in that case

[21:44] <lizmat> do you have an example ?

[21:45] <AlexDaniel> timotimo: yes it is

[21:45] <AlexDaniel> timotimo: even with quick-from-json we still don't want to fall back to turtle speeds

[21:46] <timotimo> how much faster is quick-from-json than json-fast?

[21:46] * lizmat tests

[21:47] *** BronzeEagle2 joined
[21:51] <lizmat> timotimo: about 2x as fast as JSON::Fast, for my sample file

[21:51] <timotimo> not terrible

[21:53] <lizmat> hmmm... do we have a faster way to get handle \ in a string than EVAL ?

[21:54] <timotimo> hm?

[21:56] *** BronzeEagle2 left
[21:56] <lizmat> something like "foo a\"bar" comes out as "'foo a\"bar' rather than 'foo a"bar'

[21:56] <timotimo> right

[21:56] <timotimo> really only with a trans call

[22:00] <timotimo> well, going through character by character is also possible

[22:00] <timotimo> but not advisable, i don't think

[22:01] <timotimo> using index will at least be able to do 2 steps at a time

[22:03] <lizmat> basically, removing all \ ?

[22:03] <timotimo> well, not all \

[22:04] <timotimo> you have to take care of double escapes and everything

[22:05] <lizmat> hence my question: do we have some internal function that does that

[22:05] <timotimo> not that i know

[22:05] <timotimo> otherwise i would have stolen it for JSON::Fast :P

[22:06] <lizmat> for a given string, rather than have to EVAL the whole thig

[22:06] <lizmat> hehe

[22:06] <lizmat> ok, well with EVAL it becomes *way* slower

[22:06] <timotimo> oh yes

[22:08] <lizmat> well, then I propose we bail on *any* \ in a string

[22:08] <lizmat> and fall back to the slow one

[22:08] <timotimo> that's fine

[22:09] <lizmat> or not use this approach at all

[22:13] <timotimo> we have to be extra sure to never attempt to parse something we can't handle with this parser

[22:13] <timotimo> until then it's just fine to have a naive but fast parser

[22:13] <lizmat> well, if anything, this should only be done *after* the release

[22:14] <lizmat> AlexDaniel: can I push this to master without interfering with the release process?

[22:14] <AlexDaniel> yes

[22:14] <lizmat> timotimo: so, shall I put this in then?

[22:15] <timotimo> we should try crafting some really evil json files and see if it misparses

[22:15] <lizmat> before or after I push this ?

[22:16] <timotimo> since it wouldn't end up in the release, it should be fine to do it after

[22:16] <lizmat> ok, will put it in then

[22:21] <lizmat> running spectest now

[22:21] <timotimo> hm, so no support for numbers needed at all?

[22:22] *** MasterDuke joined
[22:22] *** p6bannerbot sets mode: +v MasterDuke

[22:22] *** MasterDuke left
[22:22] *** MasterDuke joined
[22:22] *** herbert.freenode.net sets mode: +v MasterDuke

[22:22] *** p6bannerbot sets mode: +v MasterDuke

[22:22] <timotimo> interesting

[22:23] <lizmat> when do you see numbers in a META6.json ?

[22:23] <timotimo> right

[22:24] <lizmat> If this works, I can probably squeeze another few percent out of it

[22:25] <timotimo> sure

[22:25] <lizmat> repeated item.ends-with could become a single int comparison

[22:25] <timotimo> hm.

[22:25] <timotimo> maybe order parse by what appears most often, which i imagine is strings

[22:26] <lizmat> yeah, things like that

[22:27] *** pyrimidine left
[22:27] <timotimo> using %hash.push could get weird if a key appears multiple times

[22:28] <lizmat> yeah, should it just be an assign?  multiple keys not allowed ?

[22:28] <timotimo> i think the json spec says nothing about multiple keys

[22:28] <timotimo> JSON::Fast assigns

[22:28] <tony-o> can't you just regex replace \" with " instead of EVALing lizmat ?

[22:28] <timotimo> tony-o: we're bending over backwards to avoid regexes :D

[22:29] <tony-o> got it

[22:29] <tony-o> any reason for that?

[22:29] <timotimo> gotta go fast

[22:29] <timotimo> regex are ... not terribly fast

[22:30] <tony-o> index('\\') and then grabbing two chars at a time doesn't seem that bad

[22:30] <lizmat> oohh... removing the %hash.push makes it about 3x as fast as JSON::Fast

[22:30] <timotimo> nice

[22:30] <timotimo> because it doesn't have to check exists-key i guess

[22:30] <timotimo> and potentially inlines better

[22:31] <tony-o> is that gist up to date lizmat ?

[22:31] <lizmat> no, I'll update in a mo

[22:31] <lizmat> no, actually, will push in a mo

[22:31] <tony-o> to blead ?

[22:32] <timotimo> Test::Meta6 could make extra sure the json is palatable to rakudo's fast parser

[22:34] <lizmat> tony-o: yes

[22:35] <japhb> .oO( COMPATIBLE-WITH-WARP-SPEED )

[22:35] <MasterDuke> timotimo: i probably won't be around much this evening, but if you've got a couple spare minutes https://gist.github.com/MasterDuke17/1c45e013eac54ac54e6578d49eabd36c has the latest version of my range patch and some debug output from the only spectest fail

[22:44] <Geth> ¬¶ rakudo: 16ce9c89ad | (Elizabeth Mattijsen)++ | src/core/Rakudo/Internals/JSON.pm6

[22:44] <Geth> ¬¶ rakudo: Introducing the ultra-fast braindead JSON parser

[22:44] <Geth> ¬¶ rakudo: 

[22:44] <Geth> ¬¶ rakudo: This parser only handles hashes, arrays and strings and will return

[22:44] <Geth> ¬¶ rakudo: Nil if *anything* goes wrong.  It is now plugged into "R:I:JSON.from-json"

[22:44] <Geth> ¬¶ rakudo: to first attempt the very fast parser: of that fails, fall back to the

[22:44] <Geth> ¬¶ rakudo: original, slow, grammar based parser.

[22:44] <Geth> ¬¶ rakudo: 

[22:44] <Geth> ¬¶ rakudo: How much faster: at least 10x faster!

[22:44] <Geth> ¬¶ rakudo: review: https://github.com/rakudo/rakudo/commit/16ce9c89ad

[22:44] <lizmat> have fun

[22:44] <timotimo> damn, 10x is not bad at all

[22:44] * lizmat is going to get some sleep

[22:45] <timotimo> though of course that's compared to the very slow one

[22:45] <timotimo> good work lizmat :)

[22:45] <timotimo> and have a good rest

[22:45] <lizmat> yeah, that last %hash.push -> %hash.BIND-KEY was the final multiplier

[22:45] <lizmat> sleep&

[22:47] <AlexDaniel> .tell lizmat I think you should try that parser on these files: https://raw.githubusercontent.com/ugexe/Perl6-ecosystems/master/cpan.json http://ecosystem-api.p6c.org/projects.json

[22:47] <yoleaux> AlexDaniel: I'll pass your message to lizmat.

[22:48] <timotimo>   "authors" : "Christian S\u00e1nchez"

[22:48] <timotimo> it'll basically immediately bail out, or at least it should

[22:49] <timotimo> there is also coke who has his nickname in quote marks in the middle of his "author" entry

[22:49] <timotimo> and some email addresses have the address + a little description text in quotes

[22:49] <timotimo> er, wrong

[22:49] <timotimo> auth being nickname \"address@foo.com\"

[22:49] <timotimo>   "name" : "Acme::\u0ca0_\u0ca0",

[22:49] <timotimo> who did that :D

[22:50] <timotimo> m: say "\u0ca0_\u0ca0"

[22:50] <camelia> rakudo-moar 12cfde2af: OUTPUT: ¬´5===SORRY!5=== Error while compiling <tmp>‚ê§Unrecognized backslash sequence: '\u'‚ê§at <tmp>:1‚ê§------> 3say "\7‚èè5u0ca0_\u0ca0"‚ê§    expecting any of:‚ê§        argument list‚ê§        double quotes‚ê§        term‚ê§¬ª

[22:50] <timotimo> m: say "\u0ca0\_\u0ca0"

[22:50] <camelia> rakudo-moar 12cfde2af: OUTPUT: ¬´5===SORRY!5=== Error while compiling <tmp>‚ê§Unrecognized backslash sequence: '\u'‚ê§at <tmp>:1‚ê§------> 3say "\7‚èè5u0ca0\_\u0ca0"‚ê§    expecting any of:‚ê§        argument list‚ê§        double quotes‚ê§        term‚ê§¬ª

[22:50] <AlexDaniel> u: \u0ca0

[22:50] <unicodable6> AlexDaniel, U+0CA0 KANNADA LETTER TTHA [Lo] (‡≤†)

[22:50] <timotimo> m: say "\x0ca0 _ \x0ca0"

[22:50] <camelia> rakudo-moar 12cfde2af: OUTPUT: ¬´‡≤† _ ‡≤†‚ê§¬ª

[22:50] <timotimo> ah, that's the one

[22:51] <timotimo> liz has a few modules that have quotes in the description :)

[22:51] <AlexDaniel> I'm also interested to know what's going to happen if you add two modules that depend on each other

[22:52] <AlexDaniel> afaik there's no such thing in the ecosystem yet

[22:52] <AlexDaniel> (because my stupid tool works)

[23:19] <tony-o> lizmat++

[23:20] <timotimo>     "Tadeusz \u201ctadzik\u201d So\u015bnierz",

[23:20] <timotimo> this guy is just the absolute worst :D :D

[23:39] *** PhonicUK joined
[23:43] *** PhonicUK left
[23:56] *** ggoebel_ joined
[23:57] *** p6bannerbot sets mode: +v ggoebel_

