[00:02] <dalek> nqp: cea29a3 | (Zoffix Znet)++ | docs/ops.markdown:

[00:02] <dalek> nqp: Fix broken example

[00:02] <dalek> nqp: review: https://github.com/perl6/nqp/commit/cea29a31d6

[06:19] <dalek> roast: 13a41ba | usev6++ | S03-metaops/reduce.t:

[06:19] <dalek> roast: Unfudge passing tests on JVM (RT #126899)

[06:19] <dalek> roast: review: https://github.com/perl6/roast/commit/13a41ba662

[06:19] <synopsebot6> Link:  https://rt.perl.org/rt3//Public/Bug/Display.html?id=126899

[06:59] <FROGGS> o/

[07:19] <bartolin> \o

[07:55] <[Tux]> This is Rakudo version 2016.09-148-g6977b87 built on MoarVM version 2016.09-34-g082c989

[07:55] <[Tux]> csv-ip5xs        3.207

[07:55] <[Tux]> test            16.439

[07:55] <[Tux]> test-t           7.390

[07:55] <[Tux]> csv-parser      19.802

[11:02] <dalek> nqp: 1a37f62 | FROGGS++ | tools/build/MOAR_REVISION:

[11:02] <dalek> nqp: bump moar for num->bigint fix

[11:02] <dalek> nqp: review: https://github.com/perl6/nqp/commit/1a37f62e74

[11:03] <dalek> rakudo/nom: 228cbc3 | FROGGS++ | tools/build/NQP_REVISION:

[11:03] <dalek> rakudo/nom: bump nqp/moar for num->bigint fix

[11:03] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/228cbc3971

[11:28] <lizmat> Files=1146, Tests=53276, 220 wallclock secs (13.30 usr  3.87 sys + 1339.82 cusr 126.48 csys = 1483.47 CPU)

[11:39] <psch> hm, NQP_VERBOSE_EXCEPTION makes this leaking unwind another bit less comprehensible :l

[11:39] <yoleaux2> 8 Oct 2016 23:49Z <Zoffix> psch: we do have the .tell bot. It just got stuck behind the netsplit

[11:39] <psch> apparently the EX_CAT_RETURN leaks from the &last call itself

[11:39] <psch> which is weird, i think?  because, should we even return from there when we throw a CX::Last in the first place..?

[11:49] <psch> r: say +(gather do for ^4 { .take; last if $++; CONTROL { default { .perl.say; $_ } } }).cache;

[11:49] <camelia> rakudo-moar 228cbc, rakudo-jvm 2a1605: OUTPUT«CX::Take.new␤CX::Take.new␤CX::Take.new␤CX::Take.new␤0␤»

[11:49] <psch> everything is weird /o\

[11:49] <psch> r: say +(gather do for ^4 { .take; last if $++; CONTROL { default { .perl.say; .rethrow } } }).cache;

[11:49] <camelia> rakudo-jvm 2a1605: OUTPUT«CX::Take.new␤Error in socket connection:org.perl6.nqp.runtime.UnwindException␤        at org.perl6.nqp.runtime.ThreadContext.<init>(ThreadContext.java:125)␤  at org.perl6.nqp.runtime.GlobalContext.getCurrentThreadContext(GlobalContext.java:340)␤ at org.perl…»

[11:49] <camelia> ..rakudo-moar 228cbc: OUTPUT«CX::Take.new␤Trying to unwind over wrong handler␤»

[11:54] <psch> r: say +(gather do for ^4 { .take; last if $++; CONTROL { when CX::Last { .perl.say; .rethrow } } }).cache;

[11:54] <camelia> rakudo-moar 228cbc: OUTPUT«Trying to unwind over wrong handler␤»

[11:54] <camelia> ..rakudo-jvm 2a1605: OUTPUT«Error in socket connection:org.perl6.nqp.runtime.UnwindException␤     at org.perl6.nqp.runtime.ThreadContext.<init>(ThreadContext.java:125)␤  at org.perl6.nqp.runtime.GlobalContext.getCurrentThreadContext(GlobalContext.java:340)␤ at org.perl6.nqp.runtime.G…»

[11:54] <psch> i mean, is that such a weird thing to do..?

[12:38] <dogbert17> o/ anyone there who can answer a valgrind question or have everyone grown tired of them?

[12:39] <dogbert17> there seems to be files with the extension '.S', what kind of files are those?

[12:42] <moritz> dogbert17: assembler code

[12:43] <moritz> (before running them through the preprocessor)

[12:45] <dogbert17> moritz: thanks

[12:56] <dogbert17> the thing is that sometimes when valgrinding spectests I get the error 'Syscall param write(buf) points to uninitialised byte(s)' and then it looks like valgrind restarts

[12:57] <dogbert17> if I rerun the test where this happened the error is gone, just wondering if it's something which should be reported?

[13:00] <dogbert17> if anyone feel like giving it a once over a gist can be found here: https://gist.github.com/dogbert17/3f9cfcee81cbd6b1429ef59ff49134ae

[15:27] <Zoffix> \o :)

[15:27] <cowens> Okay, I don't want to be an asshole about this, so you can tell me to shut up about it and I will.  But I read the discussion about my issues with the Str type being stored as NFC and I wanted a chance to clarify some points.

[15:27] <Zoffix> Sure, go ahead. Don't worry about being an asshole.

[15:28] <timotimo> yup, go ahead, it's fine

[15:28] <timotimo> though i'm AFK as of right now

[15:28] <cowens> I say http://unicode.org/faq/normalization.html#1 being used as justification for throwing away user's data.  That FAQ covers comparison not storage.

[15:29] <psch> NFG is not NFC, for the record

[15:29] <cowens> I completely agree that "e\x[0301]" and "e\xe9" should compare as the same

[15:30] <nine> cowens: I don't know if you've red the channel log. So, in short the sentiment seems to be: yes, there are use cases dealing with broken systems where the normalization hurts and those cases need better support. The default an prirority however should be to support people who want to deal with texts.

[15:32] <nine> cowens: when you talk about "throwing away data", you mean the exact representation of characters at a byte level. Whether this representation actually represents data could be disputed. For many people and many cases it won't matter. The actual data is the text, whether it's represented as bytes in UTF-8 encoded Unicode on a hard drive, or spoken, or written down by hand.

[15:32] <FROGGS> cowens: read this and the following few lines: https://irclog.perlgeek.de/perl6-dev/2016-10-08#i_13363590

[15:33] <FROGGS> cowens: TL;DR: it might not be "coming soon", but it will come some day

[15:33] <nine> cowens: in other cases, it will of course matter if the exact same representation is still available. The question is, how common this really is.

[15:33] <psch> uhm, this feels a bit like "ganging up" to me?  i was under the impression cowens was refering to exactly that linked discussion

[15:34] <psch> and, just maybe, we should wait for the clarification?

[15:34] * FROGGS waits :o)

[15:35] <cowens> Sorry, I lost connection somehow

[15:35] <cowens> Yes I read those logs

[15:37] <cowens> The Unicode document being used to justify forcing NFC does not recommend storing the data as NFC

[15:37] <cowens> it recommends comparing the data as the NFC

[15:38] <cowens> it has a FAQ that even covers whether or not you should normalize unnormalized data automatically

[15:38] <nine> If I understood jnthn++ correctly, we store strings in NFG, because it makes accesses O(1) instead of O(n). Something that will matter to many users.

[15:38] <cowens> and it says to make it behave like it is in NFC, but it does not say to normalize it

[15:39] <cowens> amortized O(1) indexing can be achieved without throwing away data

[15:39] <FROGGS> by duplicating data?

[15:40] <cygx> cowens: have you seen https://www.reddit.com/r/perl/comments/557m4k/any_new_perl_6_books/d8jlxji ?

[15:40] <nine> cowens: did you get my remarks about "throwing away data" before you lost connection?

[15:40] <cygx> in a perfect Unicode-aware world, the Perl6 behaviour is ok

[15:41] <cygx> the problem is that the p6 story is still lacking in the non-perfect world we live in

[15:41] <cowens> There will never be a perfect Unicode-aware workd

[15:41] <cowens> world

[15:42] <cowens> And even in such a world, the string "e\x[301]" is a valid string.

[15:42] <cowens> but it isn't in Perl 6

[15:43] <FROGGS> m: say "e\x[301]"

[15:43] <camelia> rakudo-moar 228cbc: OUTPUT«é␤»

[15:43] <cygx> cowens: semantically, p6 thinks of strings not as codepoint sequences, but equivalence classes of such

[15:44] <cygx> that's perfectly ok in my book as long as we still have a good story for the real-world problems

[15:44] * cygx is going to gist something

[15:44] <FROGGS> well, usually you are not interested in codepoints either

[15:44] <psch> a Str consists of graphemes, an Uni consists of codepoints

[15:44] <FROGGS> *I* think the exact bytes of source and NFG strings are interesting

[15:44] <cowens> Let me approach this form a different angle.

[15:44] <psch> so, yes, Uni is what wouldn't ever throw away data, and it's underimplemented

[15:45] <psch> but a Str is about what can be read on the screen

[15:45] <psch> that's how i understand jnthn++'s explanation yesterday

[15:45] <cowens> Is there a reason to discard the user's data for strings?  Shouldn't the only goal be treating comparisons as equal?

[15:45] <cygx> psch: from what I can gather, jnthn prefers generating synthetic codepoints over Uni

[15:45] <psch> cygx: but that's what Str does, isn't it?

[15:45] <nine> cowens: I already wrote that reason?

[15:46] <nine> cowens: I start to think, you're not getting my messages, as you don't react to them in any way :/

[15:46] <cowens> which was what? O(1) indexing?  You don't need to throw away data for that

[15:46] <nine> Does anyone else read me?

[15:46] <FROGGS> nine: I do :o)

[15:46] <nine> cowens: and how not?

[15:46] <cowens> simplest implementation would be an array and a sparse array

[15:46] <cygx> psch: generating synthetics for non-canonical codepoint sequences which can then be round-tripped

[15:47] <cowens> one code point graphemes go in the array

[15:47] <psch> cygx: i have no idea what you are trying to tell me, sorry :)

[15:47] <FROGGS> cowens: problem is when you split texts or do other stuff, you'd have to operate on two "strings", rather than one

[15:47] <cowens> multi code point graphemes are stored in the array as a sentinel value

[15:48] <cowens> then stored in the sparse array at that point.

[15:48] <cowens> Split should work on the grapheme level in Str

[15:48] <FROGGS> the implementation of Str is meant to be fast, and you cant be fast when you have two copies of the string data to work with

[15:49] <cowens> You have to have a lookup table now don't you?

[15:49] <FROGGS> to split something? no

[15:49] <psch> m: say Uni.new(0x65, 0x301) [&($_)] Uni.new(0xe9) for &[==], &[eq]

[15:49] <camelia> rakudo-moar 228cbc: OUTPUT«False␤True␤»

[15:50] <cowens> You don't in that array + sparse array either

[15:50] <cowens> I mean to print the data back out

[15:51] <FROGGS> to print a Str we turn it back to NFC or something, yes

[15:51] <FROGGS> but still, all string operations deal with a single stream of one element things

[15:51] <nine> cowens: split right now can work on an array of 32 bit ints where each element is a grapheme. Same as all other string operations. I don't see how you could achieve the same performance when using two data structures? Wouldn't that at least give you worst cache locality, not to speak of the additional operations necessary?

[15:52] <cowens> Hey, I was talking about O(1) which is what I saw people talking about.

[15:53] <cowens> Yeah, it won't be as performant, but it would be better than Uni and it wouldn't throw away data

[15:54] <cowens> Given that the choice was to go with Rat over floating point as the default, I assumed Perl 6 was supposed to favor integrity over speed.

[15:54] <nine> cowens: but now we're talking about trade offs. You want to make all string operations in Perl 6 slower for covering some use cases. That's totally ok, but you got to admit, that as with all judgement calls, opinions may differ :)

[15:55] <psch> i don't think Rat is about integrity over speed

[15:55] <psch> Rat is about doing the obviously right thing

[15:55] <psch> because, well, 0.1 + 0.2 *is* equal to 0.3

[15:55] <psch> and in the same vein, é is equal to, well, the other one that also looks like é

[15:55] <nine> Which for texts means keeping the integrity of texts, not necessarily the integrity of byte code level representations of texts.

[15:56] <psch> (i'm not sure which of those two i'm typing with my locale, hence my phrasing :) )

[15:56] <cowens> Well, my file contains "re\x[301]sum\x[301]"  the obvious thing to happen when I append "Chas's" with Perl is that it should be "Chas's re\x301]sume\x[301]"

[15:57] <FROGGS> cowens: why do you need the original bytes ooc?

[15:57] <cowens> Many reasons: legacy systems, audit controls, etc.

[15:57] <cygx> rfc: https://gist.github.com/cygx/b545c206a0f7ccc6d796ba4b26afccf6

[15:58] <cowens> If I round trip a file in Perl 6 strings, it might not get the same md5sum even if nothing changed

[15:59] <FROGGS> cowens: well, if you just want to write it from a to b without modification and you know that checksums are involved than perhaps use Buf

[15:59] <FROGGS> I mean, for now at least

[15:59] <cowens> It might not have no modification

[15:59] <FROGGS> what I usually do with text is interaction with humans

[15:59] <psch> Buf will not normalize

[16:00] <FROGGS> and they dont care about byte orderings

[16:00] <cowens> say you have a process that needs to change names in a file

[16:00] <cowens> but if the names aren't present, no changes should be made

[16:00] <FROGGS> cowens: Buf is meant to be string like

[16:00] <FROGGS> having subbuf instead of substr etc

[16:00] <cowens> the typical way of doing that is a filter

[16:01] <FROGGS> but I guess not being able to regex match can be a showstopper

[16:01] <cowens> Perl 6 changes things even when the user didn't ask for them to be changed if he or she uses a string

[16:01] <psch> except Perl 6 doesn't write that if you don't tell it to?

[16:01] <FROGGS> yes, and in >95% of the cases the user wont care

[16:01] <cowens> Also, Buf is bytes.  I want to work at the grapheme level

[16:01] <psch> i mean, are you memmapping the file..?

[16:01] <FROGGS> but (s)he will be more happy with faster string ops

[16:02] <cowens> But I don't want working at the grapheme level to force me into normalized data

[16:02] <cowens> that goes back to the Rat vs floating point argument

[16:02] <cowens> I don't mind there being an optional lossy string type

[16:02] <cowens> that is faster

[16:03] <psch> that's not the Rat vs floating point argument

[16:03] <cowens> But the default being lossy is very surprising

[16:03] <psch> that's the reason why the Rat vs floating point argument was made

[16:03] <psch> we pick Rat because it does the right thing with the representation

[16:03] <cowens> NFC isn't the right thing for strings

[16:04] <cowens> It is an optional thing for strings

[16:04] <psch> if you cannot visually distinguish them, they are identical

[16:04] <psch> that is what text means

[16:04] <psch> i understand that you disagree with assertion

[16:04] <psch> but it's the one the core devs arrived at, and why Str defaults to NFG

[16:04] <psch> *with this assertion

[16:04] <cygx> what psch said: any system that does treat canonically equivalent text as different is arguably broken

[16:04] <timotimo> psch: so I and l are the same thing? :P

[16:05] <cygx> as there are a lot of broken system, you need a good fallback story

[16:05] <psch> timotimo: they look different here :)

[16:05] <cygx> Perl6 curretnly lacks such a story

[16:05] <psch> cowens: now, the concern that absolute byte level integrity is hard currently is absolutely valid

[16:05] <timotimo> i can visually distinguish the one ê from the other ê by looking at the bytes in the file with a hex editor :P :P

[16:05] <FROGGS> cowens: there will be a solution... but it most likely wont be the default

[16:06] <cowens> Yeah, I can tell that there is some cool aid I haven't drunk

[16:06] <cygx> FROGGS: it's entirely possible to echive something like open(:compat) and

[16:06] <psch> oh come on

[16:06] <cygx> *achieve

[16:06] <FROGGS> yes, or have a pragma or something else

[16:06] <cygx> ...and have it do the mostlyright thing

[16:06] <psch> "your arguments are bad because i don't like the tradeoff" isn't reasonable

[16:06] <FROGGS> or a mixed in role that keeps the original bytes or a string

[16:07] <cowens> psch that cuts both ways

[16:07] <FROGGS> there are several ways of doing it, and I'm not the one proposing a good solution here :o)

[16:07] <cowens> Performance is being given more importance than correctness for strings, but not for numbers

[16:08] <cowens> That is the trade off.  And it is very odd to outsiders

[16:08] <Zoffix> But the string are "correct". The trade off is in their representation.

[16:08] <cygx> cowens: but normalization is the correct approach in a perfect Unicode-aware world

[16:08] <FROGGS> cowens: do operations on stuff that cannot be normalized to a single codepoint in all the languages you know

[16:08] <cygx> (or rather treating equivalent things as equivalent)

[16:08] <cowens> No, the graphemes are correct, but the underlying data is lost

[16:08] <FROGGS> cowens: and than count these that dont split in the middle of a grapheme

[16:09] <Zoffix> The underlying data is bytes, so the string operations are correct :)

[16:09] <psch> but the graphemes *are* the relevant data in a Str

[16:09] <psch> if you care about bytes, use Buf

[16:09] <psch> or maybe Uni, eventually

[16:09] <Zoffix> And once we have user-land encoders, I imagine this type of stuff would be even more convenient, no?

[16:09] <psch> or maybe some up-and-coming prgama

[16:09] <psch> *pragma

[16:09] <FROGGS> strings in general are not about bytes... they are about visible characters, whatever that means

[16:10] * psch is getting too heated

[16:10] <psch> sorry, clinking myself out here :S

[16:10] <FROGGS> yeah, a break sounds sane :o)

[16:10] <FROGGS> dinner &

[16:10] <cygx> FROGGS: user-perceived characters as approximated by equivalent grapheme clusters, if you want to get technical

[16:11] <cygx> ;)

[16:11] <cowens> On a more positive note: should all of the string functions be in stringy?

[16:11] <Zoffix> Don't think so, considering:

[16:11] <Zoffix> m: say Buf ~~ Stringy

[16:11] <camelia> rakudo-moar 228cbc: OUTPUT«True␤»

[16:11] <cowens> Should string functions for Uni be on the grapheme level, code point level, or take an adverb with a default

[16:12] <Zoffix> And, I mean, .match is a string function, etc

[16:12] <Zoffix> I'd imagine on grapheme level, though I'm not familiar with Uni.

[16:12] <timotimo> there's still the possibility of giving every grapheme that would be changed by normalization a synthetic that writes back what it once was. problem solved forever.

[16:12] <cygx> generic functions should operate on codepoints, string-specific ones might want to aoerce

[16:13] <timotimo> that will, however, make things like string comparison a bit more complicated

[16:13] <cowens> Yeah, that was one of my O(1) solutions

[16:13] <cygx> *coerce

[16:13] <cowens> But it has complexity attack issues and isn't as performant

[16:13] <timotimo> i don't really remember what the particular arguments against that were that were brought forth

[16:14] <cowens> What does NFG do when it runs out of synthetics?

[16:14] <cygx> die because you've exhausted your RAM ;)

[16:14] <timotimo> at the moment we don't have a mechanism for that, but we can GC through existing strings and throw out unused synthetics

[16:15] <timotimo> but yeah, you'll need a lot of input data to get to that point, and later you'll need all of that data to stick around in memory so GC won't free it up

[16:15] <cowens> So, the table is interpreter level, not string level?

[16:15] <timotimo> that's right

[16:15] <timotimo> we have a lock-free datastructure that does that stuff

[16:15] <timotimo> i haven't looked closely at that yet

[16:15] <cowens> I had assumed string level because of a comment in the docs, but I guess you just reserve the right to have it at string level

[16:18] <timotimo> btw, we currently have an entirely real attack based on NFG, compared to the pretty difficult-to-pull-off attack of exhausting the table space

[16:18] <timotimo> m: say "a" ~ "\c[COMBINING ACUTE]" xx 100000000

[16:18] <camelia> rakudo-moar 228cbc: OUTPUT«===SORRY!=== Error while compiling <tmp>␤Unrecognized character name COMBINING ACUTE␤at <tmp>:1␤------> say "a" ~ "\c[COMBINING ACUTE⏏]" xx 100000000␤»

[16:18] <timotimo> .u combining

[16:18] <yoleaux2> U+0300 COMBINING GRAVE ACCENT [Mn] (◌̀)

[16:18] <yoleaux2> U+0301 COMBINING ACUTE ACCENT [Mn] (◌́)

[16:18] <yoleaux2> U+0302 COMBINING CIRCUMFLEX ACCENT [Mn] (◌̂)

[16:18] <timotimo> m: say "a" ~ "\c[COMBINING GRAVE ACCENT]" xx 100000000

[16:18] <camelia> rakudo-moar 228cbc: OUTPUT«Memory allocation failed; could not allocate 800000000 bytes␤»

[16:18] <timotimo> oh, hehe

[16:18] <timotimo> m: say "a" ~ "\c[COMBINING GRAVE ACCENT]" xx 10000

[16:18] <camelia> rakudo-moar 228cbc: OUTPUT«à ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀…»

[16:18] <timotimo> no, actually, that won't do it

[16:19] <timotimo> m: say "a\c[COMBINING GRAVE ACCENT]" ~ "\c[COMBINING GRAVE ACCENT]" xx 10000

[16:19] <camelia> rakudo-moar 228cbc: OUTPUT«à̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀ ̀…»

[16:19] <timotimo> how do i ...

[16:19] <timotimo> probably have to go via Uni?

[16:19] <timotimo> anyway. trying to add that kind of thing to our trie datastructure exhausts the C stack

[16:22] * FROGGS thinks that synthetics have to be kept at interpreter level because otherwise you could not compare strings

[16:22] <timotimo> you can, you just have to compare synthetics that you come across

[16:23] <timotimo> if we have different synthetics for the same character but different normalizations, we'd have to do some extra work anyway

[16:23] <cowens_> So, if I were to start implementing string functions for Uni, where should I put them?  Should we have parallel functions in the different classes (Buf/Uni/Str)?

[16:23] <FROGGS> how so? their made up negative number certainly wont be the same

[16:23] <timotimo> i meant compare the underlying data for the synthetics when their indices don't match

[16:23] <timotimo> and even if the indices match, if the table is per-string, same index doesn't mean same character

[16:23] <FROGGS> well, that'd be slower again :o)

[16:24] <FROGGS> aye

[16:24] <timotimo> honestly, i'd be okay with a flag on strings that says "uses normalization-conserving synthetics"

[16:25] <timotimo> and only compare underlying synthetic data if that flag is set on one or both of the strings

[16:25] <timotimo> and we'd probably also want some kind of support for strings with different normalizations in code as literals

[16:25] <cowens_> I think S15 covers that

[16:26] <cowens_> qq:nfd"e\x[301]"

[16:26] <timotimo> ah

[16:26] <timotimo> i was thinking of a way to write "this string has mixed normalizations in it"

[16:27] <cowens_> That is called Uni

[16:27] <cowens_> Based on what people have been saying

[16:27] <timotimo> not easy to type, though :)

[16:27] <cowens_> Oh, yeah, I hate that syntax

[16:27] <timotimo> well, you can type it Uni.new(<1 2 3 4>), can't you?

[16:27] <cygx> "foo{ Uni.new(...).non-normalized-synthetic-Str }bar"

[16:28] <cowens_> Yeah, that is even worse

[16:28] <timotimo> if you just call it .nnsS ... :P

[16:29] <cowens_> Or .SaneStr (half kidding)

[16:29] <timotimo> should we consider people would expect code like 'say "asdf"' piped through xxd to have the same bytes as the part between the " in the code?

[16:29] <cowens_> Seriously, If I start implementing string functions for Uni, where should I put them: in Uni or stringy?

[16:29] <p3rln00b> m:  7 ~ "\x[308]" x 150_000

[16:29] <camelia> rakudo-moar 228cbc: OUTPUT«(signal SEGV)»

[16:30] <timotimo> for now, i'd just put them into Uni

[16:30] <timotimo> they can probably be moved up later, right?

[16:30] <timotimo> p3rln00b: thank you

[16:31] <cowens_> Should they share names with Str or have some sort of prefix?

[16:32] <cowens_> there was talk of subbuf instead of substr

[16:32] <timotimo> subuni? :P

[16:32] <cowens_> Yeah, that one is easy

[16:32] * timotimo does the AFK-dance again

[16:35] <cygx> o/

[16:42] <cowens_> A parting thought: It feels to me like Str is changing "consumed" to "ate" and people are saying I shouldn't be upset because they mean the same thing.

[17:28] <p3rln00b> hah. Debuggin something and dumping things and apparently we have something with 73 multi candidates for it :}

[17:29] <p3rln00b> (unless I'm misinterpreting my data)

[17:32] <p3rln00b> m: &postcircumfix:<[ ]>.candidates.elems.say

[17:32] <camelia> rakudo-moar 228cbc: OUTPUT«65␤»

[17:44] * geekosaur is noodling something re strings...

[17:46] <geekosaur> I kinda want to reflavor things. Str -> UI string, Uni -> unified string (may not be unicode any more), Buf8 -> octet string. files and streams are Buf8 when raw or Uni when not. Uni lets you define ranges (including "from X until further notice") with encodings (and, in a more general implementation, encoding can include compression and/or encryption)

[17:47] <geekosaur> also reinterpretations, as needed for IRC where the command framing is an ISO8859 but the payload may be a different ISO8859 or UTF8, or when an HTTP stream sends a Content-Type and/or Content-Encoding

[17:48] <geekosaur> people kinda want to believe "string is string" but that has not been true since people finally realized the world is not US ASCII carrying US English

[17:48] <nine> English has never been ASCII only

[17:49] <geekosaur> ...but the computer representation was

[17:50] <geekosaur> basically the thing I'm thinking about is that perl 5 had IO layers on filehandles; that's the wrong place since stream interpretations need to change as they go. I want layers on *streams*, where a stream is a generalized notion of "string"

[17:54] <Zoffix> m: sub foo (int $x) { $x.say }; my Int $b = 2; foo $b;

[17:54] <camelia> rakudo-moar 228cbc: OUTPUT«2␤»

[17:54] <Zoffix> Would you say that's a bug?

[17:56] <lucasb> that's expected unboxing, no?

[17:57] <lucasb> otherwise 'my int $x = $an-Int' would also have to be a bug

[17:57] <Zoffix> Fair enough. What about this one:

[17:57] <Zoffix> m: sub foo (Int $x) { $x.say }; my int $b = 2; foo $b;

[17:57] <camelia> rakudo-moar 228cbc: OUTPUT«2␤»

[17:57] <Zoffix> Would you say that is a bug?

[17:58] <lucasb> and that is expected boxing

[17:58] <geekosaur> auto(un)boxing should probably be a thing unless you want to go the strict typing route a la Haskell

[17:59] <Zoffix> Fair enough. Now, with the above in mind, which multi should this call; the native or or the Int?: multi foo (Int $x) { $x.say }; multi foo (int $x) { $x.say }; foo 2;

[18:01] <Zoffix> Or to mix it up:   multi foo (Int $x, Int $y) {}; multi foo (int $x, int $y) {}; my int $b = 2; foo 2, $b;

[18:02] <geekosaur> if a multi matches the boxing state, use it, otherwise if a multi matches the type but different box/unbox, use it, otherwise if you have a coercion you can use, box and coerce.

[18:02] <geekosaur> there might be a pragma for strict boxing if someone wants to write haskell in perl6

[18:03] <geekosaur> java's had autoboxing for some time now, it's not an unexplored concept

[18:05] <Zoffix> Is literal 2 a "boxed state"?

[18:05] <geekosaur> maybe a restatement of that which-to-call: if you have an unboxed value, first try to match the unboxed type exactly. if no multi matches, box it and do normal multi resolution

[18:05] <geekosaur> the one hard rule is that the only "coercion" available for an unboxed value is to box it

[18:06] <geekosaur> that question makes me think I need to restate that again

[18:06] <geekosaur> because that question does not make sense...

[18:07] <Zoffix> Well, is literal 2 "boxed"?

[18:07] <geekosaur> I am inclined to consider it boxed, and unbox it if needed

[18:07] <geekosaur> mostly because in perl6 literal 2 can coerce to various types, and coercion is only possible for boxed values

[18:08] <Zoffix> OK

[18:08] <geekosaur> (yes, technically you can pretend otherwise but you're really just manipulating a separate box to do so)

[18:09] <lucasb> I think this question, wether a literal integer is native or not is a very relevant question that should be answered in the FAQ

[18:10] <lucasb> I think a reasonable approach would be for it to be a native, if it fits the native range of values, otherwise it would be Int

[18:10] <Zoffix> I think that's already how it is in the optimizer.

[18:10] <lucasb> but this thinking doesn't work for strings, right? is a literal string a 'str' or Str?

[18:12] <lucasb> geekosaur: haskell has something like polymorphic constant, right? do you think this concept describes what we are talking about?

[18:12] <lucasb> I read about it in that book learn haskell for great good

[18:13] <geekosaur> yes and no. haskell also has strict typing and full type inference, so you can give a meaning to a polymorphic constant more easily

[18:13] <geekosaur> "polymorphic constant" has to do something else in a perl6-like type world

[18:13] <lucasb> 5 :: Int

[18:13] <lucasb> 5 :: Integer

[18:13] <lucasb> 5 :: Float

[18:14] <lucasb> this enforces the type in the constant, no?

[18:14] <lucasb> (in Haskell)

[18:15] <geekosaur> when you write "5" in Haskell, the compiler sees (as specified by the language definition): fromInteger (5 :: Integer)

[18:16] <geekosaur> if you write "5 :: Int" this becomes "fromInteger (5 :: Integer) :: Int" so the instance (fromInteger :: Integer -> Int) is selected

[18:16] <lucasb> hmm, interesting. thanks for clarifying

[18:19] <geekosaur> one complication in the boxing/unboxing discussion is that in haskell an unboxed value is never polymorphic, because if you do not know the type statically you can't know what the value actually is --- or even how large it is.

[18:20] <geekosaur> perl 6 "unboxed" values are actually boxed, in that sense

[18:22] <geekosaur> but in an OO language "unboxed" means "not an object", not "does not have a type witness"

[18:23] <geekosaur> so perl6 can actually do some polymorphism there... the problem being that coercions are object methods, so you still really want an object to do a coercion

[18:40] <nine> [</win 13

[18:40] <nine> 2016.10 release is next weekend, isn't it?

[18:41] <Zoffix> Right

[18:41] <Zoffix> NeuralAnomaly, status

[18:41] <NeuralAnomaly> Zoffix, [✘] Next release will be in 5 days and 9 hours. Since last release, there are 41 new still-open tickets (38 unreviewed and 0 blockers) and 149 unreviewed commits. See http://perl6.fail/release/stats for details

[18:42] <nine> Ok, then I won't bother sumbmitting 2016.09 for openSUSE. Rakudo fails the tests on i586 and this issue should be fixed in 2016.10 anyway

[19:18] <dalek> nqp: af751d3 | FROGGS++ | tools/build/MOAR_REVISION:

[19:18] <dalek> nqp: bump moar for better error messages

[19:18] <dalek> nqp: review: https://github.com/perl6/nqp/commit/af751d39ee

[19:18] <lizmat> m: sub a(&b) { b(); b() }; a sub{ say "foo" }   # I'm surprised this works

[19:18] <camelia> rakudo-moar 228cbc: OUTPUT«foo␤foo␤»

[19:18] <lizmat> I'd expect an error because of the lack of whitespace between "sub" and "{"

[19:19] <dalek> rakudo/nom: a92f092 | FROGGS++ | / (2 files):

[19:19] <dalek> rakudo/nom: improve nativecall error messages, fixes RT #129353

[19:19] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/a92f092ac5

[19:19] <synopsebot6> Link:  https://rt.perl.org/rt3//Public/Bug/Display.html?id=129353

[19:23] <lizmat> m: sub c(\sub) { sub{"foo"} }; say c(my %h)  # expected Any here

[19:23] <camelia> rakudo-moar 228cbc: OUTPUT«sub () { #`(Sub|61604456) ... }␤»

[19:24] <lizmat> m: sub c(\sup) { sup{"foo"} }; say c(my %h)  # any other name than "sub" does

[19:24] <camelia> rakudo-moar 228cbc: OUTPUT«(Any)␤»

[19:24] <lizmat> is this a bug or a DIHWIDT ?

[19:26] <geekosaur> I think unless a prototype is mandatory, it's not really possible to distinguish whether it's an anon sub or a hash?

[19:26] <geekosaur> or you want to require a brace between sub and { to indicate an anon sub

[19:26] <geekosaur> er, a sspace

[19:27] <lizmat> yeah, I expected the space to be mandatory, like lack of it is mandatory with calling foo()

[19:27] <lizmat> to distinguish itself from a hash lookup

[20:51] <Zoffix> ISAGN for nqp version of dd :/

[20:54] <Zoffix> Spent about 30 compilations already trying to dump a simple array, just to be greeted with one error or another after parse stage heh

[21:19] <dalek> rakudo/nom: f4a8a69 | lizmat++ | src/core/Str.pm:

[21:19] <dalek> rakudo/nom: Looks like we don't need 'try' here any more

[21:19] <dalek> rakudo/nom:

[21:19] <dalek> rakudo/nom: First stab at making Str.match faster

[21:19] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/f4a8a69e53

[21:27] <dalek> rakudo/nom: 13f4798 | lizmat++ | src/core/CompUnit/RepositoryRegistry.pm:

[21:27] <dalek> rakudo/nom: Don't use regexp based split for pathspec

[21:27] <dalek> rakudo/nom:

[21:27] <dalek> rakudo/nom: Use fast str based split, and just trim the whitespace fastly later,

[21:27] <dalek> rakudo/nom: without needing to start up the whole regex engine.

[21:27] <dalek> rakudo/nom:

[21:27] <dalek> rakudo/nom: Found this when I broke Str.split with my work on Str.match

[21:27] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/13f4798e00

[21:27] <lizmat> this should have a visible effect on "make spectest" I hope

[21:39] <lizmat> good night, #perl6-dev

[21:41] <Zoffix__> night

[21:48] <Zoffix> m: sub foo (int $x) { $x.say }; foo 2

[21:48] <camelia> rakudo-moar 13f479: OUTPUT«2␤»

[21:48] <Zoffix> m: multi sub foo (int $x) { $x.say }; foo 2

[21:48] <camelia> rakudo-moar 13f479: OUTPUT«Cannot resolve caller foo(Int); none of these signatures match:␤    (int $x)␤  in block <unit> at <tmp> line 1␤␤»

[21:48] <Zoffix> ^ adding to previous discussion. The latter is a bug then?

[22:04] <Zoffix> m: multi sub foo (int $x) { $x.say }; foo my int $ = 2

[22:04] <camelia> rakudo-moar 13f479: OUTPUT«2␤»

[22:04] <Zoffix> m: multi sub foo (Int $x) { $x.say }; foo my int $ = 2

[22:04] <camelia> rakudo-moar 13f479: OUTPUT«2␤»

[22:05] <Zoffix> m: multi foo (int $x) { $x.say }; my Int $x = 2; foo $x

[22:05] <camelia> rakudo-moar 13f479: OUTPUT«Cannot resolve caller foo(Int); none of these signatures match:␤    (int $x)␤  in block <unit> at <tmp> line 1␤␤»

[22:11] <Zoffix> Stresstest is floppy as hell... 5 runs so far, only the first one succeeded. Different failures on each of the following runs :/

[22:16] <Zoffix> t/spec/S05-substitution/subst.rakudo.moar                       (Wstat: 256 Tests: 183 Failed: 1)

[22:26] <Zoffix> ZOFVM: Files=1194, Tests=129672, 137 wallclock secs (21.65 usr  3.14 sys + 2425.60 cusr 195.67 csys = 2646.06 CPU)
