[00:12] <MasterDuke> moritz: i definitely typed out my message and then went back and double checked before hitting enter, seemed like a good possibility for egg on the face

[02:03] <MasterDuke> if i add an attribute to Perl6::World, how would i access that from the rest of the settings?

[03:49] <timotimo> what do you mean by "the settings"?

[03:49] <MasterDuke> m-CORE.setting

[03:50] <timotimo> the world is purely a compile-time construct

[03:50] <timotimo> the code inside the core setting is partially run at compile time (when there's BEGIN blocks, or constants), but mostly run-time code

[03:51] <MasterDuke> so i want to create a data structure at compile time that's available at run time

[03:52] <timotimo> how would you like to access it?

[03:52] <timotimo> is this about getting per-piece filenames/line numbers?

[03:52] <MasterDuke> exactly

[03:53] <MasterDuke> so i probably want it somewhere in Exception.pm and/or Backtrace.pm and/or CallFrame.pm

[03:53] <timotimo> there's multiple ways to go about this. i suggest you have a look at Actions.nqp where "special symbols" are handled

[03:53] <timotimo> gimme a sec

[03:54] <timotimo> hmm

[03:55] <MasterDuke> like the stuff happening around line 3150?

[03:56] <gfldex> RT129787 could do with a [CONC] tag

[03:56] <timotimo> what file are you looking at?

[03:57] <MasterDuke> Actions.nqp

[03:57] <timotimo> i don't think so?

[03:58] <timotimo> here's an idea

[03:59] <timotimo> keep your datastructure around in an attribute, make a rule in the grammar that'll let you return the datastructure when a given very special name is invoked, and ther just compile it as QAST::WVal.new( :value( $!datastructure ))

[03:59] <MasterDuke> gfldex: done

[03:59] <timotimo> perhaps you'll want to put a QAST::Op.new( :op<clone>, ... ) around its o you can't change the data from one place

[03:59] <timotimo> (though clone is only one level deep)

[04:01] <MasterDuke> hmmm...i already have a token that looks for '#line 1 ' and captures what comes next...

[04:01] <timotimo> 045611    gfldex │ RT129787 could do with a [CONC] tag

[04:01] <timotimo> whoops :D

[04:02] <timotimo> 045611    gfldex │ RT129787 could do with a [CONC] tag

[04:02] <synopsebot6> Link:  https://rt.perl.org/rt3//Public/Bug/Display.html?id=129787

[04:02] <timotimo> good

[04:02] <MasterDuke> where would that attribute live?

[04:02] <timotimo> it can live inside World

[04:03] <MasterDuke> i think i know how to do that. but don't know how to get to it from an Exception at runtime

[04:03] <timotimo> EZ

[04:04] <timotimo> add a rule to the grammar like token get_filenumbers_thingie { '$?GET_MASTERDUKES_FANTASTIC_DATASTRUCTURE' }

[04:04] <timotimo> the actions will look like   make QAST::WVal.new( :value($*W.filenumbers_accessor_method) )

[04:05] <timotimo> filenumbers_accessor_method will just return the attribute

[04:05] <timotimo> when the compiler sees that WVal node, it'll put your datastructure into the serialized blob and you'll get its value where $?GET_..._DATASTRUCTURE was in the code

[04:06] <MasterDuke> ahhh...i think i'm following that

[04:06] <timotimo> it's really fantastic how easy this is

[04:07] <timotimo> there's another piece in the compiler that has a proto sub in one line, a WVal in the next and an QAST::Op.new( :op<call>, ... ) around it

[04:07] <timotimo> so it's putting a piece of code from inside the compiler itself into the serialized blob of our target and compiles a call to it

[04:08] <MasterDuke> reminds me of the "Reflections on Trusting Trust" paper

[04:09] <timotimo> i don't think i've heard of that

[04:10] <MasterDuke> pretty famous, by Ken Thompson

[04:11] <MasterDuke> https://www.ece.cmu.edu/~ganger/712.fall02/papers/p761-thompson.pdf

[04:14] <timotimo> i'm already reading it :)

[04:14] <timotimo> it seems to be about quines?

[04:14] <timotimo> oh, it's *this* paper

[07:39] <dalek> nqp: 97e20d8 | MasterDuke17++ | src/vm/moar/QAST/QASTOperationsMAST.nqp:

[07:39] <dalek> nqp: Remove some unused variables+accessor methods

[07:39] <dalek> nqp:

[07:39] <dalek> nqp: See https://irclog.perlgeek.de/perl6-dev/2016-11-01#i_13495026 and

[07:39] <dalek> nqp: https://irclog.perlgeek.de/perl6-dev/2016-11-01#i_13496388

[07:39] <dalek> nqp: review: https://github.com/perl6/nqp/commit/97e20d89e7

[07:39] <dalek> nqp: 81a85b9 | niner++ | src/vm/moar/QAST/QASTOperationsMAST.nqp:

[07:39] <dalek> nqp: Merge pull request #317 from MasterDuke17/master

[07:39] <dalek> nqp:

[07:39] <dalek> nqp: Remove some unused variables+accessor methods

[07:39] <dalek> nqp: review: https://github.com/perl6/nqp/commit/81a85b9068

[08:51] <|Tux|> This is Rakudo version 2016.10-144-ga1347ca built on MoarVM version 2016.10-35-gec45ae2

[08:51] <|Tux|> csv-ip5xs        3.138

[08:51] <|Tux|> test            13.917

[08:51] <|Tux|> test-t           6.781

[08:51] <|Tux|> csv-parser      14.866

[09:11] <lizmat> Files=1151, Tests=53707, 212 wallclock secs (12.66 usr  3.44 sys + 1302.53 cusr 115.74 csys = 1434.37 CPU)

[10:46] <lizmat> m: my @a[1,1] = (42,),(666,)   # jnthn, this feels like an off-by-one error ?

[10:46] <camelia> rakudo-moar a1347c: OUTPUT«Index 1 for dimension 1 out of range (must be 0..0)␤  in block <unit> at <tmp> line 1␤␤»

[10:46] <lizmat> ah no, duh, should wake up first  :-)

[10:46] <dalek> rakudo/nom: 84455f3 | jnthn++ | t/04-nativecall/20-concurrent. (2 files):

[10:46] <dalek> rakudo/nom: Test using NativeCall from multiple threads.

[10:46] <dalek> rakudo/nom:

[10:46] <dalek> rakudo/nom: This was already fixed a while ago, but not test was added.

[10:46] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/84455f39d3

[10:47] <jnthn> :)

[10:47] <lizmat> m: my @a[1,1] = (42,)   # this *is* strange, no/

[10:47] <camelia> rakudo-moar a1347c: OUTPUT«Assignment to array with shape 1 1 must provide structured data␤  in block <unit> at <tmp> line 1␤␤»

[10:47] <lizmat> ?

[10:50] <jnthn> m: my @a[1,1] = ((42,),)

[10:50] <camelia> rakudo-moar a1347c: ( no output )

[10:51] <jnthn> Needs to be that

[10:51] <jnthn> If you want to "pour" data into a shaped array then

[10:51] <lizmat> hmmm...

[10:51] <lizmat> guess so  :-)

[10:51] <jnthn> m: my @a[1,1] Z= 42; say @a

[10:51] <camelia> rakudo-moar 84455f: OUTPUT«[[42]]␤»

[10:51] <lizmat> .oO( more tea is needed )

[10:51] <jnthn> :)

[10:51] * jnthn is looking into RT #129994

[10:52] <jnthn> In no small part 'cus somebody also mailed me a while ago about the same problem (or what I suspect is the same problem) and I forgot about it...

[11:19] <gfldex> jnthn: you need to hurry, they are catching up! :-> https://blog.nightly.mozilla.org/2016/11/01/async-await-support-in-firefox/

[11:21] <jnthn> Yeah, but in Perl 6 we don't need no stinking await ;-)

[11:21] <jnthn> argh

[11:22] <jnthn> Yeah, but in Perl 6 we don't need no stinking async ;-)

[11:22] <jnthn> (We only need the await bit, which means you don't have to refactor your whole callstack)

[11:22] <jnthn> It's async/await is very good news for JS though :)

[11:22] <jnthn> grr, I shouldn't try to write GC/nativecall patches and write here at the same time :)

[11:40] <gfldex> jnthn: don't worry. Your code is supposed to be [CONC]. You are perfectly fine in the usual serial fashion. :)

[11:46] <jnthn> ;)

[11:47] <jnthn> Yay, another conc/nativecall bug down

[11:48] <dalek> nqp: 3a09f86 | jnthn++ | tools/build/MOAR_REVISION:

[11:48] <dalek> nqp: Bump MOAR_REVISION for nativecall/GC fixes.

[11:48] <dalek> nqp: review: https://github.com/perl6/nqp/commit/3a09f8663a

[11:49] <gfldex> jnthn: HTTP::Server::Threaded segfaults reliablely on my end

[11:50] <gfldex> jnthn: that's with a 1h old Rakudo

[11:51] <dalek> rakudo/nom: f99d958 | jnthn++ | tools/build/NQP_REVISION:

[11:51] <dalek> rakudo/nom: Bump for MoarVM with nativecall/GC fixes.

[11:51] <dalek> rakudo/nom:

[11:51] <dalek> rakudo/nom: With this fix, we make sure to GC-block the current thread before we

[11:51] <dalek> rakudo/nom: make a nativecall, and unblock it afterwards (taking care with the

[11:51] <dalek> rakudo/nom: handling of callbacks). This fixes an issue where calling a long

[11:51] <dalek> rakudo/nom: running bit of native code on one thread could make the others all

[11:51] <dalek> rakudo/nom: hang at the next GC until the native code completed.

[11:51] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/f99d958cd9

[11:51] <dalek> rakudo/nom: 5ba75f4 | jnthn++ | t/04-nativecall/20-concurrent.t:

[11:51] <dalek> rakudo/nom: Test native call on one thread won't block others.

[11:51] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/5ba75f445d

[11:55] <jnthn> gfldex: If that ain't RT'd, please do so

[11:56] <jnthn> Lunch; bbiab

[11:58] <dalek> rakudo/nom: 8064ff1 | lizmat++ | src/core/Shaped1Array.pm:

[11:58] <dalek> rakudo/nom: Make @a[10].STORE at least as fast as @a.STORE

[11:58] <dalek> rakudo/nom:

[11:58] <dalek> rakudo/nom: In practice, this makes my @a[10] = ^10 about 7x faster.  Most of

[11:58] <dalek> rakudo/nom: the overhead is still in my @a[10] though.

[11:58] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/8064ff1b02

[12:06] <gfldex> jnthn: that segfault seamed not CONC related after all. It had a Supply where it needed a Supplier but didn't produce the correct error message with the first test.

[12:14] <MasterDuke> i have added a method to Perl6::World in World.nqp, but why i try to call it in Actions.nqp i get "Cannot find method '<my_method>' on object of type Perl6::World"

[12:15] <MasterDuke> oh ha, nm. i added it to Perl6CompilationContext

[12:15] <MasterDuke> pebkac

[12:17] <gfldex> jnthn: the segfaults are gone after some patching but pretty much all tests hang now. The test look OK to me. Could you have a look? (depends on pending PR https://github.com/tony-o/perl6-http-server-threaded/pull/4)

[12:34] <travis-ci> Rakudo build failed. Jonathan Worthington 'Test native call on one thread won't block others.'

[12:34] <travis-ci> https://travis-ci.org/rakudo/rakudo/builds/172584833 https://github.com/rakudo/rakudo/compare/84455f39d3b2...5ba75f445dc7

[12:34] <buggable> [travis build above] ☠ Did not recognize some failures. Check results manually. All failures are on JVM only.

[12:34] <moritz> buggable++

[12:59] <lizmat> m: my @a[42;666]; say @a.elems   # is .elems on shaped arrays supposed to give the elems in the first dimension, jnthn ?

[12:59] <camelia> rakudo-moar 8064ff: OUTPUT«42␤»

[13:00] <lizmat> or is that an artefact ?

[13:02] <timotimo> i think it's supposed to behave like a one-dimensional array of arrays with some things

[13:02] <lizmat> or a bug?  I sorta expected to see 42*666 as the number of elems

[13:02] <timotimo> but .values.elems should probably give you the product

[13:02] <lizmat> well, it better :-)

[13:02] <lizmat> otherwise .values wouldn't produce all the values  :-)

[13:05] <lizmat> well, I can live with either behaviour, just would be different optimizations :-)

[13:07] <dalek> rakudo/nom: 8c3e57d | lizmat++ | src/core/Shaped1Array.pm:

[13:07] <dalek> rakudo/nom: Go straight to the source for @a[10].elems

[13:07] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/8c3e57d77e

[13:15] <ilmari> https://github.com/a must be thrilled with all the mentions he's getting in these commits ;)

[13:15] <lizmat> :-)

[13:25] <jnthn> lizmat: .elems should give the number of elements in the first dimension, which is what it appears to be doing.

[13:26] <lizmat> ok

[13:26] <jnthn> So that once we have partial views, @a[*] can work (since it uses @a.elems)

[13:26] <lizmat> just checking...

[13:26] <jnthn> :)

[13:27] <lizmat> also, is it intentional that $!shape is a List rather than an nqp::list ?

[13:31] <jnthn> Can't remember which way it is, but either way works I think

[13:32] <lizmat> It's List now

[13:32] <jnthn> I think that's fine

[13:32] <jnthn> Since .shape has to return a List anyway

[13:32] <jnthn> So we'd only have to wrap it every single time in that case

[13:32] <jnthn> And that's far more expensive that dereferencing

[13:32] <jnthn> And range checks don't use it directly anyway; the REPR itself does those.

[13:32] <lizmat> true, but in the core we could use $!shape directly

[13:32] <jnthn> Sure, we can now, just nqp::getattr on it :)

[13:33] <jnthn> That's a really cheap op after optimization

[13:33] <lizmat> the fact that each shaped array keeps another List inside of it doesn't bother you ?

[13:33] <jnthn> Not particularly

[13:34] <lizmat> it does me  :-)

[13:34] <jnthn> Unless your shaped array is tiny it's not a great deal of overhead...and won't the List be shared between instances of the same shape anyway?

[13:34] <jnthn> So your plan is that .shape causes memory allocation every time, thus causing even more memory pressure? :P

[13:34] <lizmat> eh, I don't think the shape is shared between incarnations of the same shape, atm

[13:35] <jnthn> Hm

[13:35] <jnthn> I thought in @a[2;2] we might have a List (2,2) constant-folded and passed in as the shape arg each construction

[13:35] <lizmat> if it would be shared, I wouldn't worry so much about it

[13:35] <jnthn> If that isn't happening that's perhaps the thing to do

[13:35] <[Coke]> Hey, all my non US dev buddies, can I get some vague assurances that the US will be fine when I wake up next Wednesday? Thanks. :P

[13:35] <lizmat> ok, will look at that

[13:36] <timotimo> voting is coming up?

[13:36] <jnthn> (I kinda thought it already was, but it's been a while.)

[13:36] * lizmat assures [Coke] that all will be well

[13:36] <timotimo> yeah, it ain't so bad

[13:36] * lizmat promised [Coke] that all will be well

[13:36] <lizmat> *promises

[13:36] <jnthn> [Coke]: It's possible that brexit used up all the stupid for 2016, and that it's now out of stock until 2017... ;-)

[13:37] * moritz always presumed that there's an infinite supply of stupid

[13:37] * jnthn crosses fingers :)

[13:37] <jnthn> moritz: Well, darn. :P

[13:37] <[Coke]> moritz: not helping! :)

[13:38] <moritz> [Coke]: anyway, we have cookies in Europe too, electricity, and developer jobs

[13:38] <arnsholt> moritz: Not to mention vacation days =)

[13:39] <moritz> right; I have 30, plus public holidays. Health insurance included

[13:39] <arnsholt> (And in Norway a legal obligation to take a minimum of vacation)

[13:40] <moritz> Norway++

[13:40] <jnthn> Legal obligation to take vacation? That's great. :D

[13:41] <gfldex> Technically we got the same in Germany but it's not enforced.

[13:41] <moritz> though at $work here, even team and departments leads take 3 weeks of consecutive vacation

[13:42] <moritz> I don't know if our CEO does, but he's also (partial) owner of the business, so nobody bothers him

[13:42] <[Coke]> I am lucky enough to have the "take all the vacation you can get away with" policy.

[13:43] <moritz> [Coke]: how many days is that, on average, per year?

[13:44] <[Coke]> 0? :)

[13:44] * jnthn didn't use many vacation days this year, but is looking forward to some good time off around Christmas/New Year :)

[13:45] <lizmat> jnthn: when setting up a shaped array like @a[10], 1/3 of CPU is spent in mixing in the role

[13:45] <lizmat> with set-shape at 15%, does at 9% and mixin at 8%

[13:47] <jnthn> lizmat: How many arrays did you make?

[13:47] <lizmat> 10K

[13:47] <lizmat> for ^10000 { my @a[10] }

[13:48] <jnthn> Umm...and why can't I find the shape handling code in Array...

[13:48] <lizmat> it lives in src/core/ShapedArray nowadays

[13:48] <lizmat> and Shaped1Array/Shaped2Array/Shape3Array

[13:49] <jnthn> Wait, doesn't that expose it?

[13:49] <lizmat> no, it's still part of the Array class

[13:49] <jnthn> Rather than it being lexically scoped inside of Array?

[13:49] <lizmat> it's still lexically scoped in Array

[13:49] <jnthn> Doesn't look like it to me?

[13:49] <lizmat> say ShapedArray

[13:49] <lizmat> m: say ShapedArray

[13:49] <camelia> rakudo-moar 8c3e57: OUTPUT«===SORRY!=== Error while compiling <tmp>␤Undeclared name:␤    ShapedArray used at line 1␤␤»

[13:49] <lizmat> Array.pm only has an opening curly

[13:50] <jnthn> oh...damn

[13:50] <jnthn> o.O

[13:50] <jnthn> The things people consider improvements sometimes surprise me :P

[13:50] <lizmat> sorry, but that file was getting *way* too big

[13:50] <jnthn> The things people consider problems sometimes surprise me :P

[13:50] <jnthn> But OK, if it made it easier for you to work on... :)

[13:50] <lizmat> yes, very much so

[13:51] <lizmat> I mean, when I started working on this, 1 dim shaped arrays were like 15x slower than normal arrays

[13:51] <lizmat> they're almost on par now

[13:52] <jnthn> OK, finally found the bit of the code I was looking for :)

[13:52] <lizmat> which is ?

[13:52] <jnthn> set-shape

[13:53] <jnthn> And yeah, SHAPED-ARRAY-STORAGE is what I was thinking about

[13:53] <jnthn> (It interns types)

[13:54] <jnthn> Thing is, mixin types are also interned

[13:54] <jnthn> So I guess it's already saving some amount of time

[13:54] <jnthn> We may be able to re-shuffle things to just create the correct type in the first place and avoid the does

[13:55] <lizmat> so, how many times should infix:<does> be called for "for ^10000 { my @a[10] }" ?

[13:55] <lizmat> 1 or 10000 ?

[13:55] <jnthn> Well, at the moment it'll be 10000

[13:55] <jnthn> But it won't actually go through the whole role composition process every time, I don't think

[13:55] <jnthn> mixin will hit a cache

[13:55] <jnthn> Can verify that by a --profile I guess

[13:56] <lizmat> mixin is also called 10K times

[13:56] <jnthn> Yes, but I belive mixin is what looks in the cache

[13:56] <jnthn> You might be a speedup calling mixin directly rather than going via does

[13:56] <jnthn> *get

[13:57] <lizmat> ok

[13:57] <jnthn> But alternative would be avoiding that altogether

[13:57] <jnthn> And figure out what shaped type we want up front

[13:57] <lizmat> especially if the dimension list contains int constants only

[13:57] <jnthn> That is, obtain Array but Shaped1Array[Mu]

[13:57] <jnthn> (which doesn't cause a deopt)

[13:58] <jnthn> And then nqp::create that

[13:58] <lizmat> obtain ?

[13:58] <jnthn> Obtain as it "just do that" :)

[13:59] <jnthn> When you mix in to a type object, it doesn't really mix in, it just gives back a type object

[13:59] <jnthn> And if you make an instance of that, you can avoid the whole mixing in process

[13:59] <jnthn> .^mixin is slow in part because it is a global deopt

[13:59] <jnthn> So it de-optimizes the whole callstack

[13:59] <jnthn> So even your for ^10000 { } loop will run slower

[14:00] <travis-ci> Rakudo build failed. Elizabeth Mattijsen 'Go straight to the source for @a[10].elems'

[14:00] <travis-ci> https://travis-ci.org/rakudo/rakudo/builds/172602457 https://github.com/rakudo/rakudo/compare/8064ff1b02ed...8c3e57d77e90

[14:00] <buggable> [travis build above] ☠ Did not recognize some failures. Check results manually.

[14:00] <lizmat> ah, so say something lilke: my $dim1 := Array but Shaped1Array(Mu); then nqp::create($dim1) ?

[14:00] <lizmat> with the $dim1 living as a lexical in Array class ?

[14:01] <viki> t/04-nativecall/20-concurrent.t .......... Dubious, test returned 255 (wstat 65280, 0xff00)

[14:01] <viki> (travis above; one failure)

[14:02] <jnthn> Nice, and the output provides no clue at all why

[14:03] <jnthn> lizmat: Something like that, though not sure it's worth interning them further than but does

[14:04] <jnthn> lizmat: Could try it though

[14:04] <lizmat> will do, after some break and fresh air  :-)

[14:04] <lizmat> afk&

[15:31] <gfldex> my \IOL = Lock.new;  &say.wrap( -> |c { IOL.protect: { callwith |c } }); for ^100 { say "oops" }

[15:31] <gfldex> does callwith refer to the innermost block in this case?

[15:32] <jnthn> It's dynamically scoped

[15:32] <jnthn> So it'll be talking about the dispatcher of the nested block

[15:32] <jnthn> Not the wrapping block

[15:32] <jnthn> m: nextcallee

[15:32] <camelia> rakudo-moar 8c3e57: OUTPUT«nextsame is not in the dynamic scope of a dispatcher␤  in block <unit> at <tmp> line 1␤␤»

[15:33] <jnthn> I think your best bet is to use that to get it in the outer block

[15:35] <jnthn> So, at the moment when you await or .result a Promise that gets broken, the error reproting is a bit suck

[15:35] <jnthn> Because you get the message of the exception, but only the backtrace of where you called .result

[15:35] <jnthn> I just made it look this way:

[15:35] <jnthn> https://gist.github.com/jnthn/d03966f24159711a3e3782f030c2c4df

[15:35] <jnthn> Any wording tweaks desired?

[15:36] <jnthn> (Note this is done by mixing in to the original exception type, and so when X::Foo { } matchers will continue to work as before)

[15:40] <gfldex> m: my \IOL = Lock.new;  &say.wrap( -> |c { IOL.protect: { nextcallee.callwith |c } }); for ^100 { say "oops" }

[15:40] <camelia> rakudo-moar 8c3e57: ( no output )

[15:45] <jnthn> no, the idea was to use nextcallee int he closure actually doing the wrapping

[15:47] <jnthn> m: use soft; my \IOL = Lock.new;  &say.wrap( -> |c { my &wrappee = nextcallee; IOL.protect: { &wrappee(|c) } }); for ^100 { say "oops" }

[15:47] <camelia> rakudo-moar 8c3e57: OUTPUT«oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops␤oops…»

[15:47] <gfldex> m: my \IOL = Lock.new;  &say.wrap( -> |c { my &wrappee = nextalleee; IOL.protect: { wrappee.callwith |c } }); for ^100 { say "oops" }

[15:47] <camelia> rakudo-moar 8c3e57: OUTPUT«===SORRY!=== Error while compiling <tmp>␤Undeclared routine:␤    nextalleee used at line 1. Did you mean 'nextcallee'?␤␤»

[15:47] <gfldex> also ENODOC

[15:49] * jnthn notes that IO handles do locking down at the VM level

[15:58] <gfldex> ENODOC--

[15:59] <dalek> rakudo/nom: abf6caf | jnthn++ | src/core/Promise.pm:

[15:59] <dalek> rakudo/nom: Improve error reporting around broken promises.

[15:59] <dalek> rakudo/nom:

[15:59] <dalek> rakudo/nom: Previously, we had the message of the original exception, together

[15:59] <dalek> rakudo/nom: with the backtrace of the await or .result call. Now, we:

[15:59] <dalek> rakudo/nom:

[15:59] <dalek> rakudo/nom: * Clearly indicate that the exception was raised by obtaining the

[15:59] <dalek> rakudo/nom:   result of a broken Promise

[15:59] <dalek> rakudo/nom: * Provide the location that this happened

[15:59] <dalek> rakudo/nom: * Provide the original exception's message

[15:59] <dalek> rakudo/nom: * Provide the backtrace of the original exception

[15:59] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/abf6caf06e

[16:00] <moritz> jnthn++

[16:01] <moritz> makes me want to reconsider my choice to use 2016.10 for the book :-)

[16:01] <dalek> roast: 2972719 | jnthn++ | S17-promise/start.t:

[16:01] <dalek> roast: Test to cover RT #125782.

[16:01] <dalek> roast: review: https://github.com/perl6/roast/commit/2972719cee

[16:01] <synopsebot6> Link:  https://rt.perl.org/rt3//Public/Bug/Display.html?id=125782

[16:06] <jnthn> Yes, that one is a rather nice usability improvement.

[16:32] <dalek> roast: c3b28cc | jnthn++ | S17-channel/stress.t:

[16:32] <dalek> roast: Test for RT #127960.

[16:32] <dalek> roast: review: https://github.com/perl6/roast/commit/c3b28cce5e

[16:32] <synopsebot6> Link:  https://rt.perl.org/rt3//Public/Bug/Display.html?id=127960

[16:35] <pmurias> nqp::copy behaves differently on moar and jvm

[16:35] <yoleaux2> 31 Oct 2016 23:33Z <MasterDuke> pmurias: kind of. i think all the ones that are left also fail on moar. i'd like to get some more of them eventually, so i'll ping you again if i run into jmv problems

[16:35] <dalek> roast: d573ecb | jnthn++ | S17-supply/watch-path.t:

[16:35] <dalek> roast: Remove a warning due to a bogus unused string.

[16:35] <dalek> roast: review: https://github.com/perl6/roast/commit/d573ecbeb8

[16:35] <viki> m: my $a = (:10a).Bag; my $b = (:42a).Bag; say $a (^) $b eqv ($a ∖ $b) ∪ ($b ∖ $a)

[16:35] <camelia> rakudo-moar abf6ca: OUTPUT«False␤»

[16:36] <pmurias> nqp::copy behaves differently on moar and jvm

[16:37] <pmurias> when given a symlink as the target it follows on the moar and overwrites on the jvm

[16:46] <viki> m: my $a = (:10a).Bag; my $b = (:42a).Bag; say ($a ∖ $b) ∪ ($b ∖ $a)

[16:46] <camelia> rakudo-moar abf6ca: OUTPUT«set(a)␤»

[16:46] <viki> m: my $a = (:42a).Bag; my $b = (:10a).Bag; say ($a ∖ $b) ∪ ($b ∖ $a)

[16:46] <camelia> rakudo-moar abf6ca: OUTPUT«bag(a(32))␤»

[16:54] <dalek> nqp: b07c356 | (Pawel Murias)++ | src/vm/js/ (2 files):

[16:54] <dalek> nqp: [js] Implement stuff needed to get test 19 to pass again.

[16:54] <dalek> nqp: Implement nqp::rename, nqp::copy.

[16:54] <dalek> nqp: Make nqp::unlink fail quietly when it's target doesn't exit.

[16:54] <dalek> nqp: review: https://github.com/perl6/nqp/commit/b07c35692d

[17:03] <viki> m: my $a = (:a).Set; dd $a.Bag

[17:03] <camelia> rakudo-moar abf6ca: OUTPUT«("a"=>1).Bag␤»

[17:03] <viki> m: my $a = (:a).Set; dd $a.Mix

[17:03] <camelia> rakudo-moar abf6ca: OUTPUT«("a"=>True).Mix␤»

[17:20] <TimToady> Hotkeys: the main reason there's a .sum but not a .product is that we wanted an optimization target for [+] 1..1000000000000000

[17:20] <TimToady> and we just decided to make it user-visible

[17:23] <viki> TimToady: FWIW, there's a proposal for how (^) operator should behave with Sets/Bags/Mixes, if you wanted to weigh in: https://github.com/rakudo/rakudo/pull/911

[17:33] <TimToady> I very much like that the set behavior is a degenerate case of the bag behavior; what I do not like is any approach that autocoerces bags or mixes to sets, which is pretty non-sensical, so I think such coercions should explicitly pull out the keys and make a set, if that's really what is wanted, and fail otherwise

[17:35] <FROGGS> o/

[18:31] * viki is getting a bunch of stresstest failures for various reasons

[18:33] <dalek> roast: 91c57c3 | (Zoffix Znet)++ | S17-procasync/stress.t:

[18:33] <dalek> roast: Test::Util needs t/spec/packages in the use lib

[18:33] <dalek> roast: review: https://github.com/perl6/roast/commit/91c57c3dea

[18:34] <viki> t/spec/S17-supply/return-in-tap.t says "getexpayload needs a VMException"

[18:34] <viki> Full output: https://gist.github.com/zoffixznet/0c4b4e87641a6d349d2ad82077c92cd7

[18:35] <dalek> rakudo/nom: cdb3699 | lizmat++ | src/core/Shaped (2 files):

[18:35] <dalek> rakudo/nom: All shaped arrays share the same .elems logic

[18:35] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/cdb369903f

[18:36] <jnthn> viki: On Rakudo HEAD?

[18:36] <viki> jnthn: yeah

[18:36] <jnthn> viki: (Which implies NQP HEAD and MoarVM HEAD)

[18:36] <timotimo> i, for one, am glad that shaped arrays are getting a bit of a performance pass

[18:37] <viki> jnthn: oh, no, rakudo HEAD and the rest is whatever the specificied bumps are

[18:37] <jnthn> Are you sure? That error message is notable in being what that test would give before https://github.com/MoarVM/MoarVM/commit/a4c0a84492fcd7aaf81524dc68aabdbb3e0bebe8

[18:37] <lizmat> timotimo: glad to hear that

[18:37] <viki> This is Rakudo version 2016.10-150-gabf6caf built on MoarVM version 2016.10-15-g715e39a

[18:38] <jnthn> $ ./moar --version

[18:38] <jnthn> This is MoarVM version 2016.10-37-gf769569 built with JIT support

[18:38] <viki> I guess bumpage is needed

[18:39] <jnthn> $ cat tools/build/MOAR_REVISION

[18:39] <jnthn> 2016.10-37-gf769569

[18:39] <jnthn> (in NQP)

[18:39] <jnthn> $ git describe

[18:39] <jnthn> 2016.10-43-g3a09f86

[18:39] <jnthn> (also in NQP)

[18:39] <jnthn> And that's what's in NQP_REVISION

[18:40] <jnthn> So it *looks* like I did the bumps right

[18:40] <viki> OK. Located the issue. I ran make install only instead of the full thing

[18:40] <jnthn> oh :)

[18:40] <viki> Sorry :)

[18:40] <jnthn> np

[18:41] <jnthn> Glad the failure mode you pasted was an easily recognizable one :)

[18:53] <viki> ZOFVM: Files=1200, Tests=130118, 171 wallclock secs (20.93 usr  3.29 sys + 3086.64 cusr 296.65 csys = 3407.51 CPU)

[18:54] <lizmat> m: role A { multi method a() {"one"}; multi method a() {"two"} }; say A.a   # this feels like it should complain somehow

[18:54] <camelia> rakudo-moar cdb369: OUTPUT«one␤»

[18:55] <timotimo> yeah, it should

[18:55] <dalek> rakudo/nom: 78ef944 | lizmat++ | src/core/ShapedArray.pm:

[18:55] <dalek> rakudo/nom: How did two identical methods get in here???

[18:55] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/78ef944e92

[18:55] <dalek> rakudo/nom: 7ba7eb4 | (Zoffix Znet)++ | src/core/Setty.pm:

[18:55] <dalek> rakudo/nom: Add specific .Mix and .MixHash coercers to Setty

[18:55] <dalek> rakudo/nom:

[18:55] <dalek> rakudo/nom: ...just like we have ones for Bag(Hash).

[18:55] <dalek> rakudo/nom:

[18:55] <dalek> rakudo/nom: Otherwise, a set coerced to a Mix has Bools for weights instead of Ints

[18:55] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/7ba7eb4412

[18:56] <dalek> roast: ccc9301 | (Zoffix Znet)++ | S02-types/set.t:

[18:56] <dalek> roast: Set.Mix/.MixHash does not produce Bool weights

[18:56] <dalek> roast: review: https://github.com/perl6/roast/commit/ccc9301da0

[19:16] <dalek> rakudo/nom: 28e11c4 | lizmat++ | / (7 files):

[19:16] <dalek> rakudo/nom: Move set-shape logic to new ShapeNArray.pm

[19:16] <dalek> rakudo/nom:

[19:16] <dalek> rakudo/nom: - also close class Array in TypedArray.pm

[19:16] <dalek> rakudo/nom: - no need to stub Shaped123Array roles

[19:16] <dalek> rakudo/nom:

[19:16] <dalek> rakudo/nom: Really preliminary work for more optimizations

[19:16] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/28e11c47dd

[19:19] <dalek> rakudo/nom: d036a50 | lizmat++ | src/core/Shaped (5 files):

[19:19] <dalek> rakudo/nom: Add some comments indicating part of Array class

[19:19] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/d036a50109

[19:22] <dalek> rakudo/nom: 5d1b2c3 | lizmat++ | src/core/ShapedArray.pm:

[19:22] <dalek> rakudo/nom: Fix type in comment, MasterDuke17++

[19:22] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/5d1b2c3bc6

[19:24] <[Coke]> *typo

[19:24] <[Coke]> :)

[19:26] <viki> meta-typo

[19:27] <[Coke]> meat type

[19:30] <lizmat> .oO( once you start...  )

[19:31] <masak> ...it's hrad to sotp

[19:45] <lizmat> m: my Int @a; @a.BIND-POS(0,42)   # seems I missed one place handling completely empty lists

[19:45] <camelia> rakudo-moar 5d1b2c: OUTPUT«This type (Scalar) does not support positional operations␤  in block <unit> at <tmp> line 1␤␤»

[20:12] <dalek> rakudo/nom: 0bbe98d | lizmat++ | src/core/TypedArray.pm:

[20:12] <dalek> rakudo/nom: Make sure BIND-POS works the same on typed arrays

[20:12] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/0bbe98d886

[20:20] <bartolin> pmurias: sorry for making 019-file-ops.t fail for nqp-js. what do I need only node.js to be able to build nqp-js? (I've just read https://github.com/perl6/nqp/#javascript-backend )

[20:21] <bartolin> s/what//

[20:28] <[Coke]> hurm. rakudo's js branch's Configure.pl mentions a js backend, but then dies with: sh: gen/js/Makefile-JS.in: No such file or directory

[20:44] <dalek> rakudo/nom: ebcc33e | (Carl Masak)++ | tools/build/create-moar-runner.pl:

[20:44] <dalek> rakudo/nom: fix typo

[20:44] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/ebcc33eb6f

[20:50] <lizmat> jnthn: was there a specific reason to keep "int" and Int:D candidates for AT-POS and friends around>

[20:50] <lizmat> ?

[20:51] <lizmat> it appears that removing the "int" candidate at the moment improves performance for calls with native ints

[21:01] <nine> That's quite counter intuitive

[21:02] <timotimo> not if you know that native ints make our static optimizer unhappy

[21:02] <timotimo> (the fix for that seems to require jnthn. or at least something more than timo)

[21:03] <lizmat> well, the way I see it, is that I remove all of the "int" candidates now

[21:03] <lizmat> and then when we have "int" grokked by the optimizer, change the "Int:D" to "int" in the sigs

[21:05] <lizmat> m: sub a(int $a) { dd $a }; a my Int $ = 42  # cause this works

[21:05] <camelia> rakudo-moar ebcc33: OUTPUT«42␤»

[21:06] <timotimo> well, that probably unboxes

[21:08] <lizmat> yup

[21:09] <lizmat> so, when the optimizer groks int, we can simply change the sig from Int:D to int

[21:09] <lizmat> the Ints will be unboxed automagically

[21:09] <lizmat> and potentially be unboxed during optimization time already

[21:16] <travis-ci> Rakudo build errored. Elizabeth Mattijsen 'All shaped arrays share the same .elems logic'

[21:16] <travis-ci> https://travis-ci.org/rakudo/rakudo/builds/172716018 https://github.com/rakudo/rakudo/compare/abf6caf06eb7...cdb369903f3a

[21:16] <buggable> [travis build above] ☠ Did not recognize some failures. Check results manually.

[21:28] <jnthn> Uh, you can't remove the Int candidate and expect the multi-dispatcher to send an Int to an int candidate

[21:28] <lizmat> no?

[21:29] <jnthn> No

[21:29] <lizmat> :-(

[21:29] <timotimo> Int can asplode when it doesn't fit into an int

[21:29] <jnthn> Right

[21:29] <jnthn> Also int is tighter than Int

[21:30] <jnthn> So if int candidates accepted Int then you'd never dispatch to an Int candidate even when you did have a big integer

[21:30] <jnthn> I'd leave the int candidates int, especially for native shaped arrays

[21:30] <lizmat> ok

[21:31] <jnthn> Just because we don't always generate the code I'd like us to for these things now doesn't mean we won't in the future.

[21:31] <lizmat> it's just a significant maint burden atm

[21:31] <lizmat> ok

[21:31] <lizmat> but, re AT-POS(Int:D) taking int values larger than what an int can hold

[21:32] <lizmat> do we foresee supporting arrays with more than 2**64 elements ?

[21:32] <jnthn> No, I'm talking about the multi-dispatcher in general

[21:33] <lizmat> ok

[21:33] <jnthn> Of course, it's possible we'll also end up clever enough to get away with the Int:D candidates and stripping out the boxing...

[21:33] <jnthn> But that feels like it'll need another level of clever than just getting the code-gen to them straightened out

[21:34] <lizmat> the thing is, I'm adding quite a lot of code atm

[21:35] <lizmat> and compile times are going > 60 seconds for me

[21:35] <lizmat> and it looks like bare startup time isn't getting lower  :-(

[21:37] <lizmat> perhaps I should look at gen-cat.nqp autogenerating the "int" candidates

[21:37] <lizmat> argh, but then line number referrals  :-(

[21:41] <lizmat> ok, back to adding int / Int:D candidates all the time

[21:42] <lizmat> jnthn: getting back to the difference between for ^10000 { my @a } and for ^10000 { my @a[10] }

[21:43] <lizmat> in the former case, Array.new is never called: it looks like a Array object is created at compile time, and then cloned during each iteration.

[21:43] <lizmat> is there a reason to not do the same for shaped arrays if the shape list consists of constant values

[21:43] <lizmat> ?

[21:44] <lizmat> aka, create the object, and then clone it during execution?

[21:44] <lizmat> I guess it would have to be a HLL .clone

[21:54] <jnthn> For the "usual" case we just clone the P6opaque, yeah, but it's a shallow clone

[21:54] <jnthn> And it happens relatively low-level too

[21:56] <lizmat> well, I've just added a .clone to ShapedArray

[21:56] <lizmat> my @a[10]; for ^10000 { my @b := @a.clone }

[21:57] <lizmat> is 60x faster than

[21:57] <lizmat> for ^10000 { my @a[10] }

[21:57] <jnthn> Does it clone the storage too?

[21:57] <lizmat> yes

[21:57] <lizmat> https://gist.github.com/lizmat/a087f82975d4d7140d85f58438ce5fc1

[21:57] <jnthn> May be worth looking into if we can do it that way, then :)

[21:58] <jnthn> Ohh...

[21:58] <jnthn> But you can't do it for dynamic sizes

[21:58] <lizmat> indeed

[21:58] <jnthn> Which is why it's code-gen'd the way it is now

[21:58] <lizmat> indeed... so we need to check if it's a constant, then code gen it with a .clone

[21:58] <jnthn> (Doesn't mean we can't do better on the static sizes)

[21:58] <lizmat> otherwise, well, we have to do it the cirrent way

[21:58] <lizmat> indeed

[21:58] <jnthn> Aye. I was largely in "make it work" mode when I put this stuff in :)

[21:59] <lizmat> I know

[21:59] <lizmat> :-)

[21:59] <lizmat> I'm in "making it work faster" mode now  :-)

[22:01] <jnthn> \o/

[22:01] <jnthn> lizmat++

[22:02] <jnthn> Will be nice when I get optimization tuits again

[22:02] <jnthn> But should really get a bunch of our concurrency issues cleared up

[22:02] <jnthn> Well, a bunch more :)

[22:02] <jnthn> Trouble is, the more I fix, the better the remaining ones are at hiding.

[22:03] <lizmat> yeah, I know  :-(

[22:09] * jnthn wanders off to rest

[22:10] <lizmat> jnthn: one quick question

[22:10] <lizmat> is it

[22:10] <lizmat> ok to have shaped arrays carry around a $!todo even though it gets never set ?

[22:12] <dalek> rakudo/nom: 40429f3 | lizmat++ | src/core/ShapedArray.pm:

[22:12] <dalek> rakudo/nom: Give shaped arrays its own fast .clone

[22:12] <dalek> rakudo/nom:

[22:12] <dalek> rakudo/nom: To be hopefully used later to quickly initialize shaped arrays in

[22:12] <dalek> rakudo/nom: loops.

[22:12] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/40429f32bb

[22:13] * lizmat also goes off for some shuteye

[22:27] <MasterDuke> jnthn: reading the backlog, i thought lizmat was asking about removing the 'int' candidates (and just having 'Int'), but you said removing 'Int' (and just having 'int') was bad?

[22:29] <timotimo> yeah, only having int is bad

[22:30] <timotimo> what do you do with 2 ** 70 then?

[22:57] <MasterDuke> well yeah, but is it bad to only have Int, when those are faster than int anyway?

[23:27] <dalek> rakudo/nom: c59ab18 | raiph++ | src/core/Str.pm:

[23:27] <dalek> rakudo/nom: Fix off by one errors in Failure messages

[23:27] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/c59ab1888d

[23:27] <dalek> rakudo/nom: 88cb05e | (Zoffix Znet)++ | src/core/Str.pm:

[23:27] <dalek> rakudo/nom: Merge pull request #912 from raiph/patch-1

[23:27] <dalek> rakudo/nom:

[23:27] <dalek> rakudo/nom: Fix off by one errors in Failure messages

[23:27] <dalek> rakudo/nom: review: https://github.com/rakudo/rakudo/commit/88cb05ebd2
