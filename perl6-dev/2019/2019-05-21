[02:10] *** AlexDaniel joined
[02:27] *** ggoebel joined
[02:32] *** ggoebel left
[03:53] *** Kaiepi left
[04:10] <AlexDaniel> dogbert11: I think it's fine. Yeah Moar had a release and Rakudo didn't, functionally there's no problem

[04:35] *** Kaiepi joined
[04:52] *** MasterDuke left
[05:21] *** skids left
[06:21] *** [TuxCM] left
[07:59] *** vrurg left
[08:03] <Kaiepi> oh lizmat you mentioned you wanted to talk earlier?

[08:03] <lizmat> you should ping me about something ?

[08:08] *** [TuxCM] joined
[08:08] <Kaiepi> yesterday i was talking about my issues with feed operators and you said to talk to you later lizmat 

[08:09] <lizmat> right...

[08:09] * lizmat looks at the code again

[08:12] <lizmat> Kaiepi: so, Actions/make_feed_result is run at compile time, right ?

[08:13] <Kaiepi> yes

[08:14] <lizmat> and Rakudo::Internals.EVALUATE-FEED should be run at runtime, right ?

[08:15] <Kaiepi> it should, but when i tried that it ran slower than the current implementation of feed operators

[08:16] <lizmat> but when I look at the code, it looks like it is being run at compile time ?

[08:16] <Kaiepi> check the previous commits

[08:17] <Kaiepi> initially i wrote it so it'd run at runtime

[08:19] <lizmat> the approach in https://github.com/rakudo/rakudo/pull/2903/commits/f84ebcaf48891d49b558cfc078e1823e1330d285 of make_feed_result looks correct to me

[08:20] <lizmat> except maybe the p6store ?  is that still a thing?

[08:21] <Kaiepi> i forget, locally i made it do either p6store or p6assign depending on the variable's sigil but idk if i pushed those changes or not

[08:21] <lizmat> hmm... I guess it is

[08:22] * lizmat seems to recall we wanted to get rid of that   (probably wrongly)

[08:22] <timotimo> maybe you're confusing it with extops; p6store is implemented as a desugar, so it's implemented in nqp

[08:23] <lizmat> m: use nqp; my @a; nqp::p6store(@a,nqp::list(42,43)); dd @a

[08:23] <camelia> rakudo-moar a643b8be1: OUTPUT: «Array @a = [42, 43]␤»

[08:23] <timotimo> extops are the things that are implemented in C and so have to have an extra compilation step when building rakudo, and have to be located and loaded during perl6 startup

[08:23] <lizmat> timotimo: ah, yes...

[08:23] <lizmat> and p6store was at one point an extop, right ?

[08:24] <lizmat> anyways

[08:31] <timotimo> it might have been, dunno. but all extops start with "p6" if i'm not mistaken

[08:33] <lizmat> but p6store is no longer an extop ?

[08:33] <timotimo> that's right

[08:55] <jnthn> p6store is something like `nqp::iscont(target) ?? nqp::p6assign(target, value) !! target.STORE(value)`

[08:55] <|Tux|> Rakudo version 2019.03.1-420-g12ed245c8 - MoarVM version 2019.05-11-g248e2980a

[08:55] <|Tux|> csv-test-xs-20      0.428 -  0.432

[08:55] <|Tux|> csv-ip5xs           0.706 -  0.710

[08:55] <|Tux|> test-t --race       0.760 -  0.788

[08:55] <|Tux|> test-t              1.721 -  1.734

[08:55] <|Tux|> csv-ip5xs-20        5.862 -  5.926

[08:55] <|Tux|> test                6.390 -  7.059

[08:55] <|Tux|> test-t-20 --race    8.980 -  8.995

[08:56] <|Tux|> csv-parser         21.233 - 21.905

[08:56] <|Tux|> test-t-20          28.350 - 29.723

[08:56] <jnthn> It's what you use when you don't know what's on the LHS (e.g. no sigil)

[08:56] <jnthn> And defers the choice of how the assignment works until runtime

[08:58] <lizmat> jnthn: is that the right thing to do for the pointy end of a feed ?

[08:59] <Geth> ¦ roast: df48391aa4 | (Elizabeth Mattijsen)++ | S29-context/eval.t

[08:59] <Geth> ¦ roast: Add basic EVAL :check testing

[08:59] <Geth> ¦ roast: review: https://github.com/perl6/roast/commit/df48391aa4

[09:03] <jnthn> Hm, we can case-analyze it, no?

[09:04] <jnthn> ==> my @a # quite clearly just wants to .STORE

[09:04] <jnthn> Well maybe does...

[09:04] <jnthn> I think traditionally we've .push'd

[09:05] <lizmat> jnthn: well, that behaviour is up for some discussion  :-)

[09:05] <lizmat> https://github.com/perl6/problem-solving/issues/27

[09:07] <jnthn> Right

[10:31] <Geth> ¦ rakudo: cono++ created pull request #2911: Fix slurp error during Configure.pl

[10:31] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/pull/2911

[10:32] <Geth> ¦ rakudo: 6e14da541b | cono++ | Configure.pl

[10:32] <Geth> ¦ rakudo: Fix slurp error during Configure.pl

[10:32] <Geth> ¦ rakudo: 

[10:32] <Geth> ¦ rakudo: Was getting this error:

[10:32] <Geth> ¦ rakudo: Undefined subroutine &main::slurp called at Configure.pl line 48.

[10:32] <Geth> ¦ rakudo: when I run:

[10:32] <Geth> ¦ rakudo: Configure.pl --gen-moar --gen-nqp --backends=moar --make-install

[10:32] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/commit/6e14da541b

[10:32] <Geth> ¦ rakudo: 672fd6e2c1 | timo++ (committed using GitHub Web editor) | Configure.pl

[10:32] <Geth> ¦ rakudo: Merge pull request #2911 from cono/slurp-fix

[10:32] <Geth> ¦ rakudo: 

[10:32] <Geth> ¦ rakudo: Fix slurp error during Configure.pl

[10:32] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/commit/672fd6e2c1

[11:51] *** ggoebel joined
[12:54] <lizmat> .tell Kaiepi my take on a lazy feed handler: https://gist.github.com/lizmat/69faa8cb0f2d4972f17561b21bace743

[12:54] <yoleaux> lizmat: I'll pass your message to Kaiepi.

[12:55] <lizmat> .tell Kaiepi while doing this, I realized that we will need some type of buffering / batching to make this work in multiple threads

[12:55] <yoleaux> lizmat: I'll pass your message to Kaiepi.

[12:55] *** [TuxCM] left
[12:55] <lizmat> .tell Kaiepi I suggest we try something like this first, and continue the problem solving ticket about feed operators

[12:55] <yoleaux> lizmat: I'll pass your message to Kaiepi.

[13:00] *** pamplemousse joined
[13:05] *** grayrider left
[13:11] <Kaiepi> ahhh

[13:11] <yoleaux> 12:54Z <lizmat> Kaiepi: my take on a lazy feed handler: https://gist.github.com/lizmat/69faa8cb0f2d4972f17561b21bace743

[13:11] <yoleaux> 12:55Z <lizmat> Kaiepi: while doing this, I realized that we will need some type of buffering / batching to make this work in multiple threads

[13:11] <yoleaux> 12:55Z <lizmat> Kaiepi: I suggest we try something like this first, and continue the problem solving ticket about feed operators

[13:12] <Kaiepi> i figured there was a way to reduce the list of ops but i couldn't work out how

[13:27] *** vrurg joined
[13:40] *** [TuxCM] joined
[13:57] *** Kaypie joined
[13:58] *** dogbert17 joined
[13:59] *** [TuxCM] left
[14:00] *** titsuki_ joined
[14:00] *** nebuchad` joined
[14:01] *** klapperl_ joined
[14:01] *** commavir_ joined
[14:01] *** scovit_ joined
[14:05] *** [TuxCM] joined
[14:06] *** Kaiepi left
[14:06] *** SqrtNegI_ left
[14:06] *** dogbert11 left
[14:06] *** klapperl left
[14:06] *** llfourn left
[14:06] *** go|dfish left
[14:06] *** llfourn joined
[14:06] *** scovit left
[14:06] *** nebuchadnezzar left
[14:06] *** commavir left
[14:06] *** titsuki left
[14:09] *** nebuchad` is now known as nebuchadnezzar

[14:11] *** commavir_ is now known as commavir

[14:12] *** go|dfish joined
[14:17] *** [TuxCM] left
[15:49] *** discord6 left
[15:49] *** discord6 joined
[16:49] *** pamplemousse left
[16:49] *** pamplemousse joined
[17:10] <lizmat> m: use nqp; my num $then = nqp::time_n; say nqp::time_n - $then

[17:10] <camelia> rakudo-moar a643b8be1: OUTPUT: «1558458604.2014737␤»

[17:10] <lizmat> that feels...  wrong ?

[17:11] <lizmat> m: use nqp; say nqp::time_n - nqp::time_n   # shouldn't that be close to zero?

[17:11] <camelia> rakudo-moar a643b8be1: OUTPUT: «1558458672.3035285␤»

[17:12] <moritz> m: use nqp; say nqp::time_n() - nqp::time_n()

[17:12] <camelia> rakudo-moar a643b8be1: OUTPUT: «0␤»

[17:12] <lizmat> he

[17:21] <timotimo> it's ... an unsigned num?!?!

[17:22] <timotimo> oh, haha

[17:22] <timotimo> yeah, it's the parenthesis

[17:31] *** robertle joined
[17:32] *** Ven``_ joined
[17:33] *** vrurg left
[17:35] <lizmat> timotimo??

[17:36] <timotimo> lizmat: ?

[17:36] <lizmat> so why do the parentheses fix the problem ?

[17:36] <timotimo> because nqp::time_n - $then is nqp::time_n(-$then)

[17:37] <lizmat> but, nqp::time_n is not documented as taking any values ?

[17:37] <timotimo> right, but the parser doesn't know that

[17:37] <timotimo> it just parses all nqp ops as if they were subs

[17:38] <lizmat> aaah... ok

[17:38] <timotimo> why it doesn't result in a compilation error because it's not supposed to take a value is anyone's guess ;)

[17:38] * lizmat must have missed that gotcha many, many times without realizing it

[17:39] <timotimo> i might also have

[17:39] <timotimo> should be possible to put a check in that complains if the number of args is too high

[17:40] <timotimo> bisectable6: use nqp; nqp::time_n(1234)

[17:40] <bisectable6> timotimo, Bisecting by output (old=2015.12 new=672fd6e) because on both starting points the exit code is 1

[17:40] <timotimo> m: use nqp; nqp::time_n(1234)

[17:40] <camelia> rakudo-moar a643b8be1: OUTPUT: «This type cannot unbox to a native number: P6opaque, Int␤  in block <unit> at <tmp> line 1␤␤»

[17:40] <timotimo> m: use nqp; nqp::time_n(1234e0)

[17:40] <camelia> rakudo-moar a643b8be1: ( no output )

[17:40] <timotimo> bisect: use nqp; nqp::time_n(1234e0)

[17:40] <bisectable6> timotimo, bisect log: https://gist.github.com/60925d656e5741f757ee2f34b6b7b609

[17:40] <bisectable6> timotimo, (2016-05-12) https://github.com/rakudo/rakudo/commit/33ef5a95459b95bf7256391a053550d4efe221de

[17:40] <bisectable6> timotimo, On both starting points (old=2015.12 new=672fd6e) the exit code is 0 and the output is identical as well

[17:40] <bisectable6> timotimo, Output on both points: «»

[17:46] *** Kaypie is now known as Kaiepi

[18:12] <lizmat> Kaiepi: tried various parallel feed ideas, but none of them beat the simple, single threaded approach, even for very large lists

[18:13] <ugexe> not sure why the size of the list would really matter

[18:14] <lizmat> if you're batching stuff, the size of the batch compared to the size of the list matters

[18:14] <ugexe> oh feed is batching now?

[18:14] <lizmat> well, no

[18:14] <lizmat> but I have some proof of concepts

[18:15] <ugexe> what would be the difference (other than syntax) for ==> vs hyper?

[18:15] <lizmat> https://gist.github.com/lizmat/8652e4a403fffe64e84b392b31cc6ad4

[18:15] <lizmat> the serial approach: https://gist.github.com/lizmat/69faa8cb0f2d4972f17561b21bace743

[18:17] <timotimo> with workloads as small as these, you're paying loads and loads of overhead on inter-process communication

[18:17] <lizmat> *inter-thread

[18:17] <timotimo> yes

[18:17] <lizmat> but yeah

[18:17] <timotimo> sorry

[18:17] <timotimo> remember, when one core wants to access data that another core recently wrote the first core has to flush it out of its cache

[18:17] <lizmat> but even if I artificially increase the load, it doesn't really help

[18:18] <timotimo> so without any batching of the data, you'll be forcing every access to be a full through-to-the-ram read

[18:18] <timotimo> what did you try so far?

[18:18] <lizmat> see above gists

[18:18] <timotimo> also: hm, with lazy oh, sleeping 0.001

[18:18] <timotimo> i don't think that's enough sleep, tbh

[18:19] <lizmat> actually, I changed that to Nil for ^1000... later

[18:19] <lizmat> the sleep isn't actually a load

[18:19] <timotimo> it'll simulate more work per stage, that should help when comparing it with a serial feed implementation

[18:19] <timotimo> in theory it could cut the total sleep amount in half, i.e. serial would take 2s of sleep, parallel 1s of sleep

[18:20] <lizmat> https://gist.github.com/lizmat/787a6ddb31d51cc67d0c00f3403de78c   # fast as you can for non-lazy sources

[18:20] <timotimo> i wonder how fast we get Nil for ^1000 today. perhaps it's blazing fast

[18:20] <ugexe> but is there a type of workload that *would* benefit from shoving data off from one CPU to another?

[18:21] <timotimo> sure

[18:21] <timotimo> imagine doing a simulation on one stage of the feed and a renderer on another

[18:21] <ugexe> so maybe ==> should be serial unless prefixed with hyper or some such as you mentioned

[18:21] <lizmat> the main issue I see, is that the values get consumed as the buffer is being filled

[18:22] <timotimo> i'm not sure i understand what you mean by that

[18:24] <timotimo> you mean how the last stage of the feed has to be "pulled from"?

[18:24] <timotimo> perhaps there's a lot to be gained by also implementing a push-all or so

[18:24] <timotimo> for when the feed gets pushed into something non-lazy

[18:28] <timotimo> you should be able to prototype "as if we had batching" by just having (^100) xx 100 as the input and mapping over the inner values each step of the feed

[18:28] <timotimo> ideally at some point we'd time the individual stages on the first few items that have to go through it and decide whether to spawn extra threads like that

[18:29] <timotimo> ideally spawn an extra thread when a timeout happens, rather than waiting for the first step to be done

[18:29] <timotimo> hold on that's BS, we can't do much with the second stage before the first stage produced the first value

[18:29] <lizmat> yup

[18:30] <lizmat> ok, I now have a serial / parallel for PROCESS-FEED( ^10_000, ( { Nil for ^10000; $_ } xx 10)); of

[18:31] <lizmat> 6 / 1.8 wallclock and 6 / 11.8 CPU

[18:31] <timotimo> what's the 6 for?

[18:31] <lizmat> oops; I meant 6 / 1.8 wallclock and 1.9 / 11.8 CPU

[18:31] <lizmat> argh

[18:31] *** pamplemousse_ joined
[18:31] <timotimo> you meant 1.9 / 1.8 and 6 / 11.8?

[18:31] <lizmat> 6 / 6 wallclock / CPU for serial, 1.9 / 11.8 for parallel

[18:31] *** pamplemousse_ left
[18:32] <timotimo> oh

[18:32] <timotimo> that's a lot faster than i would have expected for parallel

[18:33] <timotimo> oh, you put 10 stages in

[18:33] <timotimo> i thought it was just 2

[18:33] *** pamplemousse_ joined
[18:33] <lizmat> no, 10 stages   :-)

[18:34] *** pamplemousse left
[18:34] *** pamplemousse_ is now known as pamplemousse

[18:35] * lizmat tries another approach

[18:40] <ugexe> my &installed = -> :$curs = $*REPO.repo-chain { $curs.list ==> grep { $_ ~~ CompUnit::Repository::Installable } ==> map { $_ => $_.installed.grep(*.defined).map(*.meta.hash) } ==> hash; }; say installed() # this was what i was benchmarking with years ago

[18:40] <evalable6> ugexe, rakudo-moar 672fd6e2c: OUTPUT: «{/home/bisectable/.perl6 => (), /tmp/whateverable/rakudo-moar/672fd6e2c11aa3e173e7bbe64cd7…»

[18:40] <evalable6> ugexe, Full output: https://gist.github.com/f2b38e5a1309b33e6ec7d1814635e222

[18:41] <AlexDaniel> hah

[19:09] *** SqrtNegInf joined
[19:39] <Geth> ¦ roast: 92eec268bd | (Elizabeth Mattijsen)++ | S29-context/eval.t

[19:39] <Geth> ¦ roast: Must check for CHECK block being run also

[19:39] <Geth> ¦ roast: review: https://github.com/perl6/roast/commit/92eec268bd

[19:56] *** robertle left
[20:05] <timotimo> .tell vrurg passing things it doesn't know about, Configure.pl just stays silent - we had --optimize=0 debug=3 in moarvm's Configure.pl and had a hard time figuring out why breakpoints weren't working/showing up in gdb; anything you can do?

[20:05] <yoleaux> timotimo: I'll pass your message to vrurg.

[20:07] *** Kaiepi left
[20:08] *** Kaiepi joined
[20:09] *** ufobat__ joined
[20:12] *** ufobat_ left
[20:51] *** MasterDuke joined
[20:52] *** MasterDuke left
[20:52] *** MasterDuke joined
[20:53] *** Ven``_ left
[21:04] <lizmat> Kaiepi: still around ?

[21:10] <lizmat> .tell Kaiepi my latest version of the feed processor: https://gist.github.com/lizmat/cecd280112920719f87cb5c9a8fe0ee7

[21:10] <yoleaux> lizmat: I'll pass your message to Kaiepi.

[21:11] <lizmat> .tell Kaiepi I think that combines the best of both worlds, please let me know if you need more info to integrate

[21:11] <yoleaux> lizmat: I'll pass your message to Kaiepi.

[21:16] <Geth> ¦ problem-solving: rba self-assigned perl6-infra: rules and guidelines https://github.com/perl6/problem-solving/issues/28

[21:17] <Geth> ¦ problem-solving: rba assigned to maettu Issue perl6-infra: rules and guidelines https://github.com/perl6/problem-solving/issues/28

[21:17] <Geth> ¦ problem-solving: rba self-assigned perl6-infra: group of services: DNS hosting https://github.com/perl6/problem-solving/issues/29

[21:17] <Geth> ¦ problem-solving: rba assigned to maettu Issue perl6-infra: group of services: DNS hosting https://github.com/perl6/problem-solving/issues/29

[21:18] <lizmat> rba++

[21:18] <Geth> ¦ problem-solving: rba self-assigned perl6-infra: service: Password handling https://github.com/perl6/problem-solving/issues/30

[21:18] <Geth> ¦ problem-solving: rba assigned to maettu Issue perl6-infra: service: Password handling https://github.com/perl6/problem-solving/issues/30

[21:22] * lizmat goes away for some other stuff

[21:55] *** pamplemousse left
[22:08] <Geth> ¦ rakudo/ugexe-patch-1: 630a68858e | (Nick Logan)++ (committed using GitHub Web editor) | appveyor.yml

[22:08] <Geth> ¦ rakudo/ugexe-patch-1: [ignore] appveyor bisect moar aad6fdc

[22:08] <Geth> ¦ rakudo/ugexe-patch-1: review: https://github.com/rakudo/rakudo/commit/630a68858e

[22:09] <Geth> ¦ rakudo: ugexe++ created pull request #2913: [ignore] appveyor bisect moar aad6fdc

[22:09] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/pull/2913

[22:18] <Geth> ¦ rakudo/ugexe-patch-1: d97138459e | (Nick Logan)++ (committed using GitHub Web editor) | appveyor.yml

[22:18] <Geth> ¦ rakudo/ugexe-patch-1: Use an older rakudo

[22:18] <Geth> ¦ rakudo/ugexe-patch-1: review: https://github.com/rakudo/rakudo/commit/d97138459e

[22:24] <Geth> ¦ rakudo/ugexe-patch-1: 93b87b4b09 | (Nick Logan)++ (committed using GitHub Web editor) | appveyor.yml

[22:24] <Geth> ¦ rakudo/ugexe-patch-1: fixup syntax

[22:24] <Geth> ¦ rakudo/ugexe-patch-1: review: https://github.com/rakudo/rakudo/commit/93b87b4b09

[22:42] <Geth> ¦ rakudo/ugexe-patch-1: c3b3d86e15 | (Nick Logan)++ (committed using GitHub Web editor) | appveyor.yml

[22:42] <Geth> ¦ rakudo/ugexe-patch-1: moar 2fe2f58

[22:42] <Geth> ¦ rakudo/ugexe-patch-1: review: https://github.com/rakudo/rakudo/commit/c3b3d86e15

[22:45] <Geth> ¦ rakudo/ugexe-patch-1: 935479414d | (Nick Logan)++ (committed using GitHub Web editor) | appveyor.yml

[22:45] <Geth> ¦ rakudo/ugexe-patch-1: final commit

[22:45] <Geth> ¦ rakudo/ugexe-patch-1: review: https://github.com/rakudo/rakudo/commit/935479414d

[23:04] *** tobs left
[23:11] *** Kaiepi left
[23:12] *** Kaiepi joined
[23:18] *** tobs joined
[23:30] *** ggoebel left
[23:53] *** j3nnn1 left
