[00:05] <japhb> Nah, I really need to *completely* separate download from build.  I'm effectively serializing now, but I think zef runs a download/unpack, assumes it succeeds, and then proceeds with testing, only to have it fail, because there was never a working/complete tarball to unpack.

[00:06] *** reportable6 left
[00:10] *** guifa joined
[00:21] *** jgaz joined
[00:30] <El_Che> crosscompiling moarvm/rakudo ia less that obvious due the non-static nature of the setup?

[00:52] *** morte_ joined
[01:09] *** reportable6 joined
[01:52] *** jgaz left
[02:18] *** morte_ left
[02:28] *** frost joined
[02:37] *** monkey_ left
[03:03] *** guifa left
[03:06] *** morte_ joined
[03:41] *** lockywolf joined
[04:41] *** squashable6 left
[04:41] *** notable6 left
[04:41] *** linkable6 left
[04:41] *** sourceable6 left
[04:41] *** benchable6 left
[04:41] *** quotable6 left
[04:41] *** releasable6 left
[04:41] *** coverable6 left
[04:41] *** shareable6 left
[04:41] *** tellable6 left
[04:41] *** bisectable6 left
[04:41] *** bloatable6 left
[04:41] *** nativecallable6 left
[04:41] *** unicodable6 left
[04:41] *** statisfiable6 left
[04:41] *** committable6 left
[04:41] *** evalable6 left
[04:41] *** reportable6 left
[04:41] *** greppable6 left
[04:41] *** sourceable6 joined
[04:41] *** benchable6 joined
[04:42] *** bloatable6 joined
[04:42] *** quotable6 joined
[04:42] *** evalable6 joined
[04:42] *** reportable6 joined
[04:43] *** releasable6 joined
[04:52] *** morte_ left
[05:41] *** notable6 joined
[05:42] *** committable6 joined
[05:43] *** coverable6 joined
[05:43] *** greppable6 joined
[05:43] *** linkable6 joined
[05:44] *** nativecallable6 joined
[05:44] *** statisfiable6 joined
[05:44] *** tellable6 joined
[05:58] *** mexen joined
[06:08] *** reportable6 left
[06:27] <Woodi> do using classic modules versioning (like in Perl5), without that guix-like hashes mess, would speed things up ?

[07:08] *** linkable6 left
[07:08] *** evalable6 left
[07:09] *** evalable6 joined
[07:10] *** reportable6 joined
[07:24] *** guifa joined
[07:28] *** seednode left
[07:29] *** seednode joined
[07:45] *** guifa left
[08:32] *** Sgeo left
[08:42] *** bisectable6 joined
[08:43] *** unicodable6 joined
[08:43] *** shareable6 joined
[08:45] *** epony left
[08:48] *** epony joined
[09:01] *** jjido joined
[09:10] *** linkable6 joined
[09:44] * lizmat is not sure what Woodi means

[09:46] *** Skarsnik joined
[09:56] *** MoC joined
[10:48] *** jjido left
[11:14] *** sena_kun joined
[11:17] *** jjido joined
[12:07] *** reportable6 left
[12:07] *** reportable6 joined
[12:19] *** jjido left
[12:34] *** jjido joined
[12:41] <ugexe> do you feel hashing is slow? if so, why?

[12:41] *** squashable6 joined
[12:42] <ugexe> computers don't really care if a string is human readable. a computer can look up a seemingly random string as quickly as it can a human readable one, even if its encoded into a file path

[13:25] *** jjido left
[13:40] *** monkey_ joined
[13:55] *** monkey_ left
[14:00] *** monkey_ joined
[14:40] *** guifa joined
[15:02] *** Kaiepi joined
[15:06] *** monkey_ left
[15:13] *** Sgeo joined
[15:20] *** jjido joined
[15:26] *** squashable6 left
[15:44] *** guifa left
[16:09] *** seednode left
[16:10] *** guifa joined
[16:23] *** seednode joined
[16:29] *** squashable6 joined
[16:53] *** euandreh left
[16:57] *** euandreh joined
[17:15] *** lucasb joined
[17:56] *** sena_kun left
[18:07] *** reportable6 left
[18:09] *** reportable6 joined
[18:11] <moon-child> maybe longer pathnames?  But I wouldn't expect that to be a bottleneck anyway

[18:41] *** qorg11 left
[19:08] *** jgaz joined
[19:10] <Woodi> moustly I mean total mess on filesystem. classic way you have source file and compiled, per version, simple. and no need for links or lookups. also I'm asking: do simpler structure could gain something in speed or unmess ?

[19:13] <Woodi> that modern hash repos are implemented via some intermediate and generalized api's ? would be nice to have classic repositories implementation. or maybe it is one ?

[19:15] <ugexe> I have implemented such a repository. if anything its slower

[19:15] <ugexe> https://github.com/ugexe/Perl6-CompUnit--Repository--Lib

[19:18] <lizmat> https://www.reddit.com/r/rakulang/comments/rrcp4c/steal_these_ideas_for_raku_fosdem_talks/

[19:26] *** qorg11 joined
[19:33] *** qorg11 left
[19:33] *** qorg11 joined
[19:33] <Woodi> ugexe: too bad it's slower. still, hours for base distro installation is not good. any idea which part is slow ?

[19:35] *** lucasb left
[19:52] <leont> If it was an IRL conference I'd submit my 'raku syntax I miss in other languages', but doing it online twice feels a bit weird

[20:06] <lizmat> maybe you started missing more?  :-)

[20:21] <qorg11> Is there an emacs completion framework (like company) for raku?

[20:27] <jdv> Woodi: parsing is still painfully slow.  maybe thats most of what youre seeing?

[20:28] <Woodi> ...actually no. if problem is: initial installation of compilers distro *with modules* is slow  then in classic lib/Foo/Bar.pm type of repos module installation is solved during unpacking. no need for parsing, hashing, coping, linking or running anything. just configure repo path. and, for cheating purposes, precompilation is done during first run, if I remember corectly :)  but can be done just after 

[20:28] <Woodi> unpacking...

[20:29] <jdv> by installation do you count running zef?

[20:29] <Woodi> jdv: actually all that *hours* thing can be considered not so slow :)  if raku is ~20x slower then Perl5 then 2 hours is not so bad ;)

[20:29] <MasterDuke> nine has some suggestions about making module installation faster by not duplicating some work

[20:30] <Woodi> jdv: not anymore. just unpack where it need to be

[20:30] <MasterDuke> and fwiw, that hours for installation is/was just on RPIs, not more normal desktop/laptop hardware

[20:30] <jdv> curious.  be interesting what exactly is slow for you.

[20:30] <Woodi> zef/hashes-style repos looks cargo-culted into installing distribution...

[20:31] <Woodi> on my laptop or old desktop installing rakudo-202[01]... was around hour...

[20:32] <jdv> what exactly did that entail?

[20:32] <Woodi> and repositories mechanism is buildin and many types of repos can coexists ?

[20:32] <jdv> i compiled rakudo head on my rpi4 the other day and it was minutes, not hours.

[20:32] <Woodi> with modules ?

[20:32] <jdv> many minutes  ht still:)

[20:33] <jdv> *but

[20:33] <jdv> no

[20:33] <jdv> installing modules, afaik, is dominated by the parse perf issue.

[20:34] <Woodi> parse of sources or jsons ?

[20:34] <jdv> source.  grammaes basically.

[20:35] *** linkable6 left
[20:35] *** evalable6 left
[20:35] <jdv> the thing precomp tries to ameliorate:(

[20:35] <Woodi> zef is like cpanm not installing from tarball...

[20:36] *** linkable6 joined
[20:36] <jdv> it has to comp/precomp to run tests...

[20:36] <Woodi> also other day i found hashes are fast now with new dispatch dispatch :) jnthn++

[20:37] *** evalable6 joined
[20:37] <jdv> in any case its a known pain point.  people are trying.  thanks for playing:)

[20:39] <Woodi> but eg. debian just unpack deb files do not run any tests. installing from release tarball is like deb, imo/ but i just could not fall into sleep but maybe I'm dreaming anyway ?

[20:40] <jdv> raku is like perl where tests are run upon install, at least with cpan, cpanm, zef, etc...

[20:40] <jdv> yes, if the modules were distro pkged youd skip that...

[20:41] <Woodi> do deb contains precompiled modules ? :)

[20:41] <jdv> afaik no so you take inital hit...

[20:42] <MasterDuke> the suse packages might be pre-precompiled. i think nine is involved there and he's talked about it at least

[20:43] <jdv> perf is center stage these days.  it might take a while but its a priority.

[20:46] *** guifa left
[20:48] <MasterDuke> the problem is that the current slowest part, grammars, has the fewest people who understand it well enough to improve it. and it might be the most novel thing about raku. some of the moarvm improvements are "just" implementing a reasonably-well-known theory or algorithm (i.e., there's prior practice to learn from, even though it could very well be

[20:48] <MasterDuke> quite complicated). but raku's grammar has fewer places to steal code from (as far as i'm aware, which is limited), so improving it requires doing more things for the first time

[20:49] <MasterDuke> and most of the original implementors of it aren't currently active for various reasons

[20:50] <jdv> :(

[21:01] *** bdju left
[21:09] *** bdju joined
[21:18] <nine> The openSUSE packages do contain precompiled files. It's really just installing them within seconds and your application will start up immediately

[21:19] <nine> If Debian packages do not contain precomp files, they are kind of only doing half the job and I'd wonder why.

[21:20] <nine> In fact being able to package precompiled files is one of the major goal of the often critiziced (and rarely understood) module management system.

[21:21] <nine> Also I really don't understand why people would waste hours having an underpowered device like a Pi precompile Raku code, when you can have a system doing it that's probably tens of times faster. But then, people seem to prefer making the wildest guesses as to how to improve them to actually understanding the systems they using.

[21:22] <nine> Understanding them would gain you the insight that precomp files are architecture independent and that you can simply copy them from your beefy desktop to your embedded device.

[21:42] *** MoC left
[21:47] *** bdju left
[21:54] *** bdju joined
[21:55] <El_Che> nine: copy hashed directories is something people in the know would do, but it's not something very user friendly

[21:56] <El_Che> ask 100 raku users if they know about it and round 99 wouldn't have a clue

[21:56] <discord-raku-bot> <Skarsnik#7370> then why not have precompile file stored in mlodule management repo

[21:56] <discord-raku-bot> <Skarsnik#7370> ?

[22:26] *** bdju left
[22:33] *** bdju joined
[22:44] <japhb> Skarsnik: Precompiles are based on versions of the compiler and other modules.  A linux distro could do waterfall packaging, so guaranteed versions of all dependencies including the compiler, but zef could not reasonably do this without a storage explosion.  In theory we *could* offer a variant that has precompiles only from a snapshot at the instant of a new compiler release, but ... well, that kinda 

[22:44] <japhb> overlaps with Rakudo Star.

[22:47] <japhb> Woodi: As MasterDuke said, the multiple hours on RPi 4B/4 GB that I quoted was just for my full rebuild with all my favorite modules.  After a couple runs of just MoarVM, NQP, Rakudo, Zef, that base stack of four builds was 35-40 minutes on the RPi.

[22:50] <japhb> nine: My guess would be that precomp files are arch independent in the same way MoarVM is uint agnostic -- was fine in theory, but probably less accurate in real life.  I have my suspicions about whether 64-bit Linux on x64 to 32-bit Rasbian on aarch64 is handled perfectly, though to be honest I've never tested it with my full stack.  (Partially because there's no existing tool to test a full suite of 

[22:51] <japhb> *already installed* modules.)

[23:33] *** evalable6 left
[23:33] *** linkable6 left
[23:33] *** djerius left
[23:40] *** djerius joined
[23:54] *** jjido left
