[00:17] <disbot1> <antononcube> I vaguly remember doing some illustrations abot that event. (I think I posted them here, in this channel.)

[01:11] *** bdju left
[01:17] *** bdju joined
[01:21] *** wayland joined
[01:22] *** wayland76 left
[02:11] *** benchable6 joined
[02:11] *** wayland76 joined
[02:13] *** mc3 joined
[02:13] *** mc3 left
[02:13] *** mc3 joined
[02:14] *** gugod_ joined
[02:17] *** wayland left
[02:17] *** Sgeo left
[02:17] *** benchable6__ left
[02:17] *** mc2 left
[02:17] *** gugod left
[02:17] *** mtj left
[02:35] *** kylese left
[02:35] *** hulk joined
[02:58] *** mtj joined
[03:15] *** hulk left
[03:15] *** kylese joined
[03:42] *** simcop2387 left
[03:54] *** simcop2387 joined
[03:58] *** Aedil left
[04:08] *** Aedil joined
[05:13] *** arkiuat left
[05:25] *** arkiuat joined
[05:57] *** Sgeo joined
[06:29] *** arkiuat left
[06:42] *** arkiuat joined
[06:46] *** arkiuat left
[06:54] *** arkiuat joined
[06:59] *** arkiuat left
[07:24] *** abraxxa-home joined
[07:27] *** arkiuat joined
[07:31] *** arkiuat left
[07:47] *** melezhik joined
[07:54] *** arkiuat joined
[07:59] *** arkiuat left
[08:27] *** arkiuat joined
[08:36] *** arkiuat left
[08:37] *** arkiuat joined
[08:42] *** arkiuat left
[09:09] *** arkiuat joined
[09:14] *** arkiuat left
[09:15] *** oodani left
[09:15] *** oodani joined
[09:24] *** habere-et-disper joined
[09:26] *** Aedil left
[09:44] *** arkiuat joined
[09:48] *** arkiuat left
[09:57] *** melezhik left
[09:58] *** habere-et-disper left
[10:18] *** arkiuat joined
[10:23] *** arkiuat left
[10:25] *** abraxxa-home left
[10:48] *** arkiuat joined
[10:53] *** arkiuat left
[11:00] *** Sgeo left
[11:04] <disbot1> <librasteve> the coffee cup is a very good meme for many things btw - topology, entropy and complexity, robotics - so raku is in good company

[11:05] *** librasteve_ joined
[11:16] <disbot1> <librasteve> SmokeMachine: can you maybe make a blue and yellow variant so that I can use for the weekly header?

[11:17] <disbot1> <librasteve> https://www.etsy.com/uk/market/raku_coffee

[11:18] <disbot1> <librasteve> coffee also features in PL world ... Java(Script), CoffeeScript ;-)

[11:22] *** arkiuat joined
[11:27] *** arkiuat left
[11:32] *** arkiuat joined
[11:36] *** arkiuat left
[11:59] *** arkiuat joined
[12:05] *** arkiuat left
[12:20] *** arkiuat joined
[12:24] *** arkiuat left
[12:39] <tbrowder> thnx all, now i remember the event (at least the report of the event).

[12:45] *** melezhik joined
[12:49] *** arkiuat joined
[12:53] *** arkiuat left
[12:55] *** arkiuat joined
[13:02] *** arkiuat left
[13:05] *** arkiuat joined
[13:06] *** Guest5038 joined
[13:12] *** camelia left
[13:12] *** camelia joined
[13:24] *** arkiuat left
[13:31] *** arkiuat joined
[13:40] *** arkiuat left
[13:42] *** arkiuat joined
[13:49] *** MoC joined
[13:58] *** arkiuat left
[14:06] *** arkiuat joined
[14:15] *** arkiuat left
[14:17] *** arkiuat joined
[14:22] *** arkiuat left
[14:34] *** arkiuat joined
[14:41] *** nahita joined
[14:42] *** arkiuat left
[14:46] <disbot1> <nahita3882> weekly: candidate for Raku tricks: generate N standard Normals and "visualize" their distribution in 2 + 3 lines of pure Raku: https://paste.debian.net/1405350/

[14:46] <notable6> nahita3882, Noted! (weekly)

[14:47] <disbot1> <antononcube> Is "call as method" the proper name for using .& syntax? As in my &f = {$_ + 2}; 4.&f .

[14:47] <disbot1> <antononcube> Is “ampersand call syntax” another correct name, by any chance?

[14:47] <disbot1> <librasteve> Nahita: awesome! thanks...

[14:52] *** nahita left
[14:52] <timo> is the `-3` for the first bin misaligned because of a copy-pasting accident, or is there something not quite right with the code?

[14:55] *** arkiuat joined
[14:55] *** melezhik left
[14:58] <timo> ah, you're putting an array, so you get a space between elements, but not before the first of course, so the first line is a bit too far to the left

[14:59] <timo> @nahita3882 you may want something like `put (-3, *+$bin-width … +3).map({ .fmt: "%4.1f {"-" x +%binned{$_}}" }).join("\n");'` for the final line there

[15:00] <timo> personally, i like `.say for ...` if i want lines from an array or sequence

[15:16] <tbrowder> folks ought to prep your in-work showy stuff for soon-upcoming Raku-Advent article

[15:23] <timo> antononcube, look for "uniform function call syntax" for something that is at least related

[15:24] <disbot1> <librasteve> tbrowder ++

[15:26] <disbot1> <librasteve> @antononcube -- I (also) looked in the docs but nothing seems to be standard ... in the new periodic table, we went with method-like call

[15:37] *** apac left
[16:07] *** Aedil joined
[16:08] <disbot1> <antononcube> Thank you! Searching "call as method" I landed (again) here: https://news.ycombinator.com/item?id=41886647

[16:14] <Voldenet> Is × the same as *?

[16:14] <Voldenet> I just looked at the paste and was wondering what would be the use case of it

[16:15] <Voldenet> even worse, it looks almost exactly like x in my terminal ;\

[16:20] *** Aedil left
[16:40] *** apac joined
[16:45] *** Guest5038 left
[16:45] *** Guest5038 joined
[16:50] *** Aedil joined
[16:51] <disbot1> <librasteve> @antononcube - yeah, since hopefully there will be some take up of the periodic table posters, i would lean to method-like call otherwise we will end up with two options

[16:52] <arkiuat> w

[16:55] <arkiuat> Raku::Elements doesn't seem to single out that usage for naming

[16:56] <arkiuat> it just falls generically under Methodic as one of several different ways of making a Methodic

[16:58] <disbot1> <librasteve> @antononcube - I just reread that HN page ... bit wierd since (i) it was generally quite positive on Raku and (ii) tbh I had forgotten about it, but I think that this is the nudge that set me to start with Air development...

[16:58] *** derpydoo joined
[17:01] <disbot1> <librasteve> m: say (3 × 4)

[17:01] <evalable6> librasteve, rakudo-moar 690b7f07a: OUTPUT: «12␤»

[17:01] <disbot1> <librasteve> m: say (12 ÷ 3)

[17:01] <evalable6> librasteve, rakudo-moar 690b7f07a: OUTPUT: «4␤»

[17:01] <Voldenet> wow ÷ is even more arcane symbol

[17:01] <Voldenet> though it's very legible compared to x

[17:01] <Voldenet> which… looks like x

[17:02] <disbot1> <librasteve> Voldenet: I would say the use case is "do math like a regular human and not like a nerd"

[17:02] <Voldenet> regular humans in europe use dot (e.g. 2 • 3 or 2 · 3)

[17:03] <disbot1> <librasteve> yeah these chars are quite hard to make out at my resolution ... anyway seems like if anyone wanted to build a command line calculator could have keys for these symbols

[17:03] <Voldenet> none of these work in raku though

[17:03] <Voldenet> BUT

[17:04] <Voldenet> in my opinion * and / are perfectly legible and probably better for one line of text

[17:05] <Voldenet> mostly because font creators work hard to make them legible

[17:05] <disbot1> <librasteve> well, yeah and they appear in qwerty keyboard and so became quite popular in computing ;-)

[17:05] <timo> true mathematicians will use the invisible multiplication sign unicode character

[17:05] <disbot1> <librasteve> huuh?

[17:06] <timo> u: U+2062

[17:06] <unicodable6> timo, U+2062 INVISIBLE TIMES [Cf] (control character)

[17:06] *** apac left
[17:06] <timo> m: say "5 \u2062 9 == 45"

[17:06] <camelia> rakudo-moar 690b7f07a: OUTPUT: «===SORRY!=== Error while compiling <tmp>␤Unrecognized backslash sequence: '\u'␤at <tmp>:1␤------> say "5 \<HERE>u2062 9 == 45"␤    expecting any of:␤        argument list␤        double quotes␤        term␤»

[17:06] <timo> m: say "5 \x2062 9 == 45"

[17:06] <camelia> rakudo-moar 690b7f07a: OUTPUT: «5 ⁢ 9 == 45␤»

[17:06] <timo> beautiful, isn't it?

[17:06] <Voldenet> amazing

[17:07] <timo> unicode never ceases to amaze

[17:09] <disbot1> <librasteve> m: multi infix:<\x2062>($a, $b) { $a * $b }; say 6 \x2062 7;

[17:09] <evalable6> librasteve, rakudo-moar 690b7f07a: OUTPUT: «42␤»

[17:10] <timo> now that's just silly :D :D :D

[17:10] <disbot1> <librasteve> falls off chair

[17:11] <timo> m: multi infix:<<\x2062>>($a, $b) { $a * $b }; say 6  9

[17:11] <camelia> rakudo-moar 690b7f07a: OUTPUT: «===SORRY!=== Error while compiling <tmp>␤Two terms in a row␤at <tmp>:1␤------> ix:<<\x2062>>($a, $b) { $a * $b }; say 6<HERE>  9␤    expecting any of:␤        infix␤        infix stopper␤        postfix␤        statement end␤        …»

[17:12] <timo> m: multi infix:<<\x2062>>($a, $b) { $a * $b }; use MONKEY; say EVAL "5 \x2062 9"

[17:12] <camelia> rakudo-moar 690b7f07a: OUTPUT: «45␤»

[17:13] <librasteve_> m: multi infix:<\<\x2062\>>($a, $b) { $a * $b }; say 5 \x2062 9

[17:13] <camelia> rakudo-moar 690b7f07a: OUTPUT: «===SORRY!=== Error while compiling <tmp>␤Confused␤at <tmp>:1␤------> :<\<\x2062\>>($a, $b) { $a * $b }; say 5<HERE> \x2062 9␤    expecting any of:␤        infix␤        infix stopper␤        postfix␤        statement end␤        stat…»

[17:13] <librasteve_> oh

[17:15] <Voldenet> though I really love characters I can simply type instead of copying from google

[17:15] <timo> if you use < rather than << i think it will not interpret the backslash sequence

[17:15] <Voldenet> well nowadays you can simply ask llm `type seahorse emoji` and it'll give you the proper sequence ;)

[17:16] <disbot1> <librasteve> got it ... so the only problem with our code is that it is easier to type 6 * 7 than 6 \x2062 7 ... surely a Slang beckons?

[17:17] <arkiuat> I wonder if klibertp ever figured out the compile-time type-checking capabilities

[17:18] <timo> who's that?

[17:18] <timo> oh from that old hackernews thread?

[17:18] *** abraxxa-home joined
[17:21] <disbot1> <librasteve> arkuiat: I get that compile time type checking is a neat technology ... and for a systems language (Rust being the archetype) this is important to save every cycle & byte going ... but I'm not really convinced that computationally that is really a good ROI for an expedience language such as Raku... most CPUs spend most of their time IO bound and in some cases (array bound check) you are stuck with runtime checks anyway

[17:22] <Voldenet> hmm, it really depends on whether it's possible at some point to pre-compile the code

[17:22] <Voldenet> if it is, then even expensive type checking makes total sense

[17:22] <disbot1> <librasteve> I understand (?) that one of the goals of RakuAST is to provide greater semantic introspection for the MOAR jit so hopefully that will help us to optimise the cr*p out of all the standard runtime type checks anyway

[17:24] <Voldenet> detailed compile time checking actually allows you to optimize the code before it's being executed

[17:25] <Voldenet> for example you can skip type checking or inline without ever running the code, in some cases you can even deduce the result before running the code

[17:25] <timo> we do have a lot of things that make compile-time analysis hairy

[17:26] <timo> method calls on our objects are completely unconstrained for example

[17:26] *** Guest5038 left
[17:26] <timo> even when we have a type on a variable that points at one class, subclasses and the same class but with mixins are also allowed

[17:27] <timo> languages like C++ have strict rules for how a derived class may overload a virtual method

[17:27] <timo> for us, a derived class or a mixin can have a completely different signature, including return type annotation

[17:27] <timo> and then there's the possibility of calling .wrap on the code object

[17:27] <disbot1> <librasteve> please forgive me if I sound like I know what I am talking about ;-) ... but I get the feeling that Raku syntax was not defined with this in mind

[17:28] <timo> i think it's less about the syntax and more about the semantics

[17:28] <timo> we have things like traits we can attach to a wide variety of things

[17:28] <disbot1> <librasteve> well -yes

[17:29] <timo> so we're not necessarily held back by the lack of a syntactic hook to place some kind of restriction on that the user wishes to establish

[17:30] <arkiuat> sure, but it's not as if Raku can't do any compile-time type checking at all, which is what it sounded like klibertp was thinking

[17:30] <timo> what we can have is custom metaclasses that enforce certain restrictions on methods that a class of that metaclass can have, and then a slang could hook into the compiler at the right spot and do its type checking work only on types of that metaclass

[17:31] <timo> an example of custom metaclasses is "monitor" from OO::Monitors, which i assume a couple of you have seen

[17:39] <disbot1> <librasteve> I was thinking that formal techniques (such as Hindley–Milner) are very interdependent with the language design (and for me its nicer to have a type system I can employ "on demand" rather than spend my coding brainpower on serving a too-strict model) ... I see that using meta inspection and attaching optimisers at various points is more the Raku way - thanks for explaining!

[17:54] <timo> it's mostly an opinion of mine, take it with a grain of salt :)

[17:58] *** derpydoo left
[18:01] *** apac joined
[18:17] *** Sgeo joined
[18:25] *** apac left
[18:26] <Voldenet> I'd lean towards the HM type system as well

[18:26] <Voldenet> to me types and constraints are optimization hints

[18:26] <Voldenet> not some validation steps

[18:28] <Voldenet> but it doesn't directly oppose the attachable metaclasses, more like specifies what's it for

[18:30] <Voldenet> for example, a optimized class (which is a subclass of the original class) doesn't even have to follow the same rules, its storage slots can be defined in `name -> index` hash attached to the type and then the whole type can be just n*8 bytes

[18:30] <Voldenet> and of course, all the private methods can be optimized to simply access that index without even reading the storage slots hashmap

[18:31] <Voldenet> deoptimization pretty much means using the class in the context that requires reshaping it

[18:31] <Voldenet> like mixins

[18:32] <timo> P6opaque already uses slots and cached lookups

[18:33] <Voldenet> yes, I was setting up the stage for the thing that might be even more scary

[18:33] <Voldenet> optimized class may not even have to contain the type pointer itself

[18:33] <Voldenet> but only contain array with its field values (or pointers to)

[18:34] <Voldenet> so in case `my X $x = X.new(); $x.a = 5; say $x` it could be even able to use the stack directly and not allocate anything

[18:34] <timo> that's what moar's PEA + scalar replacement do

[18:34] <timo> it's kinda limited at the moment, though

[18:36] <Voldenet> in the best world that'd be "the default mode" of operation, with all methods having `:(X $x)` in its signature being also able to use stack-based call convention as well

[18:37] <Voldenet> though I doubt it's feasible, I've never seen any language fully doing this kind of optimization on reference types

[18:37] <timo> well, inlining can get us at least part of the way

[18:37] <timo> though i'm not sure i fully follow your thinking

[18:38] <Voldenet> basically `class X { has Int $.a; }` could live fully on a stack and passing it to another sub/method would only change values in the stack

[18:39] <Voldenet> very similar thing done by C#'s stackalloc

[18:39] <Voldenet> imagine how fast would iterators or rangers be if they were never allocated

[18:39] <Voldenet> ranges*

[18:39] <timo> right, that's what PEA and scalar replacement try to do

[18:40] <timo> Partial Escape Analysis meaning that we try to do scalar replacement on things even when we can't prove they never escape. we just allocate it when the escape happens so if it doesn't end up happening we don't allocate

[18:42] <Voldenet> but it'd possible to also not allocate even when things escape the context as long as the calling context preparse space for it

[18:42] <timo> but we can only do that on stuff that's completely inside of one frame that we're speshing

[18:43] <Voldenet> so if parent frame says "I'm expecting Optimized X, here's the pointer", the escaped value can be simply accepted to that stack-based pointer

[18:44] <Voldenet> that would theoretically let everything live on the 100kb stack ;)

[18:44] <timo> that kind of amounts to inlining ...

[18:44] <Voldenet> not pure inlining though, it's only return type hint

[18:45] <timo> the amount of cooperation between the caller and the callee i mean

[18:46] <Voldenet> but then only the signature for the callee is altered

[18:46] <Voldenet> additional pointer argument is introduced, that requires no cooperation

[18:47] <Voldenet> other than pointer being of required type

[18:49] <Voldenet> I guess that the biggest "cooperation" part would be defining the optimized structure for the whole returned structure and making sure it isn't something else

[18:50] <timo> could pass all the scalar-replaced slots as rw arguments

[18:51] <timo> but doesn't that allocate LexicalRef objects ...

[18:51] <timo> er, LocalRef really

[18:53] <timo> it'd be very interesting to handle when the callee does have to allocate the object after all. i guess the normal deopt might be able to handle at least some of that situation

[18:55] <Voldenet> I think the toughest part would be probably figuring out when to bail - I'm guessing that passing `is rw` on stack would need some sort of counter during optimization

[18:56] <Voldenet> or maybe size-based estimator if it was to support variable length nested structures

[18:58] <Voldenet> e.g. `class Y { has Int $.n; }; class X { has Y @.y; }`

[18:59] <timo> well, Array has a lot more in it than just the slots

[18:59] <timo> m: .name.say for Array.^attributes

[18:59] <camelia> rakudo-moar 690b7f07a: OUTPUT: «$!descriptor␤$!reified␤$!todo␤»

[19:02] <Voldenet> partially: OptimizedX would have OptimizedArrayOfY that would only contain data

[19:02] <Voldenet> and count, of course

[19:03] <Voldenet> and using Y in different context could force the allocation

[19:03] <Voldenet> erm, OptimizedArrayOfY

[19:03] <timo> that's a whole lot of stuff all in all

[19:04] <Voldenet> Yeah, I was just painting a very ideal and pretty picture :)

[19:04] <Voldenet> in practice, how would array know how much elements on a stack can it hold, for example

[19:05] <Voldenet> in aforementioned C# `stackallow int[9000]` simply throws StackOverflowException and that's that

[19:06] <Voldenet> though the basis for it would be shape-based allocation metadata that would be wrapper for data of known type

[19:07] <Voldenet> and optimized versions would be defined only for very specific use cases

[19:09] <timo> we do have shaped native arrays

[19:09] <Voldenet> well yes, CArray exists

[19:09] <timo> that's not really what i mean

[19:09] <timo> m: my int @foo[90]; say @foo.WHAT

[19:09] <camelia> rakudo-moar 690b7f07a: OUTPUT: «(array[int])␤»

[19:11] <Voldenet> Ah, right, and in that case it has fixed length

[19:12] <timo> indeed

[19:12] <timo> and can't have a reifier

[19:12] <timo> or todo

[19:14] <Voldenet> so it'd only need additional elements count, and the max size would be defined by that native array's length

[19:14] <Voldenet> in which case it'd have to somehow deoptimize the storage for the array and potentially all the things in the stack

[19:15] <disbot1> <librasteve> in that example, what prevents me writing eg my $hack = @foo[92] ? (just curious onlooker)

[19:15] <timo> m: my int @foo[90]; say @foo[92];

[19:15] <camelia> rakudo-moar 690b7f07a: OUTPUT: «Index 92 for dimension 1 out of range (must be 0..89)␤  in block <unit> at <tmp> line 1␤␤»

[19:16] <Voldenet> the contract for usage of optimized array

[19:16] <disbot1> <librasteve> yeah - but that's runtime error ... oh so the access is not a pure pointer

[19:17] <Voldenet> Yes, but before accessing it, runtime could quietly deoptimize everything first

[19:17] <Voldenet> e.g. allocate every single object on a heap needed, with pointers etc.

[19:17] <disbot1> <librasteve> ie the code that runs on Postional AT-KEY checks the length somewhere (not actually in the storage)

[19:18] <disbot1> <librasteve> i thought that declared shape was immutable ...?

[19:18] <timo> i was wondering if the shape was actually on the type as a parameter, but it looks like it's on the instance and only the number of dimensions the shape has is part of the type

[19:19] <Voldenet> Right, so the runnig code would need the current count, allocated count and pointer for data (pointing on stack by default)

[19:19] <timo> shaped arrays are always fully allocated

[19:20] <Voldenet> but they could get stack-optimized (similar to the classes) for cases with not many small elements

[19:21] <disbot1> <librasteve> tx

[19:21] <timo> fwiw, moarvm doesn't use the C stack, so even allocating a 1000 or 10000 element array "stored on the stack" will not run into "traditional" stack size limits

[19:22] <Voldenet> yes, but having large stacks would ruin the cpu caches

[19:23] <timo> we still use the C stack inside of moarvm for all the C code, of course

[19:24] <timo> but in moarvm the depth of the stack is unrelated to the depth of the raku-level call stack

[19:24] <timo> and it tends to always come back to just roughly 4 stack frames deep

[19:25] <Voldenet> as a matter of fact, data doesn't even have to use the same stack

[19:25] <timo> you're aluding to having a stack for just return addresses?

[19:26] <Voldenet> for the whole "data" portion of the code

[19:26] <timo> what's the "data portion"?

[19:27] <Voldenet> variables and arguments, this prevents mixing return addresses with actual values

[19:28] <Voldenet> but I am not really confident in this being a good idea

[19:29] <timo> moar's help-allocated stack frames kind of store the return address, or rather the pointer to the caller frame and the return address inside its bytecode or the index of the jit label, in a different kind of slot than all the register and lexical values that make up the stack frame

[19:32] <Voldenet> Ah, so the risk of VLA introducing bugs in return addresses is low

[19:32] <timo> they are still nearby though

[19:32] <timo> not a completely different memory area

[19:34] *** stanrifkin joined
[19:36] <Voldenet> of course the most sane approach would be not allowing VLAs into optimized structures at all

[19:36] <SmokeMachine> librasteve_: I tried, but I’m not sure it went well… :( https://usercontent.irccloud-cdn.com/file/98dDRHT7/1762716964.JPG

[19:38] <timo> in any case, all the accesses to registers that a frame of moar bytecode could do are verified ahead of time by the bytecode validator. a bug can still cause access outside of the array of register values though

[19:42] <Voldenet> thing similar to `class VLA-of-T-of_2 { has int $.elems; has T $.item1; has T $.item2; }` could work as well, but it feels like it wouldn't be as optimizable

[19:43] <Voldenet> because it'd need AT-KEY that would point at the right item

[19:46] <Voldenet> and it'd require defining the in-memory storage for cached lookups, then dispatching right lookup etc.

[19:48] <disbot1> <antononcube> I think name of operator ==> was changed from "forward feed" to "right feed" -- is that a recent change?

[19:50] <disbot1> <antononcube> Hmm... the documentation calls it just "feed" : https://docs.raku.org/language/operators#infix_==%3E

[20:02] <Voldenet> there's leftward feed and feed

[20:06] <disbot1> <antononcube> Ok. And "forward feed" and "rightward feed" are synonyms of "feed" or not?

[20:16] <Voldenet> rightward would make sense because of symmetry, I remember forward being used somewhere too

[20:17] <Voldenet> as ==>

[20:39] *** apac joined
[21:03] *** Aedil left
[21:05] *** justache is now known as justache_

[21:05] *** justache_ is now known as justache

[21:07] *** apac left
[21:11] <disbot1> <librasteve> weekly: https://usercontent.irccloud-cdn.com/file/98dDRHT7/1762716964.JPG

[21:11] <notable6> librasteve, Noted! (weekly)

[21:11] <disbot1> <librasteve> SmokeMachone

[21:11] <disbot1> <librasteve> ... looks good to me - many thanks!

[21:23] *** wayland joined
[21:23] *** wayland76 left
[21:32] *** MoC left
[21:43] *** apac joined
[21:45] *** abraxxa-home left
[22:05] *** wayland left
[22:56] *** stanrifkin left
