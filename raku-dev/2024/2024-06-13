[06:29] *** finanalyst joined
[07:46] *** finanalyst left
[08:32] *** finanalyst joined
[08:53] *** sena_kun joined
[09:15] <Geth> ¦ Lingua-Number/main: e356b64237 | (Elizabeth Mattijsen)++ | 14 files

[09:15] <Geth> ¦ Lingua-Number/main: Prepare for release in zef ecosystem using mi6

[09:15] <Geth> ¦ Lingua-Number/main: 

[09:15] <Geth> ¦ Lingua-Number/main: Alas, the original tests are failing, so it's **not** ready yet

[09:15] <Geth> ¦ Lingua-Number/main: to be actually released

[09:15] <Geth> ¦ Lingua-Number/main: review: https://github.com/raku-community-modules/Lingua-Number/commit/e356b64237

[09:24] <Geth> ¦ Lingua-Number/main: f578aec4ec | (Elizabeth Mattijsen)++ | .travis.yml

[09:24] <Geth> ¦ Lingua-Number/main: Not doing Travis anymore

[09:24] <Geth> ¦ Lingua-Number/main: review: https://github.com/raku-community-modules/Lingua-Number/commit/f578aec4ec

[10:32] <lizmat> These timings feel counter-intuitive:

[10:32] <lizmat> m: sub a(str $a) { $a ~ $a }; a("foo") for ^10000000; say now - ENTER now

[10:32] <camelia> rakudo-moar 8518cc49f: OUTPUT: «0.775085136␤»

[10:32] <lizmat> m: my constant &a = -> str $a { $a ~ $a }; a("foo") for ^10000000; say now - ENTER now

[10:32] <camelia> rakudo-moar 8518cc49f: OUTPUT: «2.8015152␤»

[10:32] <lizmat> almost 4x as slow?

[10:33] <lizmat> slightly better performant:

[10:33] <lizmat> m: my constant &a = { $_ ~ $_ }; a("foo") for ^10000000; say now - ENTER now

[10:33] <camelia> rakudo-moar 8518cc49f: OUTPUT: «2.302535727␤»

[10:34] <lizmat> but still...  ?

[10:34] <lizmat> I wonder whether that's a dispatch deficiency

[10:36] <lizmat> also remarkable:

[10:36] <lizmat> m: my constant &a = { .lc }; a("foo") for ^10000000; say now - ENTER now

[10:36] <camelia> rakudo-moar 8518cc49f: OUTPUT: «0.56984057␤»

[10:37] <lizmat> m: my constant &a = -> $_ { .lc }; a("foo") for ^10000000; say now - ENTER now

[10:37] <camelia> rakudo-moar 8518cc49f: OUTPUT: «0.695784301␤»

[10:37] <lizmat> m: my constant &a = *.lc ; a("foo") for ^10000000; say now - ENTER now

[10:37] <camelia> rakudo-moar 8518cc49f: OUTPUT: «0.577406613␤»

[11:06] <lizmat> another weirdo:

[11:06] <lizmat> m: my str $a = "a"; my &b = * ~ $a; say b "b"

[11:06] <camelia> rakudo-moar 8518cc49f: OUTPUT: «ba␤»

[11:06] <lizmat> m: my str $a = "a"; my constant &b = * ~ $a; say b "b"

[11:06] <camelia> rakudo-moar 8518cc49f: OUTPUT: «Lexical with name '$a' has wrong type. real type 8 wanted type 7␤  in block <unit> at <tmp> line 1␤␤»

[11:09] <nine> lizmat: look at the generated QAST

[11:10] <nine> Pointy block lookups up $_ in outer lex. I bet that's what makes it slow

[11:15] <finanalyst> lizmat: sorry to distract you. I sent an email with a glitch. No problem if you dont want to be distracted

[11:17] <lizmat> nine: but if $_ is in the sig, why would it need to lookup in the outer lex?

[11:17] <lizmat> finanalyst: looking  :-)

[11:20] <ab5tract> m: Q| my str $a = "a"; my &b = * ~ $a; say b "b"|.AST.EVAL

[11:20] <camelia> rakudo-moar 8518cc49f: OUTPUT: «ba␤»

[11:20] <ab5tract> Ooof

[11:21] <lizmat> m: Q| my str $a = "a"; my constant &b = * ~ $a; say b "b"|.AST.EVAL

[11:21] <camelia> rakudo-moar 8518cc49f: OUTPUT: «===SORRY!===␤Unknown compilation input 'qast'␤»

[11:22] <ab5tract> lizmat: did you already file a bug report for that one? Because that needs to be dug into for sure

[11:22] <lizmat> ab5tract: don't bother this until nine has merged the BEGIN work branch

[11:22] <ab5tract> Ok :)

[11:22] <lizmat> ab5tract: no, didn't do any issues yet

[11:24] <Geth> ¦ rakudo/main: 46511d59cb | (Elizabeth Mattijsen)++ | src/core.c/RakuAST/LegacyPodify.rakumod

[11:24] <Geth> ¦ rakudo/main: RakuAST: fix podifying issue spotted by finanalyst++

[11:24] <Geth> ¦ rakudo/main: review: https://github.com/rakudo/rakudo/commit/46511d59cb

[11:24] <ab5tract> m: my constant &a =  { .lc }; a("foo") for ^10000000; say now - ENTER now

[11:24] <camelia> rakudo-moar 8518cc49f: OUTPUT: «0.588587184␤»

[11:24] <finanalyst> Thank you

[11:25] <lizmat> finanalyst: you're welcome: if all bugs where these little ones  :-)

[11:26] <nine> lizmat: which branch?

[11:27] <lizmat> the branch jnthn started and you worked on since ?

[11:28] <lizmat> the one that started with 0 tests passing and now something like 7 files still failing ?

[11:32] <nine> ah, yeah

[11:49] <Geth> ¦ rakudo/lizmat-Block.WhateverCode: 7b89fb2153 | (Elizabeth Mattijsen)++ | src/core.c/Block.rakumod

[11:49] <Geth> ¦ rakudo/lizmat-Block.WhateverCode: Introduce a Block.WhateverCode coercer

[11:49] <Geth> ¦ rakudo/lizmat-Block.WhateverCode: 

[11:49] <Geth> ¦ rakudo/lizmat-Block.WhateverCode: This is really just a quick implementation of an idea wrt performance.

[11:49] <Geth> ¦ rakudo/lizmat-Block.WhateverCode: Since WhateverCodes cannot have phasers, they can be treated differently

[11:49] <Geth> ¦ rakudo/lizmat-Block.WhateverCode: in .map / for loops taking a simpler path.  However, from the grammar

[11:49] <Geth> ¦ rakudo/lizmat-Block.WhateverCode: it is impossible to create slightly more complex WhateverCodes, even

[11:49] <Geth> ¦ rakudo/lizmat-Block.WhateverCode: though they are actually quite simple, e.g.: { $_ ~ $_ } .

[11:49] <Geth> ¦ rakudo/lizmat-Block.WhateverCode: review: https://github.com/rakudo/rakudo/commit/7b89fb2153

[11:49] <Geth> ¦ rakudo: lizmat++ created pull request #5596: Introduce a Block.WhateverCode coercer

[11:49] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/pull/5596

[14:14] <ab5tract> Do you reckon that RakuAST will allow us to easily bypass laziness in the case of .IO.lines.elems?

[14:14] <ab5tract> And - importantly - if so, how?

[14:16] <ab5tract> Asking because right now it reportedly segfaults or otherwise dies at 4 million lines or fewer

[15:14] *** kjp left
[15:35] *** nine left
[15:36] *** nine joined
[15:37] *** kjp joined
[16:19] <lizmat> ab5tract: I don't see how we could produce .elems without reading the whole file?

[16:20] <ab5tract> But presumably the lazy version of reading the whole file is much slower than the eager one?

[16:20] <ab5tract> Either way, we can’t actually do the thing at the moment

[16:22] <lizmat> .IO.slurp.linnes.elems tends to be a little bit faster, if the file is not like humongous

[16:24] <ab5tract> But what about when the file is humongous? Why are we unable to do the same thing that q:x( wc -l ) can easily accomplish?

[16:28] <ab5tract> My impression was that it was the overhead of lazy evaluation. Would be happy to learn I’m wrong and now how to proceed in addressing it

[16:28] <lizmat> NFG

[16:29] <ab5tract> So we are doomed to be incapable?

[16:29] *** sena_kun left
[16:30] <lizmat> to mimic wc -l, we could use .read().indices("\n".ord) ?

[16:30] <lizmat> thus bypassing NFG ?

[16:33] <ab5tract> Excellent! So that circles back to my original question: is taking that approach potentially unlocked by RakuAST?

[16:34] <ab5tract> I guess I’m asking: what does a RakuAST-based optimizer look like?

[16:34] <lizmat> that's a good question   I'm not sure yet

[16:35] <lizmat> it all depends on how much we want to keep of the current status optimize stage

[16:41] <lizmat> some timings on a 810 MB text file:

[16:41] <lizmat> say "sixteenth.txt".IO.slurp.lines.elems    # 17.7 seconds

[16:42] <lizmat> say "sixteenth.txt".IO.lines.elems  # 38.65 seconds

[16:43] <lizmat> wc -l sixteenth.txt   # 0.86 seconds

[16:43] <lizmat> and apparently we don't have an .indices on Buf  :-(

[16:55] <ab5tract> Even if the optimizer did something outrageous and use Q:x to call wc, it would be a massive win…

[16:58] <ab5tract> nine: do you have any envisionings re: what a RakuAST-based optimizer would look like, or when it would be appropriate to break ground on one?

[17:36] <lizmat> except that wc is not a thing on Windows ?

[17:49] <ab5tract> then presumably we would fallback or use an alternative…

[17:51] <ab5tract> Shelling out to wc is an outrageous approach anyway, but presumably feasible for a RakuAST based optimizer

[17:57] <lizmat> indeed

[18:01] <nine> Laziness is a feature, not a bug. That's even more true for things like .IO.lines.elems. You absolutely don't want to read the whole file into memory first, then construct an array with a string for each line just to count the array's elements. wc doesn't do that either.

[18:02] <nine> Even if all of that were not the case, the static optimizer couldn't do anything about this, unless it could prove that the object you call .IO.lines.elems on is just a string or at least a type with an IO method of which we know that it will return an IO::Path from the setting.

[18:05] <nine> Actually the problem seems to be that we are not lazy enough

[18:12] <ab5tract> I’m not talking about doing the wrong-headed thing. I’m asking whether we can ever unlock doing the right-headed thing

[18:13] <nine> Just make GetLineFast a PredictiveIterator and give it a count-only method

[18:14] <lizmat> :-)

[18:14] <nine> Or have Seq.elems *not* cache the sequence

[18:14] <lizmat> yeah, I tried that once...

[18:14] <nine> That seems weird anyway. A Seq is supposed to be read only once

[18:15] <lizmat> well, the amount of code that breaks is impressive if you do that  :-)

[18:16] <nine> The amount of code that *is* broken

[18:17] <lizmat> the problem is really that a lot of code expects core methods (that return a Seq) to cache stuff

[18:17] <lizmat> also Bool

[18:18] <lizmat> unless the iterator is a PredictiveIterator, calling .Bool on a Seq will turn on caching

[18:18] <lizmat> if $seq { say "start"; .say for $seq }

[18:28] <nine> That just looks like a broken pattern 

[18:29] <lizmat> if foo -> $seq { .say for $seq }

[18:30] <lizmat> fwiw, I *think* we could actually handle the Bool case better: by replacing the iterator in a Seq by a wrapper iterator that would first produce the first value, and then replace itself by the original iterator on subsequent fetches

[18:38] <nine> Well for .Bool Seq would only have to cache the very first value. But I really don't see the point of .elems caching. If you call .elems on a Seq it's pretty clear that it must be consumed.

[18:39] <lizmat> to us it is, to many Rakoon it isn't  :-(

[18:40] <nine> Then that's just one of the things they have to learn. I am not aware of any other languages where iterators try to cater to people who don't understand what an iterator is. You learn the concept once and then you can reap the benefits.

[18:41] <ab5tract> Weren’t iterators introduced years after Seq?

[18:53] *** sena_kun joined
[18:53] <lizmat> here's the roast fallout of making Seq.elems *not* cache

[18:53] <lizmat> https://gist.github.com/lizmat/8f89f076f567cecd2637601b66ea7be6

[18:53] <lizmat> and that's just roast

[18:53] <lizmat> pretty sure the ecosystem fallout would be much bigger

[19:06] <ugexe> would it be possible to know when e.g. ecosystem code is used in a way to suggest it needs the sequence to be cached and to throw a warning?

[19:06] <ugexe> in other words: is it possible for rakudo to tell me if i'm doing this in any of my code?

[19:13] <lizmat> in RakuAST we might be able to

[19:36] <[Tux]> Rakudo v2024.05-27-g46511d59c (v6.d) on MoarVM 2024.05-5-gf48abb710

[19:36] <[Tux]> csv-test-xs-20      0.142 -  0.142

[19:36] <[Tux]> csv-ip5xs           0.270 -  0.271

[19:36] <[Tux]> test-t --race       0.273 -  0.277

[19:36] <[Tux]> test-t              0.425 -  0.433

[19:36] <[Tux]> csv-ip5xs-20        1.134 -  1.208

[19:36] <[Tux]> test-t-20 --race    1.234 -  1.249

[19:36] <[Tux]> csv-parser          1.555 -  1.639

[19:36] <[Tux]> test                1.950 -  1.958

[19:36] <[Tux]> test-t-20           5.091 -  5.214

[19:36] <[Tux]> https://tux.nl/Talks/CSV6/speed4-20.html / https://tux.nl/Talks/CSV6/speed4.html https://tux.nl/Talks/CSV6/speed.log

[19:41] *** sena_kun left
[19:45] <ab5tract> If caching a sequence is so wrong, why was it implemented in the first place?

[19:46] <lizmat> the answer is the PositionalBindFailover role

[19:46] <lizmat> to make $seq[42] work

[19:46] <lizmat> afk&

[19:50] <nine> Well if you're missing a .cache we already tell you. After all it's missing when you actually do try to read the Seq again. The error contains "(you might solve this by adding .cache on usages of the $kind_name, or by assigning the $kind_name into an array)"

[20:02] <ugexe> if that was catching the aforementioned uses then it wouldnt break the roast or ecosystem

[20:03] <ugexe> because they would have already been giving that error

[21:01] *** lizmat left
[21:01] *** lizmat joined
[22:14] *** vrurg_ left
[22:17] *** vrurg joined
[22:59] *** finanalyst left
