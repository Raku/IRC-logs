[03:18] <vrurg> lizmat: Thanks for your question about ollama API. That's how I found out about it and got it attached to VScode. And it even manages to somehow help with Raku code!

[07:42] *** sena_kun joined
[09:01] <lizmat> nice!

[10:00] <ab5tract> vrurg: cool!

[10:43] <ab5tract> I was planning to install it but wasn’t sure if it would be useful

[11:19] <lizmat> you need quite a bit of RAM I understand

[11:52] <lizmat> notable6: weekly

[11:52] <notable6> lizmat, 2 notes: 2024-01-18T11:12:18Z <lizmat>: https://github.com/Raku/Raku-Steering-Council/blob/main/announcements/20240117.md  ;  2024-01-23T20:26:50Z <lucs>: https://www.hillelwayne.com/post/randomness/

[11:52] <lizmat> notable6: weekly reset

[11:52] <notable6> lizmat, Moved existing notes to “weekly_2024-01-29T11:52:46Z”

[12:21] *** epony left
[12:24] *** epony joined
[12:27] <lizmat> and yet another Rakudo Weekly News hits the Net: https://rakudoweekly.blog/2024/01/29/2024-05-brain-nrg/

[14:05] <vrurg> lizmat: They say that memory requirements depend on the model used. With 128G I don't feel this pressure, but the bigger the model the slower it is. And this is somewhat a problem for when used with IDE.

[14:06] <lizmat> 128G  wow  :-)

[14:08] <vrurg> Aha. My work was paying for it, so M2 Ultra too. :) Nice toy.

[14:09] <lizmat> MBP?

[14:12] <lizmat> ah, no Mac Pro I assume ?

[14:12] <vrurg> A compromise option: Studio.

[14:13] <vrurg> BTW, MBP went through direct M1 -> M3 transition with no M2 version, I think.

[14:14] <lizmat> yeah, looks like

[15:27] *** epony left
[15:29] *** epony joined
[20:46] *** epony left
[21:53] *** finanalyst joined
[23:02] *** sena_kun left
[23:40] *** epony joined
[23:54] *** finanalyst left
