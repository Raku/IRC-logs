[00:52] <timo> JIT isn't supported on riscv64-linux-thread-multi yet.

[00:52] <timo> sadface

[05:20] <ab5tract> Is it supported now on aarch64?

[05:42] *** sena_kun joined
[06:07] <ab5tract> MasterDuke: thank you for remind me about pmurias++ truffle work. It seems to have gotten quite a ways before he stopped

[06:07] <tellable6> ab5tract, I'll pass your message to MasterDuke

[06:08] <ab5tract> *reminding

[08:51] *** sena_kun left
[10:10] <Geth> ¦ rakudo/main: 38fa6c4821 | (Elizabeth Mattijsen)++ | 4 files

[10:10] <Geth> ¦ rakudo/main: RakuAST: fix various deparsing and highlighting issues

[10:10] <Geth> ¦ rakudo/main: 

[10:10] <Geth> ¦ rakudo/main: This was mostly about making the use of whitespace more consistent,

[10:10] <Geth> ¦ rakudo/main: and more esthetically pleasing.

[10:10] <Geth> ¦ rakudo/main: 

[10:10] <Geth> ¦ rakudo/main: So:

[10:10] <Geth> ¦ rakudo/main:     =begin pod

[10:10] <Geth> ¦ rakudo/main: <…commit message has 12 more lines…>

[10:10] <Geth> ¦ rakudo/main: review: https://github.com/rakudo/rakudo/commit/38fa6c4821

[10:42] *** El_Che joined
[12:21] <[Coke]> ARGH. I didn't run it in tmux this time, because when it failed before, it took out the tmux session anyway. Come back to laptop this morning to find that *iterm* had crashed on my mac.

[12:21] <[Coke]> Will bump up VM specs again before rerunning again.

[12:22] <[Coke]> ... huh? but somehow it automatically reconnected?

[12:22] <[Coke]> magic. ⏳ 608 out of 2204 modules processed

[12:46] <timo> ab5tract: we only have jit on x86_64

[12:49] <ab5tract> That was my understanding but didn’t know if the move away from the expression JIT changed that fact

[12:50] <ab5tract> Regardless, I hope you can understand why I might be confused by mentions of supporting riscv64 when aarch64 is missing? :)

[12:55] <timo> yeah it was a little tongue-in-cheek

[12:56] <timo> actually the expression jit was supposed to be an easier way to get further architectures supported i seem to recall?

[13:02] <timo> i'd share my riscv64 and ppc64 and ppc32 images for you all to enjoy, but i'm still on a tethered connection with a monthly traffic limit :D

[13:15] <[Coke]> ok, and now later it got disconnected after my laptop has been up the whole time. wtf.

[13:30] <lizmat> perhaps a ping -i 60 might help ?

[13:31] <[Coke]> resizing, will run in tmux again for next run.

[13:31] <[Coke]> I doubt the OOM will get it this time.

[13:40] <[Coke]> going from 2-4 cores seems to be more than doubling the throughput here.

[13:41] <[Coke]> I just restarted a few minutes ago, already back up to ⏳ 97 out of 2204 modules processed

[13:42] <[Coke]> (rerunning against the same commit ID I was testing earlier, it's still testing all the "new" endpoints)

[13:42] <[Coke]> s/endpoints/distros/

[13:45] <[Coke]> coleman: any preference for tooling to "run a bunch of commands on a fresh linux box to get it setup properly?" (will make a shell script for now to regen the VM I am doing the blin runs on)

[13:47] <[Coke]> ... er, to be able to get a Blin install on a *fresh* VM, not touching this one. :)

[13:51] <Geth> ¦ rakudo/main: a8111db83e | (Elizabeth Mattijsen)++ | 2 files

[13:51] <Geth> ¦ rakudo/main: RakuAST: re-imagine 'use v6' and '=finish' handling

[13:51] <Geth> ¦ rakudo/main: 

[13:51] <Geth> ¦ rakudo/main: in syntax highlighting.  Fixes #5637

[13:51] <Geth> ¦ rakudo/main: review: https://github.com/rakudo/rakudo/commit/a8111db83e

[14:13] <[Coke]> ⏳ 392 out of 2204 modules processed - sooo much faster.

[14:28] <coleman> [Coke]: start with a raw script. I am a Packer/VM image baker guy, usually.

[14:29] <coleman> install dependencies, take a snapshot of the VM. then the VM is ready to go for tests 

[14:33] <timo> if you make a Dockerfile instead of script, you can pull the container image from somewhere and immediately jump in

[14:34] <timo> do we want to investigate making blin "cumulative" / "resumable"? then we can make a "volume" with the important bits and upload that after some amount of blin is done and then fully destroy the VM instead of just turning it off; does that save any costs?

[14:35] <[Coke]> eh. having a machine setup but turned off is just disk storage (which can add up but isn't too bad)

[14:36] <[Coke]> I'm up to about 5 bucks so far with all the failed runs across 3 different VMs (including all the setups, installs, builds, and blin runs)

[14:38] <[Coke]> I think we'd have to decide if we wanted to have multiple blin clients submitting data for the same runs. (rather than making a single blin runner more resilient)

[14:40] <[Coke]> I think the latter is pretty achievable. (and may already be partially implemented)

[14:41] <[Coke]> Not sure we have enough blin runners ATM to consider the former.

[14:43] <coleman> feel free to open an issue on Raku/infra for discussion. 

[14:44] <coleman> we will need a small controller process to start/stop 

[15:02] <timo> blin makes sure to isolate things from each other, right? do you think we can find some clever techniques to save some work there?

[15:03] <timo> with containers, it's cheap to snapshot and resume with COW and such, so what if we find the most common "prefixes" of flattened lists of dependencies, install them once in a container and stash that away for faster future installations?

[15:03] <timo> or is blin already clever enough about that?

[15:04] <timo> do we have a full-ecosystem dependency graph already available somewhere to play with? does the meta.json of REA have something like that?

[15:11] * timo tries git clone --filter=blob:limit=16k --depth=10 git@github.com:raku/REA

[15:12] <timo> poor github had to spend a lot of time compressing these objects ... and now i get to spend a long time receiving them ...

[15:13] <nine> The Not Invented Here is super strong here

[15:18] <timo> haha

[15:18] <timo> what, with smoke testing?

[15:18] <timo> are you asking why we are not using the free open build service?

[15:19] <nine> That question did indeed cross my mind. I mean, it's only a 12000 machine large cluster that you can use for free that handles the whole dependency graph thing for you to parallelize as much as possible. But I guess you can also try to build all of that yourself and run it on a VM somewhere that will run out of RAM :)

[15:20] *** [Coke] left
[15:20] <timo> will it be all right to use it extensively like that for "a single project"?

[15:21] <nine> I did ask the openSUSE guys at FOSDEM a few years back whether it'd be ok to use the OBS as CI for Rakudo and build those modules and they were ok with it.

[15:23] <timo> ok cool, so let's look further into that then

[15:23] <timo> do we have to learn RPM specs? :D

[15:23] <El_Che> nine: the opensuse infra has the worst UI I have seen. Ever

[15:24] <nine> El_Che: so?

[15:24] <El_Che> (that said, most devops/infra UIs are crap, but the suse was was I next level weird)

[15:24] *** [Coke] joined
[15:24] <El_Che> that's why people use VMs and container elsewhere

[15:24] <El_Che> that pain is less painful

[15:24] <El_Che> it's sad, because it's a very generous offer from Suse

[15:25] <nine> Most of the time I don't even use the web UI and use the osc command line client instead

[15:26] <El_Che> yeah, it's a steep learning curve

[15:26] <[Coke]> I certainly would rather use someone else's infra to run the tests. I'm guessing "blin as is" is not the right shape for that.

[15:26] <El_Che> [Coke]: indeed

[15:26] <[Coke]> so my short term is "being able to run blin multiple times a month to reduce last minute surprises for release"

[15:26] <timo> El_Che: can it really be worse than github + azure pipelines?

[15:27] <El_Che> timo: github pipelines not an option?

[15:27] <[Coke]> I think there are a lot of dials to consider if we re-architect this, including: "Do we really need to do the whole ecosystem or do we need to curate the modules we test?"

[15:28] <El_Che> [Coke]: yes, drawings lines will save a lot of work

[15:28] <timo> well, ideally we do the whole ecosystem, i thought that's more than half the point?

[15:28] <El_Che> timo: I mean github actions aren't that bad

[15:29] <El_Che> but again, need to invest enough time in it :/

[15:29] <nine> I don't see what's so bad about the OBS UI in the first place, so I for sure don't see how it could be any worse than having to click 6 links just to get to the log output on a failed run like with that Azure thing. Puts me off enough so I mostly don't bother.

[15:29] <timo> ^- exactly this

[15:29] <El_Che> nine: I get Azure is bad.

[15:29] <El_Che> I am just saying that I tries OBS and ran

[15:29] <El_Che> d

[15:30] <El_Che> maybe someone else will have more affinity with it

[15:30] <timo> i haven't tried OBS yet, and i could certainly use the exercise if i do have to run

[15:30] <El_Che> (I have nothing against Suse)

[15:31] <El_Che> it's clear nine had a better experience with it

[15:34] <[Coke]> thought: per release we can do the whole ecosystem. if we run multiple times per a release cycle, maybe we just do certain canary distros for fast feedback.

[15:35] <timo> or OBS just does the canary distros first and the rest later while we forget it even exists because we don't have to keep an eye on it

[15:36] <nine> Basically what I did with https://build.opensuse.org/project/show/home:niner9:rakudo-git

[15:38] <El_Che> nine: so you choose on which distros it runs?

[15:38] <El_Che> (I see a Fedora repo)

[15:39] <El_Che> last github

[15:39] <El_Che> oops

[15:42] <timo> it's not limited to suse, it's cross-distro

[15:42] <El_Che> [Coke]: so where is the smoking repo?

[15:42] <El_Che> github actions free have a 50 minutes limits for runs

[15:43] <El_Che> but you can run lots in parallel

[15:43] <[Coke]> El_Che: ?

[15:43] <El_Che> [Coke]: the code you run to test the ecosystem

[15:43] <[Coke]> El_Che: do you mean https://github.com/Raku/Blin?

[15:43] <El_Che> ah ok, I thought it was replaced

[15:44] <[Coke]> it depends on Whateverable (which is the same backend that the bisect bot uses)

[15:44] <El_Che> and what blin command do you run before a release?

[15:44] <[Coke]> I think we're talking about the shape of what might replace it.

[15:44] <El_Che> [Coke]: yes, sorry, I was confused

[15:45] <[Coke]> that's on jdv, but something like "RAKULIB=lib bin/blin.p6" probably has sane defaults for a release run.

[15:45] <El_Che> just looking if something can be run in parallel

[15:45] <El_Che> thx

[15:45] <[Coke]> I'm currently running "time RAKULIB=lib bin/blin.p6  --old=2024.08 --heartbeat=120.0 --new=fd309af89 --nproc-multiplier=1.5"

[15:46] <[Coke]> by default it runs things across all available processors.

[15:46] <El_Che> cpu sucks in most free places, run things in parallel is the trick

[15:47] <[Coke]> This does that, but still everything is run on one single machine.

[15:48] <[Coke]> (it's not farmed out)

[15:50] <El_Che> and you care only about 1 OS

[15:51] <El_Che> so "install of the modules with this commit of rakudo (and create a report)"

[15:51] <El_Che> sorry for the basic questions, just trying to understand what the requirements are

[15:56] *** [Coke]_ joined
[15:56] *** [Coke] left
[15:56] <[Coke]_> yay, network blip here, and everything survived.

[15:57] *** [Coke]_ is now known as [Coke]

[15:57] <[Coke]> (except my nick)

[15:58] <[Coke]> afk for a bit

[16:06] <jdv> wuts on me now?

[16:50] <coleman> We appreciate you, jdv

[16:51] <timo> jdv: i think just how exactly you run blin before a release

[16:53] <jdv> is that not my job as the release automaton?

[16:53] <jdv> :)

[16:56] <timo> i wonder if it's an oversight that we only have byte-to-str and str-to-byte encoders/decoders and nothing like "filters" where you would put stuff like compression or maybe even encryption

[16:57] <timo> for example with zstd, I can use the READ and WRITE and EOF methods of IO::Handle when deriving, then I'll have a handle that "wraps" or "connects to" another handle

[16:58] <timo> if we had something like filters, or a way to combine multiple encoder/decoder/filter things in a row then a handle could just switch its encoding over to "utf8 inside zstd"

[17:00] <timo> as it stands, i can implement "zstd and utf8" as one encoder / decoder and slot that into a Handle, though, including of course sockets

[17:00] <timo> because zstd is byte-to-byte and utf8 is byte-to-str or str-to-byte, and the interfaces for encoder and decoder do byte-to-str and str-to-byte

[17:39] <ab5tract> timo: that sounds really cool

[17:43] <ab5tract> Would such filters be a reasonable place to hang protobuf or AVRO encoders?

[17:46] <timo> hm, not so sure about protobuf, since that's more of an "object graph" kind of output

[17:46] <timo> i haven't looked at avro at all yet

[17:49] <ab5tract> AVRO is similar, you define the types of values to be found in different places in an object

[17:49] <ab5tract> I’m quite sleep deprived so don’t mind me if I’m way off base :)

[17:50] <timo> yeah, something that outputs structured data is not quite as close a fit

[17:51] <timo> another thing about encode streams and decode strings is feeding some amount of bytes/graphemes in at one end and getting as much as possible out at the other end

[17:52] <timo> with utf8 you may need to supply more bytes before a codepoint is finished, and you may need to supply enough bytes for more codepoints if there's combiners (or the possibility of combiners)

[17:57] *** nine left
[17:57] *** nine joined
[18:04] <timo> who wants to see jitted function names in kcachegrind raise your hands up

[19:01] <[Coke]> ok, new record. new feature request: estimated completion time shown during the heartbeat. (x/y done, taken z minutes so far...)

[19:17] *** vrurg_ joined
[19:17] *** vrurg left
[19:20] *** vrurg joined
[19:23] *** vrurg_ left
[19:24] <[Coke]> (new *progress* record, I meant to include)

[19:24] <[Coke]> I am only 1/3 through and am already in the Sm's.

[19:56] <timo> SMH my head

[20:06] *** sena_kun joined
[20:10] *** vrurg_ joined
[20:10] *** vrurg left
[20:23] <nine> o/

[22:20] *** sena_kun left
