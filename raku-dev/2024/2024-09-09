[00:05] *** japhb left
[00:48] *** japhb joined
[06:46] *** sena_kun joined
[07:04] *** sena_kun left
[08:22] <lizmat> m: sub a(/^foo\d/) { dd }   # meh

[08:22] <camelia> rakudo-moar cc194cdcd: OUTPUT: «===SORRY!===␤Cannot find method 'compile_time_value' on object of type QAST::Op␤»

[08:24] <lizmat> feels to me we should be able to codegen this to:

[08:24] <lizmat> m: sub a($ where /^foo\d/) { dd }; a "foo2"

[08:24] <camelia> rakudo-moar cc194cdcd: OUTPUT: «sub a($ where { ... })␤»

[08:24] <lizmat> m: sub a($ where /^foo\d/) { dd ~$/ }; a "foo2"

[08:24] <camelia> rakudo-moar cc194cdcd: OUTPUT: «"foo2"␤»

[08:31] <ab5tract> Hmm.. it seems reasonable on the one hand but also a bit too implicit on the other

[08:32] <ab5tract> Would it only be for regexen or would it support any valid where thunk?

[08:36] <lizmat> I guess any valid where thunk

[08:36] <lizmat> m: sub a($ where 42) { dd }; a 42

[08:36] <camelia> rakudo-moar cc194cdcd: OUTPUT: «sub a($ where { ... })␤»

[08:36] <lizmat> m: sub a(42) { dd }; a 42

[08:36] <camelia> rakudo-moar cc194cdcd: OUTPUT: «sub a(42)␤»

[08:36] <lizmat> already allowed for literals

[08:36] <ab5tract> Maybe it’s almost a running joke now (I feel like it’s the hammer I reach for), but maybe we could add a named arg to the sub definition to enable this

[08:37] <ab5tract> Oh, that’s interesting

[08:37] <ab5tract> sub s(.foo):m { … }

[08:38] <ab5tract> But if it’s already there for literals, I guess that adverb is not really necessary

[08:40] <ab5tract> So it seems almost like an afterthought..

[08:40] <ab5tract> Honestly this would be interesting to support outside of single argument subs

[08:41] <ab5tract> sub s(@a, AnEnum::A) {…}

[08:41] <ab5tract> Oops, forgot the multi

[08:42] <ab5tract> It’s a lot nicer than multi s(@a, $ where AnEnum::A) {…}, in my opinion

[08:44] <lizmat> m: sub a($a, More) { dd $a }; a 42, More

[08:44] <camelia> rakudo-moar cc194cdcd: OUTPUT: «42␤»

[08:44] <lizmat> that already works ...  :-)

[08:44] <lizmat> falls out of smartmatching

[08:45] <ab5tract> Wild!

[08:45] <ab5tract> m: multi s(@a, 36) { say 36 }; multi s(@a, 42) { say 42 }; s @, 36

[08:45] <camelia> rakudo-moar cc194cdcd: OUTPUT: «36␤»

[08:45] <ab5tract> To me this looks like just a feature that was started but couldn’t be finished with the old compiler and dev resources

[08:47] <ab5tract> m: enum Foo <A B>; multi s(@a, Foo::A) { dd A }; multi s(@a, Foo::B) { dd B }; s @, B

[08:47] <camelia> rakudo-moar cc194cdcd: OUTPUT: «Foo::B␤»

[08:48] <ab5tract> That’s funny! I guess I didn’t actually try it, or else something else went wrong when I did and I misinterpreted the cause of failure

[10:29] * timo is now not only losing his mind because of azure windows vms, but additionally and unrelatedly also because of qemu-system

[10:34] * lizmat goes looking for timo's mind

[10:42] <Geth> ¦ rakudo/main: 36e8403dc1 | (Elizabeth Mattijsen)++ | src/core.c/hash_slice.rakumod

[10:42] <Geth> ¦ rakudo/main: Add dedicated { }:p|kv|k|v candidates

[10:42] <Geth> ¦ rakudo/main: 

[10:42] <Geth> ¦ rakudo/main: Not so much performance improvement, but lower bytecode size for the

[10:42] <Geth> ¦ rakudo/main: fast paths, so better inlining.  And one step closer to getting rid

[10:42] <Geth> ¦ rakudo/main: of the SLICE_ONE_HASH behemoth (that once was a good optimization

[10:42] <Geth> ¦ rakudo/main: pre new-disp)

[10:42] <Geth> ¦ rakudo/main: review: https://github.com/rakudo/rakudo/commit/36e8403dc1

[11:05] <Geth> ¦ rakudo/main: 753c755941 | (Elizabeth Mattijsen)++ | src/core.c/hash_slice.rakumod

[11:05] <Geth> ¦ rakudo/main: Micro-opt { }:delete:exists

[11:05] <Geth> ¦ rakudo/main: 

[11:05] <Geth> ¦ rakudo/main: making it up to 7x as fast

[11:05] <Geth> ¦ rakudo/main: review: https://github.com/rakudo/rakudo/commit/753c755941

[11:10] <timo> holy ...

[11:57] <Geth> ¦ rakudo/main: e22881214e | (Elizabeth Mattijsen)++ | src/core.c/hash_slice.rakumod

[11:57] <Geth> ¦ rakudo/main: Micro-opt { }:delete:(:p|kv)

[11:57] <Geth> ¦ rakudo/main: 

[11:57] <Geth> ¦ rakudo/main: making it up to 7x as fast if the key didn't exist, otherwise just

[11:57] <Geth> ¦ rakudo/main: smaller bytecode size so easier inlining

[11:57] <Geth> ¦ rakudo/main: review: https://github.com/rakudo/rakudo/commit/e22881214e

[12:02] <timo> oh, how good is our code-gen / dispatcher / whatever for coercing types in parameters?

[12:04] <timo> i wonder how annoying / possible it is to use a Scalar "itself" as the key to a hash, instead of the value inside of it (now that i saw we have \key there and don't nqp::decont it

[12:08] <lizmat> explain

[12:08] <timo> object hashes*

[12:09] <lizmat> ah...  hmmm   not seeing the advantage yet

[12:09] <timo> m: my %foo{Scalar}; %foo{$_} = "underscore"; %foo{$/} = "slash"; .say for %foo; $_ = 9; $/ = "Hi"; .say for %foo; say %foo{$_}:p; say %foo{$/}:p;

[12:09] <camelia> rakudo-moar 753c75594: OUTPUT: «===SORRY!=== Error while compiling <tmp>␤Unsupported use of $/ variable; in Raku please use the filehandle's .nl-in attribute␤at <tmp>:1␤------> $/} = "slash"; .say for %foo; $_ = 9; $/⏏ = "Hi"; .say for %foo; say %foo{$_}:p; ␤»

[12:09] <timo> no advantage, just something silly?

[12:10] <timo> m: my %foo{Scalar}; %foo{$_} = "underscore"; %foo{$/} = "slash"; .say for %foo; $_ = 9; "Hello" ~~ /../; .say for %foo; say %foo{$_}:p; say %foo{$/}:p;

[12:10] <camelia> rakudo-moar 753c75594: OUTPUT: «Type check failed in binding to parameter 'key'; expected Scalar but got Any (Any)␤  in block <unit> at <tmp> line 1␤␤»

[12:10] <timo> m: my %foo{Scalar}; %foo{$_.VAR} = "underscore"; %foo{$/.VAR} = "slash"; .say for %foo; $_ = 9; "Hello" ~~ /../; .say for %foo; say %foo{$_.VAR}:p; say %foo{$/.VAR}:p;

[12:10] <camelia> rakudo-moar 753c75594: OUTPUT: «(Any) => underscore␤Nil => slash␤9 => underscore␤｢He｣ => slash␤9 => underscore␤｢He｣ => slash␤»

[12:10] <timo> wheee

[12:10] <timo> that's kinda cool?

[12:12] <lizmat> hehe

[12:12] <lizmat> but yeah.... that works

[12:12] <lizmat> everything is an object  :-)

[12:13] <Geth> ¦ rakudo/main: eb7a8279e5 | (Elizabeth Mattijsen)++ | src/core.c/hash_slice.rakumod

[12:13] <Geth> ¦ rakudo/main: Micro-opt { }:delete:exists:(:p|kv)

[12:13] <Geth> ¦ rakudo/main: 

[12:13] <Geth> ¦ rakudo/main: making it up to 7x as fast if the key didn't exist, otherwise just

[12:13] <Geth> ¦ rakudo/main: smaller bytecode size so easier inlining

[12:13] <Geth> ¦ rakudo/main: review: https://github.com/rakudo/rakudo/commit/eb7a8279e5

[12:14] <timo> everything is an object, sure, but many places decont

[12:37] *** nine left
[12:37] *** nine joined
[13:09] <Geth> ¦ rakudo/main: 49be2cf54e | (Elizabeth Mattijsen)++ | src/core.c/hash_slice.rakumod

[13:09] <Geth> ¦ rakudo/main: Micro-opt { }:delete:(k|v)

[13:09] <Geth> ¦ rakudo/main: 

[13:09] <Geth> ¦ rakudo/main: making it up to 7x as fast if the key didn't exist, otherwise just

[13:09] <Geth> ¦ rakudo/main: smaller bytecode size so easier inlining.

[13:09] <Geth> ¦ rakudo/main: 

[13:09] <Geth> ¦ rakudo/main: Also reorganize some candidates for better maintainability

[13:09] <Geth> ¦ rakudo/main: review: https://github.com/rakudo/rakudo/commit/49be2cf54e

[13:35] <Geth> ¦ rakudo/main: 74b45bb342 | (Elizabeth Mattijsen)++ | src/core.c/hash_slice.rakumod

[13:35] <Geth> ¦ rakudo/main: Remove all SLICE_ONE_HASH references in %h<key>

[13:35] <Geth> ¦ rakudo/main: 

[13:35] <Geth> ¦ rakudo/main: They are no longer needed.  Add a single candidate catching all

[13:35] <Geth> ¦ rakudo/main: other named arg combinations

[13:35] <Geth> ¦ rakudo/main: review: https://github.com/rakudo/rakudo/commit/74b45bb342

[14:14] <Geth> ¦ rakudo/main: 4646481e09 | (Elizabeth Mattijsen)++ | 2 files

[14:14] <Geth> ¦ rakudo/main: Simplify %h<a b c> handling

[14:14] <Geth> ¦ rakudo/main: 

[14:14] <Geth> ¦ rakudo/main: by moving the fulfilling logic to a new .List method on the iterator

[14:14] <Geth> ¦ rakudo/main: review: https://github.com/rakudo/rakudo/commit/4646481e09

[15:04] *** finanalyst joined
[15:20] <Geth> ¦ rakudo/main: 0dd0d72ee0 | (Elizabeth Mattijsen)++ | src/core.c/array_slice.rakumod

[15:20] <Geth> ¦ rakudo/main: Micro-opt []:(k|p|kv|v)

[15:20] <Geth> ¦ rakudo/main: 

[15:20] <Geth> ¦ rakudo/main: Maybe a 3% faster, but more importantly much lower bytecode size,

[15:20] <Geth> ¦ rakudo/main: so better inlineable

[15:20] <Geth> ¦ rakudo/main: review: https://github.com/rakudo/rakudo/commit/0dd0d72ee0

[15:42] <Geth> ¦ rakudo/main: b093bc42cd | (Elizabeth Mattijsen)++ | src/core.c/array_slice.rakumod

[15:42] <Geth> ¦ rakudo/main: Micro-opt [x]:exists

[15:42] <Geth> ¦ rakudo/main: 

[15:42] <Geth> ¦ rakudo/main: Makes it about 25% faster and has a smaller bytecode size for better

[15:42] <Geth> ¦ rakudo/main: inlining

[15:42] <Geth> ¦ rakudo/main: review: https://github.com/rakudo/rakudo/commit/b093bc42cd

[16:15] <|Tux|> Rakudo v2024.08-50-gb093bc42c (v6.d) on MoarVM 2024.08-9-g570db2612

[16:15] <|Tux|> csv-test-xs-20      0.141 -  0.141

[16:15] <|Tux|> csv-ip5xs           0.260 -  0.265

[16:15] <|Tux|> test-t --race       0.265 -  0.268

[16:15] <|Tux|> test-t              0.403 -  0.404

[16:15] <|Tux|> csv-ip5xs-20        1.095 -  1.112

[16:15] <|Tux|> test-t-20 --race    1.155 -  1.181

[16:15] <|Tux|> csv-parser          1.502 -  1.532

[16:15] <|Tux|> test                1.810 -  1.815

[16:15] <|Tux|> test-t-20           4.792 -  4.904

[16:15] <|Tux|> https://tux.nl/Talks/CSV6/speed4-20.html / https://tux.nl/Talks/CSV6/speed4.html https://tux.nl/Talks/CSV6/speed.log

[16:29] <lizmat> m: sub a($a) { $a ?? 42 !! 666 }; a(True) for ^10000000; say now - ENTER now

[16:29] <camelia> rakudo-moar b093bc42c: OUTPUT: «0.23355295␤»

[16:29] <lizmat> m: sub a(Bool() $a) { $a ?? 42 !! 666 }; a(True) for ^10000000; say now - ENTER now

[16:29] <camelia> rakudo-moar b093bc42c: OUTPUT: «0.130698307␤»

[16:30] <lizmat> that feels counter-intuitive....

[16:33] <Geth> ¦ rakudo/main: 50b8614031 | (Elizabeth Mattijsen)++ | src/core.c/array_slice.rakumod

[16:33] <Geth> ¦ rakudo/main: Micro-opt []:foo by Boolifying in the signature

[16:33] <Geth> ¦ rakudo/main: 

[16:33] <Geth> ¦ rakudo/main: This appears to make all these candidates about 3% faster.  Not

[16:33] <Geth> ¦ rakudo/main: entirely sure why, possibly because the coercion happens at the

[16:33] <Geth> ¦ rakudo/main: callsite?  Looks like this creates a smaller bytecode-size footprint

[16:33] <Geth> ¦ rakudo/main: review: https://github.com/rakudo/rakudo/commit/50b8614031

[16:55] *** finanalyst left
[17:10] <Geth> ¦ intellij-ide-fork: ab5tract++ created pull request #1: Merge intellij/idea/232.10335.12 to main

[17:10] <Geth> ¦ intellij-ide-fork: review: https://github.com/Raku/intellij-ide-fork/pull/1

[17:11] <ab5tract> Ah, that's not actually ready yet.. I thought it was going to be internal to my own repo

[17:15] <Geth> ¦ rakudo/main: 86a5a10cb5 | (Elizabeth Mattijsen)++ | src/core.c/array_slice.rakumod

[17:15] <Geth> ¦ rakudo/main: Micro-opt [foo]:(p|kv|v)

[17:15] <Geth> ¦ rakudo/main: 

[17:15] <Geth> ¦ rakudo/main: The :p :kv candidates can *not* forward to their Int:D candidate,

[17:15] <Geth> ¦ rakudo/main: as they need to produce the key value unaltered.

[17:15] <Geth> ¦ rakudo/main: 

[17:15] <Geth> ¦ rakudo/main: The :v candidate forwards, and this makes it 25% faster

[17:15] <Geth> ¦ rakudo/main: review: https://github.com/rakudo/rakudo/commit/86a5a10cb5

[17:21] <ab5tract> apparently it takes a bit of time to reconcile 16,000+ commits :)

[17:21] <lizmat> is that all?

[17:22] <ab5tract> I want to apologize for misrepresenting jnthn++ -- the .cmd files are actually some sort of wild hybrid of sh + DOS batch syntax that are supported on both platforms

[17:24] <ab5tract> lizmat: I know, I know.. amateur stuff :)

[17:29] *** finanalyst joined
[18:23] *** vrurg_ joined
[18:26] *** vrurg left
[18:27] *** vrurg joined
[18:30] *** vrurg_ left
[18:30] *** vrurg_ joined
[18:34] *** vrurg__ joined
[18:34] *** vrurg left
[18:36] *** vrurg_ left
[19:23] <timo> my runcy_funcy_optimizations branch makes it a tiny bit faster still

[19:25] <timo> 0.31113 +- 0.00280 seconds time elapsed  <--  0.51927 +- 0.00327 seconds time elapsed

[19:26] <timo> that's for 50000000 runs of the loop with Bool() in the sig

[19:31] <lizmat> nice!

[19:34] <timo> m: say 1_758_078_934 / 50_000_000, " cpu cycles per loop iteration"

[19:34] <camelia> rakudo-moar 86a5a10cb: OUTPUT: «35.16157868 cpu cycles per loop iteration␤»

[19:34] <timo> i mean that isn't super terrible right?

[19:34] <ab5tract> that's a nice bump indeed!

[19:34] <lizmat> nope

[19:34] <ab5tract> https://gist.github.com/ab5tract/270cf5959df3db0dd13dbac76034a561

[19:35] <ab5tract> (tl;dr -- is make install working for others?)

[19:35] <timo> m: say 2_768_952_429 / 50_000_000, " cpu cycles per loop iteration without runcy_funcy_optimizations"

[19:35] <camelia> rakudo-moar 86a5a10cb: OUTPUT: «55.37904858 cpu cycles per loop iteration without runcy_funcy_optimizations␤»

[20:04] <Geth> ¦ rakudo/main: 045644e0a0 | (Elizabeth Mattijsen)++ | src/core.c/hash_slice.rakumod

[20:04] <Geth> ¦ rakudo/main: Actually only allow concrete iterables in %h{...}

[20:04] <Geth> ¦ rakudo/main: review: https://github.com/rakudo/rakudo/commit/045644e0a0

[21:44] <Geth> ¦ rakudo/windows_latest_azure_pipeline: 3de00c9847 | (Timo Paulssen)++ | 2 files

[21:44] <Geth> ¦ rakudo/windows_latest_azure_pipeline: try to cache moar build, it's so agonizingly slow

[21:44] <Geth> ¦ rakudo/windows_latest_azure_pipeline: review: https://github.com/rakudo/rakudo/commit/3de00c9847

[21:47] <Geth> ¦ rakudo/windows_latest_azure_pipeline: 4c3d6f9d43 | (Timo Paulssen)++ | azure-pipelines.yml

[21:47] <Geth> ¦ rakudo/windows_latest_azure_pipeline: yeah guess what has dots in it ... dates!

[21:47] <Geth> ¦ rakudo/windows_latest_azure_pipeline: review: https://github.com/rakudo/rakudo/commit/4c3d6f9d43

[22:04] <Geth> ¦ rakudo/windows_latest_azure_pipeline: 4285588c43 | (Timo Paulssen)++ | azure-pipelines.yml

[22:04] <Geth> ¦ rakudo/windows_latest_azure_pipeline: now that moar has been built and cached, try building rakudo again

[22:04] <Geth> ¦ rakudo/windows_latest_azure_pipeline: review: https://github.com/rakudo/rakudo/commit/4285588c43

[22:07] <timo> ah crap, i guess changing the pipeline setup emptied the cache?

[22:31] *** finanalyst left
