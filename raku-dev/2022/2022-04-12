[00:07] *** reportable6 left
[00:08] *** reportable6 joined
[01:34] *** RakuIRCLogger left
[01:34] *** Geth left
[03:28] *** frost joined
[06:03] *** releasable6 left
[06:03] *** coverable6 left
[06:03] *** greppable6 left
[06:03] *** bisectable6 left
[06:03] *** bloatable6 left
[06:03] *** linkable6 left
[06:03] *** shareable6 left
[06:03] *** committable6 left
[06:03] *** reportable6 left
[06:03] *** notable6 left
[06:03] *** statisfiable6 left
[06:03] *** evalable6 left
[06:03] *** sourceable6 left
[06:03] *** nativecallable6 left
[06:03] *** unicodable6 left
[06:03] *** quotable6 left
[06:03] *** benchable6 left
[06:04] *** shareable6 joined
[06:04] *** benchable6 joined
[06:04] *** bloatable6 joined
[06:04] *** quotable6 joined
[06:04] *** greppable6 joined
[06:04] *** linkable6 joined
[06:05] *** coverable6 joined
[06:05] *** notable6 joined
[06:05] *** sourceable6 joined
[06:05] *** bisectable6 joined
[06:05] *** committable6 joined
[06:06] *** nativecallable6 joined
[06:06] *** reportable6 joined
[06:06] *** releasable6 joined
[06:06] *** evalable6 joined
[06:07] *** unicodable6 joined
[06:07] *** statisfiable6 joined
[06:27] <nine> japhb: can vs does
[06:37] <japhb> nine: Fair enough.  Is anyone yet working on turning 'can' into 'does'?  (IIUC, that's what Xliff is asking for.)
[06:40] <nine> Not that I'm aware of
[06:44] <japhb> OK, so it sounds like the current status is "The data is there, there may even be an internal API for it, but either that API is not exposed externally and/or Zef is not currently using that data to communicate to the end user."  So I guess the next question is whether there actually is any work to be done to expose that data in an official API, or whether it's just a matter of hacking Zef to expose what 
[06:44] <japhb> it already knows.
[06:55] <nine> It is rather simple: the workhorse for installation is CURI's install method. It takes a Distribution object and installs this distribution, i.e. copying bin and resource files and precompiling modules. The Distribution object is essentially the META6.json in form of an object.
[06:57] <nine> Since the META6.json contains information like what distro it is and how many and what modules it contains and zef is the thing that reads this information and passes it to the install method in the first place, zef already knows how many modules are going to be installed.
[06:57] <nine> And of course it could easily take timings for how long it takes to install that distribution.
[07:01] <nine> And if the installer was really keen on giving more fine grained information like what modules is currently being precompiled, it could even do that right now. It would just have to set RAKUDO_LOG_PRECOMP in the environment and replace $*STDERR with an object that intercepts the "Precompiling $id ($_.key())" message and uses it to e.g. drive a counter
[07:07] <lizmat> that's exactly what I want to do, in a slightly different way
[07:07] <lizmat> however, that counter doesn't really keep track
[07:08] <lizmat> take the example of NativeCall: it uses NC::Types, ::Compiler::GNU and ::Compiler::MSVC
[07:08] <lizmat> so that's 4 files
[07:09] <lizmat> because CURI sorts the provides keys, it will precomp NativeCall first
[07:10] <lizmat> *but* because of its use statements, that means it will also recursively precompile those modules as well
[07:10] <lizmat> so suppose it would be the only things being installed, then it would start with 1/4 NativeCall, and then be done
[07:11] <lizmat> because the other 3 modules would be precompiled already by the time CURI is even thinking of precompiling them
[07:11] <nine> We ought to get rid of that recursion as it blocks proper parallelization
[07:11] <lizmat> agree
[07:12] <lizmat> so that's what I've been doing the past week or so, trying to grok the whole process and try to come up with a way for proper reporting and parallelization
[07:12] <lizmat> and not break anythinhg
[07:12] <lizmat> and type correctly  :-)
[07:12] <nine> The latter is probably the hardest
[07:13] <lizmat> ineed
[07:13] <lizmat> :-)
[07:28] *** [Coke] left
[07:31] *** [Coke] joined
[08:59] <MasterDuke> oh, Geth is down?
[09:02] <lizmat> again?
[09:02] *** Geth joined
[09:02] *** RakuIRCLogger joined
[09:03] *** TempIRCLogger joined
[09:04] <lizmat> MasterDuke: which repo should I replay commits ?
[09:04] <MasterDuke> nqp and rakudo
[09:06] <Geth> ¦ rakudo: 91185079e0 | (Elizabeth Mattijsen)++ | src/Perl6/World.nqp
[09:06] <Geth> ¦ rakudo: One unncessary return at the end of a method
[09:06] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/commit/91185079e0
[09:08] <Geth> ¦ rakudo: vrurg++ created pull request #4861: Initial attempt with `will complain` trait
[09:08] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/pull/4861
[09:09] <Geth> ¦ nqp/faster_sorted_keys: 6eb2954d7e | (Elizabeth Mattijsen)++ | 2 files
[09:09] <Geth> ¦ nqp/faster_sorted_keys: Some more tweaks
[09:09] <Geth> ¦ nqp/faster_sorted_keys: 
[09:09] <Geth> ¦ nqp/faster_sorted_keys: - remove now superfluous decrement (it's handled in the loop condition)
[09:09] <Geth> ¦ nqp/faster_sorted_keys: - find out that it sorts in reverse, document that
[09:09] <Geth> ¦ nqp/faster_sorted_keys: - fix sorting for 2 elements, it's supposed to be in reverse!
[09:09] <Geth> ¦ nqp/faster_sorted_keys: - add tests for "sorted_keys", there weren't any
[09:09] <Geth> ¦ nqp/faster_sorted_keys: review: https://github.com/Raku/nqp/commit/6eb2954d7e
[09:09] <lizmat> I think that covers it
[09:37] <Geth> ¦ nqp: b4d5848597 | (Elizabeth Mattijsen)++ (committed using GitHub Web editor) | 2 files
[09:37] <Geth> ¦ nqp: Speed up "sorted_keys" sub
[09:37] <Geth> ¦ nqp: 
[09:37] <Geth> ¦ nqp: - faster collection of keys using nqp::iterator/nqp::iterkey_s
[09:37] <Geth> ¦ nqp: - one check for > 2
[09:38] <Geth> ¦ nqp: - one check for == 2 and order
[09:38] <Geth> ¦ nqp: - decrement in while condition, account for that in initialization
[09:38] <Geth> ¦ nqp: - document it's actually sorting in *reverse* order
[09:38] <Geth> ¦ nqp: <…commit message has 7 more lines…>
[09:38] <Geth> ¦ nqp: review: https://github.com/Raku/nqp/commit/b4d5848597
[09:39] <Geth> ¦ rakudo: 02c59dc790 | (Elizabeth Mattijsen)++ | src/core.c/CompUnit/Repository/Installation.pm6
[09:39] <Geth> ¦ rakudo: Make script stubs and used extensions constants
[09:39] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/commit/02c59dc790
[09:43] *** sena_kun left
[09:52] <Geth> ¦ rakudo: f41d5c5a74 | (Elizabeth Mattijsen)++ | tools/templates/NQP_REVISION
[09:52] <Geth> ¦ rakudo: Bump nqp to get faster sorted_keys logic
[09:52] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/commit/f41d5c5a74
[09:54] *** sena_kun joined
[10:20] <Geth> ¦ rakudo: 42457734f9 | (Elizabeth Mattijsen)++ | src/core.c/CompUnit/Repository/Installation.pm6
[10:20] <Geth> ¦ rakudo: Lose the original wrapper initializations
[10:20] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/commit/42457734f9
[10:36] <[Tux]> Rakudo v2022.03-196-g91185079e (v6.d) on MoarVM 2022.03-17-g794e1d589
[10:36] <[Tux]> csv-test-xs-20      0.400 -  0.494
[10:36] <[Tux]> csv-ip5xs           0.823 -  0.846
[10:36] <[Tux]> test-t --race       0.903 -  0.960
[10:36] <[Tux]> test-t              1.428 -  1.501
[10:36] <[Tux]> csv-parser          3.899 -  4.490
[10:36] <[Tux]> csv-ip5xs-20        5.133 -  5.394
[10:36] <[Tux]> test                6.660 -  6.738
[10:36] <[Tux]> test-t-20 --race    6.600 -  6.953
[10:36] <[Tux]> test-t-20          20.958 - 21.112
[11:05] *** TempIRCLogger left
[12:07] *** reportable6 left
[12:09] *** reportable6 joined
[12:15] <Geth> ¦ rakudo: 6b50a940af | (Elizabeth Mattijsen)++ | src/core.c/CompUnit/Repository/Installation.pm6
[12:15] <Geth> ¦ rakudo: Make sure $*REPO gets restored on exception
[12:15] <Geth> ¦ rakudo: 
[12:15] <Geth> ¦ rakudo: At the moment, if anything goes wrong with module installation, we
[12:15] <Geth> ¦ rakudo: completely abort anyway.  But that may not be like that in the future.
[12:15] <Geth> ¦ rakudo: Make sure that $*REPO gets restored on failure.  Also reduce the number
[12:15] <Geth> ¦ rakudo: of $*REPO lookups.
[12:15] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/commit/6b50a940af
[12:16] <Geth> ¦ rakudo: b2a8bfc9e7 | (Elizabeth Mattijsen)++ (committed using GitHub Web editor) | 8 files
[12:16] <Geth> ¦ rakudo: Remove the $?COMPILATION-ID constant
[12:16] <Geth> ¦ rakudo: 
[12:16] <Geth> ¦ rakudo: - it is not used anywhere
[12:16] <Geth> ¦ rakudo: - it is only tested for its existence
[12:16] <Geth> ¦ rakudo: - it is not documented
[12:16] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/commit/b2a8bfc9e7
[13:02] *** frost left
[13:35] *** sena_kun left
[13:36] *** sena_kun joined
[13:37] <Geth> ¦ rakudo/CUDS-lookup-id: a39ddc222d | (Elizabeth Mattijsen)++ | 2 files
[13:37] <Geth> ¦ rakudo/CUDS-lookup-id: Add CompUnit::DependencySpecification.lookup-id method
[13:37] <Geth> ¦ rakudo/CUDS-lookup-id: 
[13:37] <Geth> ¦ rakudo/CUDS-lookup-id: And use it.   I guess technically any CUR can devise its own way of
[13:37] <Geth> ¦ rakudo/CUDS-lookup-id: encoding a shortname lookup into a filename, but it feels that it
[13:37] <Geth> ¦ rakudo/CUDS-lookup-id: being in the CUDS is more appropriate.
[13:37] <Geth> ¦ rakudo/CUDS-lookup-id: review: https://github.com/rakudo/rakudo/commit/a39ddc222d
[13:37] <Geth> ¦ rakudo: lizmat++ created pull request #4862: Add CompUnit::DependencySpecification.lookup-id method
[13:37] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/pull/4862
[14:21] <Geth> ¦ rakudo: 8a1e778874 | (Elizabeth Mattijsen)++ (committed using GitHub Web editor) | src/core.c/IO/Path.pm6
[14:21] <Geth> ¦ rakudo: Add an IO::Path.dir-with-entries method
[14:21] <Geth> ¦ rakudo: 
[14:21] <Geth> ¦ rakudo: Checking whether a directory has entries in it, can be checked by
[14:21] <Geth> ¦ rakudo: doing e.g. an "if .dir.head {".  However, this will leak resources
[14:21] <Geth> ¦ rakudo: as the iterator that runs "dir" will never be finished, and thus
[14:21] <Geth> ¦ rakudo: the underlying directory handle will also never be closed.
[14:21] <Geth> ¦ rakudo: 
[14:21] <Geth> ¦ rakudo: <…commit message has 8 more lines…>
[14:21] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/commit/8a1e778874
[18:05] *** sena_kun left
[18:06] *** sena_kun joined
[18:08] *** reportable6 left
[18:08] *** reportable6 joined
[19:36] *** linkable6 left
[19:37] *** linkable6 joined
[19:46] *** linkable6 left
[19:49] *** linkable6 joined
[19:51] *** sena_kun left
[19:54] *** sena_kun joined
[20:11] <Xliff> lizmat: I've started another run of timings, as requested.
[20:49] <lizmat> Xliff++
[20:51] <Xliff> lizmat: I am noticing that prereqs are being recompiled.
[20:51] <Xliff> Which might be why the numbers are off. 
[20:52] <lizmat> hmmm... intriguinig
[20:52] <Xliff> GIO is compiled before soup, but the parts of GIO that are used by SOUP are adding 61 seconds to SOUPs time.
[20:52] <lizmat> ok, then stop the timing....
[20:53] <Xliff> Done.
[20:53] <lizmat> I guess I need to look at why it is re-doing dependency checks (I know it re-does these for modules in the core repo)
[20:53] <lizmat> but in that case, it doesn't actually re-precompile the dependencies
[20:54] <lizmat> Xliff: if you could golf this, that would be brill!
[20:55] <Xliff> lizmat: I'll see what I can do.
[20:56] <lizmat> ++Xliff
[21:29] *** Xliff left
