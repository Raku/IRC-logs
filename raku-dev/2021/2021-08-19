[00:30] *** linkable6 left
[00:30] *** unicodable6 left
[00:30] *** tellable6 left
[00:30] *** evalable6 left
[00:30] *** benchable6 left
[00:30] *** greppable6 left
[00:30] *** evalable6 joined
[00:31] *** unicodable6 joined
[00:33] *** greppable6 joined
[00:33] *** tellable6 joined
[01:31] *** benchable6 joined
[01:32] *** linkable6 joined
[02:29] *** japhb left
[02:36] *** melezhik left
[02:56] *** squashable6 left
[02:58] *** squashable6 joined
[03:28] *** MasterDuke left
[03:58] *** japhb joined
[04:03] *** reportable6 joined
[04:06] <japhb> m: use nqp; my int $t0 = my int $prev = nqp::time; my int $long = 0; my $t; for ^10_000_000 { $t = nqp::time; $long++ if nqp::isgt_i(nqp::sub_i($t, $prev), 10_000_000); $prev = $t; }; say (nqp::time() - $t0)/1_000_000_000; say $long;

[04:06] <camelia> rakudo-moar 289a62f4a: OUTPUT: «4.632589257␤1␤»

[04:06] <japhb> m: use nqp; my int $t0 = my int $prev = nqp::time; my int $long = 0; my $t; for ^20_000_000 { $t = nqp::time; $long++ if nqp::isgt_i(nqp::sub_i($t, $prev), 10_000_000); $prev = $t; }; say (nqp::time() - $t0)/1_000_000_000; say $long;

[04:07] <camelia> rakudo-moar 289a62f4a: OUTPUT: «9.152689692␤1␤»

[04:07] <japhb> m: use nqp; my int $t0 = my int $prev = nqp::time; my int $long = 0; my $t; for ^10_000_000 { $t = nqp::time; $long++ if $t - $prev > 10_000_000; $prev = $t; }; say (nqp::time() - $t0)/1_000_000_000; say $long;

[04:08] <camelia> rakudo-moar 289a62f4a: OUTPUT: «7.823173845␤0␤»

[04:08] <japhb> m: use nqp; my int $t0 = my int $prev = nqp::time; my int $long = 0; my $t; for ^10_000_000 { $t = nqp::time; $long++ if $t - $prev > 5_000_000; $prev = $t; }; say (nqp::time() - $t0)/1_000_000_000; say $long;

[04:08] <camelia> rakudo-moar 289a62f4a: OUTPUT: «7.715262905␤2␤»

[04:09] <japhb> m: use nqp; my int $t0 = my int $prev = nqp::time; my int $long = 0; my $t; for ^10_000_000 { $t = nqp::time; $long++ if nqp::isgt_i(nqp::sub_i($t, $prev), 5_000_000); $prev = $t; }; say (nqp::time() - $t0)/1_000_000_000; say $long;

[04:09] <camelia> rakudo-moar 289a62f4a: OUTPUT: «4.323051041␤52␤»

[04:09] <japhb> OK, you can see it clearly in that last pair.  I've been looking at this for a bit, and I'm mystified as to why it's happening.

[04:11] <japhb> I was trying to determine whether getting high-res time was stable performance-wise, so I started checking for "long" intervals (greater than N milliseconds between consecutive time reads).

[04:12] <japhb> I was stripping off extra layers of overlying code one piece at a time, until I was mostly just doing nqp:: ops and assignments within the loop.

[04:12] <japhb> That's when I noticed that turning the "long interval" check into nqp:: ops made the loop quite a bit faster, as expected ... but the number of long intervals per test went WAY up.

[04:14] <japhb> On my local laptop, I see that scale of difference with 10 ms long intervals; obviously whatever system camelia works on is faster, but accounting for the speed difference by dropping down to 5 ms as the "long" threshold shows it again.

[04:15] <japhb> Normally an nqp::time read is less than a microsecond.  But sometimes it appears to be thousands of times slower.  At first I assumed preemption problems, so I quiesced my system.  And then checked against camelia.

[04:15] <japhb> The effect is still there -- the faster loop body appears to have much spikier latency.

[04:15] <japhb> WTH is going on here?

[04:16] <japhb> (FWIW, you can see the same effect with 'now' instead of 'nqp::time' as long as you fix the variable types and account for the factor of 1_000_000_000 conversion.)

[04:17] <moon-child> I wonder if it has to do with vdso latency

[04:17] <moon-child> are you running linux?

[04:18] <japhb> Yes.  'vdso'?

[04:19] <japhb> Oh this?  https://en.wikipedia.org/wiki/VDSO

[04:19] <moon-child> hmm, on further thought, that doesn't make much sense.  The kernel maps a page into every process containing things like the current time, so to get the time, you can just read it from that page without having ot do a ctx switch.  So maybe, if you're faster, you're more likely to read a stale value from there

[04:19] <moon-child> but that doesn't seem likely, the more I think about it

[04:22] *** mattil joined
[04:23] <japhb> That's kindof a cool hack -- does it map the *same* page into every process?  Meaning that there is just 1 of these special pages *physically*, it's just memory mapped separately into every process?

[04:23] <moon-child> I think so.  Don't know too much about it

[04:24] <japhb> Huh.  I wonder what happens when you enable large pages

[04:24] <japhb> I suppose since all the copies are probably virtual, it doesn't really matter much.

[05:10] *** mattil left
[06:02] *** reportable6 left
[06:41] *** MasterDuke joined
[06:44] <MasterDuke> japhb: do you get the same results if you disable spesh? or might it be gc pauses?

[06:45] <nine> GC pauses may actually be the explanation.

[06:46] <MasterDuke> nqp: my int $i := 0; my int $t0 := my int $prev := nqp::time; my int $long := 0; my $t; while $i++ < 10_000_000 { $t := nqp::time; $long++ if nqp::isgt_i(nqp::sub_i($t, $prev), 5_000_000); $prev := $t; }; say(nqp::div_n((nqp::time() - $t0), 1_000_000_000)); say($long);

[06:46] <camelia> nqp-moarvm: OUTPUT: «0.510087937␤0␤»

[06:46] <MasterDuke> nqp: my int $i := 0; my int $t0 := my int $prev := nqp::time; my int $long := 0; my $t; while $i++ < 10_000_000 { $t := nqp::time; $long++ if nqp::isgt_i(nqp::sub_i($t, $prev), 1_000_000); $prev := $t; }; say(nqp::div_n((nqp::time() - $t0), 1_000_000_000)); say($long);

[06:46] <camelia> nqp-moarvm: OUTPUT: «0.536608651␤2␤»

[07:00] <releasable6> Next release in ≈2 days and ≈11 hours. 1 blocker. Please log your changes in the ChangeLog: https://github.com/rakudo/rakudo/wiki/ChangeLog-Draft

[08:04] *** reportable6 joined
[08:32] *** AlexDaniel left
[08:32] *** rba[m] left
[08:34] <bartolin> btw, I'd like to get https://github.com/Raku/nqp/pull/734 into the next release. (It's only for the JVM backend.) I'm inclined to merge it myself, unless someone has objections. 

[08:35] *** AlexDaniel joined
[08:36] <MasterDuke> i don't know the jvm backend well enough to review it, but no objection here

[08:37] *** rba[m] joined
[09:37] <Geth> ¦ nqp: 7e33586479 | (Christian Bartolomäus)++ | src/vm/jvm/QAST/Compiler.nqp

[09:37] <Geth> ¦ nqp: [JVM] Coerce to SixModelObject for isconcrete test

[09:37] <Geth> ¦ nqp: 

[09:37] <Geth> ¦ nqp: If we end up with a Java string|long|double on the stack, invoking

[09:37] <Geth> ¦ nqp: 'isconcrete' will blow up badly.

[09:37] <Geth> ¦ nqp: 

[09:37] <Geth> ¦ nqp: This doesn't help with the functionality of 'with' yet, but it seems

[09:37] <Geth> ¦ nqp: clearer to make it a separate commit.

[09:37] <Geth> ¦ nqp: review: https://github.com/Raku/nqp/commit/7e33586479

[09:37] <Geth> ¦ nqp: ad700a25f9 | (Christian Bartolomäus)++ | 3 files

[09:37] <Geth> ¦ nqp: [JVM] Let with/without use 'defined'

[09:37] <Geth> ¦ nqp: 

[09:37] <Geth> ¦ nqp: ... instead of 'isconcrete'.

[09:37] <Geth> ¦ nqp: 

[09:37] <Geth> ¦ nqp: I'm not sure if my usage of InvokeDynamic is the right way to call

[09:37] <Geth> ¦ nqp: the found 'method defined', but it seems to improve the situation

[09:37] <Geth> ¦ nqp: a lot.

[09:37] <Geth> ¦ nqp: <…commit message has 8 more lines…>

[09:37] <Geth> ¦ nqp: review: https://github.com/Raku/nqp/commit/ad700a25f9

[09:37] <Geth> ¦ nqp: 71899a940a | (Elizabeth Mattijsen)++ (committed using GitHub Web editor) | 3 files

[09:37] <Geth> ¦ nqp: Merge pull request #734 from usev6/jvm_with

[09:37] <Geth> ¦ nqp: 

[09:37] <Geth> ¦ nqp: [JVM] Let with/without use 'defined'

[09:37] <Geth> ¦ nqp: review: https://github.com/Raku/nqp/commit/71899a940a

[09:45] <bartolin> oh, thanks ;)

[09:48] <lizmat> bartolin++   # not giving up on JVM

[09:49] <MasterDuke> very much so

[09:56] *** evalable6 left
[09:56] *** linkable6 left
[11:15] *** frost joined
[11:58] *** linkable6 joined
[11:59] *** evalable6 joined
[12:02] *** reportable6 left
[12:04] *** reportable6 joined
[12:40] *** frost left
[14:06] *** evalable6 left
[14:06] *** linkable6 left
[14:08] *** linkable6 joined
[14:09] <japhb> nine, MasterDuke: GC pausing for ... what?  It's the nqp::ops version that has more long pauses, the variables are all native types, and the variables are declared outside the loop, so I don't think there are any objects being created?

[14:14] <nine> japhb: but $t is not natively typed?

[14:16] <MasterDuke> and i suspect that even if your code isn't explicitly creating object, rakudo itself may be

[14:16] <japhb> nine: Gah, I didn't see that while copying over from my local tests (it wasn't native typed at the beginning because it was originally assigned with `now`)

[14:17] <japhb> m: use nqp; my int $t0 = my int $prev = nqp::time; my int $long = 0; my int $t; for ^10_000_000 { $t = nqp::time; $long++ if nqp::isgt_i(nqp::sub_i($t, $prev), 5_000_000); $prev = $t; }; say (nqp::time() - $t0)/1_000_000_000; say $long;

[14:17] <camelia> rakudo-moar 289a62f4a: OUTPUT: «0.544126166␤0␤»

[14:17] <japhb> m: use nqp; my int $t0 = my int $prev = nqp::time; my int $long = 0; my $t; for ^10_000_000 { $t = nqp::time; $long++ if nqp::isgt_i(nqp::sub_i($t, $prev), 5_000_000); $prev = $t; }; say (nqp::time() - $t0)/1_000_000_000; say $long;

[14:17] <camelia> rakudo-moar 289a62f4a: OUTPUT: «4.717587611␤56␤»

[14:17] <japhb> WTH?

[14:18] <japhb> Wait ... creating Int objects and destroying them?

[14:18] <japhb> Because nqp::time > "small" bigint?

[14:19] <japhb> Well damn.  Now I feel like an idiot.  nine++  # Thank you for the second pair of eyes!

[14:21] <japhb> That is a rather amazing performance difference too, by fixing just that one declaration.

[14:22] <japhb> MasterDuke: Was there something *else* you had in mind that might be creating objects?

[14:22] <MasterDuke> re "small" bigints: `src/6model/reprs/P6bigint.h:5:#define MVM_IS_32BIT_INT(i)     ((long long)(i) >= -2147483648LL && (long long)(i) <= 2147483647LL)`

[14:22] <MasterDuke> scheduler maybe?

[14:23] <japhb> MasterDuke: Oh hmmm, that's an interesting point.  I think lizmat++ did some work to reduce the object churn in there, but I dunno if she was able to eliminate it.

[14:24] <MasterDuke> yeah, i wouldn't expect much, but i'd be mildly surprised if it was completely nothing

[14:24] <lizmat> but I don't think the scheduler actually runs unless you're doing a start { } somewhere

[14:25] <lizmat> if you run your code with -Msnapper it should tell you whether the scheduler actually ran

[14:25] <japhb> lizmat: Would you be able to add GC runs to Telemetry?  I probably would have noticed something off if I'd seen the GC runs ....

[14:26] <japhb> lizmat: I did run it that way yesterday, and I just saw a thing about the supervisor thread running the whole time

[14:26] <lizmat> there's no interface to get that data, afaik

[14:26] <japhb> MoarVM folk: Pretty please?  ^^

[14:27] <lizmat> hmmm    "my int $i; 1 until ++$i == 100000" tells me the supervisor thread ran the whole time

[14:28] <lizmat> that's... intriguing

[14:29] <lizmat> that shouldn't happen afaik

[14:30] <ugexe> japhb: just run --profile ?

[14:31] <lizmat> profile says no allocations basically, just from startup: 0 garbage collects

[14:31] <lizmat> 104 allocations to be precise

[14:32] <lizmat> hmmm... maybe the message from Telemetry is a false positive

[14:32] <nine> lizmat: could it be that Telemetry itself is causing the supervisor thread to get started?

[14:33] <lizmat> no, I made sure of that (originally

[14:33] <lizmat> )  :-)

[14:44] <lizmat> ok, confirmed that we appear to *always* have a supervisor thread  :-(

[14:45] <ugexe> that seems logical to me

[14:46] <lizmat> why?

[14:47] <nine> We really shouldn't. The supervisor thread is started when someone interacts with the thread pool, i.e. queueing something or taking a job from a queue

[14:47] <japhb> ugexe: Because my real scripts have multiple phases with different performance envelopes, and I want to see which parts are causing the GCs.

[14:48] <ugexe> i guess i was assuming something in the core would be spawning a thread somewhere

[14:48] <lizmat> ah, but it *is*

[14:48] <nine> Precompilation of a module would be one such thing, through Proc::Async

[14:48] <lizmat> for spesh and so on

[14:48] <nine> The spesh thread is not part of the thread pool

[14:48] <lizmat> but that is *not* the supervisor thread

[14:49] <lizmat> e.g. the snapper module also creates a thread, *outside* of the thread pool

[14:52] <lizmat> the supervisor does *not* get started with method !maybe-start-supervisor(--> Nil) {

[14:53] <lizmat> so I guess my next guess is going to be that Telemetry starts the supervisor somehow

[14:54] <lizmat> argh... found it

[14:55] <lizmat> japhb: are you running on MacOS

[14:55] <lizmat> ?

[14:56] <lizmat> looks like the initialization of $*DISTRO is calling shell()

[14:57] <lizmat> as a Proc, but that is a Proc::Async

[14:57] <Geth> ¦ rakudo: MasterDuke17++ created pull request #4496: Make concurrent use of %!conc_table safe

[14:57] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/pull/4496

[14:57] <lizmat> and $*DISTRO is used by Telemetry,

[14:58] *** squashable6 left
[14:59] <lizmat> MasterDuke: I assume the binding is atomic ?

[15:00] <lizmat> hmmm.. Telemetry doesn't use $*DISTRO ?

[15:00] <MasterDuke> lizmat: that's my understanding

[15:00] <lizmat> aaah... loading a module causes the supervisor to be started

[15:05] <lizmat> ok, that can be fixed :-)

[15:15] *** discord-raku-bot left
[15:17] *** discord-raku-bot joined
[15:19] <Geth> ¦ rakudo: 89df7f4ba9 | (Elizabeth Mattijsen)++ | 2 files

[15:19] <Geth> ¦ rakudo: Make checking for Windows cheaper

[15:19] <Geth> ¦ rakudo: 

[15:19] <Geth> ¦ rakudo: The R:I.IS-WIN method doesn't need to actually initialized $*DISTRO,

[15:19] <Geth> ¦ rakudo: and as such will not actually shell out on some OS's, which will in

[15:19] <Geth> ¦ rakudo: turn not cause the threadpool supervisor thread to be started.

[15:19] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/commit/89df7f4ba9

[15:19] <lizmat> sadly, that does not appear to fix the issue, but is a good thing anyway

[15:20] <lizmat> afk for an hour or so&

[15:25] <MasterDuke> nine: any idea why https://github.com/rakudo/rakudo/pull/4496 would have all those t/02-rakudo/reproducible-builds.t failures?

[15:27] <japhb> lizmat: Linux Mint on x64 and Raspberry Pi OS 32-bit on RPi4

[15:30] <ugexe> raku -e "say $*KERNEL.version"

[15:30] <ugexe> vWindows.10.Pro

[15:31] <ugexe> so $*KERNEL.version could potentially be a better windows detector 

[15:31] <ugexe> dunno what it says for e.g. cygwin

[15:37] <nine> MasterDuke: I bet on nqp::scwbdisable();/enable

[15:38] <nine> I think you want those around the %!conc_table := %conc_table_clone;

[15:38] <MasterDuke> should i just put them around the whole method body?

[15:38] <nine> The point of those are to prevent a serialization dependency on the object doing the Perl6::Metamodel::Concretization role

[15:39] <nine> Too much of those is just as bad

[15:39] <MasterDuke> k

[15:41] <MasterDuke> oops

[17:01] *** squashable6 joined
[17:05] <lizmat> looks like signal().tap in the end starts the supervisor thread

[17:09] <[Tux]> Rakudo v2021.07-26-g289a62f4a (v6.d) on MoarVM 2021.07-18-g343d0f37f

[17:09] <[Tux]> csv-test-xs-20      0.367 -  0.382

[17:09] <[Tux]> csv-ip5xs           0.876 -  0.878

[17:09] <[Tux]> test-t --race       0.981 -  1.038

[17:09] <[Tux]> test-t              1.993 -  2.034

[17:09] <[Tux]> test                8.410 -  8.550

[17:09] <[Tux]> csv-ip5xs-20        8.844 -  9.163

[17:09] <[Tux]> test-t-20 --race   10.605 - 10.664

[17:09] <[Tux]> csv-parser         27.941 - 28.054

[17:09] <[Tux]> test-t-20          33.604 - 34.722

[17:09] <[Tux]> Next one will be in 2½weeks

[17:09] <lizmat> [Tux]: have a nice holiday!

[17:11] <japhb> [Tux]++  # Enjoy!

[17:12] * japhb wonders if it's possible to get new-disp merged by the time he can run another test

[17:12] *** b2gills left
[17:14] <japhb> lizmat: "signal().tap in the end"?  The one at https://github.com/rakudo/rakudo/blob/master/lib/Telemetry.rakumod#L939 ?

[17:21] <lizmat> yup, and snapper.pm6 calls that sub

[17:22] <lizmat> so maybe we need to copy snapper.rakumod to safe-snapper.rakumod, and remove the call to control-c from snapper

[17:22] <lizmat> so you'd have the option with -Msnapper and -Msafe-snapper

[17:23] <lizmat> but yeah, running snapper.pm6 will always start the supervisor thread in its current state

[17:34] *** mattil joined
[17:47] *** b2gills joined
[18:01] *** mattil left
[18:02] *** mattil joined
[18:02] *** reportable6 left
[18:02] *** reportable6 joined
[18:33] *** nine left
[18:33] *** camelia left
[18:37] *** nine joined
[18:39] *** camelia joined
[18:54] *** kjp_ left
[19:00] *** Altai-man left
[19:00] *** jdv left
[19:00] *** timo left
[19:00] *** jdv joined
[19:00] *** timo joined
[19:00] *** Altai-man joined
[19:08] *** evalable6 joined
[19:52] <Geth> ¦ rakudo: 58ae9394ad | (Daniel Green)++ | src/Perl6/Metamodel/Concretization.nqp

[19:52] <Geth> ¦ rakudo: Make concurrent use of %!conc_table safe

[19:52] <Geth> ¦ rakudo: 

[19:52] <Geth> ¦ rakudo: Because it's used by MRO method dispatch, doing things such as parsing a

[19:52] <Geth> ¦ rakudo: grammar in a start block can cause concurrent access and modification.

[19:52] <Geth> ¦ rakudo: Locking didn't seem to work, but clone->modify-clone->replace-with-clone

[19:52] <Geth> ¦ rakudo: does. Fixes the various hash-related MVM_oops in S17-promise/start.t.

[19:52] <Geth> ¦ rakudo: dogbert17++, nine++, vrurg++

[19:52] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/commit/58ae9394ad

[19:52] <Geth> ¦ rakudo: 6d529046e5 | MasterDuke17++ (committed using GitHub Web editor) | src/Perl6/Metamodel/Concretization.nqp

[19:52] <Geth> ¦ rakudo: Merge pull request #4496 from MasterDuke17/make_concurrent_access_to_concretization_table_safe

[19:52] <Geth> ¦ rakudo: 

[19:52] <Geth> ¦ rakudo: Make concurrent use of %!conc_table safe

[19:52] <Geth> ¦ rakudo: review: https://github.com/rakudo/rakudo/commit/6d529046e5

[19:53] *** kjp joined
[19:54] *** mattil left
[21:07] <gfldex> docs.raku.org is down for me

[21:47] <Altai-man> .tell rba docs.raku.org is not available?

[21:47] <tellable6> Altai-man, I'll pass your message to rba

[21:54] <rba> .

[21:56] <rba> Cloudflares maintenance has already led to outages recentrly. https://www.cloudflarestatus.com

[21:56] <rba> For the

[21:57] <rba> moment I have turned off the proxifying for docs.raku.org and raku.org. 

[21:57] <rba> Give DNS a few minutes time to resolvee the new ip. 

[22:08] <Altai-man> rba, thank you very much for reacting so fast!

[22:23] *** evalable6 left
[22:23] *** linkable6 left
[22:25] *** evalable6 joined
[23:25] <discord-raku-bot> <pie_flavor#7868> it's still busted

[23:25] *** linkable6 joined
[23:42] <rba> Still most of the sites are down. Sorry. http://stats.raku.org

[23:44] <japhb> rba: Still believed to be a Cloudflare sideswipe?

[23:47] <rba> japhb: no, think there is an issue with the webhosting server atm

[23:47] <rba> japhb: notified them and hope it will get fixed soon...

[23:49] <japhb> rba++

