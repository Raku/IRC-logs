[01:05] *** [Coke] left
[01:07] *** [Coke] joined
[06:29] *** coverable6 left
[06:29] *** evalable6 left
[06:29] *** shareable6 left
[06:29] *** bisectable6 left
[06:29] *** linkable6 left
[06:29] *** nativecallable6 left
[06:29] *** greppable6 left
[06:29] *** benchable6 left
[06:29] *** tellable6 left
[06:29] *** sourceable6 left
[06:29] *** quotable6 left
[06:29] *** bloatable6 left
[06:29] *** releasable6 left
[06:29] *** unicodable6 left
[06:29] *** notable6 left
[06:29] *** committable6 left
[06:32] *** linkable6 joined
[06:32] *** shareable6 joined
[06:32] *** bisectable6 joined
[06:32] *** unicodable6 joined
[06:32] *** releasable6 joined
[06:33] *** nativecallable6 joined
[06:33] *** committable6 joined
[06:33] *** evalable6 joined
[06:33] *** coverable6 joined
[06:33] *** notable6 joined
[06:33] *** benchable6 joined
[06:33] *** quotable6 joined
[06:34] *** sourceable6 joined
[06:34] *** greppable6 joined
[06:34] *** tellable6 joined
[06:34] *** bloatable6 joined
[07:25] *** [TuxCM] joined
[08:57] <timo> it's still running without having crashed

[10:39] *** finanalyst joined
[11:47] *** finanalyst left
[13:21] *** [TuxCM] left
[13:35] *** [TuxCM] joined
[13:54] *** finanalyst joined
[15:21] *** MasterDuke joined
[15:23] <MasterDuke> ugexe, timo: have you seen https://github.com/rakudo/rakudo/issues/5872 ? seems like maybe it's actually a problem in App::Prove6? or a precomp bug? or a run/locking bug?

[15:24] *** [TuxCM] left
[15:25] <timo> can you get the stack traces from the other threads? 2, 4 and 6 are interesting

[15:25] <MasterDuke> heh. i forgot to get them all and closed my gdb session overnight

[15:26] <MasterDuke> i'll try to repro

[15:26] <timo> i do think we have a bug with "run" or maybe Proc::Async where making too many async processes may just create an army of workers that are blocking on something and deadlocking that way

[15:28] <timo> but in this case there are not that many

[15:28] <timo> if you can get an rr recording, that would also include subprocesses, which depending on what the actual bug is could also be important to have

[15:29] <timo> but you can also just attach to the subprocesses at the point when it's hanging

[15:30] <MasterDuke> it didn't take too long to happen last time, if i can't get it in a reasonable amount of time i'll trying running it under rr on the desktop

[15:32] <timo> rr has its "chaos mode" as well which can make issues come up faster

[15:32] *** finanalyst left
[15:34] <MasterDuke> ah, it just hung

[15:35] <MasterDuke> https://gist.github.com/MasterDuke17/a147ccbf82c2161f9b7f146ccf3ecc2b

[15:37] <timo> the workers all look like they're waiting for a task to appear on their queue

[15:38] <timo> we don't really have like, a debug command to list stuff on the libuv event loop

[15:39] <MasterDuke> i've never tried to look in the uv event loop

[15:39] <timo> since this is working with subprocesses, there'd be some file handles / pipes with read tasks where something coming from the subprocess, or the input handle becoming writable, would cause things to move further

[15:40] <MasterDuke> should i get a rakudo backtrace in the various threads?

[15:40] <timo> you can. my assumption is they are all in ThreadPoolScheduler's file, the different "start bla launcher" functions

[15:45] <timo> can you look at the processes that live under this rakudo process? like with `ps faux`

[15:45] <timo> you could attach to them and see what they are up to

[15:46] <MasterDuke> gist updated

[15:46] *** finanalyst joined
[15:48] <MasterDuke> gist updated again

[15:49] *** finanalyst_ joined
[15:49] <MasterDuke> no subprocesses

[15:51] <timo> ok, next step would probably be to look exactly at App::Prove6 there

[15:51] *** finanalyst left
[15:52] <MasterDuke> lunchtime, so might be afk on and off. but i'll leave the gdb session open and check the logs if there's anything else i should run

[15:53] <timo> ok

[15:53] <MasterDuke> but i think https://github.com/Leont/app-prove6/blob/master/lib/App/Prove6.rakumod#L52 is the line it's at

[16:06] <leont> The real work there happens in TAP::Harness.run really

[16:15] *** finanalyst_ left
[16:15] <timo> right, the question is what's not finishing up correctly, and that's tricky to answer from within C / gdb

[16:16] *** finanalyst_ joined
[16:16] <MasterDuke> yeah, from the backtraces it doesn't look like any of the threads are in TAP::Harness at the point of the hang

[16:19] <timo> right, everything in TAP::Harness is set up with like, taps on supplies and such

[16:19] <timo> i'm not exactly sure which different Source and Handler classes are relevant to this use case

[16:20] <timo> do you have it as a rr recording btw? or just the current state?

[16:20] <MasterDuke> just the current state

[16:21] <MasterDuke> but it reproed pretty quickly, i can try to get it in rr on the desktop

[16:22] <timo> we could have it in "rr record" and also turn MVM_COVERAGE_LOG=blabla on

[16:33] *** finanalyst_ left
[16:36] <MasterDuke> hm, taking longer to repro there

[16:42] <timo> i've been running the nqp test suite nonstop since yesterday and not a repro in sight :)

[16:45] <MasterDuke> i usually *also* run a rakudo spectest in a loop to increase load

[16:52] <MasterDuke> hm. i wonder if it needs MVM_JIT_DISABLE=1 on the desktop to repro...

[17:00] <timo> is it arm64/aarch64 on the other machine?

[17:01] <MasterDuke> no, x86

[17:01] <timo> ah, 32bit

[17:02] <MasterDuke> x86-64

[17:02] <MasterDuke> zen2

[17:06] <MasterDuke> hm. if i have a rr record running and raku hangs, will ctrl-c safely stop and save the recording?

[17:08] <timo> yeah

[17:08] *** finanalyst_ joined
[17:13] <MasterDuke> well, i have an aarch64 recording, want that?

[17:20] <MasterDuke> but rr definitely is not quite a solid on this system

[17:23] <timo> i'm not sure if i can run an rr replay on my machine, but i also have an aarch64 qemu VM now

[17:24] <MasterDuke> what's that website you use for sending files?

[17:25] <timo> maybe https://sendfiles.dev/

[18:40] <MasterDuke> i know it's pretty late, but https://news.ycombinator.com/item?id=43751076 would be a good place for a raku comment

[18:41] <MasterDuke> unrelated. i looked at the slides for https://archive.fosdem.org/2018/schedule/event/python_regex_derivatives/ but not the talk yet. anybody know if it's relevant for rakudo/nqp/moarvm?

[18:54] *** finanalyst_ left
[18:54] *** finanalyst_ joined
[19:21] *** MasterDuke left
[19:28] *** [TuxCM] joined
[21:02] *** [TuxCM] left
[21:34] <ab5tract> ugexe: I just finished a first pass at Resource::Wrangler. I don't know what I was complaining about, really, it's not hard to set up the transfer of the file to a new path

[21:34] <ab5tract> but I figure it is useful to get the corner cases covered in an ecosystem module

[21:34] <ab5tract> (none of which are covered by my current implementation, but hey :) )

[21:54] *** finanalyst_ left
[21:54] <ab5tract> come to think of it, these corner cases are probably already well taken care of in the distibution internals

[22:15] <ugexe> ab5tract: you'll want to account for multiple version/api/auth

[22:16] <ugexe> i.e. the $prefix should probably default to something like like "/tmp/{nqp::sha1($?DISTRIBUTION.Str)}"

[22:18] <ugexe> otherwise different versions can potentially overwrite the files underneath each other

[22:25] <ugexe> https://github.com/raku-community-modules/OpenSSL/blob/034df90c7b0983e503ed9639fe6e925cf5f982eb/lib/OpenSSL/NativeLib.rakumod#L31-L35

[22:26] <ugexe> there is how i implemented in openssl long ago... it would fall victim to the version issue i just described

[22:26] <ugexe> it could probably use your module instead

[23:22] *** guifa joined
[23:46] *** guifa left
