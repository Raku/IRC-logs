[00:48] *** softmoth left
[00:49] *** softmoth joined
[01:05] *** toddr left
[02:37] *** Kaeipi left
[02:38] *** Kaeipi joined
[03:34] *** cognominal joined
[03:38] *** cognomin_ left
[03:41] *** cognomin_ joined
[03:45] *** cognominal left
[06:48] *** MasterDuke joined
[07:42] *** [Tux] left
[07:59] *** [Tux] joined
[08:48] *** Altai-man_ joined
[09:08] *** Ven`` joined
[09:15] *** sena_kun joined
[09:16] *** Altai-man_ left
[09:43] *** Kaeipi left
[09:43] *** Merfont joined
[09:51] <nine> MasterDuke: is that with timotimo++'s gc_measurement_debughelper branch?

[09:52] *** softmoth left
[10:25] <MasterDuke> nine: yes, with https://github.com/MoarVM/MoarVM/pull/1270 rebased on top of it also

[10:31] <nine> So....we're gonna need some more improvements :)

[10:32] <nine> In the meantime, maybe you can simply add some swap space? Since the memory is used for collecting results, it should only be written once and not read all the time, so performance shouldn't be all that bad

[10:39] <MasterDuke> trying again with a 256gb swap file

[10:43] *** Ven`` left
[10:54] *** Ven`` joined
[11:02] <nine> And yet another mystery: testing our Cro application with ab2 -n20000 -c1 http://localhost:10000/ now shows stable memory usage

[11:02] <nine> However when I test with while curl --silent -o /dev/null 'http://localhost:10000/' ; do true ; done memory usage climbs and climbs

[11:03] <lizmat> is one of those cases hitting the server harder than the other ?

[11:03] <nine> The only differences in the sent requests I see are User-Agent: ApacheBench/2.3 vs User-Agent: curl/7.69.1 and `GET / HTTP/1.0` (ab2) vs `GET / HTTP/1.1` (curl)

[11:03] <lizmat> I would think ab2 would be the faster one, but maybe not ?

[11:04] <nine> lizmat: yeah, I'd bet on ab2 being faster than the shell loop

[11:04] <lizmat> HTTP 1.1 defaults to keep-alive ?

[11:04] <lizmat> could you force curl to use HTTP 1.0 ?

[11:05] <lizmat> also, the shell loop is unended ?

[11:12] <nine> lizmat: that....might be it! With curl --http1.0 memory usage seems to stay in the same region as ab2

[11:13] <jnthn> Hmmm....that's interesting.

[11:13] <lizmat> most modern browsers default to HTTP/1.1 afaik

[11:14] <jnthn> Yes, but they don't make a thousand requests on the connection usually, and I'm guessing it's some leak over many requests on one connection.

[11:14] *** Altai-man_ joined
[11:14] <lizmat> so the benchmark is flawed when using HTTP/1.1 is what you're saying ?

[11:16] <jnthn> Not exactly; there's something to fix, but real-world workloads are less likely to show such an impact.

[11:16] <jnthn> lunch, bbiab

[11:16] <lizmat> nine: perhaps add a "Connection: close" header to the curl case and then use HTTP/1.1

[11:16] *** sena_kun left
[11:22] *** Xliff joined
[11:25] <nine> lizmat: that does indeed help!

[11:31] *** committable6 left
[11:31] *** committable6 joined
[11:37] *** Xliff left
[11:46] <nine> actually not

[11:47] <nine> At 9K requests it's already at 2G RSS. When its stable, it stays around 800M

[11:48] <nine> I'll give --http1.0 a full run now to get conclusive numbers

[11:56] <Geth_> ¦ Blin: bba41de470 | (Aleks-Daniel Jakimenko-Aleksejev)++ | bin/blin.p6

[11:56] <Geth_> ¦ Blin: Remove .chomp

[11:56] <Geth_> ¦ Blin: 

[11:56] <Geth_> ¦ Blin: We *do* need these newlines after all :)

[11:56] <Geth_> ¦ Blin: review: https://github.com/Raku/Blin/commit/bba41de470

[11:56] <AlexDaniel> Altai-man_: ok, the newline issue is fixed ↑

[11:56] <Altai-man_> AlexDaniel++

[11:56] <AlexDaniel> I did test it this time :)

[11:57] <Altai-man_> AlexDaniel, can you try to test November (or almost any other module, really) issue locally? `--old=2020.02 --new=43c7e96f9a5f3ded6d7cbb7e8cc9ddc44b2fe8a9 November` is enough.

[11:57] <AlexDaniel> yeah, already on it

[12:06] <MasterDuke> it's writing profiler output...with an rss of 28.2gb. mem is completely used, 18gb of swap used also

[12:06] <MasterDuke> well, it says it's writing, hasn't created the file yet

[12:07] <AlexDaniel> MasterDuke: do you want me to run something on a machine with 64GB RAM? :)

[12:07] <MasterDuke> `'/home/dan/Source/perl6/install/bin/moar' --libpath='/home/dan/Source/perl6/rakudo/blib' --libpath='/home/dan/Source/perl6/install/share/nqp/lib' rakudo.moarvm --nqp-lib='/home/dan/Source/perl6/rakudo/blib' --setting=NULL.c --ll-exception --profile-compile=core.c.sql --optimize=3 --target=mbc --stagestats --output=blib/CORE.c.setting.moarvm

[12:08] <MasterDuke> 'gen/moar/CORE.c.setting'`, with the right paths for your machine

[12:08] <AlexDaniel> mhm give me a few minutes… :)

[12:13] <timotimo> oh, did nine push a change to split the sql output into smaller chunks?

[12:13] <lizmat> timotimo: yes he did afaik

[12:14] <timotimo> good

[12:23] <MasterDuke> heh. still hasn't started actually writing the file

[12:24] <timotimo> hmm

[12:24] <MasterDuke> timotimo: have any idea why nine's patch is required? think there's an easy fix?

[12:25] <timotimo> it's required because sqlite doesn't like sql statements that are hundreds of megabytes long

[12:25] <timotimo> in the parser

[12:26] <AlexDaniel> MasterDuke: using which rakudo version?

[12:26] <timotimo> but also, writing out more frequently should reduce the peak memory usage

[12:27] <MasterDuke> AlexDaniel: HEAD. might also need nqp at HEAD, not sure if there's been a bump since nine's commit

[12:39] *** gugod joined
[12:41] <AlexDaniel> MasterDuke: OK, it did start doing something

[12:42] <MasterDuke> writing a profile already!?

[12:44] <AlexDaniel> MasterDuke: I don't think so, but it's running

[12:49] <timotimo> can always™ attach gdb, interrupt, print stack trace

[12:49] <timotimo> probably a few thousand frames deep in recursion

[12:49] <timotimo> in the "precompute" phase

[12:50] <AlexDaniel> looking at how it's using just one core and the memory just keeps creeping up slooowly I guess I just leave it running for a few hours? :)

[12:52] <AlexDaniel> if it doesn't actively use all that memory then I guess anyone can just swap it to an SSD and it'll be fine

[12:52] <timotimo> hum. i wonder if there's any way at all to parallelize preprocessing of the tree and consuming the tree to generate the write-out ...

[12:53] <MasterDuke> for sql, the file doesn't need to be in any sort of order (other than the couple create table statements at the beginning. could even the file writing be parallelized?

[12:54] <timotimo> i think i actually use an auto_increment field in many of the tables

[12:55] <jnthn> I wonder if the painfully pragmatic solution is to just generate the SQL string in C from the graph...

[12:56] <AlexDaniel> timotimo: for IDs? UUIDs can do the trick then? :)

[12:56] <timotimo> oh lord

[12:57] *** rypervenche joined
[12:57] <MasterDuke> oh, right

[13:04] <lizmat> afk for a few hours&

[13:06] <MasterDuke> timotimo: wait, why does that matter?

[13:06] <timotimo> saves a bit of memory per entry

[13:07] <timotimo> if the id doesn't have to be written in the file

[13:08] <MasterDuke> well yeah, but then you're just assuming their corresponding values somewhere else?

[13:10] <timotimo> yeah i just increment a number in the code

[13:10] <timotimo> since i can't receive an answer from the sql server what id got allocated

[13:13] <MasterDuke> get_remapped_type_id() ?

[13:15] *** sena_kun joined
[13:16] *** Altai-man_ left
[13:18] <timotimo> is that the lookup or the generation? not sure

[13:18] <MasterDuke> what is this doing? https://github.com/Raku/nqp/blob/master/src/vm/moar/HLL/Backend.nqp#L482

[13:19] <timotimo> empties out the array

[13:20] <MasterDuke> why not just nqp::setelems($pieces, 0)?

[13:20] <timotimo> you know, that's a very good question

[13:21] <AlexDaniel> MasterDuke: and what if it finished without writing the file?

[13:21] <AlexDaniel> it wasn't killed as far as I can see

[13:22] <MasterDuke> oh right. you need to apply https://gist.github.com/niner/8ebb8c6a1052a319d50f9212759d85c4 first

[13:31] <MasterDuke> huh, but it actually seems to be very slightly faster than nqp::setelems($pieces, 0)

[13:33] <AlexDaniel> applied, rerunning

[13:40] <MasterDuke> `62.2g  27.4g   0.9m R  95.0  87.2 171:35.75  5 moar`, be prepared to wait a while

[13:54] <AlexDaniel> MasterDuke: question is, does it need more than 64G?

[13:55] *** squashable6 left
[13:55] <MasterDuke> well, its rss is ~28gb. assuming all swap is it also, that's another 18.5gb

[13:55] <MasterDuke> so, maybe?

[13:56] *** squashable6 joined
[13:56] <AlexDaniel> okay we'll see what happens… I don't have any swap right now as I never thought this machine could possibly need more than 64G

[13:57] <AlexDaniel> but I can add a swap file I guess

[13:57] <nine> timotimo: I think MasterDuke's question about my patch was actually about https://gist.github.com/niner/8ebb8c6a1052a319d50f9212759d85c4 i.e. the END block confusion

[13:57] <MasterDuke> i didn't have any before either, usually if something goes over my 32gb i'm ok with it dying. i just added the swap file for this run, i'll get rid of it after

[14:36] <AlexDaniel> MasterDuke: hah, I came back to an unresponsive black screen

[14:36] <AlexDaniel> so… rerunning

[14:36] <AlexDaniel> don't know what happened there

[14:38] <AlexDaniel> now with a 60G swap file :)

[14:39] <MasterDuke> whoops

[14:41] <MasterDuke> `perf top` is showing MVM_coerce_i_s https://github.com/MoarVM/MoarVM/blob/master/src/core/coerce.c#L203-L227 up near the top (though of course MVM_profile_instrumented_mark_data is dominating everything). any thoughts on how to make that faster?

[14:41] *** Merfont is now known as Kaiepi

[14:42] <jnthn> Is profiling causing a lot of coerce_i_s?

[14:42] <jnthn> Or does it do it without profiling also?

[14:44] <MasterDuke> pretty sure it's the profiling. writing lots of ints to strings for the sql output

[14:45] <jnthn> Ah, writing the data, ok

[14:46] <Geth_> ¦ nqp/jvm-opcode-cleanup: a778b2962b | Coke++ | 2 files

[14:46] <Geth_> ¦ nqp/jvm-opcode-cleanup: remove closefh_i

[14:46] <Geth_> ¦ nqp/jvm-opcode-cleanup: review: https://github.com/Raku/nqp/commit/a778b2962b

[14:48] <MasterDuke> there's gc stuff too of course. but also memcpy and malloc_consolidate

[14:48] <Geth_> ¦ nqp/jvm-opcode-cleanup: 15 commits pushed by Coke++

[14:48] <Geth_> ¦ nqp/jvm-opcode-cleanup: review: https://github.com/Raku/nqp/compare/a778b2962be2...ebab9be457c6

[14:52] <AlexDaniel> sena_kun: yep, I can reproduce!

[15:14] *** Altai-man_ joined
[15:15] *** Ven`` left
[15:16] *** sena_kun left
[15:16] <AlexDaniel> MasterDuke: yep, it claims that it started writing the file, it's using all 64G and 5G of swap right now

[15:17] <MasterDuke> ah ah, mine just actually started writing the file

[15:18] <MasterDuke> only 4 or so hours after starting...

[15:48] *** Ven`` joined
[15:57] <[Coke]> ooh: #  Internal Error (signature.cpp:109), pid=62292, tid=40451

[15:57] <[Coke]> #  Error: ShouldNotReachHere()

[15:57] <[Coke]> #

[15:57] <[Coke]> (running make j-test on jvm with an nqp patch)

[15:59] <[Coke]> running j-test again, no issue. weird.

[16:07] <AlexDaniel> MasterDuke: it died. Segmentation Fault

[16:07] <AlexDaniel> MasterDuke: should I try again?

[16:13] <MasterDuke> guess so, mine's still going

[16:14] <MasterDuke> up to 405mb written

[16:18] <AlexDaniel> MasterDuke: how do you know? I don't see the file

[16:19] <MasterDuke> it just takes a while for it to actually write anything after it says it is

[16:32] *** [Coke] left
[16:35] *** [Coke] joined
[16:35] *** [Coke] left
[16:35] *** [Coke] joined
[16:39] <Geth_> ¦ Blin: 5e65ba0d00 | (Aleks-Daniel Jakimenko-Aleksejev)++ | bin/blin.p6

[16:39] <Geth_> ¦ Blin: Remove warnings about using Any in string context

[16:39] <Geth_> ¦ Blin: 

[16:39] <Geth_> ¦ Blin: `.bisected` can be empty for some modules, so we can't use that for

[16:39] <Geth_> ¦ Blin: sorting. Grep first instead of next-ing inside the loop.

[16:39] <Geth_> ¦ Blin: review: https://github.com/Raku/Blin/commit/5e65ba0d00

[16:39] <Geth_> ¦ Blin: 425719e5e0 | (Aleks-Daniel Jakimenko-Aleksejev)++ | bin/blin.p6

[16:39] <Geth_> ¦ Blin: Remove double space

[16:39] <Geth_> ¦ Blin: review: https://github.com/Raku/Blin/commit/425719e5e0

[16:48] *** patrickb joined
[16:55] <Geth_> ¦ nqp: coke++ created pull request #617: Jvm opcode cleanup

[16:55] <Geth_> ¦ nqp: review: https://github.com/Raku/nqp/pull/617

[17:08] <AlexDaniel> Altai-man_: it's interesting. So the first time it attempts to install November zef finishes with exit code 1 and this output: https://gist.github.com/AlexDaniel/17df1df17383934895b22fadd8ab29da

[17:08] <AlexDaniel> The following packages were stubbed but not defined: November

[17:08] <AlexDaniel> what does that mean?

[17:09] <Altai-man_> AlexDaniel, that's not Blin specific failure, just a breakage of long abandoned module.

[17:09] <AlexDaniel> Altai-man_: yes, but not really

[17:09] <Altai-man_> hm?

[17:09] <Altai-man_> It gives me the same error when installed locally.

[17:10] <AlexDaniel> Altai-man_: either zef or rakudo are getting confused about something

[17:10] <AlexDaniel> Altai-man_: what if you try to install it again? Will it succeed then?

[17:11] <Altai-man_> On 2020.02 the same result.

[17:11] <AlexDaniel> point is, I think it succeeds if you try to install it twice

[17:12] <Altai-man_> You can try some other module, e.g. Module::Toolkit.

[17:12] <Altai-man_> Let me check again...

[17:13] <AlexDaniel> in some sense Blin is perhaps wrong because it attempts to --install-to into the same dir?

[17:13] <AlexDaniel> I never thought about that

[17:15] *** sena_kun joined
[17:16] <sena_kun> AlexDaniel, the same result for me.

[17:16] <sena_kun> I agree this is either a rakudo or zef bug in processing of something, but don't have time right now to dig. :(

[17:17] *** Altai-man_ left
[17:17] <MasterDuke> huh, why do i get no output (or file written) when i try to callgrind an nqp one-liner? i do when i run some random other thing

[17:19] *** AlexDaniel left
[17:20] *** AlexDaniel joined
[17:20] *** AlexDaniel left
[17:20] *** AlexDaniel joined
[17:21] <AlexDaniel> sena_kun: what do you mean same result?

[17:21] <sena_kun> AlexDaniel, the same output as in your gist each time.

[17:21] <AlexDaniel> hmm

[17:22] <sena_kun> Module::Toolkit is more interesting, by the way. It does clearly indicate something is very broken and then says "Ok, we installed that" and it is indeed listed in installed modules, can be uninstalled etc.

[17:22] <sena_kun> Maybe can start investigating from this one.

[17:22] <MasterDuke> huh again. works when i use the nqp i installed, but not when i ./nqp-m in my nqp directory (though it work no under valgrind)

[17:24] <timotimo> how much memory usage do we have while profiling a core setting compilation? upwards of 20 gigs? 30?

[17:43] <MasterDuke> top is showing my res at 27.4g and my virt at 65g. i had to add a swap file, it has 26g used

[17:44] <MasterDuke> currently 1.1g of profile written, but it's still going

[17:47] <timotimo> get yourself a copy of "smem" and run "sudo smem -kas swap"

[17:47] <Geth_> ¦ rakudo: 9b66980d25 | (Patrick Böker)++ | 3 files

[17:47] <Geth_> ¦ rakudo: Fix bug report URL in binary release README

[17:47] <Geth_> ¦ rakudo: review: https://github.com/rakudo/rakudo/commit/9b66980d25

[17:51] <MasterDuke> timotimo: `247918 dan              /home/dan/Source/perl6/install/bin/moar --libpath=/home/dan/Source/perl6/rakudo/blib --libpath=/home/dan/Source/perl6/install/share/nqp/lib rakudo.moarvm --nqp-lib=/home/dan/Source/perl6   38.2G   27.5G   27.5G   27.5G`

[17:51] <timotimo> oh my

[17:51] <timotimo> already almost 40 gigs swapped out :D

[18:03] <Geth_> ¦ nqp: 2853a1a5fa | (Jonathan Worthington)++ | 2 files

[18:03] <Geth_> ¦ nqp: Support anon declarator on NQP subs

[18:03] <Geth_> ¦ nqp: 

[18:03] <Geth_> ¦ nqp: So that in places like the Rakudo bootstrap, we can give the sub we use

[18:03] <Geth_> ¦ nqp: for setting up the various built-in methods names, but not have them get

[18:03] <Geth_> ¦ nqp: installed anywhere.

[18:03] <Geth_> ¦ nqp: review: https://github.com/Raku/nqp/commit/2853a1a5fa

[18:04] *** robertle joined
[18:26] <Geth_> ¦ nqp: patrickbkr++ created pull request #618: Static nqp home hll var

[18:26] <Geth_> ¦ nqp: review: https://github.com/Raku/nqp/pull/618

[18:26] <Geth_> ¦ nqp: e27b394231 | (Patrick Böker)++ | 7 files

[18:26] <Geth_> ¦ nqp: Revert "Revert "Merge pull request #611 from patrickbkr/static-nqp-home-hll-var""

[18:26] <Geth_> ¦ nqp: 

[18:26] <Geth_> ¦ nqp: This reverts commit e89893ed7309636536786f5b974c418c2582568a.

[18:26] <Geth_> ¦ nqp: review: https://github.com/Raku/nqp/commit/e27b394231

[18:26] <Geth_> ¦ nqp: fbae77eaac | (Patrick Böker)++ | tools/templates/jvm/Makefile.in

[18:26] <Geth_> ¦ nqp: Add a missing dependency in Makefile rule

[18:27] <Geth_> ¦ nqp: 

[18:27] <Geth_> ¦ nqp: This broke building in some cases.

[18:27] <Geth_> ¦ nqp: review: https://github.com/Raku/nqp/commit/fbae77eaac

[18:27] <Geth_> ¦ nqp: cd87855866 | (Patrick Böker)++ (committed using GitHub Web editor) | 7 files

[18:27] <Geth_> ¦ nqp: Merge pull request #618 from patrickbkr/static-nqp-home-hll-var

[18:27] <Geth_> ¦ nqp: 

[18:27] <Geth_> ¦ nqp: Static nqp home hll var

[18:27] <Geth_> ¦ nqp: review: https://github.com/Raku/nqp/commit/cd87855866

[18:30] <Geth_> ¦ rakudo/master: 5 commits pushed by (Patrick Böker)++, (Patrick Boeker)++

[18:30] <Geth_> ¦ rakudo/master: 8759240778 | Bump NQP

[18:30] <Geth_> ¦ rakudo/master: 2a08b1652f | Bump nqp-configure to allow '-' in build config variables

[18:30] <Geth_> ¦ rakudo/master: 94fdb3d517 | Fix `--nqp-home` Configure.pl parameter

[18:30] <Geth_> ¦ rakudo/master: 59fe24bce9 | Fix up JVM backend to work again after the static nqp home changes

[18:30] <Geth_> ¦ rakudo/master: a4906a713b | Merge pull request #3602 from patrickbkr/issue-3581

[18:30] <Geth_> ¦ rakudo/master: review: https://github.com/rakudo/rakudo/compare/285da3b8faac...a4906a713b75

[18:37] <AlexDaniel> MasterDuke: it segfaulted again. Sooo… good luck!

[18:49] *** patrickb left
[18:50] *** hankache joined
[18:55] *** patrickb joined
[18:55] *** softmoth joined
[18:59] *** robertle left
[19:02] *** robertle joined
[19:05] <Geth_> ¦ rakudo/rakuast: 36 commits pushed by (Jonathan Worthington)++

[19:05] <Geth_> ¦ rakudo/rakuast: review: https://github.com/rakudo/rakudo/compare/d79010918513^...d7105acf80b1

[19:06] <[Coke]> there it is!

[19:06] <jnthn> Only so much done so far, but it's a start. :-)

[19:07] <jnthn> Needs NQP HEAD (the anon sub commit I pushed there earlier today)

[19:10] <[Coke]> do we have a preference on PRs for merge vs. rebae?

[19:14] *** Altai-man_ joined
[19:15] <AlexDaniel> [Coke]: just merge, unless there's a reason to rebase

[19:16] <AlexDaniel> a reason could be for example that the PR is very old

[19:16] *** sena_kun left
[19:16] <[Coke]> this one is very recent, but understood.

[19:16] <Geth_> ¦ nqp/master: 17 commits pushed by Coke++, (Will Coleda)++

[19:16] <Geth_> ¦ nqp/master: review: https://github.com/Raku/nqp/compare/cd8785586688...892bbc0bdf7b

[19:22] <hankache> Hello *

[19:23] <[Coke]> ~~

[19:23] <hankache> what is the Raku native type equivalent of wchar_t?

[19:25] <[Coke]> MasterDuke: hi

[19:26] *** lichtkind joined
[19:27] <[Coke]> MasterDuke: the change you made to nqp docs is causing a test failure. I assume it means the doc test is broken.

[19:27] *** robertle left
[19:27] *** lucasb joined
[19:33] *** patrickb left
[19:36] *** patrickb joined
[19:39] <MasterDuke> do you know which change?

[19:47] <lizmat> nqp:: anon sub { "42" }

[19:47] <MasterDuke> i'm getting a failure before my change

[19:47] <patrickb> rba: I have updated a new revision of the windows 2020.02.1 binary release here: https://rooster.uber.space/patcloud/index.php/s/qmkreEJLQDZcjbf

[19:48] <lizmat> jnthn: I think anon sub commit is already in rakudo HEAD

[19:48] <MasterDuke> `Malformed UTF-8 near bytes 00 00 b2 at gen/moar/stage2/NQPCORE.setting:809  (/usr/share/nqp/lib/NQPCORE.setting.moarvm:consume-all-chars)` for t/docs/tests.t

[19:48] <patrickb> rba: It's named rakudo-moar-2020.02.1-02-win-x86_64.zip/asc

[19:48] <patrickb> rba: Can you upload?

[19:57] *** hankache left
[20:11] <rba> patrickb: sure give me a sec. 

[20:30] <jnthn> lizmat: Ah yes, somebody did indeed do a dump since then :)

[20:30] <jnthn> Hadn't noticed that

[20:30] <lizmat> how did you know I just did that?  :-)

[20:31] <jnthn> oops, bump :D

[20:52] *** Ven`` left
[20:59] <[Coke]> MasterDuke: it was removing the smrt_, I think

[21:00] <[Coke]> a5332ac14 ?

[21:00] <linkable6> (2020-04-15) https://github.com/Raku/nqp/commit/a5332ac14e smrt_(int|num|str)ify -> (int|num|str)ify

[21:00] <[Coke]> ooh, nifty.

[21:00] <[Coke]> doc test complains: not ok 1542 - documented op 'strify' exists in moar

[21:01] <[Coke]> doc test cheats (and fails sometimes) to figure out which ops are defined in each backend.

[21:12] <[Coke]> also failing: not ok 728 - Opcode 'smrt_strify' (moar) is documented

[21:12] <[Coke]> nqp: nqp::say(nqp::smrt_strify(3))

[21:12] <camelia> nqp-moarvm: OUTPUT: «No registered operation handler for 'smrt_strify'␤   at gen/moar/stage2/QAST.nqp:1504  (/home/camelia/rakudo-m-inst-1/share/nqp/lib/QAST.moarvm:compile_op)␤ from gen/moar/stage2/QAST.nqp:6145  (/home/camelia/rakudo-m-inst-1/share/nqp/lib/QAST.moarvm:compile_…»

[21:13] <[Coke]> nqp: nqp::say(nqp::strify(3))

[21:13] <camelia> nqp-moarvm: OUTPUT: «No registered operation handler for 'strify'␤   at gen/moar/stage2/QAST.nqp:1504  (/home/camelia/rakudo-m-inst-1/share/nqp/lib/QAST.moarvm:compile_op)␤ from gen/moar/stage2/QAST.nqp:6145  (/home/camelia/rakudo-m-inst-1/share/nqp/lib/QAST.moarvm:compile_node)…»

[21:13] <[Coke]> looks like there is a reference to smrt_strify in src/vm/moar/QAST/QASTOperationsMAST.nqp

[21:14] *** donaldh joined
[21:15] *** sena_kun joined
[21:16] *** Altai-man_ left
[21:25] *** patrickb left
[21:26] *** patrickb joined
[21:26] *** sena_kun left
[21:27] *** Summertime left
[21:27] *** Summertime joined
[21:34] *** dogbert17 joined
[21:45] <rba> patrickb: uploaded.

[21:46] <patrickb> rba: Looking good. Thanks!

[22:03] *** patrickb left
[22:03] *** softmoth left
[22:04] *** softmoth joined
[22:09] *** softmoth left
[22:09] *** softmoth joined
[22:10] <AlexDaniel> Altai-man_: https://github.com/ugexe/zef/issues/342

[22:10] <tellable6> AlexDaniel, I'll pass your message to Altai-man_

[22:12] <AlexDaniel> Altai-man_: I don't know if it's the only issue, but at least it's something I was able to reproduce on my own setup

[22:12] <tellable6> AlexDaniel, I'll pass your message to Altai-man_

[22:31] <MasterDuke> woohoo, finally finished! don't know exactly how long that took, but i think over 10 hours. 3.2g file created

[22:52] <timotimo> incredible

[22:52] *** softmoth left
[22:54] <MasterDuke> hm, but not sure how correct the values are...

[22:55] <MasterDuke> it says https://github.com/Raku/nqp/blob/master/src/how/NQPClassHOW.nqp#L586-L588 is the most expensive by exclusive time

[22:56] <timotimo> yeah that seems odd

[22:57] <MasterDuke> do you want the sqlite3 file? it's only 1.7g

[23:06] <timotimo> i wonder how much zstd can do with that

[23:10] <MasterDuke> zst of the original sql file is only 615mb

[23:11] <MasterDuke> zstd of the sqlite file is 650mb

[23:14] *** lichtkind left
[23:17] <timotimo> ha, that's fun

[23:17] <timotimo> i'll take the sqlite file anyway

[23:17] <timotimo> not sure how, tho

[23:20] <MasterDuke> what's that file transfer service we've used before?

[23:23] <MasterDuke> from moarperf: "The profiled code ran for 1,852,391.13ms", "The Garbage Collector ran 1613 times. 1 GC runs inspected the entire heap", "GC runs have taken 86.45% of total run time", 

[23:24] <MasterDuke> but it thinks there weren't any allocations?

[23:31] <MasterDuke> timotimo: https://send.firefox.com/download/e038cb2efe8f25a3/#HXEpTYJDddukU-ijUAWoyw

[23:36] <MasterDuke> moarperf is showing more expected things for routines. i guess my sql query was wrong

[23:54] *** softmoth joined
[23:54] <timotimo> sharedrop.io or something?

[23:55] *** MasterDuke left
