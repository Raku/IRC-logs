[00:42] *** evalable6 left
[00:42] *** notable6 left
[00:42] *** tellable6 left
[00:42] *** bisectable6 left
[00:42] *** unicodable6 left
[00:42] *** nativecallable6 left
[00:42] *** bloatable6 left
[00:42] *** squashable6 left
[00:42] *** committable6 left
[00:42] *** shareable6 left
[00:42] *** releasable6 left
[00:42] *** greppable6 left
[00:42] *** statisfiable6 left
[00:42] *** sourceable6 left
[00:42] *** benchable6 left
[00:42] *** coverable6 left
[00:42] *** quotable6 left
[00:42] *** linkable6 left
[00:42] *** reportable6 left
[00:42] *** evalable6 joined
[00:42] *** nativecallable6 joined
[00:42] *** committable6 joined
[00:42] *** releasable6 joined
[00:42] *** reportable6 joined
[00:43] *** unicodable6 joined
[00:43] *** tellable6 joined
[00:43] *** statisfiable6 joined
[00:43] *** quotable6 joined
[00:43] *** squashable6 joined
[00:44] *** bisectable6 joined
[00:44] *** bloatable6 joined
[00:44] *** linkable6 joined
[00:44] *** shareable6 joined
[00:44] *** greppable6 joined
[00:45] *** coverable6 joined
[00:45] *** notable6 joined
[00:45] *** benchable6 joined
[00:45] *** sourceable6 joined
[02:15] *** AlexDani` left
[02:16] *** AlexDani` joined
[03:31] *** MasterDuke left
[04:37] *** Kaiepi left
[04:47] *** Kaiepi joined
[06:44] *** MasterDuke joined
[08:12] *** shareable6 left
[08:12] *** notable6 left
[08:12] *** evalable6 left
[08:12] *** releasable6 left
[08:12] *** nativecallable6 left
[08:12] *** benchable6 left
[08:12] *** tellable6 left
[08:12] *** statisfiable6 left
[08:12] *** greppable6 left
[08:12] *** bisectable6 left
[08:12] *** unicodable6 left
[08:12] *** quotable6 left
[08:12] *** committable6 left
[08:12] *** reportable6 left
[08:12] *** squashable6 left
[08:12] *** linkable6 left
[08:12] *** sourceable6 left
[08:12] *** bloatable6 left
[08:12] *** coverable6 left
[08:13] *** releasable6 joined
[08:13] *** bisectable6 joined
[08:13] *** nativecallable6 joined
[08:13] *** notable6 joined
[08:13] *** unicodable6 joined
[08:13] *** statisfiable6 joined
[08:13] *** linkable6 joined
[08:14] *** coverable6 joined
[08:14] *** quotable6 joined
[08:14] *** sourceable6 joined
[08:14] *** tellable6 joined
[08:14] *** benchable6 joined
[08:14] *** evalable6 joined
[08:14] *** squashable6 joined
[08:15] *** shareable6 joined
[08:15] *** bloatable6 joined
[08:15] *** greppable6 joined
[08:15] *** reportable6 joined
[08:15] *** committable6 joined
[08:43] *** Summertime left
[08:45] *** Summertime joined
[08:52] <lizmat> Files=1306, Tests=111230, 223 wallclock secs (29.02 usr  8.37 sys + 3028.17 cusr 279.57 csys = 3345.13 CPU)

[08:53] <lizmat> hmmm..  50 CPU secs more than the last time

[08:53] <lizmat> weird

[09:15] *** sena_kun joined
[09:50] <MasterDuke> the new tests you added running in parallel with existing tests, so same wallclock, but more cpu?

[09:57] <lizmat> you mean the new ... tests ?  they are not part of make spectest yet

[09:57] <lizmat> wallclock is 11 more than yesterday

[10:01] <MasterDuke> huh. i just ran one and the numbers didn't look crazy, but i reset yesterday so i don't have any scrollback to actually compare to

[10:13] *** Kaiepi left
[10:14] *** Kaiepi joined
[10:39] *** Altai-man_ joined
[10:41] *** sena_kun left
[10:44] *** Kaiepi left
[10:44] *** Kaiepi joined
[11:22] *** AlexDani` is now known as AlexDaniel

[11:22] *** AlexDaniel left
[11:22] *** AlexDaniel joined
[11:27] <AlexDaniel> tellable6: Xliff

[11:27] <tellable6> AlexDaniel, I saw Xliff 2020-04-07T23:45:41Z in #raku-dev: <Xliff> Hmm....

[11:27] <AlexDaniel> hmmm

[11:41] *** Xliff joined
[11:41] <Xliff> \o

[11:42] <Xliff> m: my $a = '%s is rw'; my $start = now; for ^10000 { for <loop hah dur feta> { my $b - $a.sprintf($_); ); LAST say now - $start; }; 

[11:42] <camelia> rakudo-moar 3c83ce75a: OUTPUT: «5===SORRY!5=== Error while compiling <tmp>␤Missing block␤at <tmp>:1␤------> 3hah dur feta> { my $b - $a.sprintf($_); 7⏏5); LAST say now - $start; };␤»

[11:42] <Xliff> m: my $a = '%s is rw'; my $start = now; for ^10000 { for <loop hah dur feta> { my $b - $a.sprintf($_); }; LAST say now - $start; }; 

[11:42] <camelia> rakudo-moar 3c83ce75a: OUTPUT: «WARNINGS for <tmp>:␤Useless use of "-" in expression "my $b - $a.sprintf($_)" in sink context (line 1)␤Use of uninitialized value of type Any in numeric context␤  in block  at <tmp> line 1␤Cannot convert string to number: base-10 number must b…»

[11:42] <Xliff> m: my $a = '%s is rw'; my $start = now; for ^10000 { for <loop hah dur feta> { my $b = $a.sprintf($_); }; LAST say now - $start; }; 

[11:42] <camelia> rakudo-moar 3c83ce75a: OUTPUT: «4.5798884␤»

[11:43] <Xliff> Is it just me, or is that awfully slow? (It's even slower on https://repl.it/languages/perl6)

[11:45] *** Kaiepi left
[11:46] <MasterDuke> Xliff: sprintf is know to be very slow. lizmat is/was working on a faster reimplementation

[11:47] <lizmat> it's on the back burner atm

[11:47] <lizmat> the problem with sprintf is that it uses a grammar

[11:48] <lizmat> and *every* call to sprintf parses the format string with the grammar, and the associated actions build the result string

[11:48] <lizmat> my approach would let the grammar parse the format string once, build a piece of code, EVAL that and cache that

[11:49] <lizmat> problem with that approach is that the EVAL overhead is only cancelled out after about 100 runs of the same format string

[11:49] <lizmat> before that, my approach is slower

[11:50] <lizmat> am now thinking of building AST's to prevent the expensive EVAL step

[11:50] <lizmat> and hoping that jnthn's work on macros will make that a lot easier

[11:50] <jnthn> Speaking of which, just published the talk slides and a video about that: https://twitter.com/jnthnwrthngtn/status/1248941150666461185

[11:51] *** Kaiepi joined
[11:51] <Geth_> ¦ rakudo: b9105f1a8b | (Elizabeth Mattijsen)++ | 3 files

[11:51] <Geth_> ¦ rakudo: Show that the Supply class is spread over 3 files

[11:51] <Geth_> ¦ rakudo: 

[11:51] <Geth_> ¦ rakudo: Should fix R#3615

[11:51] <Geth_> ¦ rakudo: review: https://github.com/rakudo/rakudo/commit/b9105f1a8b

[11:51] <linkable6> R#3615 [open]: https://github.com/rakudo/rakudo/issues/3615 Closing curly brace missing?

[11:52] <jnthn> Why is it spread over 3 files, btw? I never know where to look any more. :P

[11:52] <jnthn> (Though `git grep` to the rescue)

[11:53] *** Kaiepi left
[11:54] *** Kaiepi joined
[11:54] <lizmat> I guess for the same reason we have an Any.pm6 and a Any-iterable.pm6 ?

[11:55] <lizmat> I split it up because I was adding quite a few methods, and it already had a separation in core / factories / coercers sort of

[11:56] <lizmat> jnthn: if you want it merged again, I can do that

[11:56] <jnthn> Don't worry for now, I don't really work on CORE.setting

[11:56] <jnthn> So it's not that important what I think :)

[11:59] <nine> jnthn: it's kinda nice that with the video, you can actually stand in front of the nice background instead of just showing a pretty picture on the projector :)

[11:59] *** Kaiepi left
[12:00] *** Kaiepi joined
[12:00] <nine> That's something that one could take further....a lot further... like speaking in front of a pretty mountain top, some nice woods, a jungle...

[12:01] <nine> Somehow I end up with a very Bear Grylls like into with jnthn in a helicopter next to the open door over some waterfall "Hi folks, let's talk about object models"

[12:01] <nine> s/into/intro/

[12:02] <jnthn> :D

[12:09] <AlexDaniel> lizmat: I just realized that you can use … with multiple values and it's a bugnest of its own

[12:09] <AlexDaniel> m: .say for 1…5.5

[12:09] <camelia> rakudo-moar 3c83ce75a: OUTPUT: «1␤2␤3␤4␤5␤»

[12:09] <lizmat> it is :-)

[12:09] <AlexDaniel> m: .say for 1…3…5.5

[12:09] <camelia> rakudo-moar 3c83ce75a: OUTPUT: «1␤2␤3␤4␤5␤5.5␤»

[12:10] <AlexDaniel> should be the same I think

[12:10] <lizmat> agree

[12:10] <AlexDaniel> and this I don't even know how it's supposed to behave:

[12:10] <AlexDaniel> m: .say for 1…5.5…1

[12:10] <camelia> rakudo-moar 3c83ce75a: OUTPUT: «1␤2␤3␤4␤5␤5.5␤4.5␤3.5␤2.5␤1.5␤1␤»

[12:11] <AlexDaniel> lizmat: at least you can't do that with …^, that's nice

[12:11] <AlexDaniel> but

[12:11] <AlexDaniel> m: .say for 1^…^3^…^5.5

[12:11] <camelia> rakudo-moar 3c83ce75a: OUTPUT: «2␤3␤4␤5␤5.5␤»

[12:12] <AlexDaniel> I mean… um… whatever…

[12:13] <AlexDaniel> and you know what?

[12:13] <AlexDaniel> you can also do that with strings, because of course we have that special case

[12:14] <AlexDaniel> m: .say for "ac"^…^"cc"^…^"ac"

[12:14] <camelia> rakudo-moar b9105f1a8: OUTPUT: «bc␤cc␤cc␤bc␤ac␤ac␤»

[12:14] <AlexDaniel> not that it works any better without ^…^

[12:14] <AlexDaniel> m: .say for "ac"…"cc"…"ac"

[12:14] <camelia> rakudo-moar b9105f1a8: OUTPUT: «ac␤bc␤cc␤cc␤bc␤ac␤ac␤»

[12:17] <AlexDaniel> and you'd think that it'd work better with the generic .succ/.pred case

[12:17] <jnthn> If I'd had to guess, I'd have thought ... was non-assoc...

[12:17] <AlexDaniel> m: .say for "a".IO…"c".IO…"c".I

[12:17] <camelia> rakudo-moar b9105f1a8: OUTPUT: «No such method 'I' for invocant of type 'Str'. Did you mean 'IO'?␤  in block <unit> at <tmp> line 1␤␤»

[12:18] <AlexDaniel> jnthn: if I had to guess I'd have thought that … uses .succ/.pred instead of doing magic

[12:19] <jnthn> AlexDaniel: I tend to consider ... as the thing that *does* to magic (e.g. deducing sequences) as opposed to Range (which is far simpler because all the magic was put into ...).

[12:19] <jnthn> *do

[12:19] <AlexDaniel> then we end up with both ops doing magic :)

[12:20] <AlexDaniel> m: .say for "a".IO…"c".IO…"c".IO

[12:20] <camelia> rakudo-moar b9105f1a8: OUTPUT: «"a".IO␤Cannot get sequence start value from an empty list␤  in block <unit> at <tmp> line 1␤␤"b".IO␤"c".IO␤»

[12:20] <jnthn> I don't know that .. is especially magical?

[12:21] <jnthn> I mean, for strings it knows unicode ranges, and I'm not sure those are actually part of the Unicode spec, which is arguably magical

[12:22] <AlexDaniel> jnthn: unicode ranges? You mean pattern generation?

[12:23] <AlexDaniel> like, this is far from being a range:

[12:23] <AlexDaniel> m: .say for ‘aa’..‘ca’

[12:23] <camelia> rakudo-moar b9105f1a8: OUTPUT: «aa␤ba␤ca␤»

[12:23] <AlexDaniel> and this is more like a range:

[12:23] <AlexDaniel> m: .say for ‘aa’.IO..‘ca’.IO

[12:23] <camelia> rakudo-moar b9105f1a8: OUTPUT: «"aa".IO␤"ab".IO␤"ac".IO␤"ad".IO␤"ae".IO␤"af".IO␤"ag".IO␤"ah".IO␤"ai".IO␤"aj".IO␤"ak".IO␤"al".IO␤"am".IO␤"an".IO␤"ao".IO␤"ap".IO␤"aq".IO␤"ar".IO␤"as".IO␤"at".IO␤"au".IO␤"av".IO␤"aw".IO␤"ax".IO␤"ay".IO␤"…»

[12:23] <lizmat> the default is to use .succ

[12:23] <jnthn> Oh wait, that's actaully derived from .succ behavior :)

[12:23] <jnthn> So the "magic" is just there

[12:24] <jnthn> So what *does* ... do on Str? :)

[12:24] <AlexDaniel> same as .. some sort of string generation based on the patterns you give

[12:25] <jnthn> m: say "a", "c" ... "x"

[12:25] <camelia> rakudo-moar b9105f1a8: OUTPUT: «(a c d e f g h i j k l m n o p q r s t u v w x)␤»

[12:25] <AlexDaniel> pfffft

[12:25] <jnthn> Arguably that should be "a", "c", "e", though maybe that's asking for trouble :P

[12:26] <AlexDaniel> .oO( coming up: geometric string ranges )

[12:26] <jnthn> I'm not convinced it's actually very useful :)

[12:26] <lizmat> I think in the specs, TimToady said to only do that magic on numerics

[12:27] <jnthn> Yeah

[12:27] <AlexDaniel> I mean, sequences, but you get the point :)

[12:27] <jnthn> I mean, even dice faces, but by the time you specified 2, 4, and 6 you've written the full list of them :P

[12:27] *** Kaeipi joined
[12:27] *** Kaiepi left
[12:27] <lizmat> also, 'a' ... 'c' will do codepoint increment if both endpoints are 1 codepoint

[12:28] <jnthn> So yeah, I'd agree with TimToady to keep deduction just to numerics

[12:28] <lizmat> otherwise it will do .succ

[12:28] <jnthn> Hmm, why?

[12:28] <lizmat> jnthn: ask TimToady ?

[12:29] <jnthn> haha :)

[12:29] <lizmat> but basically, anything that knows how to do .succ should work

[12:29] <lizmat> m: dd Date.today ... Date.new(2020,5,1)

[12:29] <camelia> rakudo-moar b9105f1a8: OUTPUT: «(Date.new(2020,4,11), Date.new(2020,4,12), Date.new(2020,4,13), Date.new(2020,4,14), Date.new(2020,4,15), Date.new(2020,4,16), Date.new(2020,4,17), Date.new(2020,4,18), Date.new(2020,4,19), Date.new(2020,4,20), Date.new(2020,4,21), Date.new(2020,4,22)…»

[12:29] <jnthn> Yes, that makes sense, I'm just not sure why single codepoints are different, and wondering if it was just optimization or something else.

[12:30] <lizmat> I don't think it's an optimization, it's to allow things like this to work:

[12:30] <AlexDaniel> jnthn: dunno if you read my thoughts on it some time ago, but even if we do remove special casing for Strs and just let it .succ then we'll still have this issue:

[12:30] <AlexDaniel> m: .say for (‘-5’..*)[^10]

[12:30] <camelia> rakudo-moar b9105f1a8: OUTPUT: «-5␤-6␤-7␤-8␤-9␤-10␤-11␤-12␤-13␤-14␤»

[12:30] <AlexDaniel> which is kinda bad in its own way

[12:30] <lizmat> m: dd "█" ... "▁"

[12:30] <camelia> rakudo-moar b9105f1a8: OUTPUT: «("█", "▇", "▆", "▅", "▄", "▃", "▂", "▁").Seq␤»

[12:32] <AlexDaniel> uniprop: █

[12:32] <AlexDaniel> unidump: █

[12:32] <unicodable6> AlexDaniel, https://gist.github.com/301a4a59a8580703444445d72b7db42d

[12:40] *** sena_kun joined
[12:41] *** Altai-man_ left
[13:02] <nine> I've just looked through our HTML templating modules and none of them, not even Cro::WebApp::Template does the right thing and puts a compiled result into a precomp store :(

[13:02] <Xliff> nine++: I was wondering about that.

[13:03] <Xliff> nine: What do you think... Templates compile down to a QAST?

[13:06] <nine> Xliff: well Cro::WebApp::Template for example compiles the template into Raku and EVALs that.

[13:07] <nine> The precomp store and the precompilation repository would provide lots of very useful functionality for such a used case, e.g. all the up-to-date checking

[13:07] <lizmat> jnthn: just having watched your excellent presentation... looking forward to the initial release and applying my sprintf work on it

[13:07] *** Kaeipi left
[13:08] <lizmat> jnthn: one question, re LessVM: have you considered going for something like LLVM as a base ?   And if not, why not  :-)

[13:09] <jnthn> nine: I tried to do some kind of precomp for template modules (e.g. where you have a distribution just for templates) and ran into trouble.

[13:09] <jnthn> nine: And didn't have time to debug it (actually needed to work on the project we were meant to be delivering :))

[13:09] <Xliff> nine: Ahh. Yeah. It would be nice take said Raku and get it rendered into a QAST. Then we can take that to bytecode.

[13:11] *** Kaiepi joined
[13:11] <jnthn> nine: On templates at development time, though, I'd like an option to reload the on any change without restarting the process during development, because it's a bit of a waste to restart the whole process just for a template tweak (especially when doing visual/layout tweaks)

[13:12] <nine> true, true

[13:13] <jnthn> lizmat: Well, the whole joke there is largely that "less is moar" - e.g. it's evolution rather than revolution. :) There are numerous articles out there on the downsides of LLVM for a dynamic language JIT from those who have tried it, however.

[13:13] <jnthn> Well, maybe numerous overstates it, but they exist.

[13:14] *** Kaiepi left
[13:14] *** Kaiepi joined
[13:14] <sena_kun> oh, there is a talk released? link pls?

[13:15] <lizmat> https://twitter.com/jnthnwrthngtn/status/1248941150666461185

[13:16] <sena_kun> yay, thanks! will watch after $dayjob...

[13:38] *** Kaiepi left
[13:44] *** Kaiepi joined
[13:56] <MasterDuke> jnthn++ very interesting

[14:06] *** Kaeipi joined
[14:06] * nine is quite proud that he thought of the bootstrap issue and that the variable is gonna need a block to live in bevore jnthn said it :)

[14:07] *** Kaiepi left
[14:38] <nine> Sounds like in the end, the mbc backend I wrote in NQP will be somewhat beneficial for the RakuAST and maybe even for migrating spesh into the higher levels :)

[14:39] *** Altai-man_ joined
[14:42] *** sena_kun left
[14:57] <Kaeipi> the rakuast stuff is really exciting, macros are something i've wanted to be usable for a long time

[15:10] <Xliff> Same here

[15:51] *** patrickb joined
[16:09] <Geth_> ¦ nqp: acf41ba617 | Coke++ | docs/ops.markdown

[16:09] <Geth_> ¦ nqp: Add substr3 doc

[16:09] <Geth_> ¦ nqp: review: https://github.com/Raku/nqp/commit/acf41ba617

[16:27] <[Coke]> going through docs, I see a lot of VM specific opcodes. Should we be working towards unifying the opcode set?

[16:28] <[Coke]> e.g. : 'rindexfromend' in the JVM backend only. it's only used to supply the 2 arg version of rindex

[16:29] <[Coke]> (I see that they're tagged as "Internal" in the docs (need to update the doc test to understand that), but that's just advisory.

[16:40] *** sena_kun joined
[16:41] *** Altai-man_ left
[17:22] <Geth_> ¦ nqp: 6ad50effff | Coke++ | t/docs/opcodes.t

[17:22] <Geth_> ¦ nqp: allow VM overrides at the opcode level...

[17:22] <Geth_> ¦ nqp: 

[17:22] <Geth_> ¦ nqp: ... not just for the heading row. Follows what the

[17:22] <Geth_> ¦ nqp: existing markdown was already doing, improves test reporting

[17:22] <Geth_> ¦ nqp: review: https://github.com/Raku/nqp/commit/6ad50effff

[17:22] <Geth_> ¦ nqp: f6906e4678 | Coke++ | docs/ops.markdown

[17:22] <Geth_> ¦ nqp: Update VM marks

[17:22] <Geth_> ¦ nqp: review: https://github.com/Raku/nqp/commit/f6906e4678

[17:26] <Geth_> ¦ nqp: 1c3a49def5 | Coke++ | docs/ops.markdown

[17:26] <Geth_> ¦ nqp: Treat JS-specific NFG opcodes as variants

[17:26] <Geth_> ¦ nqp: review: https://github.com/Raku/nqp/commit/1c3a49def5

[17:32] <Geth_> ¦ nqp: 9074950e41 | Coke++ | docs/ops.markdown

[17:32] <Geth_> ¦ nqp: treat substr2/3 as variants

[17:32] <Geth_> ¦ nqp: review: https://github.com/Raku/nqp/commit/9074950e41

[17:32] <Geth_> ¦ nqp: f9df3f1cab | Coke++ | docs/ops.markdown

[17:32] <Geth_> ¦ nqp: add substr variants

[17:32] <Geth_> ¦ nqp: review: https://github.com/Raku/nqp/commit/f9df3f1cab

[17:51] * [Coke] wonders why the opcode is 'falsey' and not 'not'

[18:00] <Geth_> ¦ nqp: 8ce2ce4cc6 | Coke++ | docs/ops.markdown

[18:00] <Geth_> ¦ nqp: document falsey

[18:00] <Geth_> ¦ nqp: review: https://github.com/Raku/nqp/commit/8ce2ce4cc6

[18:00] <Geth_> ¦ nqp: a7bb66ddac | Coke++ | docs/ops.markdown

[18:00] <Geth_> ¦ nqp: add some variants

[18:00] <Geth_> ¦ nqp: review: https://github.com/Raku/nqp/commit/a7bb66ddac

[18:09] *** AlexDaniel left
[18:10] <Geth_> ¦ nqp: 70520fb5f7 | Coke++ | t/docs/opcodes.t

[18:10] <Geth_> ¦ nqp: Find a few more op definitions in JS VM

[18:10] <Geth_> ¦ nqp: review: https://github.com/Raku/nqp/commit/70520fb5f7

[18:11] <[Coke]> (326 fails left)

[18:21] <Geth_> ¦ nqp: coke self-assigned Bunch of things undocumented https://github.com/Raku/nqp/issues/293

[18:39] *** Altai-man_ joined
[18:42] *** sena_kun left
[19:00] <lizmat> m: use nqp; say nqp::falsey(42)

[19:00] <camelia> rakudo-moar b9105f1a8: OUTPUT: «===SORRY!===␤No registered operation handler for 'falsey'␤»

[19:00] <lizmat> [Coke] ^^^  ??

[19:01] <[Coke]> Whoops.

[19:01] <[Coke]> maybe it's QAST only?

[19:01] <[Coke]> was just pulling them out of the source, wasn't actually testing they were usable. :)

[19:02] <lizmat> I only see it in nqp, nowhere in the Raku sources

[19:02] <lizmat> maybe it's an old name of nqp::isfalse ?

[19:02] <[Coke]> both moar & jvm nqp have: $ops.add_hll_op for it.

[19:03] <[Coke]> and js has a slightly different variant.

[19:03] <[Coke]> nqp: nqp::say(3)

[19:03] <camelia> nqp-moarvm: OUTPUT: «3␤»

[19:03] <[Coke]> nqp: nqp::say(nqp::falsey(0));

[19:03] <camelia> nqp-moarvm: OUTPUT: «1␤»

[19:04] <[Coke]> No clue why it isn't mapped in rakudo.

[19:05] <lizmat> well, for the functionality documented, I use nqp::isfalse in Rakudo

[19:06] <[Coke]> Maybe we can kill it.

[19:06] <[Coke]> worth opening a ticket for "why do we have both of these" - if there is a difference, we should document it.

[19:07] <Geth_> ¦ nqp: d06ab4ee3e | (Stefan Seifert)++ | src/vm/moar/HLL/Backend.nqp

[19:07] <Geth_> ¦ nqp: Fix sqlite3 running out of memory when importing large profiles

[19:07] <Geth_> ¦ nqp: 

[19:07] <Geth_> ¦ nqp: Seems like sqlite3 deals badly with insert statements containing a large number

[19:07] <Geth_> ¦ nqp: of data records. A generated profile with lines that are several 100 MB long,

[19:07] <Geth_> ¦ nqp: sqlite3 can use 10s of GB of memory to process.

[19:07] <Geth_> ¦ nqp: Use the already existing batching infrastructure to split those lines into

[19:07] <Geth_> ¦ nqp: multiple insert statements for call data.

[19:07] <Geth_> ¦ nqp: review: https://github.com/Raku/nqp/commit/d06ab4ee3e

[19:08] <lizmat> nine++

[19:08] <nine> With this sqlite3 tops out at ~ 4G of RSS versus running out of memory with > 44G available...

[19:09] <nine> I think splitting allocations would be quite beneficial as well. Alas, rakudo probably will run out of memory before being able to write a profile that large

[19:39] <dogbert17> m: my int $i = -(2**63); say $i; say abs($i) # ?

[19:39] <camelia> rakudo-moar b9105f1a8: OUTPUT: «-9223372036854775808␤-9223372036854775808␤»

[20:10] *** AlexDaniel joined
[20:10] *** AlexDaniel left
[20:10] *** AlexDaniel joined
[20:34] *** AlexDaniel left
[20:40] *** sena_kun joined
[20:41] *** Altai-man_ left
[21:10] *** AlexDaniel joined
[21:10] *** AlexDaniel left
[21:10] *** AlexDaniel joined
[21:18] *** Kaeipi left
[21:19] *** Kaeipi joined
[21:22] *** AlexDaniel left
[21:24] *** AlexDaniel joined
[21:28] *** AlexDaniel left
[21:40] *** AlexDaniel joined
[21:40] *** AlexDaniel left
[21:40] *** AlexDaniel joined
[22:29] <AlexDaniel> sourceable6: &[…]((1, 2, 4), ∞)

[22:29] <sourceable6> AlexDaniel, https://github.com/rakudo/rakudo/blob/b9105f1/src/core.c/operators.pm6#L129

[22:30] <AlexDaniel> hmm

[22:30] <AlexDaniel> sourceable6: Seq.new(SEQUENCE((1, 2, 4), ∞))

[22:30] <sourceable6> AlexDaniel, https://github.com/rakudo/rakudo/blob/b9105f1/src/core.c/Seq.pm6#L10

[22:31] <AlexDaniel> sourceable6: SEQUENCE((1, 2, 4), ∞)

[22:31] <sourceable6> AlexDaniel, https://github.com/rakudo/rakudo/blob/b9105f1/src/core.c/Rakudo/SEQUENCE.pm6#L1

[22:39] *** Altai-man_ joined
[22:42] *** sena_kun left
[22:48] *** patrickb left
[22:50] <AlexDaniel> m: say (1, -1, 1 … -1)[^5]

[22:50] <camelia> rakudo-moar b9105f1a8: OUTPUT: «(1 -1 Nil Nil Nil)␤»

[22:50] <AlexDaniel> hmm

[22:51] <AlexDaniel> arguably same as this:

[22:51] <AlexDaniel> m: say (1, 2, 3 … 2)[^5]

[22:51] <camelia> rakudo-moar b9105f1a8: OUTPUT: «(1 2 Nil Nil Nil)␤»

[22:51] <AlexDaniel> kinda makes sense, kinda

[23:02] *** cognominal joined
[23:04] <AlexDaniel> lizmat, jnthn: okay that may sound crazy but even geometric sequences are not very justified in my eyes

[23:04] <AlexDaniel> as a party trick, maybe

[23:05] *** cognomin_ left
[23:05] <AlexDaniel> m: say (-1, -2, -4 … *)[^10]

[23:05] <camelia> rakudo-moar b9105f1a8: OUTPUT: «(-1 -2 -4 -8 -16 -32 -64 -128 -256 -512)␤»

[23:05] <AlexDaniel> m: say (-1, -2, -4 … -16)[^10]

[23:05] <camelia> rakudo-moar b9105f1a8: OUTPUT: «(Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil)␤»

[23:05] <AlexDaniel> bug.

[23:05] <AlexDaniel> probably the first bug I discovered solely by staring at the code :)

[23:08] <AlexDaniel> like, I think it'd be nice to have a well-defined feature set that we can actualy get right

[23:10] <AlexDaniel> and also * × 2 isn't that hard to write anyway

[23:13] <jnthn> Complexity you push out of the standard library will just pop up in non-standard ones.

[23:14] <AlexDaniel> except that nobody is going to implement the absolutely unnecessary logic for geometric sequences or weird string generation

[23:15] <AlexDaniel> m: say (-1, {$_ × 2} … -16)[^10]

[23:15] <camelia> rakudo-moar b9105f1a8: OUTPUT: «(-1 -2 -4 -8 -16 Nil Nil Nil Nil Nil)␤»

[23:15] <jnthn> Dunno about the string one; geometric progressions aren't so unusual though.

[23:15] <AlexDaniel> look how this just works

[23:16] <AlexDaniel> it's a bit more complicated if the endpoint is not in the sequence though

[23:16] <jnthn> (For example, in doing back-off when retrying)

[23:16] <AlexDaniel> jnthn: if they're so unusual add another operator or function

[23:16] <AlexDaniel> same for string stuff

[23:17] <AlexDaniel> how come a single operator has to deal with all of the edge cases

[23:17] <AlexDaniel> (and get half of them wrong)

[23:17] <jnthn> I said they're *not* unusual

[23:18] <AlexDaniel> jnthn: yeah, I read it right but replied wrong. If they're so common add another operator or function

[23:19] <jnthn> I don't really see how that'd help; you'd just have the logic elsewhere. Logic that only comes into play if you don't provide a function to generate the next value.

[23:21] <AlexDaniel> m: say (1,2,4 … 256 … 2)[^10]

[23:21] <camelia> rakudo-moar b9105f1a8: OUTPUT: «(1 2 4 8 16 32 64 128 256 255)␤»

[23:21] <AlexDaniel> so you don't think that separate manageable functionality where all the unneeded stuff is thrown away is easier to maintain?

[23:22] <AlexDaniel> or that it is easier to document, understand and teach?

[23:22] <jnthn> You're assuming your lack of need reflects everyone elses.

[23:23] <AlexDaniel> what's the need we're talking about

[23:23] <jnthn> Anyway, enough.

[23:23] <jnthn> &

[23:23] <AlexDaniel> I just can't look at this bloat anymore

[23:29] <AlexDaniel> m: say (1, 2, 4 … 256 … ∞)[^10]

[23:29] <camelia> rakudo-moar b9105f1a8: OUTPUT: «(1 2 4 8 16 32 64 128 256 257)␤»

[23:31] <AlexDaniel> it's kinda cool you can actually reverse it geometrically too

[23:31] <AlexDaniel> m: say (1, 2, 4 … 256, 128, 64 … 0)[^20]

[23:31] <camelia> rakudo-moar b9105f1a8: OUTPUT: «(1 2 4 8 16 32 64 128 256 128 64 32 16 8 4 2 1 0.5 0.25 0.125)␤»

[23:46] <AlexDaniel> this one is kinda interesting :)

[23:46] <AlexDaniel> m: say (-Inf, 0, Inf … Inf)[^20]

[23:46] <camelia> rakudo-moar b9105f1a8: OUTPUT: «(-Inf NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN)␤»

[23:46] <AlexDaniel> m: say (-Inf, 0, Inf … 0)[^20]

[23:46] <camelia> rakudo-moar b9105f1a8: OUTPUT: «(-Inf 0 Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil)␤»

[23:47] <AlexDaniel> but yeah infs are unfair

[23:50] <AlexDaniel> there are other meaningless cases that are weird too, but at least they don't matter as much

[23:50] <AlexDaniel> like

[23:50] <AlexDaniel> m: say (False, True … False)[^20]

[23:50] <camelia> rakudo-moar b9105f1a8: OUTPUT: «(False 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19)␤»

[23:51] <AlexDaniel> m: say (False, True … True)[^20]

[23:51] <camelia> rakudo-moar b9105f1a8: OUTPUT: «(False Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil)␤»

[23:51] <AlexDaniel> so both are wrong because of Bool special-casing on the endpoint, but there's probably some reason for it

[23:54] <AlexDaniel> ah

[23:54] <AlexDaniel> finally found something in the most basic code path

[23:54] <AlexDaniel> m: say (5, 5 … 10)[^20]

[23:54] <camelia> rakudo-moar b9105f1a8: OUTPUT: «(Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil Nil)␤»

[23:55] <AlexDaniel> m: say (5, 5 … -10)[^20]

[23:55] <camelia> rakudo-moar b9105f1a8: OUTPUT: «(5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5)␤»

