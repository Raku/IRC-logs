[01:20] *** Altai-man_ joined
[01:22] *** sena_kun left
[01:26] *** TreyHarris left
[01:39] *** TreyHarris joined
[01:56] *** kalkin-- joined
[01:59] *** kalkin- left
[02:26] *** leont left
[03:21] *** sena_kun joined
[03:23] *** Altai-man_ left
[04:23] *** bloatable6 left
[04:23] *** bisectable6 left
[04:23] *** sourceable6 left
[04:23] *** greppable6 left
[04:23] *** committable6 left
[04:23] *** coverable6 left
[04:23] *** shareable6 left
[04:23] *** releasable6 left
[04:23] *** reportable6 left
[04:23] *** nativecallable6 left
[04:23] *** squashable6 left
[04:23] *** quotable6 left
[04:23] *** unicodable6 left
[04:23] *** notable6 left
[04:23] *** statisfiable6 left
[04:23] *** benchable6 left
[04:24] *** shareable6 joined
[04:24] *** nativecallable6 joined
[04:24] *** squashable6 joined
[04:24] *** committable6 joined
[04:25] *** releasable6 joined
[04:25] *** reportable6 joined
[04:25] *** coverable6 joined
[04:25] *** unicodable6 joined
[04:25] *** notable6 joined
[04:26] *** statisfiable6 joined
[04:26] *** bloatable6 joined
[04:26] *** sourceable6 joined
[04:26] *** benchable6 joined
[04:26] *** bisectable6 joined
[04:26] *** quotable6 joined
[04:26] *** greppable6 joined
[05:20] *** Altai-man_ joined
[05:23] *** sena_kun left
[07:21] *** sena_kun joined
[07:23] *** Altai-man_ left
[08:26] <|Tux|> Rakudo version 2019.11-291-g9a571b685 - MoarVM version 2019.11-97-geb13ccad1

[08:26] <|Tux|> csv-test-xs-20      0.429 -  0.434

[08:26] <|Tux|> csv-ip5xs           0.721 -  0.727

[08:26] <|Tux|> test-t --race       0.797 -  0.814

[08:26] <|Tux|> test-t              1.684 -  1.767

[08:26] <|Tux|> csv-ip5xs-20        6.446 -  6.796

[08:26] <|Tux|> test                6.987 -  7.232

[08:26] <|Tux|> test-t-20 --race    9.067 -  9.248

[08:26] <|Tux|> csv-parser         22.944 - 23.070

[08:26] <|Tux|> test-t-20          29.985 - 29.989

[08:41] <lizmat> Files=1294, Tests=109647, 209 wallclock secs (28.23 usr  8.27 sys + 2939.15 cusr 268.01 csys = 3243.66 CPU)

[09:10] <Xliff> lizmat: What tests are these and how can I run them?

[09:10] <lizmat> make spectest

[09:13] <Xliff> Jeebus! 209 wallclock? What is that being run on?

[09:13] <lizmat> my monster MBP  :-)

[09:13] <Xliff> Are there any specs on that?

[09:13] <Xliff> .oO( And I thought mine was a monster! )

[09:13] <lizmat> 2.4GHz Intel Core i9

[09:14] <lizmat> 32 GB 2400 Mhz DDR4

[09:14] <lizmat> 1TB SSD

[09:14] <lizmat> with TEST_JOBS=16

[09:14] <Xliff> Aha!

[09:16] <Xliff> Hmmm... my make spectest fails to find Inline::Perl5, which is installed.

[09:16] <Xliff> I'm running 0e2485a83f337099a58005d86b696dccd397f6a8

[09:20] *** Altai-man_ joined
[09:21] <Xliff> Files=1294, Tests=109655, 163 wallclock secs (26.10 usr  3.85 sys + 2959.43 cusr 160.03 csys = 3149.41 CPU)

[09:21] <Xliff> TEST_JOBS=20

[09:21] <nine> Xliff: did you follow the instructions printed by make spectest?

[09:21] <Xliff> nine: Yesss...

[09:21] <Xliff> Actually, I just did that on the posted run. That did NOT affect the results.

[09:21] <lizmat> Xliff: looks like you have a bigger monster  :-)

[09:22] <Xliff> Currently spectest FAILS

[09:22] <lizmat> nine: those instructions don't work for me

[09:22] <Xliff> Those aren't outright failures, BTW. All are marked Dubious

[09:22] <Xliff> t/spec/S12-construction/destruction.t

[09:23] <Xliff> t/spec/S12-construction/roles-6e.t  

[09:23] <Xliff> t/spec/S14-roles/submethods-6e.t

[09:23] *** sena_kun left
[09:25] <nine> Sounds like vrurg++'s recent work?

[09:28] <lizmat> hmmm... don't fail for me...

[09:32] <Xliff> Recompiled to latest on git.

[09:32] <Xliff> Now only one failure:

[09:32] <Xliff> t/spec/S16-io/watch.t -- test 1 failed

[09:32] <Xliff> Files=1294, Tests=109659, 171 wallclock secs (25.82 usr  3.61 sys + 3043.49 cusr 165.04 csys = 3237.96 CPU)

[09:33] <Xliff> Again... same "failure" : Dubious, test returned 1 (wstat 256, 0x100)

[09:39] <kalkin--> Can some one have a look at my Rakudo PRs?

[09:39] <kalkin--> Feedback is welcome

[09:40] <kalkin--> https://github.com/rakudo/rakudo/pulls?q=is%3Apr+is%3Aopen+sort%3Aupdated-desc+author%3Akalkin ‚Üê the top three ones

[09:46] <Xliff> m: my $a = 2; $a.perl.say

[09:46] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´2‚ê§¬ª

[09:46] <Xliff> m: my $a = 2/21; $a.perl.say

[09:46] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´<2/21>‚ê§¬ª

[09:46] <Xliff> m: my $a = 2/21; say "$a.perl"

[09:46] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´0.095238.perl‚ê§¬ª

[09:48] <Xliff> kalkin--: Are you sure you don't want braces around $_.perl() here -> "enum $_.perl() { signature2text $_.enums.pairs } \n" 

[09:48] <Xliff> https://github.com/rakudo/rakudo/pull/3360/commits/df9d1ab4316ac3abcdc5b58bbe000ae08e2caa7e

[10:05] <kalkin--> Xliff: it looks to me you are right, but I wonder why it worked for me? Maybe i copy pasted something wrong. I have an own internal Pod::To::Text2 PM file, may be i copy/pasted old version?

[10:05] <kalkin--> Will fix that

[10:19] <kalkin--> Xliff: Just tested it. It works o_O

[10:20] <kalkin--> p6: enum Foo <Bar Buz Boom>; my $f = Buz; say "==> $f.perl()"; say "$f"

[10:20] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´==> Foo::Buz‚ê§Buz‚ê§¬ª

[10:20] <kalkin--> looks to me that this is completely fine :)

[10:30] *** Xliff left
[10:30] *** Xliff_ joined
[11:21] *** sena_kun joined
[11:23] *** Altai-man_ left
[11:25] <AlexDaniel> sena_kun: forget about ZefFailures, look at AlwaysFails

[11:26] <sena_kun> AlexDaniel, but I spotted a regression looking at ZefFailures...

[11:26] <AlexDaniel> sena_kun: OK then don't listen to me!

[11:26] <AlexDaniel> :)

[11:26] <AlexDaniel> I mean, it never hurts to look, yes

[11:27] <sena_kun> AlexDaniel, well, my guess is "Just check each module which fails", and there are around 300 of them anyway, so 30 more or less...

[11:27] <AlexDaniel> to clarify, AlwaysFail means that it was tested on --new (usually master HEAD) and tests failed, then it tested on --old (usually previous release) and it also failed

[11:28] <AlexDaniel> normally that means that the module is just broken and it should be ignored

[11:28] <AlexDaniel> or that you don't have some dependencies installed so it can't be tested

[11:28] <sena_kun> AlexDaniel, what's the motivation behind suggesting me to look at AlwaysFails then, if they are supposedly broken anyway?

[11:28] <AlexDaniel> but because we're at ‚âà100 more AlwaysFail modules, it means that there's something wrong somewhere

[11:29] <AlexDaniel> sena_kun: cuz these 100 modules were testable just fine during the previous release

[11:30] <sena_kun> AlexDaniel, ah. well, but they can be broken and we don't know about that. anyway, I'm going to report that zef search timeout, if it is not reported already, because that's annoying

[11:30] <AlexDaniel> so something is wrong somewhere, it could be a zef regression, or an incomplete setup with dependencies not installed, or something‚Ä¶

[11:30] <AlexDaniel> sena_kun: as for that zef search timeout, I think the output is buffered and we're not getting the rest of it

[11:30] <AlexDaniel> sena_kun: so it's simply a timeout, the module failed to install in 10 minutes

[11:31] <AlexDaniel> or whatever the limit is

[11:31] <sena_kun> AlexDaniel, possibly...

[11:31] <sena_kun> anyway, less talking and more checking. ;)

[11:31] <AlexDaniel> pretty sure this thing is a clear indication that something changed in zef: https://github.com/rakudo/rakudo/pull/3373#issuecomment-568438862

[11:32] <AlexDaniel> and even if the change is good, it should probably be reverted if it causes issues in tens of modules‚Ä¶

[11:32] <AlexDaniel> just tried it locally and I can reproduce

[11:32] <sena_kun> latest commits to zef were at Nov 3, and we had a release with that, apparently

[11:32] <sena_kun> no?

[11:33] <sena_kun> I mean, "latest commits that are not for appveynor"

[11:33] <AlexDaniel> not sure

[11:33] <AlexDaniel> to be fair I just have this file here‚Ä¶ which is X months old

[11:34] <AlexDaniel> maybe it's from the releas before the last one

[11:34] <AlexDaniel> release*

[11:34] <sena_kun> AlexDaniel, then we need to check 'em all the more

[11:35] <AlexDaniel> hmmmmmmmm

[11:36] <AlexDaniel> just tried that module with the right PERL6LIB and it failed some tests‚Ä¶

[11:36] <AlexDaniel> Cannot look up attributes in a WorkdayCalendar type object

[11:37] <AlexDaniel> probably a regression

[11:37] <AlexDaniel> or something

[11:37] <AlexDaniel> it's weird

[11:47] <AlexDaniel> sena_kun: I did this: https://github.com/ugexe/zef/issues/330

[11:47] <sena_kun> AlexDaniel, thanks!

[11:48] <sena_kun> AlexDaniel, I am continuing to go over failures...

[11:48] <sena_kun> AlexDaniel, you probably should get some rest. ;)

[11:49] <AlexDaniel> maybe?

[11:49] <AlexDaniel> I didn't sleep today, didn't feel like sleeping‚Ä¶

[12:09] *** leont joined
[12:12] <lizmat> sena_kun AlexDaniel: I can push to master without interfering with the release, right ?

[12:13] <sena_kun> lizmat, yeah

[12:13] <lizmat> oki

[12:13] <sena_kun> lizmat, we have regressions anyway, so 1)need to check every failing module; 2)prepare info about broken ones and report, wait for fixes; 3)another round

[12:13] <sena_kun> lizmat, while you are here, Method::Also is broken on master

[12:13] * lizmat is hoping to get the re-imagined val() handling into master today

[12:14] <lizmat> sena_kun: looking at it now

[12:14] <sena_kun> reliably so, and it wasn't before, so a regression...

[12:15] <lizmat> Cannot resolve caller bar_ber(Bar:U, Str:D); Routine does not have any candidates. Is only the proto defined?

[12:15] <lizmat> looks like something vrurg did  :-)

[12:16] <sena_kun> lizmat, I am seeing Too many positionals passed; expected 4 arguments but got 5 at /home/koto/.zef/store/Method-Also-0.0.4.tar.gz/Method-Also-0.0.4/t/01-basic.t:32

[12:16] <lizmat> as it is related to roles

[12:16] <sena_kun> don't tell me I am doing it wrong just running `zef install Foo` with the correct rakudo checkout

[12:16] <lizmat> sena_kun: I assume that is on the release branch ?

[12:17] <sena_kun> lizmat, 2019.11-291-g9a571b685 built on MoarVM version 2019.11-93-g7a93b2897

[12:17] <sena_kun> not release branch, but what Blin tested yesterday

[12:17] <lizmat> that's what I'm testing with

[12:18] <lizmat> I'm just running raku t/01-basic.t in the repo

[12:18] <sena_kun> lizmat, can you try `zef install .`?

[12:19] <lizmat> ok, then I get that error

[12:20] <sena_kun> lizmat, well, either way it is broken and I reported that. :S

[12:21] <sena_kun> should likely create a ticket

[12:21] <lizmat> the line in question is "class Bar does Ber {" so I think the error is actually somewhere in the RoleHOW

[12:22] <lizmat> is there an invocation for zef to have it run with --ll-exception ?

[12:23] <sena_kun> (no idea)

[12:23] <lizmat> https://gist.github.com/lizmat/72970bb417e2b944b69c787590d35940

[12:24] <sena_kun> lizmat, I'm creating a ticket then...

[12:26] <sena_kun> https://github.com/rakudo/rakudo/issues/3378

[12:27] <lizmat> well, that gist is pretty useless:

[12:30] <lizmat> hmm... what is a BOOTContext ?

[12:31] <lizmat> apparently the "specialize with" method gets one

[12:33] <lizmat> hmmm... looks like Xliff_'s changes to Method::Also are interfering with vrurg's work

[12:55] <lizmat> sena_kun: at least temporary fix on its way to CPAN.  Removed the blocker label

[12:55] <sena_kun> lizmat, thanks, noted

[13:06] <sena_kun> I am running Blin again, with increased timeout... after that will look at results

[13:10] <Geth_> ¬¶ roast: 5b06aeeaf6 | (Elizabeth Mattijsen)++ | S03-operators/arith.t

[13:10] <Geth_> ¬¶ roast: Make sure undefine keeps working in test

[13:10] <Geth_> ¬¶ roast: 

[13:10] <Geth_> ¬¶ roast: As it will be removed in v6.e

[13:10] <Geth_> ¬¶ roast: review: https://github.com/perl6/roast/commit/5b06aeeaf6

[13:10] <sena_kun> a stupid question, but how do I know which rakudo revision is used in Blin?

[13:12] <AlexDaniel> sena_kun: should be in the output, no?

[13:12] <AlexDaniel> good question :D

[13:17] <sena_kun> I guess latest HEAD

[13:17] <sena_kun> "Will compare between 2019.11 and HEAD"

[13:20] *** Altai-man_ joined
[13:21] <Altai-man_> ok, now $dayjob

[13:23] *** sena_kun left
[13:36] <kalkin--> Another Bug or Feature Question: =defn is parsed as Pod::Defn, but =para is parsed as Pod::Block::Named with name set to para. IMHO it's inconsistent, but may be it should be like this?

[13:36] *** kalkin-- is now known as kalkin-

[14:12] <tbrowder> =defn is a special pod name and it gets special handling and has additional attributes

[14:15] *** lucasb joined
[14:16] <tbrowder> note that pod class naming isn‚Äôt real consistent due in part to the number of pod objects not implemented when the Christmas release was presented to the public

[14:25] <tbrowder> ^^^ that‚Äôs my opinion

[14:33] <Geth_> ¬¶ roast: e012309c70 | (Elizabeth Mattijsen)++ | 4 files

[14:33] <Geth_> ¬¶ roast: Some more 'undefine' fixes

[14:33] <Geth_> ¬¶ roast: 

[14:33] <Geth_> ¬¶ roast: Either add a local "undefine" sub, or change it to = Nil, or remove

[14:33] <Geth_> ¬¶ roast: a test completely if it was just testing for the existence of "undefine".

[14:33] <Geth_> ¬¶ roast: review: https://github.com/perl6/roast/commit/e012309c70

[14:39] <kalkin-> tbrowder: There is a lot of stuff broken/wrong in Pod6 parsing. I dunno what i should do. Should I open for everything a GitHub issue, or should i write everything down + my own ideas about how some specific parts should work as one big GitHub issue?

[14:40] <lizmat> kalkin-: having a master issue is a good start, then maybe add sub issues later

[14:41] <kalkin-> lizmat: k, will do

[14:53] <lizmat> m: 10 ** 100000000; say "compiled"    # wonder what is going wrong here?  perhaps we shouldn't do this as Ints?

[14:53] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´(timeout)¬ª

[14:53] <lizmat> m: use nqp; dd nqp::tonum_I(10) ** 100000000

[14:53] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´Inf‚ê§¬ª

[15:21] *** sena_kun joined
[15:23] *** Altai-man_ left
[15:59] <tbrowder> kalkin: PRs would be wonderful!

[16:25] *** toddr left
[17:21] *** Altai-man_ joined
[17:23] *** sena_kun left
[17:30] <jnthn> lizmat: Just constant folding, no?

[17:40] <kalkin-> tbrowder: I would love to do PRs, but the stuff is very complicated. IMHO Pod parsing should be an own grammar which is used each time a pod block is encountered, instead the parsing is all over the place, but may be it's a na√Øve approach

[17:41] <kalkin-> It's very hard to tell what is used for what.

[17:41] <kalkin-> My current approach is add nqp::say("DRIN") and see if i get it triggered

[17:44] <tbrowder> i agree, but that‚Äôs the rub: no one has documented how to do that that i know of, and the experts are too busy with other higher-priority projects.

[17:46] *** unclechu left
[17:46] *** Demos[m] left
[17:46] *** AlexDaniel` left
[17:46] *** rba[m] left
[18:02] *** Demos[m] joined
[18:27] <lizmat> jnthn: yeah, just constant folding, but also with runtime

[18:27] <lizmat> m: my $a = 10; say "started"; dd $a ** 100000000

[18:28] <lizmat> hmmm...

[18:28] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´(timeout)started‚ê§¬ª

[18:28] <lizmat> ah, ok

[18:29] *** unclechu joined
[18:29] *** AlexDaniel` joined
[18:29] *** rba[m] joined
[18:35] *** lucasb left
[19:06] <lizmat> so, use nqp; dd nqp::pow_I(10,100000,Num,Int) takes about 4 seconds to run on my MBP

[19:07] <lizmat> the infix:<**>(Int,Int) candidate has a comment: # when a**b is too big nqp::pow_I returns Inf

[19:07] <lizmat> this appears to be untrue

[19:07] <nine> You know you have an algorithmic problem, when you can get the result faster doing it by hand...

[19:07] <lizmat> https://github.com/perl6/nqp/blob/master/docs/ops.markdown#pow specifically states that it will always return an Int

[19:08] <lizmat> m: dd 10e100000

[19:08] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´Inf‚ê§¬ª

[19:08] <lizmat> yet this returns Inf without any complaints

[19:09] <lizmat> this feels inconsistent  :-)

[19:21] *** sena_kun joined
[19:23] *** Altai-man_ left
[19:45] *** Xliff_ left
[20:09] <lizmat> bisectable6: dd "1.".succ

[20:09] <bisectable6> lizmat, On both starting points (old=2015.12 new=9a571b6) the exit code is 0 and the output is identical as well

[20:09] <bisectable6> lizmat, Output on both points: ¬´"2."‚ê§¬ª

[20:11] <lizmat> m: dd "¬π".succ

[20:11] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´"¬π"‚ê§¬ª

[20:17] *** AlexDani` joined
[20:17] <lizmat> whee!  my val() re-imagining passes all spectests!

[20:18] <moritz> that can just mean one thing: too few tests :D

[20:18] <moritz> congrats lizmat 

[20:18] *** AlexDaniel left
[20:19] <lizmat> moritz:  meh   :-)

[20:19] <lizmat> that's the next thing  :-)

[20:20] <lizmat> it's between 1.6x and 2.1x faster

[20:20] <lizmat> so far  :-)

[20:23] <lizmat> with about 20% of allocations

[20:25] <lizmat> I guess I'll first write some more tests before merging

[20:25] <lizmat> and I definitely don't want this in the 2019.12 release

[20:45] <lizmat> raku -e 'say val(q/:16{ aa bb cc dd }/)'

[20:45] <lizmat> Blob:0x<AA BB CC DD>

[20:45] <lizmat> ^^ new feature, soon in a release near you 

[20:56] * sena_kun thinks about the release

[20:59] *** pmurias joined
[21:04] <pmurias> lizmat: re pow_I, Inf is returned for exponents that don't fint into a bigint digit

[21:04] <tellable6> 2019-12-17T20:46:18Z #raku-dev <MasterDuke> pmurias: think it would make sense to try and have rakudo listed here? https://github.com/neomatrix369/awesome-graal

[21:05] <lizmat> pmurias: and how big is that?  and how long does it take it to find out ?

[21:11] <pmurias> lizmat: it's cheaply compared

[21:11] * pmurias is figuring the exact size

[21:12] <lizmat> m: dd 10e100000

[21:12] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´Inf‚ê§¬ª

[21:12] <lizmat> m: dd 10 ** 100000

[21:12] <pmurias> on the js backend Inf is returned for exponents bigger than 4294967296

[21:12] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000‚Ä¶¬ª

[21:12] <lizmat> m: dd 10 ** 1000000

[21:12] <pmurias> m: say 10e1.^name

[21:12] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´(timeout)¬ª

[21:12] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´Num‚ê§¬ª

[21:13] <lizmat> so why does 10 ** 1000000 timeout then ?

[21:16] <pmurias> lizmat: because the exponent is not big enough?

[21:16] <pmurias> m: dd 10 ** 1000000000000

[21:16] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´Failure.new(exception => X::Numeric::Overflow.new, backtrace => Backtrace.new)‚ê§¬ª

[21:19] <pmurias> lizmat: the exponent is too big enough to calculate and not big enought to trigger the too big check

[21:20] <lizmat> well, technically I guess it's correct that it doesn't trigger

[21:20] <lizmat> but realistically, I've had "10 ** 1000000" run for 15 minutes without result

[21:21] <lizmat> so it may well be that it will just take too long, at least until our computers are 1000x faster

[21:21] <lizmat> so effectively a program would hang

[21:21] *** Altai-man_ joined
[21:21] <lizmat> so maybe we need a $*MAX-EXPONENT

[21:23] *** sena_kun left
[21:23] <lizmat> $*MAX-POWER

[21:25] <pmurias> do people use super big bigints that take hundreds of mb of memory?

[21:27] * pmurias is not sure what the sane value for throwing the exceptions is and just allowing tweaking it without a good answer to that won't help much

[21:31] <lizmat> I ran into this while trying to re-implement nqp::numify in Raku

[21:32] <lizmat> nqp::numify handles 10e100000 without any issue

[21:32] <lizmat> m: dd 10e100000

[21:32] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´Inf‚ê§¬ª

[21:32] <lizmat> yet 10 ** 100000 "hangs"

[21:37] <jnthn> 10e100000 isn't calculating anything, though; it's just a Num literal

[21:38] <jnthn> And it doesn't have all the precision of the Int, so it's kind of apples and oranges

[21:38] <lizmat> but that Num literal needs to be calculated

[21:38] <lizmat> m: <10*10**100000>

[21:39] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´WARNINGS for <tmp>:‚ê§Useless use of constant integer 10*10**100000 in sink context (line 1)‚ê§¬ª

[21:39] <jnthn> A floating point number is actually represented in memory as a significant and an exponent

[21:39] <jnthn> *significand

[21:39] <lizmat> m: <10*10**10000000>

[21:39] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´WARNINGS for <tmp>:‚ê§Useless use of constant integer 10*10**10000000 in sink context (line 1)‚ê§¬ª

[21:39] <lizmat> m: dd <10*10**10000000>

[21:39] <jnthn> Whereas a big integer ain't; it's represented using as much memory is needed for the digits.

[21:40] <jnthn> *as is needed

[21:40] <camelia> rakudo-moar 672c5d403: OUTPUT: ¬´(timeout)¬ª

[21:40] <jnthn> I'm not surprised such a calculation on a bigint takes so long, though 15 minutes is quite a while... I don't think putting arbitrary limits in place helps anyone who is actually wanting to do such math.

[21:58] <japhb> Still, integer exponentiation should be relatively "fast" in that you need O(log(exponent)) multiplications of O(log(exponent)) digit numbers, yes?

[22:09] <kalkin-> Pod docs on roles are missing the role in WHEREFORE *sigh*

[22:09] <japhb> * O(log(exponent)) multiplications of O(exponent) digit numbers

[22:20] <japhb> multiplication of very large numbers is O(n log n) for n=exponent, and for midsize numbers more in the range of O(n ** 1.46), so it's somewhere around n**1.5 in practice I suppose.  So for 10 ** 1_000_000, I guess around 1_000_000_000 ops.

[22:21] <japhb> (back of the envelope thinking obviously)

[22:52] *** dogbert11 joined
[22:54] *** dogbert17 left
[23:01] *** Kaiepi left
[23:02] *** Kaiepi joined
[23:10] *** dogbert17 joined
[23:12] *** dogbert11 left
[23:21] *** sena_kun joined
[23:23] *** Altai-man_ left
