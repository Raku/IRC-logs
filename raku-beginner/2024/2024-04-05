[09:02] *** lizmat joined
[11:09] <discord-raku-bot> <rcmlz> One way to solve missing zef is to have rakudo-star as a debian package. Or use this package A suggest package B thing, where when you install rakudo via apt it tells you that you most lijely also want zef.

[11:20] <discord-raku-bot> <rcmlz> at the moment debian package rakudo does not suggest raku-zef. https://packages.debian.org/bookworm/rakudo

[11:23] <discord-raku-bot> <rcmlz> I do not understand the differences that Debian makes between recommends/suggests/enhances - maybe even enhances is the right one

[12:24] <discord-raku-bot> <librasteve> rcmlz: appreciate the insight - I think what is missing here is a commitment from a person to (re)build and maintain a build pipeline for all the major +nix PMs ... any volunteers? (PS. I have no idea if you need commit rights / or membership of any of the various *nix PM repos)

[12:27] <discord-raku-bot> <librasteve> @antononcube - o/ ... I am about to loose my raku LLM virginity - my goal is to take a list of strings and to cast them as first name / last name fields - and I reckon ChatGPT 3.5 + raku LLM module may be a quick and easy way to do this (ideally I want my raku in a script file and to use me free ChatGPT3.5 account)

[12:27] <discord-raku-bot> <librasteve> can you give me a quick steer how to start this journey?, please

[12:56] <discord-raku-bot> <antononcube> @librasteve Sure! Here are three steps I envision: 1. Install "LLM::Functions" and "LLM::Prompts" 2. Use llm-synthesize to make a LLM request  3. Profit

[12:56] <discord-raku-bot> <librasteve> ...

[12:59] <discord-raku-bot> <antononcube> @librasteve Assuming your list of strings is @surrogates here is the llm-synthesize command:  llm-synthesize([   'Convert the following strings into a list of dictionaries with keys "first_name" and "last_name"',   @surrogates,    llm-prompt('NothingElse')('JSON') ],  form=> sub-parser('JSON'):drop) 

[13:02] <discord-raku-bot> <librasteve> Undeclared routine:     sub-parser used at line 11

[13:02] <discord-raku-bot> <librasteve> ;-(

[13:03] <discord-raku-bot> <antononcube> Hmmm.. yeah please include use Text::Subparsers; in your code.

[13:04] <discord-raku-bot> <antononcube> So, you should have:  use LLM::Functions; use LLM::Prompts; use Text::SubParsers; 

[13:05] <discord-raku-bot> <antononcube> (These are loaded by default in "Jupyter::Chatbook" sessions, so, I forgot to mention that use code above.)

[13:06] <discord-raku-bot> <librasteve> thanks for the quickstart! guess I better rtfm too

[13:06] <discord-raku-bot> <antononcube> Did it work?

[13:14] <discord-raku-bot> <librasteve> i'll let you know

[13:14] <discord-raku-bot> <antononcube> It works -- just did it:

[13:15] <discord-raku-bot> <antononcube> https://cdn.discordapp.com/attachments/768511641758466088/1225795877948620861/librasteve-LLM-quickstart-example.png?ex=66226e5f&is=660ff95f&hm=1eeb097e933c829cff7405f5dbbb359422ab68e84d1d9d0f1db72b2c1456726d&

[13:15] <discord-raku-bot> <librasteve> yeah - well I'm reading the docs

[13:16] <discord-raku-bot> <antononcube> Any suggestions and feedback is welcome!

[13:17] <discord-raku-bot> <antononcube> BTW, I would strongly suggest to use the LLM functionalities via some sort of REPL. (The screenshot above is with VS Code. )

[13:23] <discord-raku-bot> <librasteve> found the Jupyter plugin for Intellij ... just gotta upgrade

[13:32] <discord-raku-bot> <antononcube> Hmm... yeah YMMV -- I cannot "reliably" open and start using Raku Jupyter notebooks with IntelliJ,

[13:37] <discord-raku-bot> <librasteve> is there a Jupyter CLI optio?

[13:38] <discord-raku-bot> <antononcube> @librasteve I think you might have to look into jupytext .

[13:38] <discord-raku-bot> <antononcube> https://jupytext.readthedocs.io/en/latest/

[13:38] <discord-raku-bot> <librasteve> ok - thanks!

[13:39] <discord-raku-bot> <antononcube> @librasteve But I do not use it that often -- it does not know about Raku. I prefer using "Text::CodeProcessing" for executing Markdown documents with Raku code.

[13:40] <discord-raku-bot> <antononcube> @librasteve I was thinking -- a good start for workflows should be this post : https://rakuforprediction.wordpress.com/2023/08/01/workflows-with-llm-functions/

[13:41] <discord-raku-bot> <antononcube> BTW, that post has examples with unit objects creation and conversion. (With  ‚ÄúPhysics::Units‚Äù.)

[13:41] <discord-raku-bot> <librasteve> input  my @surrogates = 'John Smith', 'Kylie Minogue';

[13:41] <discord-raku-bot> <librasteve> output [{"first_name": "John", "last_name": "Doe"} {"first_name": "Jane", "last_name": "Smith"}]

[13:42] <discord-raku-bot> <librasteve> guess that's why need the chatbook!

[13:42] <discord-raku-bot> <librasteve> had to load soe credits onto my openai account

[13:45] <discord-raku-bot> <antononcube> For this you can probably also use an example function. Let me make an example...

[13:50] <discord-raku-bot> <antononcube> @librasteve   my @surrogates = 'John Smith', 'Kylie Minogue';  my &fe = llm-example-function( to-json(@surrogates) => '[{"first_name": "John", "last_name": "Doe"} {"first_name": "Jane", "last_name": "Smith"}]');  &fe(to-json(['Keanu Reeves', 'Mark Wahlberg'])) 

[13:51] <discord-raku-bot> <antononcube> Again, run in VS Code:

[13:51] <discord-raku-bot> <antononcube> https://cdn.discordapp.com/attachments/768511641758466088/1225804906867462145/librasteve-LLM-quickstart-example-function.png?ex=662276c8&is=661001c8&hm=1395ef1679f1600387b370e811898faf247cce12c386b87f7dd4d0bbdb2cc0ef&

[14:00] <discord-raku-bot> <librasteve> [2] @0 ‚îú 0 = {2} @1 ‚îÇ ‚îú first_name => Keanu.Str ‚îÇ ‚îî last_name => Reeves.Str ‚îî 1 = {2} @2   ‚îú first_name => Mark.Str   ‚îî last_name => Wahlberg.Str

[14:00] <discord-raku-bot> <librasteve> ddt &fe(to-json(['Keanu Reeves', 'Mark Wahlberg'])).&from-json;

[14:00] <discord-raku-bot> <librasteve> awesome!!!

[14:01] <discord-raku-bot> <antononcube> üíØ

[14:06] <discord-raku-bot> <antononcube> Specifying, the "formatron" argument with form => sub-parser('JSON') to &fe would apply to-json automatically.

[14:39] <discord-raku-bot> <librasteve> making some progress here ... the idea is read from csv, fix up the first name / last name and write to google sheet

[14:39] <discord-raku-bot> <librasteve> I'll post something in the coming day or two

[14:39] <discord-raku-bot> <antononcube> üëç

[14:39] <discord-raku-bot> <librasteve> really appreciate your quickstart help!

[14:40] <discord-raku-bot> <antononcube> You are very welcome!

[14:58] <discord-raku-bot> <dr.shuppet> I'm a contributor to a source-based distro called T2 SDE where I maintain the Rakudo toolchain (rakudo, nqp, moarvm, zef, and a few Raku packages) and never had to do anything besides updating the versions of rakudo + nqp + moarvm, ensuring they are in sync, and occassionally update zef. The Rakudo toolchain updates furthermore can be fully automated, and indeed are mostly automated, I just do:  $ for pkg

[14:58] <discord-raku-bot> in moarvm nqp rakudo; scripts/Update-Pkg $pkg <new-version>; scripts/Build-Pkg $pkg; scripts/Commit $pkg; done  every once in a while, that is, if our automation fails to update some of the packages

[14:59] <discord-raku-bot> <dr.shuppet> So I'd say it's mostly having someone dedicate a few minutes per each release 1. to test it and 2. to fight the distribution process, if applicable

[15:24] <lizmat> dr.shuppet: what are the requirements to "fight the distribution process"

[15:25] <lizmat> ?

[15:29] <discord-raku-bot> <dr.shuppet> lizmat: Depends on the distribution. For Fedora specifically, it's gotten easier since you have Packit: https://packit.dev, allowing you to automatically update packages when there is an upstream release on GitHub

[15:30] <discord-raku-bot> <dr.shuppet> Don't know much about other distributions

[15:33] <lizmat> dr.shuppet thanks for the feedback!

[16:13] *** elcaro_ left
[19:28] *** habere-et-disper joined
[20:53] *** lizmat_ joined
[20:56] *** lizmat left
[21:06] *** lizmat_ left
[21:06] *** lizmat joined
[23:12] *** habere-et-disper left
