[03:01] *** jgaz left
[03:06] *** jgaz joined
[05:44] *** teatwo left
[06:01] *** teatime joined
[07:08] *** ab5tract joined
[07:41] *** ab5tract left
[07:41] *** ab5tract joined
[08:01] *** Manifest0 joined
[08:09] *** dakkar joined
[08:21] *** teatwo joined
[08:23] *** teatwo left
[08:23] *** teatwo joined
[08:24] *** teatime left
[08:35] *** Manifest0 left
[08:50] *** Manifest0 joined
[13:20] <discord-raku-bot> <rcmlz> Hello @antononcube , I like to try out Jupyter::Chatbook by running   brew install python python3 -m venv $HOME/.virtualenvs/chatbook source $HOME/.virtualenvs/chatbook/bin/activate  python3 -m pip install --upgrade pip python3 -m pip install --upgrade wheel python3 -m pip install --upgrade notebook  brew install zmq # get zeromq 4.3.4 brew install rakudo-star # get v2023.08 zef install Jupyter::Chatbook  but I

[13:20] <discord-raku-bot> get  ===> Testing [FAIL]: LLM::Functions:ver<0.1.9>:auth<zef:antononcube>:api<1> Aborting due to test failure: LLM::Functions:ver<0.1.9>:auth<zef:antononcube>:api<1> (use --force-test to override)  I am running  uname -a Darwin Macbook.local 21.6.0 Darwin Kernel Version 21.6.0: Thu Jul  6 22:18:26 PDT 2023; root:xnu-8020.240.18.702.13~1/RELEASE_X86_64 x86_64  Is it broken? Do I need to specify OpenAI keys beforehand?

[13:20] <discord-raku-bot> Thank you.

[13:22] <discord-raku-bot> <antononcube> @rcmlz Thanks for trying that out! Can you install ‚ÄúLLM::Functions‚Äù by itself?

[13:24] <discord-raku-bot> <rcmlz>  zef install LLM::Functions ===> Searching for: LLM::Functions ===> Searching for missing dependencies: HTTP::Tiny:ver<0.2.5+>, Text::SubParsers:ver<0.1.1+>, WWW::OpenAI:ver<0.2.8+>, WWW::PaLM:ver<0.1.8+> ===> Searching for missing dependencies: DateTime::Grammar:ver<0.1.3+> ===> Testing: HTTP::Tiny:ver<0.2.5>:auth<zef:jjatria> ===> Testing [OK] for HTTP::Tiny:ver<0.2.5>:auth<zef:jjatria> ===> Testing:

[13:24] <discord-raku-bot> DateTime::Grammar:ver<0.1.3>:auth<zef:antononcube>:api<1> ===> Testing [OK] for DateTime::Grammar:ver<0.1.3>:auth<zef:antononcube>:api<1> ===> Testing: Text::SubParsers:ver<0.1.4>:auth<zef:antononcube>:api<1> ===> Testing [OK] for Text::SubParsers:ver<0.1.4>:auth<zef:antononcube>:api<1> ===> Testing: WWW::OpenAI:ver<0.2.8>:auth<zef:antononcube>:api<1> ===> Testing [OK] for

[13:24] <discord-raku-bot> WWW::OpenAI:ver<0.2.8>:auth<zef:antononcube>:api<1> ===> Testing: WWW::PaLM:ver<0.1.8>:auth<zef:antononcube>:api<1> ===> Testing [OK] for WWW::PaLM:ver<0.1.8>:auth<zef:antononcube>:api<1> ===> Testing: LLM::Functions:ver<0.1.9>:auth<zef:antononcube>:api<1> ===> Testing [FAIL]: LLM::Functions:ver<0.1.9>:auth<zef:antononcube>:api<1> Aborting due to test failure: LLM::Functions:ver<0.1.9>:auth<zef:antononcube>:api<1> (use

[13:24] <discord-raku-bot> --force-test to override) 

[13:25] <discord-raku-bot> <antononcube> Hmm‚Ä¶ I am investigating this right now, then. (On my macOS computer ‚ÄúLLM::Functions‚Äú installs without problems.)

[13:27] <discord-raku-bot> <antononcube> Meanwhile, can you install it with ‚Äîforce-test and see does ‚ÄúJupyter::Chatbook‚Äù installs ?

[13:30] <discord-raku-bot> <nemokosch> also, could you maybe run it with --verbose and post a gist with the output?

[13:32] <discord-raku-bot> <rcmlz>  [LLM::Functions] t/05-LLM-prompt-synthesizing.rakutest .. Dubious, test returned 1 [LLM::Functions] No subtests run [LLM::Functions] All tests successful. [LLM::Functions]  [LLM::Functions] Test Summary Report [LLM::Functions] ------------------- [LLM::Functions] t/05-LLM-prompt-synthesizing.rakutest (Wstat: 256 Tests: 0 Failed: 0) [LLM::Functions] Non-zero exit status: 1 [LLM::Functions]   Parse errors: No

[13:32] <discord-raku-bot> plan found in TAP output [LLM::Functions] Files=5, Tests=41,  13 wallclock secs [LLM::Functions] Result: FAILED ===> Testing [FAIL]: LLM::Functions:ver<0.1.9>:auth<zef:antononcube>:api<1> Aborting due to test failure: LLM::Functions:ver<0.1.9>:auth<zef:antononcube>:api<1> (use --force-test to override) 

[13:33] <discord-raku-bot> <nemokosch> now that's more helpful

[13:33] <discord-raku-bot> <antononcube> Yes, @rcmlz  -- thanks!

[13:34] <discord-raku-bot> <antononcube> That file does have a plan statement. I will try to setup a build workflow on GitHub.

[13:34] <discord-raku-bot> <antononcube> (That includes Linux.)

[13:35] <discord-raku-bot> <rcmlz> Thank you.

[13:39] <discord-raku-bot> <rcmlz> I was today also playing around with Github workflows, attaching one to my little weekly-challenge-benchmark project. Is "massa" reading here? Have a look at "Run Benchmark" here https://github.com/rcmlz/perlweeklychallenge-club/actions/runs/6171321923/job/16749298659 - it seems to be that your solution for week234 task 2 is quite slow.

[13:40] <discord-raku-bot> <rcmlz> In 3 seconds only problem of size 128 was solvable.

[13:40] <discord-raku-bot> <antononcube> @rcmlz If it is not a secret -- what Linux distribution you are trying to install "Jupyter::Chatbook" on?

[13:41] <discord-raku-bot> <nemokosch> wasn't it downright a Mac?

[13:41] <discord-raku-bot> <rcmlz> MacOS Monterey 12.8.6

[13:41] <discord-raku-bot> <nemokosch> > Darwin Macbook.local 21.6.0 Darwin Kernel Version 21.6.0: Thu Jul  6 22:18:26 PDT 2023; root:xnu-8020.240.18.702.13~1/RELEASE_X86_64 x86_64

[13:41] <discord-raku-bot> <antononcube> Duh... obvious...

[13:42] <discord-raku-bot> <antononcube> I will try installing "LLM::Functions" on my x86 macOS computer.

[13:42] <discord-raku-bot> <nemokosch> it works on Silicon?

[13:43] <discord-raku-bot> <antononcube> Yes, but, that is my environment.

[13:43] <discord-raku-bot> <nemokosch> Still, it's kinda surprising

[13:43] <discord-raku-bot> <antononcube> Although, I did remove it wit zef before reinstalling.

[13:43] <discord-raku-bot> <nemokosch> that anything would work better on Silicon xD

[13:44] <discord-raku-bot> <antononcube> Well, the current macOS version is 13.5.2, so, I do not know... üôÇ

[13:50] <discord-raku-bot> <rcmlz> [Jupyter::Chatbook] # You failed 1 test of 1 [Jupyter::Chatbook] t/01-basic.t ......... Dubious, test returned 1 [Jupyter::Chatbook] Failed 1/1 subtests  [Jupyter::Chatbook] t/02-sandbox.t ....... ok [Jupyter::Chatbook] t/03-service.t ....... ok [Jupyter::Chatbook] t/04-completions.t ... skipped [Jupyter::Chatbook] t/05-autocomplete.t .. ok [Jupyter::Chatbook] t/06-magic.t ......... Dubious, test returned 1

[13:50] <discord-raku-bot> [Jupyter::Chatbook] No subtests run [Jupyter::Chatbook] t/07-comms.t ......... ok [Jupyter::Chatbook] t/08-paths.t ......... ok [Jupyter::Chatbook] t/09-history.t ....... ok [Jupyter::Chatbook] t/20-end-to-end.t .... Dubious, test returned 1 [Jupyter::Chatbook] No subtests run [Jupyter::Chatbook] t/99-meta.t .......... ok

[13:50] <discord-raku-bot> <nemokosch> can you run the tests on their own?

[13:51] <discord-raku-bot> <rcmlz> I assume that also a "plan" is missing in the files, Anton? I run zef install --verbose Jupyter::Chatbook

[13:51] <discord-raku-bot> <nemokosch> > That file does have a plan statement. I will try to setup a build workflow on GitHub.

[13:52] <discord-raku-bot> <rcmlz> [Jupyter::Chatbook] # Failed test 'Jupyter::Kernel module can be use-d ok'

[13:53] <discord-raku-bot> <rcmlz> Missing Dependency?

[13:53] <discord-raku-bot> <rcmlz> [Jupyter::Chatbook] # Could not find WWW::MermaidInk in:

[13:54] <discord-raku-bot> <antononcube> Yeah, I will check that -- I thought I included "WWW::MermaidInk" in the meta file.

[13:59] *** ab5tract left
[14:01] <discord-raku-bot> <antononcube> I think I found and fixed the 2 problems for installing "LLM::Functions". I also made the GitHub workflows. Will proclaim success, when it comes.

[14:11] *** jgaz left
[14:16] *** jgaz joined
[14:16] <discord-raku-bot> <antononcube> @rcmlz Well, it looks like the installation of "LLM::Functions" works now.

[14:17] <discord-raku-bot> <antononcube> I will fix "Juputer::Chatbook" later today. You can try installing it from GitHub : https://github.com/antononcube/Raku-Jupyter-Chatbook . (It has many new features.)

[14:18] <discord-raku-bot> <antononcube> https://github.com/antononcube/Raku-LLM-Functions/actions/runs/6173719924/job/16756710534

[14:22] <discord-raku-bot> <rcmlz> when will it be available via zef?

[14:23] <discord-raku-bot> <antononcube> I just submitted it to zef (with fez.) Should take less than an hour to be indexed in raku.land . (Most likely)

[14:32] *** ab5tract joined
[14:39] <discord-raku-bot> <antononcube> The improved "LLM::Functions"  -- with verified installation on GitHbub -- is available in Zef ecosystem:  https://raku.land/zef:antononcube/LLM::Functions

[14:57] *** ab5tract left
[15:01] <discord-raku-bot> <rcmlz> üëç

[15:04] <discord-raku-bot> <antononcube> Agh, one of the test files is misplaced -- but GitHub did not complain. Submitting the new version within 2 min. (After I verify the GitHub workflows finish with success.)

[15:45] *** ab5tract joined
[16:36] <discord-raku-bot> <antononcube> @rcmlz  Please, (bravely) install "Jupyter::Chatbook:ver<0.1.3>" from Zef ecosystem. I verified it can be installed from scatch on macOS x86 computer.

[16:39] *** dakkar left
[16:59] *** jgaz left
[18:37] *** MasterDuke left
[18:48] *** MasterDuke joined
[19:08] *** jgaz joined
[19:32] *** lizmat_ joined
[19:33] *** RakuIRCLogger__ left
[19:33] *** lizmat left
[19:37] *** lizmat_ left
[19:37] *** lizmat joined
[19:42] *** deoac joined
[20:21] *** teatwo left
[20:21] *** teatwo joined
[20:23] *** tea3po joined
[20:26] *** teatwo left
[22:02] *** samebchase left
[22:03] *** samebchase joined
[23:00] *** RakuIRCLogger left
[23:55] *** Manifest0 left
