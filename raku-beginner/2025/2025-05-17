[06:46] <discord-raku-bot> <shalokshalom> When I want to write a simple transpiler from one language to another (none of who are Raku) what tools would you recommend?

[11:37] *** stanrifkin joined
[12:01] <discord-raku-bot> <antononcube> Look at the ‚ÄúLLM::*‚Äù packages.

[12:25] <discord-raku-bot> <shalokshalom> thanks a lot

[12:27] <discord-raku-bot> <shalokshalom> how are large language models involved

[12:27] <discord-raku-bot> <shalokshalom> https://cdn.discordapp.com/attachments/768511641758466088/1373275656200392814/Bildschirmfoto_20250517_142648.png?ex=6829d21e&is=6828809e&hm=20bc6dc50a71aa8a99fba35355f9d3b1c90c5fa048162d62bd4089b8f9097fdd&

[12:30] <discord-raku-bot> <antononcube> It is easy to make an LLM function that translates from one programming language to another. An ad hoc prompt can be crafted or the ‚ÄúCodeWriterX‚Äù prompt can be used. For the ad hoc prompt using the prompt ‚ÄúNothingElse‚Äù would be helpful.

[12:37] <discord-raku-bot> <antononcube> For example:  use LLM::Functions; use LLM::Prompts;  my $conf = llm-configuration(‚Äòchatgpt‚Äô, model => ‚Äúgpt-4.1-mini‚Äù, max-tokens => 8192, temperature => 0.45); my &fTrans = llm-function( -> $code, $lang = ‚ÄòRaku‚Äô { llm-prompt(‚ÄúCodeWriterX‚Äù)($lang) ~ ‚Äú\n\n‚Äù ~ $code}, e => $conf) 

[12:40] <discord-raku-bot> <antononcube> So, you can call &fTrans on certain code string like this:  my $code = q:to/END/; 100.rand xx 20 END  say &fTrans($code, ‚ÄòPython‚Äô) 

[12:49] <discord-raku-bot> <shalokshalom> but I would need to run a model

[12:49] <discord-raku-bot> <shalokshalom> I am trying to run a transpiler üòÖ

[12:49] <discord-raku-bot> <shalokshalom> Like, a pure function

[12:50] <discord-raku-bot> <shalokshalom> not an unreliable llm implementation, that costs tons of ressources and produces a different outcome every time

[13:03] <discord-raku-bot> <antononcube> Sure. Then use LLaMA models (run locally, on your computer or sever.) For example, specialized code generators from DeepSeek provided here: https://github.com/Mozilla-Ocho/llamafile .

[13:04] <discord-raku-bot> <antononcube> The outcome is not necessary "different time" and it can be "managed" i.e. made faster and more relible.

[13:05] <discord-raku-bot> <antononcube> BTW, I completely understand and share your point of view. To large extend that is why I deal a lot with LLMs.

[14:07] *** stanrifkin left
[14:18] *** stanrifkin joined
[16:26] <sdomi> "how to make a transpiler" -> "oh, use an LLM" is really sad to read.

[16:26] <sdomi> at this point you're writing a prompt for a glorified markov chain, NOT raku

[16:27] <sdomi> and this isn't the #llm-beginners channel, is it?

[16:30] <sdomi> @shalokshalom depends on whether you want to write everything yourself or want to use libraries. In latter option, look for a parser generator; if the languages are close enough together, you may be able to get around with very minimal intermediate representation

[16:31] <sdomi> raku has the included `grammar` functionality which would work just fine for a very simple transpiler

[16:33] <sdomi> if you don't like parser generators (just like me ;p) then you need to write your own parser, tokenizer, etc.; check out craftinginterpreters.com - the first few chapters should help you lots

[16:34] <discord-raku-bot> <coranila> wow gatekeeping is very raku and butterfly friendly

[16:35] <discord-raku-bot> <coranila> that's to say, those first three lines couldve just not been there i think

[16:35] <discord-raku-bot> <coranila> no pointing finers or flinging blame here, just stating a fact, i think everyone knows what i mean

[17:37] <discord-raku-bot> <antononcube> @sdomi "and this isn't the #llm-beginners channel, is it?" -- yes, it is, if LLMs are used via Raku.

[17:39] <discord-raku-bot> <antononcube> Also, of course, LLMs can be fairly successfully used to generate grammars and "transpiler" code.

[17:50] <discord-raku-bot> <dr.shuppet> "Just call an LLM" is a very disappointing answer to "I want to write a transpiler in a language with native support for grammars"

[17:55] *** sdomi left
[18:02] <discord-raku-bot> <coranila> can we all agree on the compromise that asking an LLM what a specific transpiler might look like can be a good idea instead of starting a fight about a new kind of tool that isn't going to go away?

[18:03] <discord-raku-bot> <coranila> note that this must not be extended to homotopy; it does not imply that no one should talk to anyone anymore

[18:03] <discord-raku-bot> <coranila> it just means that maybe instead of arguing about the fact that a new tool with outrageous implications exists

[18:04] <discord-raku-bot> <coranila> we try to be constructive?

[18:06] <discord-raku-bot> <coranila> again, not accusing anyone, just trying to remind people that drama for drama's sake isn't going to fix issues or complete features, neither in rakudo nor your own projects

[18:07] <discord-raku-bot> <antononcube> @dr.shuppet & @sdomi I am looking at the definition of transcompiler in Wikipedia, https://en.wikipedia.org/wiki/Source-to-source_compiler,  > A source-to-source translator, source-to-source compiler (S2S compiler), transcompiler, or transpiler1[3] is a type of translator that takes the source code of a program written in a programming language as its input and produces an equivalent source code in the

[18:07] <discord-raku-bot> same or a different programming language, usually as an intermediate representation.

[18:08] <discord-raku-bot> <antononcube> So, it seems that the LLM-based code implements are transcomilier. (Usin two lines of Raku code.)

[19:31] <discord-raku-bot> <librasteve> if the languages have BNF definitions then perhaps https://raku.land/zef:raku-community-modules/Grammar::BNF would be helpful ... either way a raku Grammar would be my go to for this

[19:46] <discord-raku-bot> <antononcube> "EBNF::Grammar" is better!!

[19:56] <discord-raku-bot> <antononcube> The interaction with LLMs for making grammars and visualizing them is exemplified here: https://rakuforprediction.wordpress.com/2023/07/06/graph-representation-of-grammars/

[20:00] <discord-raku-bot> <librasteve> i have no experience, but at 10,000' it seems to me that a great use of LLMs would be to help write a transpiler - but that they are too variable to be relied on to be the sausage machine itself

[20:05] *** librasteve_ joined
[20:20] <discord-raku-bot> <antononcube> Right. The "bigger picture" is to use a combination of grammars, DSL examples, and LLM prompts for making source-to-source translations.

[20:22] <discord-raku-bot> <antononcube> For example, using the data of "DSL::Examples" is not that hard to make a reliable LLM source-to-source translator for the corresponding DSLs.

[20:24] <discord-raku-bot> <antononcube> In general -- as we have discussed before -- Raku should have grammars for many programming languages and DSLs in order to facilitate those kind of translations.

