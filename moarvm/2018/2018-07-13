[00:07] *** lizmat left
[00:45] *** MasterDuke left
[01:05] *** MasterDuke joined
[05:13] *** kanopis joined
[05:28] *** nebuchadnezzar left
[05:29] *** nebuchadnezzar joined
[05:34] *** robertle left
[05:47] *** kanopis left
[06:46] *** robertle joined
[07:40] *** domidumont joined
[07:46] *** domidumont left
[07:47] *** domidumont joined
[08:03] *** masak joined
[08:04] <masak> aloha. AlexDaniel``++ found a spesh-related regression: https://github.com/rakudo/rakudo/issues/2057

[08:04] <masak> is there some way I can help pinpoint it?

[08:04] <masak> m: "" ~~ /{ (make 0 for 0) }/ && print "." for ^100

[08:04] <camelia> rakudo-moar 612d071b8: OUTPUT: ¬´.Cannot bind attributes in a Nil type object‚ê§  in regex  at <tmp> line 1‚ê§  in block <unit> at <tmp> line 1‚ê§‚ê§.................................................................................................¬ª

[08:37] *** brrt joined
[09:19] *** lizmat joined
[09:19] <brrt> \o

[09:34] <masak> o/

[09:42] <brrt> ohai masak

[09:42] <brrt> long time no \o

[09:47] <samcv> o/

[09:49] <brrt> ohai samcv

[10:08] <jnthn> o/

[10:08] <jnthn> masak: You can try running it MVM_JIT_DISABLE=1 in the environment to rule out that part of the opts. Also MVM_SPESH_INLINE_DISABLE=1 and MVM_SPESH_OSR_DISABLE=1 each rule out various kinds of optimization.

[10:16] * brrt points at tools/jit-bisect.pl with --spesh option, which automagically figures out which options are decisive

[10:21] <brrt> given a test case that fails with a nonzero exit code

[10:29] <jnthn> brrt: Any progress towards getting guards covered by exprjit?

[10:30] <jnthn> (Unless that happened without me noticing...

[10:37] <brrt> no... I hadn't thought of that as a priority

[10:37] <brrt> I can do that for sure

[10:38] <jnthn> Well, they quite often show up in sequences of instructions

[10:38] <jnthn> like do X, guard it, do stuff with it

[10:48] <brrt> i see

[10:49] <brrt> I don't think implementing them should actually be a problem. It might trigger a sync because we might deoptimize

[10:49] <brrt> well, it would trigger a sync

[10:49] <lizmat> hmmm... seeing one test break: S04-phasers/in-loop.t 14

[10:49] <lizmat> double checking...

[10:50] <Geth> ¬¶ MoarVM: 5429bf254d | (Samantha McVey)++ | build/Makefile.in

[10:50] <Geth> ¬¶ MoarVM: Add uthash_types.h to Makefile.in

[10:50] <Geth> ¬¶ MoarVM:

[10:50] <Geth> ¬¶ MoarVM: This had been missed when the file was added.

[10:50] <Geth> ¬¶ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/5429bf254d

[10:50] <Geth> ¬¶ MoarVM: e766345db9 | (Samantha McVey)++ | 2 files

[10:50] <Geth> ¬¶ MoarVM: Speed up hash garbage collection a lot (gc_mark); add new macros

[10:50] <Geth> ¬¶ MoarVM:

[10:50] <Geth> ¬¶ MoarVM: Add new MVM_gc_worklist_add macros. These new macros assume that the

[10:50] <masak> brrt: I should hang out more on this channel. not doing so is more due to forgetfulness than anything else.

[10:50] <Geth> ¬¶ MoarVM: worklist is large enough to hold the new entries so MVM_gc_worklist_presize_for

[10:50] <Geth> ¬¶ MoarVM: must be called before hand removing one check and a potential function

[10:50] <Geth> ¬¶ MoarVM: call and hence why these are named `nocheck`.

[10:50] <Geth> ¬¶ MoarVM:

[10:50] <Geth> ¬¶ MoarVM: <‚Ä¶commit message has 14 more lines‚Ä¶>

[10:50] <Geth> ¬¶ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/e766345db9

[10:50] <masak> jnthn: oki, trying now

[10:52] <jnthn> brrt: Can be defer the sync until we know we're deoptimizing, 'cus the guard fails?

[10:52] <masak> jnthn: problem persists for MVM_JIT_DISABLE and MVM_SPESH_OSR_DISABLE, but goes away for MVM_SPESH_INLINE_DISABLE

[10:52] <jnthn> (As in, can we in theory...)

[10:52] <lizmat> yeah, confirmed: S04-phasers/in-loop.t test 14 fails, will bump nonetheless

[10:52] <masak> adding this info to the github issue.

[10:53] <jnthn> lizmat: Does it fail due to a MoarVM change or an NQP change, ooc?

[10:53] <lizmat> good question

[10:54] <lizmat> lemme double double check

[10:55] <lizmat> nqp fad8b7cdaf2eae9aae appears to be a candidate

[10:55] <lizmat> (in nqp) ?

[10:56] <lizmat> checking if a revert fixes that

[10:57] <brrt> jnthn: let me check

[10:57] <brrt> masak: welcome back :-)

[10:58] <brrt> (i hang out in #perl6 far too little)

[10:58] <masak> heh :)

[10:58] <masak> I'm mostly a 007 programmer these days, but recent developments have made me more interested in the runtime/bytecode end of things

[11:02] <lizmat> jnthn: it's not that commit

[11:04] <jnthn> lizmat: Phew :)

[11:04] <lizmat> I'm going to bump now anyways... if it's still there in a day or two, I'll make a blocker issue

[11:04] <jnthn> OK

[11:10] <lizmat> m: for ^1 { POST .say; 42 }

[11:10] <camelia> rakudo-moar 612d071b8: OUTPUT: ¬´WARNINGS for <tmp>:‚ê§42‚ê§Useless use of constant integer 42 in sink context (line 1)‚ê§¬ª

[11:11] <lizmat> the essence of the test

[11:11] <lizmat> After the bump, it becomes Mu

[11:19] <jnthn> Hm, that can't even really be spesh to blame

[11:19] <jnthn> Because it's a loop 1 time

[11:20] <jnthn> Well, unless spesh breaks the compiler, but that's a stretch too for such a short program to be compiled

[11:21] <Geth> ¬¶ MoarVM/new-deopt-point-algo: df0ecf2b0f | (Jonathan Worthington)++ | src/spesh/usages.c

[11:21] <Geth> ¬¶ MoarVM/new-deopt-point-algo: Add unseen read handling to new deopt algorithm

[11:21] <Geth> ¬¶ MoarVM/new-deopt-point-algo:

[11:21] <Geth> ¬¶ MoarVM/new-deopt-point-algo: So that it can better handle loops.

[11:21] <Geth> ¬¶ MoarVM/new-deopt-point-algo: review: https://github.com/MoarVM/MoarVM/commit/df0ecf2b0f

[11:22] <lizmat> jnthn: maybe it used to work because of a bug, and you fixed the bug

[11:22] <lizmat> test 15, the one after, is similar, but todoed

[11:23] <jnthn> Hmm, that analysis is a bit expensive

[11:26] <brrt> how's 007 going

[11:51] <samcv> don't bump moarvm. may be some issues with my latest commit. may cause some tests to fail

[11:51] <timotimo> the bump already happened, samcv

[11:51] <samcv> oh ok

[11:52] <samcv> so it must not have issues?

[11:52] <samcv> :P

[11:52] <samcv> well i can bump it again otherwise

[11:52] <brrt> or we screwed up and fix it later :-)

[11:52] * brrt has done that some times

[11:52] <timotimo> it bumped to masak's typo fix commit i think?

[11:52] <samcv> though not certain if it causes issues. but i'm compiling newest rakudo so i can check

[11:57] <masak> gosh, I hope my typo fix is not causing issues :P

[12:04] <samcv> ok the bump didn't have my change in it. so all is ok

[12:05] <Geth> ¬¶ MoarVM: d8e1ad9fca | (Samantha McVey)++ | src/gc/worklist.h

[12:05] <Geth> ¬¶ MoarVM: Fix a crash caused by the previous commit

[12:05] <Geth> ¬¶ MoarVM:

[12:05] <Geth> ¬¶ MoarVM: It turns out this can be null, so we really need to check before

[12:05] <Geth> ¬¶ MoarVM: accessing the struct.

[12:05] <Geth> ¬¶ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/d8e1ad9fca

[12:08] <timotimo> https://morepypy.blogspot.com/2015/10/pypy-memory-and-warmup-improvements-2.html

[12:09] <samcv> jnthn: any more places that could benefit from quicker MVM_gc_worklist_add where we add a bunch of things at once? i'm working on adding it for arrays in addition to hashes

[12:10] <brrt> so... I have a union of a struct and a int32; and I know the struct fits into the int32

[12:10] <brrt> I kind of want to use that union as 'just' integers at some point

[12:10] <samcv> 'just' integers?

[12:10] <brrt> I know that's not actually legal in C these days, but I also know that it will work

[12:10] <brrt> yes

[12:11] <brrt> I have an array of those unions, and one part of it is an integer, and the other is a tiny struct

[12:11] <samcv> you mean like mystruct - mystruct = 0?

[12:11] <brrt> no, i mean: MVMint32 *ints = (MVMint32*)structs; MVMint32 i = ints[10];

[12:12] <samcv> ah so it's a struct of int's

[12:12] <brrt> uhm, i mean MVMint32 *ints = (MVMint32*)unions;

[12:12] <samcv> and the unions are 32 bits in size?

[12:12] <samcv> what else is in the struct other than int32?

[12:12] <brrt> yes, the union is like union { struct { char x[4]; }; int y; }

[12:12] <brrt> that's basically it

[12:12] <samcv> ah ok

[12:12] <timotimo> samcv: when we mark SCRef maybe?

[12:13] <brrt> so; it should never break if I cast it to integers, and deref that

[12:13] <brrt> on the other hand, what I understand from C standard UB is that this is not legal

[12:14] <samcv> yeah it's not. though you could add a compile assert and make sure the size of the struct is the right size

[12:14] <samcv> if it is the right size i'd say you're okay

[12:14] <brrt> can i do that in C? I know there's static_assert in C++

[12:14] <samcv> yeah let me find it

[12:14] <brrt> what I could do is take a reference to the y

[12:15] <brrt> as in: MVMint32 *ys = &(unions[10].y);

[12:15] <brrt> i think that'd be legal?

[12:16] <samcv> brrt: https://stackoverflow.com/a/809465/8046034

[12:17] <samcv> essentially you make an assert macro. and if the condition is true, it makes a typedef of a positive number of bytes. but if it's not it tries to make it negative and the compiler errors

[12:18] <samcv> it's not a C feature until recently, but the macro is fully standards compliant, and doesn't assume anything odd about the compiler

[12:22] <samcv> and also won't make the code any bigger as well. there's other ways that do `char foo[sizeof(mything)==2]` but then you define a variable, and you can only put it where variables are allowed

[12:22] <samcv> though that should get removed when we compile on O3, but the typedef is nicer as it doesn't add variables

[12:24] *** brrt left
[12:28] <jnthn> samcv: I can only think of those two off hand

[12:44] <lizmat> looks like Travis is red because build fails in stage optimize when moar=master

[12:46] <samcv> jnthn: the order of the worklist doesn't matter rigth?

[12:47] <lizmat> afk for a bit&

[12:47] <jnthn> samcv: Not really. I mean, it's cache helpful if things we'll process close in time are close together

[12:48] <jnthn> But correctness wise, no

[12:48] <samcv> ok thanks

[12:51] <Geth> ¬¶ MoarVM/new-deopt-point-algo: be56234ee0 | (Jonathan Worthington)++ | 6 files

[12:51] <Geth> ¬¶ MoarVM/new-deopt-point-algo: Switch over to using the new deopt use method

[12:51] <Geth> ¬¶ MoarVM/new-deopt-point-algo:

[12:51] <Geth> ¬¶ MoarVM/new-deopt-point-algo: We don't currently every throw away any deopt usages, so in the

[12:51] <Geth> ¬¶ MoarVM/new-deopt-point-algo: immediate this is a step backwards (since it removes the "can't do

[12:51] <Geth> ¬¶ MoarVM/new-deopt-point-algo: a deopt after the last deopting instruction" optimization). However,

[12:51] <Geth> ¬¶ MoarVM/new-deopt-point-algo: this will let us work out places where we fail to keep something alive

[12:51] <Geth> ¬¶ MoarVM/new-deopt-point-algo: for deopt that we should be.

[12:51] <Geth> ¬¶ MoarVM/new-deopt-point-algo: review: https://github.com/MoarVM/MoarVM/commit/be56234ee0

[12:51] <jnthn> Well, that explodes CORE.setting...

[13:04] <jnthn> ah, turns out one thing I didn't think was needed in the old handling is :P

[13:05] <Geth> ¬¶ MoarVM/new-deopt-point-algo: 787b7bb7e6 | (Jonathan Worthington)++ | src/spesh/usages.c

[13:05] <Geth> ¬¶ MoarVM/new-deopt-point-algo: Value written by deopt instruction also needed

[13:05] <Geth> ¬¶ MoarVM/new-deopt-point-algo: review: https://github.com/MoarVM/MoarVM/commit/787b7bb7e6

[13:11] *** lizmat left
[13:11] *** reportable6 left
[13:11] *** reportable6 joined
[13:13] *** brrt joined
[13:18] <brrt> samcv: cool

[13:22] <samcv> it looks like SCRef sometimes pushes null's but even if it does it's faster to just not check and check later when processing the worklist

[13:23] <jnthn> Yeah :)

[13:23] <samcv> though most of the time it doesn't. but i tested one of the roast files which did a lot of them

[13:23] <jnthn> It's because lazy deserialization :)

[13:23] <samcv> since i knew it was faster in most files which that doesn't happen

[13:24] <timotimo> how about a vectorized null-check for a whole bunch of pointers at once?

[13:24] <timotimo> for quickly skipping over big amounts of not-yet-deserialized objects

[13:24] <samcv> not sure if that'd be faster?

[13:24] <timotimo> there's sometimes like a hundred null pointers in a row

[13:24] <samcv> does that even happen often enough?

[13:24] <timotimo> well, the core setting is huge and many programs don't use most of the classes in there

[13:25] <jnthn> True, but first of all you need a program that runs long enough to reach a gen2 collect. :)

[13:25] <timotimo> also true

[13:25] <jnthn> But yes, once that happens, the CORE.setting one should contain a lot of non-deserialized things

[13:26] *** lizmat joined
[13:26] <timotimo> do we ever clean up objects we've deserialized? i don't think we do. do we allocate them in the gen2 by default, then?

[13:26] <timotimo> in that case we can skip checks for gen2 there, too

[13:30] <jnthn> Well, SCs are elligible for GC

[13:30] <timotimo> right, only when the SC itself gets collected do its objects die

[13:31] <jnthn> But yeah, we presume that once we've deserialized them once, they'll be needed again

[13:31] <timotimo> could be a tiny bit faster, too

[13:37] <jnthn> Ugh. First attempt at using the new deopt data to decide what things we don't need to keep immediately throws away something important

[13:37] <jnthn> Now to figure out why.

[13:38] <jnthn> That said, a spectest comes out looking alright before I try deleting deopt usages that we in theory no longer need.

[13:39] <jnthn> So at least the more precise capture of them seems to not be missing anything in the first place.

[13:58] <Geth> ¬¶ MoarVM: 6ec68988d5 | (Samantha McVey)++ | src/6model/reprs/VMArray.c

[13:58] <Geth> ¬¶ MoarVM: Rename VMArray gc_mark to VMArray_gc_mark

[13:58] <Geth> ¬¶ MoarVM:

[13:58] <Geth> ¬¶ MoarVM: This makes it easy to see which `gc_mark` is taking up time when we

[13:58] <Geth> ¬¶ MoarVM: profile MoarVM code.

[13:58] <Geth> ¬¶ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/6ec68988d5

[13:58] <Geth> ¬¶ MoarVM: 8ac13c2942 | (Samantha McVey)++ | src/6model/reprs/VMArray.c

[13:58] <Geth> ¬¶ MoarVM: Optimize VMArray_gc_mark to be a bit faster

[13:58] <Geth> ¬¶ MoarVM:

[13:58] <Geth> ¬¶ MoarVM: Use the new macros to get a bit of speed improvement.

[13:58] <samcv> well this makes it a bit faster when that code is used

[13:58] <Geth> ¬¶ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/8ac13c2942

[13:58] <Geth> ¬¶ MoarVM: 7bf4c429f2 | (Samantha McVey)++ | src/6model/reprs/SCRef.c

[13:58] <Geth> ¬¶ MoarVM: Optimize SCRef_gc_mark by using faster MVM_gc_worklist_add calls

[13:58] <Geth> ¬¶ MoarVM:

[13:58] <Geth> ¬¶ MoarVM: Use these faster calls which gives a noticable improvement in code that

[13:58] <samcv> the SCRef that is. and the array as well too

[13:58] <Geth> ¬¶ MoarVM: has to do a fair amount of SCRef gc marking.

[13:58] <Geth> ¬¶ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/7bf4c429f2

[14:16] <jnthn> Ah, found it

[14:16] <jnthn> Call optimization can introduce additional guards

[14:16] <jnthn> And they get their own deopt point

[14:17] <jnthn> But none of them steal/move the deopt point that was in that area in the first place

[14:17] <jnthn> Thus we think it's not used

[14:19] <jnthn> samcv++ # GC speedups

[14:50] <Geth> ¬¶ MoarVM/new-deopt-point-algo: 3345ec3646 | (Jonathan Worthington)++ | 5 files

[14:50] <Geth> ¬¶ MoarVM/new-deopt-point-algo: Fix handling of added deopt points

[14:50] <Geth> ¬¶ MoarVM/new-deopt-point-algo:

[14:50] <Geth> ¬¶ MoarVM/new-deopt-point-algo: During call optimization, we might choose to insert extra deopting

[14:50] <Geth> ¬¶ MoarVM/new-deopt-point-algo: instructions, each which get their own annotation. However, we were

[14:50] <Geth> ¬¶ MoarVM/new-deopt-point-algo: leaving the original annotation then on a prepargs, which is not a

[14:50] <Geth> ¬¶ MoarVM/new-deopt-point-algo: deopt-causing instruction, so we would wrongly drop use of the deopt

[14:50] <Geth> ¬¶ MoarVM/new-deopt-point-algo: point. Fix by establishing a link between those added "synthetic"

[14:50] <Geth> ¬¶ MoarVM/new-deopt-point-algo: deopt points and the original one they stole the target address from.

[14:50] <Geth> ¬¶ MoarVM/new-deopt-point-algo: review: https://github.com/MoarVM/MoarVM/commit/3345ec3646

[14:52] <jnthn> With that, the new more aggressive deopt point deletion builds NQP and Rakudo and passes make test in both.

[14:53] <jnthn> Unfortunately, though, the algorithm that assembles the more precise deopt point information is le slow

[14:54] <lizmat> le slow ?

[14:54] <jnthn> Even bad things sound classy in French :P

[14:54] <lizmat> hehe

[14:55] <jnthn> I suspect I can speed it up some, though it wasn't really worth it until I knew the whole thing wasn't utterly flawed

[14:55] <jnthn> This is attempt 4 at getting sufficient deopt handling improvement.

[14:56] <jnthn> In various cases we lower things that could potentially deopt into things that simply could not.

[14:56] <jnthn> I'd also like to make us able to delete guards that we don't use

[14:57] <lizmat> .oO( who guards the guards )

[14:57] <jnthn> Well, rather, that we have but later prove we don't need

[14:58] <jnthn> But I noticed that even if I did that, we'd still have kept instructions alive in case a guard that is no longer there would deopt.

[14:58] <jnthn> And we didn't track which things we were keeping alive by the deopt point keeping them alive.

[14:59] <jnthn> This was already an issue in that we'd lower a potentially deopting instruction into one that never could, but again have to assume the worst

[14:59] <jnthn> So the branch gives us far more precise tracking of which deopt points keep alive which instructions

[15:00] <jnthn> And then we do a pass afterwards seeing which deopt points can really deopt

[15:01] <jnthn> And delete deopt usages for things that never could.

[15:01] <jnthn> Anyway, this approach seems solid model wise.

[15:13] *** brrt left
[15:19] <dogbert17> jnthn, lizmat: I'm quite certain that https://github.com/MoarVM/MoarVM/commit/1b1edfe5ffed20f0f9f7fe28edff50bc0b3de7e8 is the commit which breaks the Optimize stage on a 32 bit build

[15:19] <jnthn> haha, part of it was O(MG) :)

[15:20] <jnthn> Now a good bit better :)

[15:20] <jnthn> dogbert17: Hmm, intresting.

[15:21] <dogbert17> I'm 90+ percent certain ...

[15:22] <jnthn> Yeah, now even with spesh blocking the test times look sensible again :)

[15:23] <lizmat> jnthn: so it wasn't as expensive as you thought ?

[15:24] <jnthn> lizmat: Well, it *was* expensive the way I originally implemented it

[15:24] <lizmat> aahhh  ok

[15:24] <jnthn> lizmat: But that's because I was repeatedly calculating an O(n) thing that was in itself in an O(a different n) thing

[15:24] <lizmat> yeah, you quickly go to O(MG) then

[15:25] <jnthn> Whereas it was possible to make the first thing O(1) and in some cases to realize we didn't need to do the O(n) at that point either.

[15:25] <jnthn> That O(n) already being repeated per basic block

[15:25] <jnthn> So basically it was cubic :)

[15:26] <jnthn> Though in 3 different things, but I guess they can be expected to correlate in how they grow

[15:26] <nwc10> jnthn: is this evil O(bother) thing on the main thread? or on the spesh thread (so just slowing down optimisations, not main throughput)?

[15:27] <Geth> ¬¶ MoarVM/new-deopt-point-algo: 91540080eb | (Jonathan Worthington)++ | src/spesh/usages.c

[15:27] <Geth> ¬¶ MoarVM/new-deopt-point-algo: Remove leftover debugging code

[15:27] <Geth> ¬¶ MoarVM/new-deopt-point-algo: review: https://github.com/MoarVM/MoarVM/commit/91540080eb

[15:27] <Geth> ¬¶ MoarVM/new-deopt-point-algo: fc1378ad27 | (Jonathan Worthington)++ | src/spesh/usages.c

[15:27] <Geth> ¬¶ MoarVM/new-deopt-point-algo: Don't repeatedly calcuate if preds are seen

[15:27] <Geth> ¬¶ MoarVM/new-deopt-point-algo:

[15:27] <Geth> ¬¶ MoarVM/new-deopt-point-algo: We can instead keep track of which basic blocks have had all of their

[15:27] <Geth> ¬¶ MoarVM/new-deopt-point-algo: preds handled, and update it by looking at the succs of a basic block

[15:27] <Geth> ¬¶ MoarVM/new-deopt-point-algo: after processing it. Better still, if nothing changes, then we know we

[15:27] <Geth> ¬¶ MoarVM/new-deopt-point-algo: don't have to both processing the outstanding reads at all.

[15:27] <Geth> ¬¶ MoarVM/new-deopt-point-algo: review: https://github.com/MoarVM/MoarVM/commit/fc1378ad27

[15:27] <jnthn> nwc10: The spesh thread, but that has to be sync'd up for GC reasons, so if it sticks itself in a C loop for ages then it'll clog up the lot

[15:28] <nwc10> thanks. As you can tell from needing that rider on the end, I'd forgotten that bit

[15:32] <jnthn> Now, do I dare try this with NODELAY... :)

[15:32] * jnthn does it

[15:33] <dogbert17> go go go :)

[15:33] <jnthn> Really hope it copes

[15:33] * dogbert17 is trying to build Rakudo with asan to see if it has anything to say ...

[15:33] <jnthn> This was quite difficult to come up with :)

[15:35] <dogbert17> I'm optimistic

[15:36] <jnthn> NQP is happy

[15:37] <dogbert17> yay

[15:38] <dogbert17> meh, my asan experiment failed

[15:42] *** domidumont left
[15:43] *** robertle left
[15:44] <jnthn> Two NativeCall tests are a bit unhappy under NODELAY

[15:46] <dogbert17> that wasn't too much was it?

[15:47] <jnthn> No, and I didn't actually run with NODELAY for a day or two, so should check if it even is my branch

[15:51] <jnthn> My next task will be to sort out guards so we can handle proving they ain't needed

[15:51] <jnthn> After that, I'll focus on cleaning up after all the changes :-)

[15:51] <jnthn> And the Rakudo blockers

[15:54] <jnthn> btw, for those of you working on spesh things: once the branch lands, the facts section includes for each register kept alive by deopt a list of the indexes of the deopt points keeping it alive.

[15:55] <jnthn> That together with the DU graph means we now have a very clear picture of why things can't be eliminated

[15:56] <jnthn> *DU work

[15:59] <jnthn> Looks like what spectest failures under the nodelay exist are all error reporting/backtrace related

[15:59] <jnthn> Which we know is an issue

[16:02] <jnthn> And the nativecall one seems to be about OSR

[16:04] <jnthn> And yeah, it was this branch that did it

[16:14] <dogbert17> do you know what the problem might be?

[16:22] <jnthn> Though we're in unoptimized code when things go wrong

[16:38] *** japhb joined
[16:57] <jnthn> Ah, I think spesh plugins are perhaps to blame

[16:58] <jnthn> They meddle with the graph a bit too much

[16:58] *** japhb left
[16:58] <jnthn> Hm, maybe

[16:58] <jnthn> argh, yes, certainly

[17:00] *** japhb joined
[17:01] <jnthn> D'oh

[17:01] <jnthn> That code will have to shuffle along to the optimize phase

[17:02] <jnthn> Oh, and I see why the previous algorithm got away with it too

[17:03] <jnthn> Though it'll be a tad more involved that just calling the code from a different place, 'cus it will also have to use that new synthetic deopt point mechanism also

[17:04] <jnthn> Will fix it later.

[17:05] <jnthn> dinner &

[17:42] <lizmat> samcv: sanity check: if a hash is not altered wrt to keys, will each iteration on the hash produce the same order or not ?

[17:42] <lizmat> samcv: nvm, it needs to be consistent across different hashes with the same keys

[17:43] <timotimo> that won't be the same

[17:43] <lizmat> yeah

[17:47] *** greppable6 left
[17:47] *** greppable6 joined
[17:55] *** domidumont joined
[18:01] <dogbert17> interesting, valgrind gets angry with t/spec/S24-testing/3-output.t

[18:03] <dogbert17> perhaps something for jnthn: https://gist.github.com/dogbert17/d6172f8443a79459ded87eaac890ffb4

[18:03] *** domidumont left
[18:18] <lizmat> jnthn timotimo moritz: if "Perl 5 is Turing complete, impure, untyped, locally-scoped, dynamically-dispatched with non-local control flow"

[18:18] <lizmat> how would you characterize Perl 6 in one line ?

[18:19] <lizmat> I guess s/untype/gradually typed/

[18:25] *** robertle joined
[18:38] <TimToady> .oO(The language that does everything more beautifully than you.)

[18:38] <TimToady> with a nod to Martha Stewart...

[18:43] *** buggable left
[18:43] *** buggable joined
[18:44] *** buggable left
[18:44] <lizmat> fwiw, trying to draft a comment on https://news.ycombinator.com/item?id=17525175 to expose any difference  between Perl 5 and Perl 6

[18:45] *** buggable joined
[18:45] *** buggable left
[18:47] *** buggable joined
[19:05] *** buggable left
[19:07] *** buggable joined
[19:08] *** buggable left
[19:08] *** buggable joined
[19:12] *** buggable left
[19:12] *** buggable joined
[19:14] <lizmat> m: my %m is Map = ^1000; %m.WHICH for ^100; say now - INIT now

[19:14] <camelia> rakudo-moar 9f524d0ad: OUTPUT: ¬´0.8990476‚ê§¬ª

[19:17] <lizmat> when I --profile this ^^^ , the 2 top entries are: the Bool *prototype* in Mu, and find_method from Metamodel.nqp:1105

[19:17] <lizmat> and they take up 40% of the CPU for that code.

[19:17] <lizmat> that seems weird to me: is this some artefact?  Should I make a ticket for it?

[19:19] <lizmat> the Bool prototype appears to create 2 CallCapture objects for each call (or thereabouts)

[19:20] <lizmat> *confused*

[19:20] <jnthn> Something sounds a bit off there, yes

[19:38] <dogbert17> turns out valgrind is unhappy about a lot of scripts, same error though, in lessen_deopt_requires_for_bb()

[19:39] <lizmat> jnthn: so ticket ?

[20:26] <jnthn> dogbert17: Hah, I don't have to debug that then :D

[20:27] <jnthn> dogbert17: That function ceased to exist in my current branch :)

[20:27] <jnthn> lizmat: Yeah

[20:27] <lizmat> jnthn: moar or rakudo issue ?

[20:28] <jnthn> lizmat: Sounds like Rakudo

[20:28] <lizmat> ok, will do

[20:30] <dogbert17> jnthn: lol

[21:15] <MasterDuke> lizmat: fwiw, here's a perf report of your above example (with the two numbers both increased to 5000) https://gist.github.com/MasterDuke17/8192fcc93650e1b05d4908325a0afc35

[21:16] <MasterDuke> huh, just tried to --profile it and got `MoarVM oops: Spesh: failed to fix up handler 1 in <unit> (930, -1, -1)`

[21:19] <lizmat> aha, ok so something screwy going on

[21:23] <MasterDuke> updated the gist with a gdb backtrace after putting a breakpoint in MVM_oops

[21:26] *** dogbert11 joined
[21:28] *** dogbert17 left
[21:29] *** AlexDaniel left
[21:30] *** AlexDaniel joined
[22:24] * jnthn tries a patch to fix the facts last known issue in the new deopt algo

[22:24] <yoleaux> 20:58Z <lizmat> jnthn: do you think .hash should always return a .Hash , or can it also return an immutable Map ?

[22:24] <jnthn> .tell lizmat It's a conextualizer, so so long as it returns something Hashish it's all good.

[22:24] <yoleaux> jnthn: I'll pass your message to lizmat.

[22:24] <jnthn> .tell lizmat Uh...Hash-ish :P

[22:24] <yoleaux> jnthn: I'll pass your message to lizmat.

[22:26] <jnthn> NQP is happy after the changes, and the failing NativeCall test also

[22:27] <jnthn> Doing a full NODELAY Rakudo build now

[22:33] *** robertle left
[22:36] <Geth> ¬¶ MoarVM/new-deopt-point-algo: 8821a35820 | (Jonathan Worthington)++ | 2 files

[22:36] <Geth> ¬¶ MoarVM/new-deopt-point-algo: Move speshresolve handling into optimize phase

[22:36] <Geth> ¬¶ MoarVM/new-deopt-point-algo:

[22:36] <Geth> ¬¶ MoarVM/new-deopt-point-algo: Previously, the guards were inserted at the facts phase. We got away

[22:36] <Geth> ¬¶ MoarVM/new-deopt-point-algo: with this when deopt processing was more lax and in band with the facts

[22:36] <Geth> ¬¶ MoarVM/new-deopt-point-algo: analysis. However, now it takes place after. That's still OK for most

[22:36] <Geth> ¬¶ MoarVM/new-deopt-point-algo: guard insertion cases. But spesh plugins aren't a guard insertion. They

[22:36] <Geth> ¬¶ MoarVM/new-deopt-point-algo: are a significant graph change, rendering the graph too different from

[22:36] <Geth> ¬¶ MoarVM/new-deopt-point-algo: <‚Ä¶commit message has 10 more lines‚Ä¶>

[22:36] <Geth> ¬¶ MoarVM/new-deopt-point-algo: review: https://github.com/MoarVM/MoarVM/commit/8821a35820

[22:38] <jnthn> Hurrah.

[22:40] <MasterDuke> how close is the branch to merging?

[22:41] <jnthn> With luck, 3 minutes

[22:41] <jnthn> ah, maybe a couple longer on this machine

[22:42] <jnthn> And after that, though not today, my next task will be the changing of the guards :)

[22:42] <jnthn> So that they produce a new SSA version

[22:42] <jnthn> Which will allow us to understand data flow before/after the guard, to eliminate ones we can prove we don't need

[22:43] <jnthn> Like if we call .chars we currently guard the result being an Int

[22:44] <jnthn> But if we've inlined it, which we will because it's tiny, then we can see it box a box_i to type Int

[22:44] <MasterDuke> nice

[22:44] <jnthn> I'll then be very close to having my int $i = $str.chars; being able to optimize away the boxing

[22:49] <Geth> ¬¶ MoarVM/master: 9 commits pushed by (Jonathan Worthington)++

[22:49] <Geth> ¬¶ MoarVM/master: 7e1ab4b2bd | Sketch out more precise deopt algorithm

[22:49] <Geth> ¬¶ MoarVM/master: df0ecf2b0f | Add unseen read handling to new deopt algorithm

[22:49] <Geth> ¬¶ MoarVM/master: be56234ee0 | Switch over to using the new deopt use method

[22:49] <Geth> ¬¶ MoarVM/master: 787b7bb7e6 | Value written by deopt instruction also needed

[22:49] <Geth> ¬¶ MoarVM/master: 3345ec3646 | Fix handling of added deopt points

[22:49] <Geth> ¬¶ MoarVM/master: 91540080eb | Remove leftover debugging code

[22:49] <Geth> ¬¶ MoarVM/master: fc1378ad27 | Don't repeatedly calcuate if preds are seen

[22:49] <Geth> ¬¶ MoarVM/master: 8821a35820 | Move speshresolve handling into optimize phase

[22:49] <Geth> ¬¶ MoarVM/master: 00d5a0611c | Merge branch 'new-deopt-point-algo'

[22:49] <Geth> ¬¶ MoarVM/master: review: https://github.com/MoarVM/MoarVM/compare/7bf4c429f2ff...00d5a0611c01

[22:50] <jnthn> There we go :)

[22:55] <dogbert11> jnthn++

[23:14] <dogbert11> t/spec/S17-promise/lock-async-stress2.t flaps. I'm quite certain it has nothing to do with your recent merge though.

[23:16] <jnthn> No, don't think so, except to the degee that if you make things faster then you are more likely to expose existing races.

[23:17] <dogbert11> Not enough positional arguments; needed at least 2 in block  at t/spec/S17-promise/lock-async-stress2.t line 11

[23:42] *** lizmat left
