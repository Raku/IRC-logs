[00:12] *** Kaiepi left
[00:28] *** Kaiepi joined
[00:29] *** p6bannerbot sets mode: +v Kaiepi

[00:46] *** MasterDuke joined
[00:46] *** p6bannerbot sets mode: +v MasterDuke

[00:46] *** MasterDuke left
[00:46] *** MasterDuke joined
[00:46] *** herbert.freenode.net sets mode: +v MasterDuke

[00:46] *** p6bannerbot sets mode: +v MasterDuke

[01:15] *** fake_space_whale joined
[01:15] *** p6bannerbot sets mode: +v fake_space_whale

[01:32] *** Kaiepi left
[01:33] *** Kaiepi joined
[01:34] *** p6bannerbot sets mode: +v Kaiepi

[03:01] *** Kaiepi left
[03:02] *** Kaiepi joined
[03:02] *** p6bannerbot sets mode: +v Kaiepi

[03:19] *** Kaiepi left
[03:19] *** Kaiepi joined
[03:20] *** p6bannerbot sets mode: +v Kaiepi

[03:54] *** fake_space_whale left
[04:00] *** MasterDuke left
[04:49] *** fake_space_whale joined
[04:49] *** p6bannerbot sets mode: +v fake_space_whale

[05:17] *** fake_space_whale left
[05:39] *** Kaiepi left
[05:39] *** Kaiepi joined
[05:40] *** p6bannerbot sets mode: +v Kaiepi

[06:25] *** robertle joined
[06:25] *** p6bannerbot sets mode: +v robertle

[06:33] *** domidumont joined
[06:33] *** p6bannerbot sets mode: +v domidumont

[07:42] *** zakharyas joined
[07:42] *** p6bannerbot sets mode: +v zakharyas

[07:48] *** zakharyas left
[08:16] <Geth> Â¦ MoarVM/nqp-mbc: dc39fc6e45 | (Stefan Seifert)++ | src/jit/graph.c

[08:16] <Geth> Â¦ MoarVM/nqp-mbc: JIT compile unbox_u

[08:16] <Geth> Â¦ MoarVM/nqp-mbc: review: https://github.com/MoarVM/MoarVM/commit/dc39fc6e45

[08:16] *** lizmat left
[08:32] *** lizmat joined
[08:32] *** p6bannerbot sets mode: +v lizmat

[08:34] *** yoleaux left
[08:36] *** zakharyas joined
[08:37] *** p6bannerbot sets mode: +v zakharyas

[08:39] *** AlexDaniel left
[08:40] *** zakharyas left
[09:50] *** zakharyas joined
[09:51] *** p6bannerbot sets mode: +v zakharyas

[10:30] *** yoleaux joined
[10:30] *** p6bannerbot sets mode: +v yoleaux

[10:35] *** Kaiepi left
[10:35] *** Kaiepi joined
[10:36] *** p6bannerbot sets mode: +v Kaiepi

[11:05] *** Kaiepi left
[11:08] *** Kaiepi joined
[11:09] *** p6bannerbot sets mode: +v Kaiepi

[11:15] *** Zoffix left
[11:32] *** lizmat left
[11:35] *** lizmat joined
[11:35] *** p6bannerbot sets mode: +v lizmat

[12:09] *** AlexDaniel joined
[12:09] *** p6bannerbot sets mode: +v AlexDaniel

[12:32] <Geth> Â¦ MoarVM: f4eafe0de0 | (Zoffix Znet)++ | src/6model/parametric.c

[12:32] <Geth> Â¦ MoarVM: Fix typo in comment

[12:32] <Geth> Â¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/f4eafe0de0

[12:35] *** brrt joined
[12:35] *** brrt left
[12:37] *** brrt joined
[12:37] *** p6bannerbot sets mode: +v brrt

[12:37] <brrt> \o

[12:38] <nwc10> o/

[12:38] <brrt> which one of us can comment here: https://www.reddit.com/r/perl6/comments/9qcd3l/perl_6_on_aix/

[12:39] <brrt> ohai nwc10

[12:39] <brrt> I'm not sure how I'll fix the UB you find

[12:45] <lizmat> brrt: not me, my experience with AIX ended early 2000 with an AIX 3 box that I decommisioned

[12:46] <nine> Looks like dyncall doesn't support AIX. But maybe libffi does?

[12:48] <brrt> well, either of those are a good answer :-) I just don't have a reddit account even

[12:49] <nine> me neither

[12:54] *** MasterDuke joined
[12:55] *** p6bannerbot sets mode: +v MasterDuke

[13:07] *** MasterDuke_ joined
[13:07] *** p6bannerbot sets mode: +v MasterDuke_

[13:08] *** MasterDuke_ left
[13:09] *** MasterDuke_ joined
[13:10] *** p6bannerbot sets mode: +v MasterDuke_

[13:10] *** MasterDuke_ left
[13:10] *** MasterDuke left
[13:18] <ugexe> fwiw i looked more into using non-blocking uv_getaddrinfo in e.g. MVM_io_socket_connect_async and i'm not sure i'll have time to figure it out anytime soon. I was going to crib from julia https://github.com/JuliaLang/julia/blob/0432866afcf1dc1f2ad080c23b6fa980bd357dff/stdlib/Sockets/src/addrinfo.jl#L13 but I ran out of time before even getting to the code writing part

[13:24] *** Kaiepi left
[13:25] *** Kaiepi joined
[13:26] *** p6bannerbot sets mode: +v Kaiepi

[13:44] <brrt> ugexe: what's the use case

[13:46] <brrt> anyway, whatever julia is doing, might not work for us

[13:55] <ugexe> is it not bad design to have a blocking (possibly indefinitely) call inside a function intended to be asynchronous?

[14:06] *** zakharyas left
[14:06] *** zakharyas joined
[14:07] *** p6bannerbot sets mode: +v zakharyas

[14:07] <ugexe> for a use case i would imagine dead-lock or starvation could occur with enough connections queued that require dns

[14:08] <brrt> oh no, you're right

[14:08] <brrt> but

[14:09] <brrt> what I'm really asking is, how do you want to expose it to the user

[14:10] <brrt> I guess the true perlish thing to do, would be to have an async addrinfo opcode, and to have async socket opcodes that used the asynchronously obtained result

[14:10] <brrt> if that makes any sense

[14:10] <brrt> otherwise, you're going to have to do it via callbackland

[14:10] <brrt> (and internalize it)

[14:10] <ugexe> i'm not worried about exposing the async getaddr info to the user, mainly for internal use (like .connect)

[14:11] *** zakharyas left
[14:12] <ugexe> but yeah the impression i got was i was going to have to create an opcode like you said

[14:14] <ugexe> it'd be simple to just handle dns in the perl6 theadpool, but seems hacky

[14:18] <brrt> why?

[14:18] <brrt> or, as in, make another thread? no, please don't :-)

[14:18] <ugexe> right, in the possible but still theoretical future IO threadpool

[14:18] <timotimo> i'm not seeing the problem yet with making getaddrinfo asynchronous via the libuv loop

[14:19] <timotimo> we do have a thread that handles async IO stuff (though not running any user code or moarvm bytecode)

[14:19] <ugexe> i mean a threadpool that async filesystem IO would be used for

[14:20] <timotimo> not sure how you mean that

[14:22] <ugexe> if async filesystem IO were to be added to perl 6 it would likely be done via a theradpool in perl6-land instead of using libuv's "async" filesystem IO ( which is also a threadpool doing sync operations )

[14:22] <timotimo> ah, i didn't know that

[14:22] <timotimo> libuv threads are still more lightweight than perl6 threads

[14:23] <timotimo> remember that a perl6 thread comes with a nursery that gets set up as 1 megabyte if i'm not mistaken and grows to 4 megabytes * 2 (because semispace copying garbage collection)

[14:23] <timotimo> so you're looking at between 2 megs and 8 megs per thread

[14:24] <ugexe> libuv isn't thread safe, i don't want to imagine trying to imagine trying to manage libuv's threadpool inside moarvm. we also have libuv loop per thread, so each thread has its own libuv threadpool?

[14:24] <timotimo> perhaps not necessary

[14:24] <timotimo> if we have one dedicated MVM thread that handles the libuv thread pool

[14:24] <timotimo> i'd assume that all these threads libuv uses to do sync io in an async fashion are transparent to us

[14:25] <timotimo> i.e. we'll never touch individual threads in that pool ourselves

[14:40] <brrt> ugexe: we have an IO thread

[14:40] <brrt> and we may have a thread pool in some future point, but we don't have that yet

[14:41] <brrt> nobody ever had that much IO needs yet

[14:41] <timotimo> so i've come up with a simple way to improve nativeref + boolification stuff

[14:41] <brrt> timotimo: tell us more

[14:42] <brrt> ugexe: also, we no longer have an uv loop per thread. We have a single IO loop thread, and it is started on demand. See src/io/eventloop.c

[14:42] <timotimo> so, the code i'm looking at at the moment is nativeattrref_i, then decont, then bool_I

[14:43] <brrt> and async file IO is a lie anyway, on linux at least :-)

[14:43] <timotimo> decont on the nativeattrref_i will get_int on the nativeref and box it into an Int object

[14:43] <brrt> uhuh

[14:43] <timotimo> if i split that apart into explicit moar bytecode ops, then it should be possible to have an if_i instead of the bool_I + if_o

[14:43] <brrt> yes

[14:43] <timotimo> and then the later stage can probably throw out the box + unbox already

[14:43] <brrt> yes

[14:44] <brrt> go for it

[14:44] <timotimo> the next improvement step would of course be to turn the get_int on the native ref into a getattr_i

[14:44] <brrt> uhuh

[14:44] <brrt> (and to make that into a sp_get_i)

[14:44] <timotimo> yup

[14:46] <brrt> anyway, I agree that having synchronous getaddrinfo in an async function is not-so-optimal design

[14:47] <brrt> what I'm not so sure about is hiding the async call versus making it explicit, and I'm usually in favor of explicit but that might upset clients that use the current interface

[14:47] <timotimo> i don't see a reason why our clients would even see the difference

[14:48] <timotimo> so long as we only change getaddrinfo that is inside a function that is already async itself

[14:51] <brrt> they wouldn't, we can hide it, but an async getaddrinfo exported to users would in fact be very nice

[14:52] <brrt> so currently we have sync getaddrinfo within 'async' connect, right?

[14:52] <timotimo> that's how i understand it; but also inside udp send message?

[14:53] <brrt> I think so, yes

[14:53] <brrt> so that's not strictly a correct factorization of the synchronous/asynchronous bits

[14:54] <brrt> correct would be: getaddrinfo(...).and-then($addr -> async-connect($addr)).and-then(...);

[14:54] <brrt> same for async-send-message

[14:54] <brrt> but that means an interface change

[14:59] <timotimo> huh, that's funny. the code will be an unbox_i followed immediately by a box_i

[15:00] *** fake_space_whale joined
[15:01] *** p6bannerbot sets mode: +v fake_space_whale

[15:04] *** brrt left
[15:12] <timotimo> oh, unbox_i isn't the right op, it seems like

[15:13] <timotimo> probably decont_[ins] instead

[15:19] <timotimo> i'll go afk for a bit, but i'm closing in on the target. just gotta get the define/usage right

[15:19] *** samebchase left
[15:20] *** samebchase joined
[15:20] *** p6bannerbot sets mode: +v samebchase

[15:22] *** Kaiepi left
[15:25] *** Kaiepi joined
[15:26] *** p6bannerbot sets mode: +v Kaiepi

[15:26] <timotimo> well, it splits it now, but it doesn't yet eliminate the box/unbox pair. gotta check into that later.

[15:27] *** domidumont left
[15:27] <Geth> Â¦ MoarVM/nativeref_decont_split: e50162dd19 | (Timo Paulssen)++ | src/spesh/optimize.c

[15:27] <Geth> Â¦ MoarVM/nativeref_decont_split: fix precedence issue

[15:27] <Geth> Â¦ MoarVM/nativeref_decont_split: review: https://github.com/MoarVM/MoarVM/commit/e50162dd19

[15:27] <Geth> Â¦ MoarVM/nativeref_decont_split: 05c476140f | (Timo Paulssen)++ | src/spesh/optimize.c

[15:27] <Geth> Â¦ MoarVM/nativeref_decont_split: decont on nativeref shall become decont_* + box_*

[15:27] <Geth> Â¦ MoarVM/nativeref_decont_split:

[15:27] <Geth> Â¦ MoarVM/nativeref_decont_split: this way we should later be able to use the deconted

[15:27] <Geth> Â¦ MoarVM/nativeref_decont_split: value directly without boxing it first, and then

[15:27] <Geth> Â¦ MoarVM/nativeref_decont_split: more easily get rid of a native ref taking instruction.

[15:27] <Geth> Â¦ MoarVM/nativeref_decont_split: review: https://github.com/MoarVM/MoarVM/commit/05c476140f

[15:28] <timotimo> feel free to tell me that "precedence issue" isn't actually an issue

[15:28] <timotimo> i do think bitwise ops bind looser than boolean ops

[15:39] *** robertle left
[16:03] *** fake_space_whale left
[16:07] *** brrt joined
[16:07] <timotimo> yay, setting KNOWN_TYPE for the spesh slot gets us to fastbox_bi_ic

[16:08] *** p6bannerbot sets mode: +v brrt

[16:08] <Geth> Â¦ MoarVM/nativeref_decont_split: 8d72f86e29 | (Timo Paulssen)++ | src/spesh/optimize.c

[16:08] <Geth> Â¦ MoarVM/nativeref_decont_split: set flags & known type on spesh slot

[16:08] <Geth> Â¦ MoarVM/nativeref_decont_split:

[16:08] <Geth> Â¦ MoarVM/nativeref_decont_split: unblocks optimizing the box_* into a fastbox, in the

[16:08] <Geth> Â¦ MoarVM/nativeref_decont_split: case of box_i it will even go through the int cache.

[16:08] <Geth> Â¦ MoarVM/nativeref_decont_split: review: https://github.com/MoarVM/MoarVM/commit/8d72f86e29

[16:08] <timotimo> oh ... oh no ...

[16:10] <timotimo> infix:<+> used to be getarg, decont, add_i

[16:10] <timotimo> now it's getarg, decont_i, box_i, add_I

[16:10] <timotimo> sorry, it was add_I before, too

[16:11] <brrt> oh, that's not necessarily bad

[16:11] <timotimo> no, that's very bad

[16:11] <timotimo> this breaks with ints bigger than 64bit stored in the Int object

[16:13] <timotimo> oh

[16:13] <timotimo> it only does that because we know it's a nativeref that's passed in

[16:13] <timotimo> even then we don't want this to happen for the general case of infix:<+> as opposed to the case where we inline it

[16:14] <timotimo> so maybe i make it depend on a getattrref (or similar) op existing in the current graph

[16:14] <timotimo> then it'll still happen post-inline, but not when we are completely unable to get rid of the get*ref op

[16:31] <timotimo> actually, it can be more efficient to split it, since now it can double-devirt in the jit and then fastbox with int cache before the add_I

[16:32] *** Zoffix joined
[16:32] *** p6bannerbot sets mode: +v Zoffix

[16:33] <Zoffix> timotimo: they bind tigher: https://en.cppreference.com/w/c/language/operator_precedence http://web.cse.ohio-state.edu/~babic.1/COperatorPrecedenceTable.pdf

[16:42] <timotimo> oh, hmm.

[16:42] <timotimo> ISTR i got misbehaviour when i did it without parens

[16:42] <timotimo> i wonder what i'm mixing up there

[16:43] <Zoffix> Anyone got any ideas for R#2400 ? Some info appeared since last night: https://github.com/rakudo/rakudo/issues/2400#issuecomment-432170805

[16:43] <synopsebot> R#2400 [open]: https://github.com/rakudo/rakudo/issues/2400 [fudged tests committed][regression][â  blocker â ] Module Crane is failing tests on HEAD

[16:46] <Zoffix> Like what's the difference between Array[Mu] and Positional[Mu]? The former got a bug but latter ain't

[17:00] <Zoffix> *crickets* :)

[17:02] *** Zoffix left
[17:17] *** robertle joined
[17:18] *** p6bannerbot sets mode: +v robertle

[17:21] *** lizmat left
[17:23] <nine> Zoffix: Array[Mu] is a class with a mixin while Positional[Mu] is a role?

[17:25] *** zakharyas joined
[17:26] *** p6bannerbot sets mode: +v zakharyas

[17:37] *** Zoffix joined
[17:37] *** p6bannerbot sets mode: +v Zoffix

[17:38] <Zoffix> nine: hehe, well yeah, I know that, but what makes one case buggy but not the other :)

[17:45] <Geth> Â¦ MoarVM: 8b4d58c7ab | (Zoffix Znet)++ (committed using GitHub Web editor) | src/6model/serialization.c

[17:45] <Geth> Â¦ MoarVM: Fix typo in comment

[17:45] <Geth> Â¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/8b4d58c7ab

[17:51] *** brrt left
[17:52] *** domidumont joined
[17:53] *** p6bannerbot sets mode: +v domidumont

[18:03] <nine> I'm equally stumped on another issue: I noticed comparing nqp-mbc's profile data to master's that on nqp-mbc there are a lot more calls to fresh_register and release_register and more confusing: to QAST::Op.new and QAST::SVal.new, but not to other QAST::Node types.

[18:04] <nine> 6639 addition calls to QAST::Op.new and 9230 more for QAST::SVal.new

[18:05] <timotimo> can you turn off the optimizer? that one builds loads of ops, too

[18:05] <nine> But my branch changes the QAST -> mbc path. The QAST should be untouched.

[18:05] <timotimo> maybe it changed the result of nqp's compiler

[18:05] <nine> And I've looked at the whole diff to master and don't see any place with a possibility of introducing additional QAST nodes

[18:05] <timotimo> that'd be kind of weird

[18:06] <nine> Why QAST::Op and QAST::SVal but not Stmt, Stmts, IVal or anything else?

[18:06] <Zoffix> Found one difference between the two cases: in the working one, when `resolve_param_interns` is called the reader->root.num_param_interns is 1, but in broken one it's 0

[18:06] <timotimo> do they perhaps use a parent node's constructor?

[18:06] <nine> Zoffix: that sounds very odd as both have parameters, don't they?

[18:07] <Zoffix> Yeah

[18:07] <timotimo> nine: what would you look for in a "callers" list for the routine overview?

[18:07] *** zakharyas left
[18:07] <nine> timotimo: doesn't look like. I went through all calls to .new in gen/moar/stage2/QASTNode.nqp in the profiler's list

[18:08] <nine> timotimo: just a flat list would be an extraordinary addition already!

[18:08] <timotimo> what columns would you expect? "times called via" for sure, for example

[18:08] <nine> If I had that, I could just compare the callers to QAST::Op.new on both branches and probably immediately see the answer

[18:09] <timotimo> it'll take me but a minute. however, the profiler format the server currently expects differs a little bit from what's there in master

[18:09] <nine> Callers and counts is all I need right now

[18:10] <nine> These minutes could potentially save me hours :)

[18:13] <nine> Ooooooooh, I think I've got it!

[18:14] <timotimo> oh?

[18:16] <nine> There's an optimization that pmurias++ did back in 2015: https://github.com/perl6/nqp/commit/9772e4587d

[18:17] <nine> Notice how the if nqp::islist($sh) in line 663 won't trigger because we return nqp::null() in 652?

[18:17] <nine> I changed that nqp::null() back to $sh, because I need to serialize that string heap, thereby removing the optimization

[18:19] <timotimo> ooh

[18:23] *** Kaiepi left
[18:23] <nine> But when I fix that I get a chars requires a concrete string, but got null

[18:23] <nine>    at <unknown>:1  (gen/moar/stage2/nqpmo.moarvm:<dependencies+deserialize>)

[18:23] *** Kaiepi joined
[18:24] *** p6bannerbot sets mode: +v Kaiepi

[18:38] <timotimo> nine: https://imgur.com/pj6KZc8

[18:39] *** domidumont left
[18:39] <nine> timotimo: very cool!

[18:40] <timotimo> i'm not yet sure how i want it to look when you expand a list that's already expanded from an outer list %)

[18:40] <timotimo> like, you should be able to get to the list of sites the routine is called from, though it'd be good if that list were structured like the call graph in reverse

[18:51] <timotimo> nine: i pushed the changes to moarperf on github

[18:51] <timotimo> you'll need the profiler-additions and profiling-additions branches of moarvm and nqp

[18:51] <nine> ok

[18:52] <timotimo> LMK if something borks

[18:53] <timotimo> a new blog post is overdue, and i think i've accumulated some show-off-able things

[18:53] <timotimo> also, i can quote you being happy about the tool existing :D

[18:59] <nine> Oh, very much so :)

[19:19] *** Zoffix left
[19:20] *** brrt joined
[19:21] *** p6bannerbot sets mode: +v brrt

[19:34] *** Zoffix joined
[19:34] *** p6bannerbot sets mode: +v Zoffix

[19:47] *** AlexDaniel left
[19:48] *** AlexDaniel joined
[19:48] *** p6bannerbot sets mode: +v AlexDaniel

[20:02] *** shareable6 left
[20:02] *** shareable6 joined
[20:03] *** p6bannerbot sets mode: +v shareable6

[20:03] *** Kaiepi left
[20:05] *** Kaiepi joined
[20:06] *** p6bannerbot sets mode: +v Kaiepi

[20:12] *** ggoebel joined
[20:13] *** p6bannerbot sets mode: +v ggoebel

[20:19] <timotimo> glad to not hear any problems from your end :D

[20:25] <nine> Well I got kinda sucked into debuggin this "chars requires a concrete string, but got null" thing.

[20:26] <nine> It happens because we read "47" as SC handle unless the string heap from nqp::serialize is assembled again in dependencies+deserialize. The funny part is that that one doesn't even contain an SC handle

[20:29] <nine> The real SC handle "3F0798663524CC53A3ED22C3BCBD30968E7A7301stage2-0" is actually in the right place in the CU's string heap. Looks like the index we're reading is just wrong. But why would that be influenced by the presence of the other string heap?

[20:35] *** ggoebel left
[20:35] <nine> Oh and even more confusing: the bytecode seems to be quite correct. moar --dump prints the dependency SC's handles just fine

[20:35] <brrt> o.O

[20:35] <brrt> Are you still compiling mbc in nqp? that's still fairly cool I think :-)

[20:35] <brrt> I probably need a rakudo commit bit if I want to really do a cleanup of nativeinvoke....

[20:36] <brrt> In fact, what I'd love to have is for nativecall to just do 'invoke' and have the REPR mechanism figure it all out

[20:36] <nine> brrt: yes. Spent the last 2 weeks trying to improve performance to the same level as MoarVM's mbc compiler. And I think the current riddle will be the last necessary step

[20:37] <brrt> nine++

[20:37] <nine> Of course, the last one may be the hardest. None of the parts make any sense.

[20:38] <brrt> it may well be that our stuff is broken

[20:42] <timotimo> nine: i wonder if you'd have to change some string object's sc owner to the new one?

[20:47] <nine> timotimo: I can't find the old compiler doing anything like that

[20:48] *** robertle left
[20:49] <timotimo> nowhere in the C either, huh?

[20:49] <timotimo> perhaps it hits a serialization write barrier while pushing to the string array

[20:49] <nine> none that i can find

[20:50] <timotimo> i.e. VMArray's push_o function has a write barrier

[20:50] <timotimo> or maybe you have to disable the scwb

[20:50] *** ggoebel joined
[20:51] *** p6bannerbot sets mode: +v ggoebel

[20:52] <nine> Ouch. I've got a lead

[20:52] *** ZofBot left
[20:53] <nine> I think MoarVM expects the strings collected during serialization to be at the start of the string heap.

[20:53] <timotimo> that sounds like a thing that could be true

[20:57] *** shareable6 left
[20:57] *** reportable6 left
[20:57] *** committable6 left
[20:57] *** releasable6 left
[20:57] *** bisectable6 left
[20:57] *** committable6 joined
[20:57] *** reportable6 joined
[20:57] *** shareable6 joined
[20:57] *** releasable6 joined
[20:57] *** greppable6 left
[20:57] *** bisectable6 joined
[20:57] *** notable6 left
[20:57] *** greppable6 joined
[20:57] *** notable6 joined
[20:58] *** p6bannerbot sets mode: +v committable6

[20:58] *** p6bannerbot sets mode: +v reportable6

[20:58] *** p6bannerbot sets mode: +v shareable6

[20:58] *** p6bannerbot sets mode: +v releasable6

[20:58] *** p6bannerbot sets mode: +v bisectable6

[20:58] *** p6bannerbot sets mode: +v greppable6

[20:58] *** p6bannerbot sets mode: +v notable6

[21:00] <nine> And there's already 387 strings in there at the point where I'm adding....darn

[21:06] <nine> This is gonna be hard :/ The whole endeavour depends on the ability to write out bytecode as we go. That includes adding strings to the heap and getting it's index. This cannot work when there's a block of strings that we only discover during compilation and that we need to write first

[21:22] <brrt> do you want to do a single pass traversal?

[21:22] <nine> absolutely

[21:23] <nine> Anything else would kill performance completely

[21:23] <brrt> and.. is there a way for an earlier pass to collect strings for you?

[21:23] <nine> But I wonder if it'd be possible to reverse direction here. Instead of seeding the mbc file's string heap with the serialization's, seed the serialization's with the existing string heap

[21:24] <brrt> not sure if I understand the difference

[21:24] <nine> After all, they both work the same and all that counts is that the indexes find the right string

[21:26] <nine> Originally we have 2 pieces of code that collect strings: the data serializer and the MAST compiler. Both end up in the mbc file's string heap. In master, the string heap created by data serialization is used as the starting point for the MAST compiler.

[21:26] <nine> I think it should work the other way as well: have the data serializer start with an existing string heap

[21:29] <brrt> hmm

[21:33] <nine> Well, I'll find out tomorrow. Good night!

[21:36] <brrt> good night

[21:36] * brrt is going afk as well

[21:36] *** brrt left
[22:48] *** fake_space_whale joined
[22:49] *** p6bannerbot sets mode: +v fake_space_whale

[23:46] *** MasterDuke joined
[23:46] *** p6bannerbot sets mode: +v MasterDuke

[23:47] *** MasterDuke left
[23:47] *** MasterDuke joined
[23:47] *** herbert.freenode.net sets mode: +v MasterDuke

[23:47] *** p6bannerbot sets mode: +v MasterDuke

