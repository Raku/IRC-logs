[02:56] *** ilbot3 joined
[06:56] <lizmat> And another Perl 6 Weekly hits the Net: https://p6weekly.wordpress.com/2018/02/12/2018-07-a-quick-one-from-apopka/

[08:08] *** brrt joined
[08:31] *** zakharyas joined
[08:38] *** zakharyas joined
[08:39] *** reportable6 joined
[08:41] *** zakharyas joined
[09:00] *** zakharyas joined
[09:31] *** notable6 joined
[10:17] *** Kaiepi joined
[10:29] *** bloatable6 joined
[10:31] <brrt> good * #moarvm

[10:35] <dogbert2_> good morning brrt

[10:35] <dogbert2_> are you still fighting with the JIT bug?

[10:35] <brrt> not at the moment, but it's still unfixed, yes

[10:36] <brrt> how badly is the release process affected

[10:36] <dogbert2_> some 'mean' person put the release blocker tag on it

[10:38] <dogbert2_> do you have any idea about for how long the bug has been present?

[10:38] <brrt> no. i know the template has been present for months

[10:38] <brrt> i think that's valid though

[10:39] <brrt> stuff should not break

[10:39] <brrt> (putting release blocker on it)

[10:39] <brrt> on the other hand, we're bus-factor constrained

[10:39] <dogbert2_> yeah, just wondering if it was present when the previous release was dome

[10:39] <dogbert2_> *done

[10:39] <brrt> we could ehm. check

[10:39] <brrt> :-)

[10:39] <dogbert2_> indeed

[10:40] <brrt> anyway, i'm not going to say 'this was broken before, so i don't care about fixing it'

[10:41] <dogbert2_> I don't doubt that you'll fix it :-)

[10:41] <dogbert2_> but I still think it's interesting to see for how long it's been there

[10:42] <brrt> for long, that's for sure, but it just might not have been triggerable

[10:43] <dogbert2_> true, 2017.12 is ok while 2018.01 is not

[10:44] <brrt> aha

[10:44] <dogbert2_> the bisectbot points to https://github.com/MoarVM/MoarVM/commit/db706bb7dfa68bd025d823e3871222bf3b4afb59

[10:46] <dogbert2_> dunno if it gives any clues though

[10:46] <brrt> not really

[10:46] <brrt> i know fairly well where the script miscompiles

[10:47] <brrt> i just don't know what the miscompile is, precisely :-)

[10:52] *** shareable6 joined
[10:53] <dogbert2_> so it's difficult to debug then

[11:10] *** zakharyas1 joined
[11:11] <brrt> yeah. doesn't break on 'first try', either

[11:11] <brrt> so the normal 'set-a-breakpoint' doesn't work here

[11:12] <brrt> oh, hang o, i have an idea

[11:15] *** zakharyas joined
[11:17] <dogbert2_> .oO

[11:18] *** zakharyas joined
[11:25] *** zakharyas joined
[11:45] *** brrt joined
[12:33] <Geth> ¦ MoarVM: wukgdu++ created pull request #801: fix format string's parameters

[12:33] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/pull/801

[12:38] <Geth> ¦ MoarVM: c27af6a54b | wukgdu++ | src/io/syncsocket.c

[12:38] <Geth> ¦ MoarVM: fix format string's parameters

[12:38] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/c27af6a54b

[12:38] <Geth> ¦ MoarVM: 48d98a1831 | (Zoffix Znet)++ (committed using GitHub Web editor) | src/io/syncsocket.c

[12:38] <Geth> ¦ MoarVM: Merge pull request #801 from wukgdu/fix_format

[12:38] <Geth> ¦ MoarVM:

[12:38] <Geth> ¦ MoarVM: fix format string's parameters

[12:38] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/48d98a1831

[12:47] *** robertle joined
[12:49] <robertle> I am trying to understand some of the tradeoffs of huge-stack-and-lazy-page vs segmented-stack-extend-in-vm vs non-segmented-stack-and-realloc strategies in the wider context, sparked by something the guile guy wrote, and was wondering what moarvm is doing, and more importantly why the design decision were made that way. anyone knows?

[12:50] <robertle> I mostly understand the consequence of having the stack move around in terms of being able to reference directly into the stack of course, and that huge-alloc doesn't really work on 32bit

[12:51] <robertle> but I am wondering about the cost of chacking whether you have enough space left on the stack

[12:51] <robertle> is there some more clever way than just checking? I thought I did read something about protected memory after the stack and trapping or so, btu can't find it anymore. some lisp source or so...

[12:53] <brrt> so, i'm a bit vague on details, but iirc the stack used to be a): a tree (because we wanted to support closures) and b): noncontiguous, and currently we do have a contiguous stack, but i'm not sure whether it's huge or not

[12:53] <brrt> i don't think it is actually very large

[12:53] <brrt> also, you only need to check on subroutine invocation

[12:54] <brrt> in perl6, subroutine invocation is not *quite* as cheap as it could be

[12:54] <brrt> so the added cost of one more check is not that significant

[12:55] <robertle> but it's a tree of stack contiguous stack segments, right? not a tree of individual stack entries?

[12:55] <robertle> some listp/scheme things have the latter, but that sounds prohibitively expensive

[13:00] <brrt> contigouous segments. and we don't have a tree anymore (again, iirc)

[13:01] <brrt> because we moved that to an optimistic scheme wherein we'd only copy the stack to heap in the case of taking a continuation

[13:01] <robertle> a, so a closure means a full stack copy?

[13:03] <robertle> I was trying to understand the paper by dybvig, where he explains how you can have closures with the environment mostly on the stack. too dumb tough...

[13:10] <brrt> not sure about a closure, but a continuation does

[13:12] <robertle> right! I think that is also what makes me wonder about the stack strategy: if you can do most things on the stack, that would allow you to get really fast in some languages. but if every push onto the stack involves checking if there is still space, then that introduces a lot of checks...

[13:23] <jnthn> At present, we try to allocate invocation records in a contiguous buffer. This is used for frames that don't "escape" - that is, end up referenced from the heap. If that happens, they get promoted to GC-managed objects (and, critically, get the generational treatement, which turns out to be very important for programs that have large numbers of closures or continuations held at once)

[13:23] <jnthn> We also note which frames have a tendency to get promoted anyway, and allocate those directly with the GC in the future

[13:24] <robertle> ok, but how do you grow that contiguous buffer? and how do you know when to grow it?

[13:25] <jnthn> We don't grow it, we keep a linked list of them

[13:25] <robertle> ok, and each has a fixed size?

[13:25] <jnthn> It's done with a bounds check

[13:25] <jnthn> Yes

[13:25] <robertle> ok, understood

[13:26] <jnthn> You'd need to recurse or have a pretty deep stack to fill the segment though

[13:26] <robertle> but this is just the method invocation "call stack", you don't use that as a general purpose work stack like native code does?

[13:26] <jnthn> Meaning the branch is predictable, which means it isn't so bad

[13:27] <robertle> right because the buffer is rarely full

[13:27] <jnthn> No, MoarVM doesn't use the "system stack" to represent the stack of the program it is running. Generally it runs very shallow on the real system stack.

[13:27] <jnthn> The only time that ever happens if with native callbacks

[13:27] <jnthn> When we don't really have a choice

[13:28] <robertle> ok, I get that. what I meant was that this buffer is used for method invocation "frames", but you don't push/pop stuff onto it while executing a method?

[13:28] <timotimo> that's right

[13:28] <robertle> k

[13:28] <timotimo> we're register-based, but our registers are basically offsets into the frame size

[13:28] <timotimo> so no pushing and popping happens

[13:28] <jnthn> Correct, we keep a register set

[13:28] <jnthn> Also worth noting that we do quite a lot of inlining

[13:28] <robertle> so where do you spill to if you run out of regs?

[13:29] <jnthn> We don't run out of regs.

[13:29] <jnthn> Each frame specifies the number it needs in its metadata

[13:29] <jnthn> We just allocate that much space

[13:29] <robertle> ok, get it. I think that's what guile does too

[13:29] <jnthn> Of course, the JIT compiler has to worry about such things :)

[13:30] <jnthn> brrt can probably tell you what happens there, but it must be something that means the GC knows where we spilled to

[13:33] <robertle> ok, great food for thought. thanks!

[13:36] <jnthn> There's no doubt lots of ways we can do better in all of this, fwiw.

[13:37] <jnthn> As with most things, we're working under resource contraints, so "how quickly can we implement X" is often a design consideration too :)

[13:55] *** zakharyas joined
[14:28] *** zakharyas joined
[14:33] <jnthn> git push

[14:33] <jnthn> d'oh :)

[14:33] <Geth> ¦ MoarVM: da41e397f1 | (Jonathan Worthington)++ | src/6model/reprs/MVMSpeshLog.c

[14:33] <Geth> ¦ MoarVM: Implement unmanaged_size in MVMSpeshLog repr

[14:33] <Geth> ¦ MoarVM:

[14:33] <Geth> ¦ MoarVM: This means the GC understands the amount of space it really takes, and

[14:33] <Geth> ¦ MoarVM: so can trigger a full collection in a far more timely manner if we are

[14:33] <Geth> ¦ MoarVM: doing nothing but accumulating spesh logs (why that happens is another

[14:33] <Geth> ¦ MoarVM: issue, however). With this, the "leak" reported in Rakudo #1513 does at

[14:33] <Geth> ¦ MoarVM: least reach an upper boundary and stop growing. Prior to this, since

[14:33] <Geth> ¦ MoarVM: only the directly allocated memory of the spesh log was accounted for,

[14:33] <Geth> ¦ MoarVM: it would have taken a very long time for the GC to decide enough had

[14:33] <Geth> ¦ MoarVM: been promoted into gen2 to do a full collection (long enough for the

[14:33] <Geth> ¦ MoarVM: memory use to grow giant).

[14:33] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/da41e397f1

[14:40] <dogbert2_> .oO jnthn reclaiming memory

[14:43] *** zakharyas1 joined
[14:49] <jnthn> Yeah, figured out the spurious log entries too

[14:49] <timotimo> that might explain why the heap analyzer didn't account fro everything in these

[14:49] <jnthn> Indeed, it also uses that

[14:52] <dogbert2_> jnthn: do you think that your fix will affect https://github.com/MoarVM/MoarVM/issues/680 as well

[14:52] <jnthn> Doubtful

[14:52] <jnthn> Though they can't hurt

[14:53] <dogbert2_> I'm retesting that moving the variable declarations still impacts maxrss, guess I should test it with you patch as well

[14:58] <Geth> ¦ MoarVM: 004680a03a | (Jonathan Worthington)++ | src/spesh/log.h

[14:58] <Geth> ¦ MoarVM: Don't spesh log if we have a spesh_cand

[14:58] <Geth> ¦ MoarVM:

[14:58] <Geth> ¦ MoarVM: This check will rule out most cases we shouldn't be logging nice and

[14:58] <Geth> ¦ MoarVM: quickly. It also rules out some cases we did not before, namely that

[14:58] <Geth> ¦ MoarVM: where we performed OSR. That meant we had a spesh correlation ID in

[14:58] <Geth> ¦ MoarVM: place (since the frame was entered through the non-specialized path

[14:58] <Geth> ¦ MoarVM: initially), resulting in the frame wrongly being considered logged

[14:58] <Geth> ¦ MoarVM: beyond being specialized and OSR'd. That in turn resulted in spurious

[14:58] <Geth> ¦ MoarVM: spesh log entries, and was at the root of the memory growth issue in

[14:58] <Geth> ¦ MoarVM: Rakudo #1513.

[14:58] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/004680a03a

[15:09] * dogbert2_ notes that the mysterious change of maxrss when running the gist in https://github.com/MoarVM/MoarVM/issues/680 remains, i.e. moving out declarations of @tags and @commits from the loop

[15:11] * dogbert2_ original code has a maxrss of 531128k while the midified code stays at 327884k

[15:11] *** zakharyas joined
[15:12] <jnthn> Yeah, it's an interesting observation

[15:12] <jnthn> Hm, the bug is filed against MoarVM but I don't know it's going to turn out to be there

[15:13] <dogbert2_> perhaps it should be moved

[15:14] <jnthn> Well, doesn't matter in a sense

[15:14] *** travis-ci joined
[15:14] <travis-ci> MoarVM build failed. Jonathan Worthington 'Don't spesh log if we have a spesh_cand

[15:14] <travis-ci> https://travis-ci.org/MoarVM/MoarVM/builds/340521536 https://github.com/MoarVM/MoarVM/compare/da41e397f167...004680a03a0c

[15:14] *** travis-ci left
[15:15] <jnthn> Yowser

[15:15] <jnthn> That fix has made the expr JIT very reliably explosive, it seems

[15:16] <nwc10> this looks just like what I'm getting with a (gcc) ASAN build

[15:16] <nwc10> src/spesh/log.c:152:41: runtime error: member access within null pointer of type 'struct MVMSpeshLog'

[15:16] <jnthn> Yup, and MVM_JIT_EXPR_DISABLE=1 seems to help

[15:17] <jnthn> Why on earth would the JITted code be trying to do something with the spesh log, though?!

[15:17] <nwc10> I was going to ask earlier "why do I seem to be in a minority of one?"

[15:17] <brrt> o.O

[15:18] <jnthn> I don't know how the above change, short of resulting in less polluted spesh data, could cause that change

[15:18] <nwc10> for me culprit(s) seem to be MoarVM commit 0e737146b73d994d9bd38208088771deb4dd6f4d or its parent

[15:18] <nwc10> and yes, with MVM_JIT_EXPR_DISABLE=1 I can build

[15:18] <nwc10> (not yet finished, but past that SEGV)

[15:19] <brrt> hmmm

[15:23] <jnthn> Yeah, the commit at HEAD seems to make it trip up over the expr jit bug a lot more

[15:24] <jnthn> Making sure of that

[15:25] *** AlexDaniel joined
[15:25] <jnthn> Yes, HEAD~1 completes the NQP build

[15:26] <jnthn> HEAD trips over the EXPR JIT

[15:27] <jnthn> The only thing it could be doing is making the spesh log contain less junk

[15:27] <brrt> and thereby making it compile more frames and breaking faster

[15:27] <jnthn> Yeah

[15:27] <jnthn> So we...get worse because we got better :P

[15:28] <brrt> it's probably a good thing though

[15:28] <jnthn> Well yes, in that it gives you a very ready supply of reproductions :)

[15:28] <brrt> nwc10 has been consistenly reporting this problem and i've consistently not been able to find anything

[15:28] <brrt> indeed

[15:32] *** zakharyas joined
[15:35] <jnthn> dogbert2_: I can reproduce #680

[15:35] <jnthn> dogbert2_: As well as the effect of moving the decls

[15:36] <jnthn> To the heap analyzer!

[15:36] <dogbert2_> hooray :)

[15:37] <dogbert2_> so now it's time for the heap analyzer to show what it's made of :)

[15:37] <nwc10> software :-(

[15:38] <jnthn> SEGV :P

[15:38] <jnthn> Well, the analyzer not, but the snapshot mechanism apparently :/

[15:40] <jnthn> ooh

[15:41] <jnthn> That's a silly typo, and it may have been around for a year or more

[15:43] *** unicodable6 joined
[15:44] <Geth> ¦ MoarVM: cf523c89c0 | (Jonathan Worthington)++ | src/profiler/heapsnapshot.c

[15:44] <Geth> ¦ MoarVM: Test the current thread's frame in heap snapshot

[15:44] <Geth> ¦ MoarVM:

[15:44] <Geth> ¦ MoarVM: Fixes a bug that can in the best case cause a SEGV (which is how I

[15:44] <Geth> ¦ MoarVM: discovered it), and in the worst case lead to missing data in the

[15:44] <Geth> ¦ MoarVM: report.

[15:44] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/cf523c89c0

[15:49] <[Coke]> oops. :)

[15:54] <jnthn> huh, what...

[15:54] <jnthn> The heap snapshot came out as a binary file, but the analyzer doesn't read that?

[15:55] <jnthn> Just complains about invalid utf-8

[15:55] <jnthn> That's after uninstalling and reinstalling it

[15:59] <jnthn> Even installing the latest version from the repo doesn't help

[16:00] <dogbert2_> jnthn: have you checked commit de6dceda8102fab4b58ebe03

[16:00] <jnthn> huh what, I added a line to print out the excepiton and it worked?!

[16:01] <jnthn> dogbert2_: Which repo?

[16:01] <dogbert2_> i.e. MoarVM, title is 'Merge branch 'heapsnapshot_binary_format''

[16:02] <jnthn> Yeah, I'm not sure what's going on, but did at least now get it to load the snapshot

[16:02] <dogbert2_> cool, the solutions is getting closer and closer

[16:03] <dogbert2_> *solution

[16:03] *** travis-ci joined
[16:04] <travis-ci> MoarVM build failed. Jonathan Worthington 'Test the current thread's frame in heap snapshot

[16:04] <travis-ci> https://travis-ci.org/MoarVM/MoarVM/builds/340543283 https://github.com/MoarVM/MoarVM/compare/004680a03a0c...cf523c89c06a

[16:04] *** travis-ci left
[16:04] <jnthn> Hm, didn't really reveal what I was thinking

[16:05] <jnthn> ah, ok, now it does

[16:06] <jnthn> I added a class LeakTracer {} and then a my $x = LeakTracer.new in the loop

[16:06] <jnthn> And there are as many instances of that in the final snapshot as there are iterations

[16:07] <jnthn> Also, darn, the binary format loads faster at least, when it works :P

[16:08] <jnthn> ahhh

[16:08] <timotimo> <3

[16:09] <jnthn> https://gist.github.com/jnthn/c56ddd83750885cecdedf3c49e1031c6

[16:09] <jnthn> So the timer (from Promise.in) stays active, because there's not a cancellation mechanism for a Promise

[16:10] <jnthn> It takes a closure

[16:10] <jnthn> Uh, refs a closure

[16:10] <jnthn> Which is the timer callback

[16:10] <timotimo> ooooooh

[16:10] <jnthn> and the snapshot tells the rest of the story

[16:10] <jnthn> uh, path even

[16:12] <timotimo> wow, so any react or supply that has a promise.in will keep around everything reachable for that particular whenever through its call stack?

[16:12] <jnthn> Yup

[16:13] <timotimo> oh, is that only if the promise.in doesn't actually resolve? i.e. if the react shuts down before that?

[16:13] <jnthn> Right, because there's currently no cancellation mechanism on a Promise

[16:16] <timotimo> so would we mix in a cancel method to some where we know we can do it and have a .^can in the react implementation?

[16:17] <timotimo> not sure if we can have something sensible for start blocks; if a task is currently awaiting it could throw an exception like in java, but i think that'll lead to some rather ugly code

[16:18] <dogbert2_> removed the promise.in code from the original gist, maxrss 255360k

[16:18] <timotimo> passing a callback to be called on cancellation might be a way, but that'll lead to lots of boilerplate for signalling across that the work is supposed to be done

[16:19] <jnthn> Yeah

[16:19] <jnthn> this change

[16:19] <jnthn> -         whenever Promise.in(10) {

[16:19] <jnthn> +         whenever Supply.interval(10, 10).head {

[16:19] <jnthn> Eliminates the leak

[16:19] <jnthn> Well, "leak" in that we don't actually lose track of memory

[16:20] <jnthn> We just keep it around a good bit longer than needed

[16:20] <jnthn> So, this is very much not a MoarVM issue

[16:20] <jnthn> Actually a language design issue :)

[16:20] <jnthn> So, who's the concurrency designer? :P

[16:21] <jnthn> timotimo: fwiw, I think a Promise::Cancellable subclass of Promise could be a way to go. It's just have an overridden method Supply that maps tap close to the cancellation

[16:21] <timotimo> "good bit longer"; do we eventually reclaim those closures/continuations?

[16:21] <jnthn> Yes

[16:22] <timotimo> oh, when the time elapses?

[16:22] <jnthn> Right

[16:22] <jnthn> Will make sure of it now, but that matches the data I saw

[16:22] <timotimo> i had imagined it a lot worse in my head :)

[16:22] <timotimo> but it also explains why moving the array outside fixes things; the closures all refer to the same array and old data is overriden every time

[16:22] <jnthn> Because my first attempt showed only one LeakTracer instance

[16:23] <jnthn> Right. :)

[16:23] <jnthn> To get all of the instances, I had to shorten the time the program ran for

[16:23] <jnthn> By making it collect less data

[16:23] <jnthn> oh, another way to verify this

[16:24] <jnthn> Bump up to Promise.in(40) and see if we end up using even more memory

[16:25] <jnthn> Hm, curiously not

[16:25] <timotimo> not enough iterations? or does it run forever?

[16:25] <jnthn> It runs for 60s

[16:25] <jnthn> I made the Promise.in 100s now

[16:25] <jnthn> So "never"

[16:26] <jnthn> Hm, curious. Doesn't have quite the impact I expected

[16:28] <jnthn> Which means it may actually be as bad as timotimo feared

[16:28] <timotimo> that it never actually reclaims it at all?

[16:28] <jnthn> yeah

[16:28] <jnthn> I need to check in a few more places

[16:36] <jnthn> timotimo: yes, it was that bad :S

[16:36] *** shareable6 joined
[16:37] <jnthn> Either Rakudo can do the cancel itself after a one-shot timer fires, or we can just clean it up in MoarVM

[16:37] *** benchable6 joined
[16:37] <jnthn> I've done a patch for the second

[16:37] <jnthn> It's still more maxrss then replacing it with Supply.interval(10, 10)

[16:37] <jnthn> But it's a lot less than it was

[16:38] * jnthn spectests

[16:39] <japhb> jnthn: BTW, is today the beginning of your grant work already?  (If so, AWESOME BTW)

[16:39] <jnthn> Yes :)

[16:39] <jnthn> Decided to start out with some leak hunting :)

[16:39] <japhb> I think that's an excellent choice. :-)

[16:42] <timotimo> jnthn++ # grant request approved

[16:43] <timotimo> i'm also glad my early work on the heap analyzer has already made working more comfortable for jnthn :)

[16:43] <jnthn> d'oh, my fix busts some tests

[16:43] * [Coke] is reminded he has many grant related things to post tonight. :|

[16:44] <[Coke]> (which is :| only because it's work for me. :)

[16:55] <timotimo> i'm still bummed i haven't properly started my grant work yet, but the apartment search and subsequent move - which is not actually finished in any way yet - have left me pretty much drained of energy

[16:55] <[Coke]> timotimo: please note that the GC has rules about long running grants with no progress. :(

[16:56] <Geth> ¦ MoarVM: c6519f4c32 | (Jonathan Worthington)++ | src/io/timers.c

[16:56] <Geth> ¦ MoarVM: Clean up one-shot timers after firing

[16:56] <Geth> ¦ MoarVM:

[16:56] <Geth> ¦ MoarVM: Otherwise, we will end up holding on to the callback functions for

[16:56] <Geth> ¦ MoarVM: them, which is a memory leak. We could in theory have solved the issue

[16:56] <Geth> ¦ MoarVM: by making Rakudo do the cancellation upon first firing also, but this

[16:56] <Geth> ¦ MoarVM: feels a tad more robust.

[16:56] <[Coke]> (for the kind that go through the voting part of the GC)

[16:56] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/c6519f4c32

[16:57] <jnthn> So there was a MoarVM issue in https://github.com/MoarVM/MoarVM/issues/680 after all

[16:58] <timotimo> [Coke]: should not be a problem once work starts, though, right?

[17:02] <[Coke]> timotimo: except it's been 4 months since the grant was awarded.

[17:03] <timotimo> can you point me at the rules in question?

[17:04] <[Coke]> We're discussing it on the GC list now, obv. Alan will reach out to you if needed.

[17:04] <timotimo> ah

[17:04] <[Coke]> http://www.perlfoundation.org/rules_of_operation - Linked to off the main nav on that site.; section 2.6

[17:07] <timotimo> yeah, that's a sensible rule

[17:09] *** hoelzro_ joined
[17:14] *** travis-ci joined
[17:14] <travis-ci> MoarVM build failed. Jonathan Worthington 'Clean up one-shot timers after firing

[17:14] <travis-ci> https://travis-ci.org/MoarVM/MoarVM/builds/340577255 https://github.com/MoarVM/MoarVM/compare/cf523c89c06a...c6519f4c32d9

[17:14] *** travis-ci left
[17:20] *** statisfiable6 joined
[17:36] *** dogbert17 joined
[17:38] <dogbert17> jnthn++: very nice, the unmodified script now shows a maxrss of 206364k, which is less than half of what it was before

[17:39] <jnthn> yay :)

[17:53] <[Coke]> jnthn++

[18:02] * jnthn wanders home

[18:04] *** zakharyas joined
[18:06] *** zakharyas joined
[19:23] *** squashable6 joined
[19:43] <nine> :q

[20:21] *** zakharyas joined
[20:38] *** bart__ joined
[20:40] <brrt> good *

[20:40] <brrt> i also get breakage in nqp build

[20:43] <brrt> however, i don't get a breakage when MVM_SPESH_BLOCKING=1

[20:45] <brrt> it is also sensitive to MVM_JIT_EXPR_DISABLE=1

[20:45] <brrt> w.t.f

[20:49] <brrt> aha, that's interesting

[20:51] <brrt> where do we insert the MVM_spesh_log_static things?

[20:55] <timotimo> you mean getlexstatic_o?

[20:55] <brrt> oh

[20:55] <brrt> is that a thing

[20:55] <timotimo> it is

[20:55] <brrt> hang on a minute

[20:56] <timotimo> we gen that op instead of getlex if we know something is not going to change, or something like that

[20:59] <Geth> ¦ MoarVM: a01cdb449c | (Bart Wiegmans)++ | 2 files

[20:59] <Geth> ¦ MoarVM: Disable getlexstatic_o for the time being

[20:59] <Geth> ¦ MoarVM:

[20:59] <Geth> ¦ MoarVM: This breaks the NQP build, but only when MVM_SPESH_BLOCKING isn't

[20:59] <Geth> ¦ MoarVM: set. No idea why yet.

[20:59] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/a01cdb449c

[21:05] <brrt> i see

[21:06] <brrt> anyway, the template looks good, so i'm curious where the jit fails

[21:07] <timotimo> hm, do we actually log anything when the frame is already jitted?

[21:09] <brrt> don't know

[21:10] <brrt> but i do note that this case looks suspiciously like the sp_p6ogetvt_o fail

[21:10] <brrt> and i hope the cause is the same

[21:10] <timotimo> ah, i already forgot what went wrong with that one

[21:10] *** ChanServ joined
[21:11] <brrt> one thing that was wrong, but not *the* thing interestingly, is that we wouldn't allocate registers for live ranges created during the tile rollup process

[21:11] <brrt> prescription for linear scan allocation is to iterate by popping-off the heap

[21:11] <brrt> doesn't work when you have individual instructions that need caretaking by the register allocator

[21:12] <brrt> like CALL, for one thing

[21:12] <brrt> so, we iterate over each tile (instruction) as well

[21:12] <brrt> and because we can allocate the last live range before running out of tiles to process

[21:12] <brrt> we could miss processing tiles, and i had a 'rollup' loop to process all the last tiles

[21:13] <brrt> but, if those last tiles would then create new live ranges (because of spilling...), those then wouldn't be processed

[21:13] <brrt> so... altogether, i fixed that by having a single loop do both things

[21:14] <brrt> and either proceed on tiles, or proceed on the live ranges

[21:14] <brrt> this works, except, it doesn't actually fix the thing that was broken, which is Something Else that I don't know about just yet

[21:16] *** travis-ci joined
[21:16] <travis-ci> MoarVM build passed. Bart Wiegmans 'Disable getlexstatic_o for the time being

[21:16] <travis-ci> https://travis-ci.org/MoarVM/MoarVM/builds/340678599 https://github.com/MoarVM/MoarVM/compare/c6519f4c32d9...a01cdb449c96

[21:16] *** travis-ci left
[21:17] <brrt> thanks timotimo++, wouldn't have found it otherwise

[21:20] <timotimo> hm?

[21:22] <brrt> disabling getlexstatic_o

[21:47] <timotimo> oh? i literally just grepped interp.c for that function :)

[22:18] *** greppable6 joined
[22:31] *** Kaiepi joined
[23:09] *** dogbert2 joined
