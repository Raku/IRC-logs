[00:00] <jnthn> I suspect merge_bbs is broken. Turns out that my moving it back to where it used to be both fixed something and broke something.

[00:13] <jnthn> Geth: On vacation? :)

[00:13] <jnthn> Ah well, I pushed stuff

[00:13] <jnthn> 'night o/

[00:14] *** Geth left
[00:43] *** Kaiepi left
[01:48] *** Kingsy9 joined
[01:50] *** Kingsy9 left
[01:56] *** avar left
[03:07] *** avar joined
[03:07] *** avar left
[03:07] *** avar joined
[03:07] *** p6bannerbot sets mode: +v avar

[03:07] *** p6bannerbot sets mode: +v avar

[04:20] *** stmuk_ joined
[04:21] *** p6bannerbot sets mode: +v stmuk_

[04:22] *** stmuk left
[05:30] *** stmuk joined
[05:31] *** p6bannerbot sets mode: +v stmuk

[05:31] *** stmuk_ left
[05:42] *** stmuk_ joined
[05:43] *** p6bannerbot sets mode: +v stmuk_

[05:44] *** stmuk left
[05:51] *** stmuk joined
[05:52] *** p6bannerbot sets mode: +v stmuk

[05:54] *** stmuk_ left
[05:54] *** stmuk_ joined
[05:55] *** p6bannerbot sets mode: +v stmuk_

[05:56] *** stmuk left
[06:25] *** stmuk joined
[06:26] *** p6bannerbot sets mode: +v stmuk

[06:27] *** stmuk_ left
[07:06] *** fake_space_whale left
[07:15] *** Croepha13 joined
[07:16] *** p6bannerbot sets mode: +v Croepha13

[07:20] *** Croepha13 left
[09:19] *** timotimo left
[09:19] *** timotimo joined
[09:19] *** asimov.freenode.net sets mode: +v timotimo

[09:19] *** p6bannerbot sets mode: +v timotimo

[09:26] *** stmuk_ joined
[09:27] *** p6bannerbot sets mode: +v stmuk_

[09:28] *** stmuk left
[11:21] *** iDanoo9 joined
[11:30] *** iDanoo9 left
[12:26] *** zakharyas joined
[12:26] *** p6bannerbot sets mode: +v zakharyas

[12:36] *** MasterDuke left
[12:43] *** zakharyas left
[12:55] <dogbert17> .tell jnthn have found a way to repro the 'SC index out of range' problem consistently.

[12:55] <yoleaux> dogbert17: I'll pass your message to jnthn.

[13:01] *** brrt joined
[13:02] *** p6bannerbot sets mode: +v brrt

[13:05] <brrt> \o

[13:05] <dogbert17> hello brrt

[13:07] <brrt> ohai dogbert17

[13:08] <dogbert17> .tell jnthn https://gist.github.com/dogbert17/23b5e847a19f2798352a44c582760963

[13:08] <yoleaux> dogbert17: I'll pass your message to jnthn.

[13:08] <dogbert17> it's a bit empty here atm

[13:11] <dogbert17> brrt: are you working on the (expr) JIT?

[13:11] <jnthn> .

[13:11] <yoleaux> 12:55Z <dogbert17> jnthn: have found a way to repro the 'SC index out of range' problem consistently.

[13:11] <yoleaux> 13:08Z <dogbert17> jnthn: https://gist.github.com/dogbert17/23b5e847a19f2798352a44c582760963

[13:13] *** dalek joined
[13:13] *** p6lert_ left
[13:13] *** synopsebot_ left
[13:13] *** synopsebot joined
[13:13] *** Geth joined
[13:13] *** p6lert joined
[13:14] *** p6bannerbot sets mode: +v dalek

[13:14] *** p6bannerbot sets mode: +v synopsebot

[13:14] *** p6bannerbot sets mode: +v Geth

[13:14] *** p6bannerbot sets mode: +v p6lert

[13:18] *** brrt left
[13:18] *** brrt joined
[13:19] *** p6bannerbot sets mode: +v brrt

[13:26] *** Kaiepi joined
[13:27] *** p6bannerbot sets mode: +v Kaiepi

[13:33] *** brrt left
[13:55] *** brrt joined
[13:56] *** p6bannerbot sets mode: +v brrt

[14:51] *** notable6 joined
[14:51] *** p6bannerbot sets mode: +v notable6

[15:01] *** stmuk joined
[15:02] *** p6bannerbot sets mode: +v stmuk

[15:03] *** stmuk_ left
[15:29] *** stmuk_ joined
[15:29] *** p6bannerbot sets mode: +v stmuk_

[15:30] *** stmuk left
[15:36] *** stmuk joined
[15:36] *** p6bannerbot sets mode: +v stmuk

[15:37] *** stmuk_ left
[15:46] *** fake_space_whale joined
[15:46] *** p6bannerbot sets mode: +v fake_space_whale

[15:51] *** brrt left
[16:01] *** JSharp20 joined
[16:02] *** JSharp20 left
[16:54] <timotimo> random observation: the substr method of Str won't get inlined, because it uses getlexref_i to pass $from to SUBSTR-START-OOR

[16:55] <timotimo> that's the (Str:D: Int:D \start) candidate

[16:56] *** zakharyas joined
[16:57] *** p6bannerbot sets mode: +v zakharyas

[17:08] *** zakharyas left
[17:08] *** zakharyas joined
[17:09] *** p6bannerbot sets mode: +v zakharyas

[17:17] *** fake_space_whale left
[17:53] *** zakharyas left
[18:21] *** brrt joined
[18:24] *** brrt left
[18:24] *** brrt joined
[18:25] *** p6bannerbot sets mode: +v brrt

[18:25] <brrt> \o

[18:25] <brrt> blog post notification: http://brrt-to-the-future.blogspot.com/2018/08/a-curious-benchmark.html

[18:27] <brrt> the tl;dr - postrelease-opts can lead to an order-of-5 benchmark improvement

[18:27] <brrt> jnthn++ timotimo++

[18:28] <timotimo> oooooh

[18:30] <timotimo> brrt: you got the origin of the benchmark right

[18:31] <timotimo> brrt: i think the parenthesis in the paragraph below "and yet..." is wrong: "perl (the interpreter) does not"?

[18:31] <timotimo> "this sbenchmark"

[18:31] <timotimo> and the parenthesized sentence after that isn't closed

[18:32] <timotimo> "c-stype for loops" -> "c-style for loops"

[18:33] <brrt> thank you

[18:33] <timotimo> yw!

[18:33] <timotimo> thanks for blogging :)

[18:34] <brrt> :-)

[18:35] <timotimo> yeah, those numbers at the end of the post are nice

[18:35] <brrt> :-D

[18:35] <brrt> yes

[18:36] <timotimo> would you say that "natives don't work" isn't as true any more in postrelease-opts?

[18:36] <timotimo> oh

[18:37] <timotimo> you didn't re-run the code for that after the branch

[18:37] <timotimo> could you do that, too, real quick? reciprocal-while.pl6 with "num" in there?

[18:38] <brrt> yeah, I tried that; it's 6.4s rather than 4.6s

[18:38] <timotimo> instead of the 36s :D

[18:38] <timotimo> hm

[18:38] <timotimo> m: say 6.4 / 4.6; say 36 / 26.5

[18:38] <camelia> rakudo-moar 5d1cec5a4: OUTPUT: «1.391304␤1.358491␤»

[18:39] <timotimo> well, it got a little better!

[18:40] <brrt> 6.6s now

[18:40] <brrt> :-)

[18:40] <timotimo> the shortest time is always the truth :P

[18:41] <brrt> yeah.

[18:41] <brrt> curiously, if you make the native $i an int, we slow it down to about 11s

[18:41] <brrt> probably because it has to do a box, then a conversion

[18:42] <timotimo> probably; do you also turn 5e7 into an int for that?

[18:42] <timotimo> manually, i mean

[18:42] <brrt> i'd expect 5e7 is a float?

[18:42] <timotimo> right

[18:43] <timotimo>       null             r25(1)

[18:43] <timotimo>       isnull           r26(1),  r25(1)

[18:43] <timotimo>       if_i             r26(1),  BB(12)

[18:46] <brrt> o.O

[18:47] <timotimo> that's some very good code

[18:47] <brrt> seems there might be an optimization opportunity there

[18:48] <timotimo> that comes from infix:</>

[18:48] <timotimo> aha, takedispatcher

[18:50] <timotimo> that if_i will only be jumping over a single bindlex instruction with outers being 0

[18:50] <timotimo> i wonder how costly that actually is?

[18:52] <brrt> well, we can eliminate the whole thing, including the bindlex

[18:52] <brrt> and removing the goto entirely

[18:52] <timotimo> you know, we do have information on how often a branch was taken during logging, if there's a logged instruction close to the branch point

[18:52] <brrt> we could potentially use that

[18:52] <brrt> but.

[18:53] <brrt> I'm thinking it would be not so hard to do this explicitly

[18:53] <brrt> I'm imagining a structure that logs basic block pairs

[18:53] <brrt> I.e. trace the graph as an edge list

[18:54] <brrt> The nice thing about that is that the size of that graph is bounded

[18:54] <brrt> a basic block can be followed by:

[18:54] <brrt> - the linear successor

[18:55] <brrt> - a conditional successor

[18:55] <timotimo> don't forget we sometimes have very many successors, in the case of handlers

[18:55] <brrt> - one of the N handlers that are active

[18:55] <timotimo> right

[18:55] <brrt> that is still a tight bound

[18:55] <brrt> far fewer than N^2 for N basic blocks

[18:56] <brrt> - a callee basic block (potentially many)

[18:56] <brrt> - the callers' basic block (potentially many)

[18:56] <timotimo> we don't explicitly have the BB structure in the interpreter stage before spesh comes into the picture, though

[18:56] <brrt> restricting to within-routine tracing, we have a nice tight bound

[18:56] <timotimo> at that point the bytecode comes straight from the bytecode file, and has only been through the verifier

[18:57] <brrt> correct, but we can insert basic block entry logging instructions

[18:57] <brrt> I expect the expense of that is relatively small

[18:57] <timotimo> how do we do that if we don't know where basic blocks start and end?

[18:57] <brrt> when we insert logs?

[18:57] <timotimo> we don't insert logs any more :)

[18:57] <brrt> oh

[18:57] <brrt> really

[18:57] <brrt> hmm

[18:57] <brrt> well, then we do it during verification

[18:57] <timotimo> yeah, all those ops now just naturally log when we're pre-spesh

[18:58] <timotimo> and those we don't turn into something better still get turned into a "does not log" variant of the same op

[18:58] <timotimo> like sp_getlex_ins is an example of that if i'm not mistaken

[18:58] <brrt> hmm

[18:58] <brrt> I actually don't expect that inserting logging statements is very expensive during bytecode verification, since we just need the CFG

[18:59] <timotimo> bytecode verification is currently an operation that doesn't mutate, except for endian-swapping

[18:59] <timotimo> it neither mutates nor allocates something new

[18:59] <brrt> hmmm

[19:00] <timotimo> we might as well have variants of our if and unless ops and sp_ variants and have the first kind log jumps and the other not log jumps

[19:00] <brrt> yeah

[19:00] <timotimo> (no need for a non-logging if_o or unless_o, though, since we always turn that into an if_i or unless_i)

[19:00] <timotimo> we wouldn't catch throwish things that way, though

[19:01] <brrt> you can log that during the exception handling?

[19:02] <brrt> alternatively, we can have the logging statements inserted by the mast compiler itself

[19:04] <timotimo> but we also want non-logging versions of things

[19:04] <timotimo> taking into account the many adhoc exceptions we have ... :\

[19:05] <timotimo> do you have an intuition how much reordering BBs so that the most likely sequence is linear could give us?

[19:07] <brrt> That by itself, not so much

[19:09] <brrt> What I expect to be the big wins, are the collection of 'deep' traces

[19:10] <brrt> That combined with per-trace escape analysis, I expect we can eliminate most of the overhead of perl6

[19:11] <timotimo> i can imagine

[19:11] <brrt> the idea being that if you have a trace through a number of routines and can treat that as one thing, you can aggressively throw out basic blocks based on probability

[19:12] <timotimo> whenever there's a :noinline instruction, having a trace instead of a regular spesh, it'd just Not Be A Problem™

[19:12] <brrt> and (assuming that the generality and indirection is useful for dealing with exceptional cases, rather than the common case), that will allow us to eliminate ever more levels of indirectoin

[19:13] <brrt> right

[19:13] <brrt> the trace will provide optimization information even though we can't inline

[19:14] <brrt> (one thing we can do already, is install a specialized candidate for uninlineable attempts at inlines, if such a candidate does not yet exist)

[19:14] <timotimo> not sure how you mean that

[19:15] <brrt> so, we currently have a fallback mechanism for when we know the invocant, but there isn't a specialized candidate yet

[19:16] <brrt> see src/spesh/inline.c:230

[19:16] <brrt> MVM_spesh_inline_try_get_graph_from_unspecialized

[19:17] <brrt> if that happens, and the graph cannot be inlined, we just throw it away

[19:18] <brrt> what we could do instead, is install a specialized candidate instead for the invocant, and call that directly with some sp_invoke call

[19:26] <timotimo> that sounds like we don't do any argument specialization at all

[19:27] <brrt> Not for this case, no

[19:27] <brrt> we create a specialized graph, then if we find that we can't inline, we just drop

[19:27] <timotimo> but if we're inlining it, we've actually got all the facts already, too?

[19:27] <brrt> at least some, eys

[19:27] <brrt> *yes

[19:28] <timotimo> i'm not sure what "on the invocant" would mean; you mean we already know the type of the first argument because otherwise how would we have found the right code object?

[19:29] <brrt> I mean invokee, not invocant :-)

[19:29] <brrt> So, we know the code that we're going to invoke

[19:30] <timotimo> i'm not entirely sure how that's not what we're already doing; if we weren't able to inline the code we got "from_unspecialized", what are we supposed to specialize?

[19:31] <timotimo> if i'm being too dense, feel free to just stop explaining it to me %)

[19:32] <brrt> if we can't inline it, that doesn't mean we can't specialize it altogether

[19:33] <brrt> so the order of operations is this (to the best of my understanding)

[19:33] <brrt> - we start specializing a frame

[19:33] <brrt> - the frame wants to call a piece of code

[19:33] <brrt> - we can resolve that piece of code during specialization

[19:33] <brrt> - we try to inline that piece of code

[19:33] <brrt> - we find that there is not already a specialized candidate

[19:34] <brrt> - we proceed to generate a specialized candidate and try to inline it

[19:34] <brrt> - if we find that we cannot inline the resulting graph, we drop it

[19:35] <brrt> - however, that leaves us with no inlining and no specialized candidate

[19:35] <timotimo> i think i get it now

[19:35] <brrt> - I claim that we would be better of generating a specialized candidate and invoking that :-)

[19:36] <timotimo> but if we just blindly specialize a candidate without much information, we'll not be logging from it at all

[19:36] <brrt> true

[19:36] <brrt> but that is a tradeoff we already make when we specialize unspecialized graphs

[19:36] <brrt> for inlining

[19:36] <timotimo> also true

[19:37] <timotimo> though when we inline, we can benefit from facts we have in the outside frame

[19:37] <brrt> all those facts ought to be available based on the call info we have though

[19:38] <brrt> it's the same information - the subset of facts from the caller graph, that is passed through to the callee graph

[19:39] <timotimo> it'd only be available if we ever called the thing

[19:39] <timotimo> not if it's super rare

[19:39] <timotimo> right?

[19:39] <brrt> true

[19:40] <brrt> in which case, it'd probably be preferable to drop it altogether, imho

[19:40] <brrt> (which is why we need trace specialization :-))

[19:40] <timotimo> i'm not saying we shouldn't go for trace specialization :)

[19:41] <brrt> https://news.ycombinator.com/item?id=17842054 maybe upvote? ;-)

[19:41] *** avar left
[19:41] *** avar joined
[19:41] *** avar left
[19:41] *** avar joined
[19:41] *** p6bannerbot sets mode: +v avar

[19:41] <timotimo> don't have an account on that site

[19:41] <brrt> o.O

[19:41] <brrt> you are wise

[19:42] *** p6bannerbot sets mode: +v avar

[19:42] <timotimo> eh, i've got an account on reddit

[19:45] <brrt> you can post it on perl reddit?

[19:45] <timotimo> i'm not actually posting on reddit

[19:46] <timotimo> just commenting every now and then

[19:46] <timotimo> it seems like reddit no longer splits karma up into post and comment karma

[19:46] <timotimo> otherwise i could have shown you

[19:47] <timotimo> i have 14 posts over a period of 4 years

[19:48] <nine> I keep wondering if there is a way to keep an encoded version of some string around attached to a string object. That could speed up any use case where we just get a string from outside and pass it back to the outside later on in the same encoding.

[19:51] <timotimo> either we make VMString a bunch bigger, or we have a per-thread cache that holds weak references or something ...

[19:51] <brrt> we have some room for making VMString a bit bigger

[19:52] <nine> Or we have an additional repr (maybe a reappropriated CStr) for that. But we'd need to handle this specially in all the necessary places.

[19:52] <nine> brrt: we do?

[19:52] <timotimo> it'd have both a reference to the buffer and an identifier for the encoding used, no?

[19:52] <timotimo> or maybe an external object that holds encoding name and resulting buffer

[19:52] <brrt> yeah, based on the theory that you kind of want your object either much smaller than a cache line, or as big as one and aligned on them

[19:52] <brrt> so.... if I take a look at the current state....

[19:53] <timotimo> personally i use pahole for that

[19:53] <timotimo> don't forget strings can be inlined into P6opaque, though

[19:54] <brrt> MVMString is 48 bytes big, of which 24 is the header

[19:55] <brrt> we can add 16 bytes, that's two pointers

[19:55] <brrt> if you want to inline the MVMStringBody into P6opaque (didn't know we could do that), then I think we have 8 bytes left still?

[19:56] <brrt> because P6opaque has this redirect pointer (that, if at all possible, I'd love to get rid of, but haven't investigated how we might do that)

[19:56] <brrt> and we have plenty of flags space left to indicate that we have a representation

[19:57] <timotimo> P6opaque has this flattened_stables thing

[19:57] <brrt> sooooooo... I say go for it

[19:57] <timotimo> int, num, str, those at the very least can go in there

[19:57] <brrt> there is also still the plan to do in situ strings

[19:57] <timotimo> aye

[19:58] <brrt> that would probably give you an ascii literal for 90% of strings, right there

[20:12] <nine> But maybe we wouldn't even have to make MVMStringBody larger. It already deals with multiple representations of strings. We could just add one more which looks like struct { MVMString *vmstr; char *encoded_str; MVMuint8 encoding; }

[20:12] <brrt> Hmmm

[20:12] <brrt> I'm not convinced I like having one more representation, tbh

[20:12] <brrt> Frankly, take that byte. It's cheap

[20:13] <brrt> (not byte, 8 bytes)

[20:18] <nine> Can't measure any performance difference in test-t.pl

[20:18] <nine> (with an additional pointer in MVMStringBody)

[20:22] <brrt> hmmm

[20:22] <brrt> maybe the cost of reallocating an encoded string isn't so large

[20:26] <nine> To be clear: I just added the field to the struct to see if memory pressure or cache usage may affect performance. But test-t may just not be a good benchmark for that.

[20:27] <brrt> oh, I see

[20:27] <brrt> :-)

[20:37] *** stmuk left
[20:37] *** stmuk joined
[20:38] *** p6bannerbot sets mode: +v stmuk

[20:40] *** stmuk_ joined
[20:41] *** p6bannerbot sets mode: +v stmuk_

[20:43] *** stmuk left
[20:43] *** fake_space_whale joined
[20:44] *** p6bannerbot sets mode: +v fake_space_whale

[21:01] *** stmuk joined
[21:02] *** p6bannerbot sets mode: +v stmuk

[21:03] *** stmuk_ left
[21:13] *** stmuk_ joined
[21:14] *** stmuk left
[21:14] *** p6bannerbot sets mode: +v stmuk_

[21:18] *** stmuk_ left
[21:19] <jnthn> brrt++ # really intersting post

[21:19] <jnthn> Also, postrelase-opts is more dramatic than I'd expected for that benchmark o.O

[21:19] *** stmuk joined
[21:20] <jnthn> timotimo: About the takedispatcher thing - yesterday I put in the smarts to optimize it from takedispatcher to null. However, we do the transform inside of the inline.

[21:20] *** p6bannerbot sets mode: +v stmuk

[21:20] <jnthn> We currently cannot optimize much inside of inlines, however, because we don't track their deopt points, so we don't know that we're not utterly busting deopt

[21:21] <jnthn> That's fixable, but it's - like all deopt-related things - hard, and when I implement it, I know I'm in for 1-2 weeks of debugging upshot.

[21:22] <jnthn> And deopt bugs are up there with GC bugs in being annoying to find. Especially as the things that reliably expose them tend to be very large.

[21:24] *** stmuk__ joined
[21:24] *** stmuk left
[21:25] *** p6bannerbot sets mode: +v stmuk__

[21:29] *** stmuk__ left
[21:31] <brrt> aye

[21:31] *** stmuk__ joined
[21:32] *** p6bannerbot sets mode: +v stmuk__

[21:32] * brrt afk

[21:32] *** brrt left
[21:36] *** stmuk__ left
[21:38] *** stmuk__ joined
[21:39] *** p6bannerbot sets mode: +v stmuk__

[21:43] <jnthn> I see I need to spend some time looking at our Perl 6 natives performance too :)

[22:31] *** stmuk joined
[22:32] *** p6bannerbot sets mode: +v stmuk

[22:33] *** stmuk__ left
[22:36] *** stmuk_ joined
[22:37] *** p6bannerbot sets mode: +v stmuk_

[22:38] *** stmuk left
[22:39] *** stmuk joined
[22:39] *** p6bannerbot sets mode: +v stmuk

[22:41] *** stmuk_ left
[23:55] *** bladernr5 joined
[23:59] *** bladernr5 left
