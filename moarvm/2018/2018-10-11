[00:01] *** lizmat joined
[00:01] *** p6bannerbot sets mode: +v lizmat

[00:06] *** lizmat left
[00:09] *** dogbert11 joined
[00:10] *** p6bannerbot sets mode: +v dogbert11

[00:13] *** dogbert17 left
[01:14] *** fake_space_whale joined
[01:14] *** p6bannerbot sets mode: +v fake_space_whale

[01:21] *** MasterDuke left
[01:40] *** ZzZombo left
[02:35] *** ZzZombo joined
[02:35] *** p6bannerbot sets mode: +v ZzZombo

[02:35] *** ZzZombo left
[06:04] *** domidumont joined
[06:05] *** p6bannerbot sets mode: +v domidumont

[06:14] *** lizmat joined
[06:14] *** p6bannerbot sets mode: +v lizmat

[06:16] *** patrickb joined
[06:16] *** p6bannerbot sets mode: +v patrickb

[06:20] *** fake_space_whale left
[06:49] *** lizmat left
[07:01] *** lizmat joined
[07:01] *** p6bannerbot sets mode: +v lizmat

[07:06] *** lizmat left
[07:21] *** robertle joined
[07:22] *** p6bannerbot sets mode: +v robertle

[07:45] *** domidumont left
[07:48] *** domidumont joined
[07:48] *** p6bannerbot sets mode: +v domidumont

[07:56] *** lizmat joined
[07:56] *** p6bannerbot sets mode: +v lizmat

[09:37] *** ZofBot left
[09:37] *** huggable left
[09:37] *** p6bannerbot left
[09:37] *** buggable left
[10:40] *** ZzZombo joined
[10:42] *** ZzZombo_ joined
[10:42] *** ZzZombo_ left
[10:42] *** ZzZombo_ joined
[10:46] *** ZzZombo left
[10:46] *** ZzZombo_ is now known as ZzZombo

[10:54] *** robertle left
[11:22] *** p6bannerbot joined
[11:22] *** ChanServ sets mode: +o p6bannerbot

[11:22] *** ZofBot joined
[11:22] *** p6bannerbot sets mode: +v ZofBot

[11:22] *** huggable joined
[11:22] *** buggable joined
[11:23] *** p6bannerbot sets mode: +v huggable

[11:23] *** p6bannerbot sets mode: +v buggable

[11:43] *** Kaiepi left
[11:44] *** Kaiepi joined
[11:45] *** p6bannerbot sets mode: +v Kaiepi

[12:49] *** scovit left
[12:55] *** scovit joined
[12:55] *** p6bannerbot sets mode: +v scovit

[12:57] *** brrt joined
[12:58] *** p6bannerbot sets mode: +v brrt

[12:58] <brrt> \o

[12:59] <jnthn> o/ brrt

[12:59] <brrt> ohai jnthn

[13:00] <brrt> I find that I'm not sure how pass-by-reference works in nativecall

[13:01] <brrt> i would have expected that we'd pass a pointer to the MVMRegister in args

[13:01] <brrt> but that doesn't appear to be how it works

[13:24] <jnthn> I don't know, alas

[13:24] <jnthn> nine++ probably does

[13:25] *** AlexDaniel left
[13:26] *** AlexDaniel joined
[13:26] *** p6bannerbot sets mode: +v AlexDaniel

[13:35] *** scovit left
[14:08] <Geth> ¦ MoarVM/vectorization: 8 commits pushed by (Timo Paulssen)++

[14:08] <Geth> ¦ MoarVM/vectorization: be35ab5bd8 | factor out profile call node creation

[14:08] <Geth> ¦ MoarVM/vectorization: a4c455263b | store time of "first ever entry" of call nodes

[14:08] <Geth> ¦ MoarVM/vectorization: d773c16f94 | expose first entry time in profiler data

[14:08] <Geth> ¦ MoarVM/vectorization: 8ccced4444 | expose a thread's start time

[14:08] <Geth> ¦ MoarVM/vectorization: fd7ded3900 | call node's first entry time should be relative

[14:08] <Geth> ¦ MoarVM/vectorization: 86faa8f17c | introducing vectorapply for native arrays

[14:08] <Geth> ¦ MoarVM/vectorization: 919476b0c3 | lego-jit vectorapply

[14:08] <Geth> ¦ MoarVM/vectorization: 3072af785f | no need for unsigned int args; jit don't like them yet

[14:08] <Geth> ¦ MoarVM/vectorization: review: https://github.com/MoarVM/MoarVM/compare/be35ab5bd8af^...3072af785f3b

[14:09] <timotimo> lizmat: ^- here's the op i was talking about

[14:10] <lizmat> timotimo: does it come with documentation in ops.markdown ?

[14:10] <timotimo> not yet

[14:11] <timotimo> my num @a = 1e0..500_000e0; my num @b = 500_000e0...1e0; my num $c = 5e0; my num @out; my $time = now; for ^500_000 { @out[$_] = @a[$_] + @b[$_] * $c; }; say now - $time; say @out[99]

[14:11] <evalable6> timotimo, rakudo-moar fbfccfa2f: OUTPUT: «0.34655233␤2499605␤»

[14:11] <timotimo> use nqp; my num @a = 1e0..500_000e0; my num @b = 500_000e0...1e0; my num @c = 5e0; my num @out; my $time = now; nqp::vectorapply(@b, @c, @b, 95, 1, 64); nqp::vectorapply(@a, @b, @out, 93, 0, 64); say now - $time; say @out[99]

[14:12] <timotimo> those are roughly equivalent

[14:12] <timotimo> because 95 is mul_n and 93 is add_n

[14:12] <timotimo> one of them is a cross operator, the one with a 1 in between, the other is a zip operator, the one with a 0 in between

[14:13] <lizmat> that looks pretty cool

[14:13] <timotimo> what i'd like you to have a look at is:

[14:13] <timotimo> make @out = @a Z+ @b X* $c turn into vectorapply calls

[14:14] <timotimo> they currently only work for 64bit wide arrays of int and num, and if it's a cross operator the smaller one has to be a native array, too, of the right kind and size, with only one element

[14:14] <lizmat> intriguing!   :-)  looks very cool

[14:15] <timotimo> \o/

[14:15] <lizmat> fwiw, I was first going to take a stab at documenting the new MAIN interface and write tests for it

[14:15] <timotimo> sure!

[14:15] <timotimo> no hurry :)

[14:15] <lizmat> and then I was planning to have a look at R#2360, attempting to fix nqp::p6store

[14:15] <synopsebot> R#2360 [open]: https://github.com/rakudo/rakudo/issues/2360 my %*FOO is Set = <a b c> dies

[14:17] <timotimo> the vectorapply version of that code can run 300 times and still finish a tiny bit faster than the for ^500_000 version

[14:17] <lizmat> and before all of that, first some sun / wind / cycling&

[14:17] <lizmat> timotimo: so you're saying that's potentially 300x as fast ?

[14:18] <timotimo> maybe i'll figure out soon-ish why it's even faster to have $c replaced with a 500_000 element @c array and using @c[$_] as well

[14:19] <timotimo> yeah, and potentially about 1.5kx faster than using Z+ and X*

[14:24] <timotimo> mhhh, my num @a = 1e0..500_000e0; takes about no time at all, but my num @a = 500_000e0...1e0; takes about 10 seconds; we recently optimized special cases of ... for for loops, surely we can put that into the push_all for the ... iterator, too :)

[14:54] *** fake_space_whale joined
[14:55] *** p6bannerbot sets mode: +v fake_space_whale

[15:21] *** domidumont left
[15:22] *** tadzik left
[15:22] *** tadzik joined
[15:23] *** p6bannerbot sets mode: +v tadzik

[15:27] *** brrt left
[15:36] *** lizmat left
[16:02] *** lizmat joined
[16:02] *** p6bannerbot sets mode: +v lizmat

[16:06] *** lizmat left
[16:26] *** patrickb left
[16:33] *** shareable6 left
[16:33] *** reportable6 left
[16:33] *** committable6 left
[16:33] *** quotable6 left
[16:33] *** squashable6 left
[16:33] *** reportable6 joined
[16:33] *** shareable6 joined
[16:33] *** committable6 joined
[16:33] *** quotable6 joined
[16:33] *** squashable6 joined
[16:33] *** evalable6 left
[16:33] *** bisectable6 left
[16:33] *** evalable6 joined
[16:33] *** bisectable6 joined
[16:34] *** p6bannerbot sets mode: +v reportable6

[16:34] *** p6bannerbot sets mode: +v shareable6

[16:34] *** p6bannerbot sets mode: +v committable6

[16:34] *** p6bannerbot sets mode: +v quotable6

[16:34] *** p6bannerbot sets mode: +v squashable6

[16:34] *** p6bannerbot sets mode: +v evalable6

[16:34] *** p6bannerbot sets mode: +v bisectable6

[16:36] *** lizmat joined
[16:36] *** p6bannerbot sets mode: +v lizmat

[16:39] *** releasable6 left
[16:39] *** notable6 left
[16:39] *** greppable6 left
[16:39] *** releasable6 joined
[16:39] *** notable6 joined
[16:39] *** greppable6 joined
[16:40] *** p6bannerbot sets mode: +v releasable6

[16:40] *** p6bannerbot sets mode: +v notable6

[16:40] *** p6bannerbot sets mode: +v greppable6

[16:42] *** unicodable6 left
[16:42] *** unicodable6 joined
[16:43] *** p6bannerbot sets mode: +v unicodable6

[16:49] *** ankitkk left
[16:49] *** ankitkk joined
[16:50] *** p6bannerbot sets mode: +v ankitkk

[16:51] *** brrt joined
[16:52] *** p6bannerbot sets mode: +v brrt

[17:00] *** robertle joined
[17:01] *** p6bannerbot sets mode: +v robertle

[17:03] *** domidumont joined
[17:03] *** p6bannerbot sets mode: +v domidumont

[17:08] <brrt> timotimo++ pretty cool work

[17:10] *** fake_space_whale left
[17:10] *** domidumont left
[17:12] <lizmat> timotimo: afaik, ... is still a gather / take combo

[17:23] *** fake_space_whale joined
[17:24] *** p6bannerbot sets mode: +v fake_space_whale

[17:32] <nine> brrt: but....that should be exactly how it works?

[17:32] <nine> brrt: that's also why I added a getarg op for reading the value back from the args buffer

[17:37] <brrt> oh, really

[17:38] <brrt> ..... so, I don't have to add a 'copy-back-to-frame' for rw arguments

[17:38] <brrt> that's good news

[17:38] <brrt> that simplifies things tremendously

[17:39] <brrt> nine++

[17:44] <nine> My initial implementation just read the value from the local with lots of assumptions about which local that might be. But that was a tiny bit too fragile ;)

[17:46] <timotimo> lizmat: OK!

[17:47] <brrt> yeah, i can imagine :-)

[17:47] <timotimo> so i'm using nine's example profile data again, and the "paths" data for one function that appears in 522 call sites was a proud ~12 megabytes, which my program took about one and a half minutes to put together into a json blob

[17:48] <timotimo> with a whole lot of memory usage

[17:48] <timotimo> i.e. when i tried it earlier, it tried to dump core because it reached the maximum my ram had to offer

[17:48] *** evalable6 left
[17:48] <timotimo> that's not quite acceptable %)

[17:48] *** evalable6 joined
[17:49] *** shareable6 left
[17:49] <timotimo> also, it'll be interesting to build the flame graph data when there's theoretically hundreds of megabytes of data in there

[17:49] *** p6bannerbot sets mode: +v evalable6

[17:51] <timotimo> brrt: you think the vectorization branch is an acceptable way forward? it's surely not optimal, but it's certainly faster than what our zip/cross ops currently can do

[17:52] <brrt> I have totally not reviewed it

[17:52] <timotimo> it's probably more efficient to try to do all operations on each little bunch of data?

[17:52] <timotimo> rather than going through all data with one operation, then through all data with another

[17:53] <timotimo> and it's surely wasteful to require intermediate arrays to be made

[17:54] <brrt> hmmmm

[17:54] <timotimo> though if every operation only goes from two arrays to one, i'd assume most of the time you can have at most one temporary array?

[17:54] <brrt> in honesty you may have exceeded my expertise :-)

[17:54] <timotimo> haha

[17:54] <timotimo> i have no expertise either, that's why i just let the C compiler do 100% of the work

[17:57] <brrt> scarily, I'm getting good at writing adhoc jit templates

[17:57] <brrt> not the most portable of skills..

[17:57] <dogbert11> brrt: do you have any theories as to why some spectest files fails when run with MVM_JIT_EXPR_DISABLE=1 ?

[17:58] <brrt> dogbert11: nope, can you point me to the right ones?

[17:58] <dogbert11> brrt; try running - MVM_JIT_EXPR_DISABLE=1 ./perl6  t/spec/S05-mass/properties-block.t

[17:59] <brrt>  huh, that's funny

[17:59] <dogbert11> I thought so too. quite strange

[18:00] <brrt> goes away with MVM_JIT_DISABLE=1

[18:00] <brrt> okay, I can probably figure that out

[18:00] <brrt> I'll put it somewhere on my todo list

[18:00] <dogbert11> ++brrt

[18:01] <brrt> .oO( we need an inverse jit bisect )

[18:01] <brrt> I need to fixup jit bisect anyway ...

[18:02] <brrt> anyway, I'll have to do all that later, afk for now :-)

[18:03] *** brrt left
[18:05] <timotimo> oh, the cro process is still at like 3.9 gigs RSS

[18:27] <japhb> yikes

[18:29] <timotimo> oh lord, this can't be right

[18:30] <timotimo> the json was being created with :pretty

[18:30] <timotimo> that's pretty bad for a deeeeeeeply nested structure

[18:31] <timotimo> routine-paths in 2.7811155

[18:31] <timotimo> routine-paths json in 2.95350603: 263873 characters

[18:31] <timotimo> ^- with :!pretty

[18:31] <timotimo> routine-paths in 2.910559

[18:31] <timotimo> routine-paths json in 120.8043488: 13517443 characters

[18:31] <timotimo> ^- with :pretty

[18:31] <japhb> timotimo: When you're doing really serious vector/matrix/tensor operations, beyond a certain point runtime will be utterly dominated by memory hierarchy effects.  Chunking large arrays so that all operations on a given set of data fit in fast caches makes a huge difference (consider e.g. multiplying a pair of 8k x 8k matrices).

[18:32] <timotimo> japhb: sadly, that means much more work :)

[18:32] <japhb> timotimo: Actually ... maybe not.  It may be that if you want to do that sort of thing, we instead automate using one of the fast linear algebra libraries.

[18:33] <timotimo> true

[18:33] <japhb> Don't get me wrong, I think your current research is very useful.  I was just answering your question earlier about vectorization of large volumes of data.

[18:34] <timotimo> alternatively, maybe the liboil compiler would actually be nice to put into moar

[18:34] <timotimo> yeah, i think i got you right :)

[18:35] <timotimo> TBF with the stuff i've implemented so far, i don't think matrix multiplication is particularly possible to implement

[18:36] <japhb> timotimo: Have you looked at PDL from the Perl 5 world?

[18:36] <timotimo> i have not

[18:37] <japhb> It's interesting just from the point of view of the things it makes easy, and the magic it does behind the scenes to make that fast-ish.

[18:38] <timotimo> i've looked a little into numpy

[18:38] <japhb> But it was not trying to do true CPU vectorization, rather just able to pump large multidim arrays into optimized C routines

[18:38] <timotimo> scipy has a thing that lets you write C++ code using some c++ library that does multidim arrays that you can slice every which way

[18:38] <japhb> It could not, for example, hold a candle to the real C/C++ fast linear algebra stuff.  Still, it beat the blazes off doing things element-wise.

[18:39] <timotimo> last time i looked it was barely documented, barely hackable if you want very specific behaviour of the compiler, and apparently hadn't been touched in a couple of years

[18:42] <timotimo> got a tree with 162338 nodes

[18:42] <timotimo> routine-paths in 272.2697089

[18:42] <timotimo> oh jeez here we go

[18:43] <timotimo> in comparison, the stuff i pasted above had "got a tree with 5755 nodes"

[18:44] <timotimo> routine-paths json in 90.608918: 7433700 characters

[18:44] <japhb> m: say 162338 / 5755, 272.2697089 / 2.7811155

[18:44] <camelia> rakudo-moar fbfccfa2f: OUTPUT: «28.20816797.899461169␤»

[18:44] <japhb> m: say 162338 / 5755, '   ', 272.2697089 / 2.7811155

[18:44] <camelia> rakudo-moar fbfccfa2f: OUTPUT: «28.208167   97.899461169␤»

[18:44] <timotimo> now chrome is chugging along on the json and the react component tree

[18:44] <japhb> Hmmm, some nonlinear effects there, but at least not O(n**2)

[18:45] *** shareable6 joined
[18:45] <timotimo> aye, you must imagine the call graph and we've got a set of leaf nodes

[18:45] <japhb> Are you sorting the keys?  Looks like there might be an N log N effect

[18:46] <japhb> (Just staring at the ratios)

[18:46] <timotimo> and the code goes via the parent ids towards the known roots

[18:46] <japhb> Ah, yeah, that would do it

[18:46] *** p6bannerbot sets mode: +v shareable6

[18:46] <timotimo> i should be able to construct an sql query that picks every "current node"'s parent rather than going node-by-node

[19:07] *** Kaiepi left
[19:07] *** Kaiepi joined
[19:08] *** p6bannerbot sets mode: +v Kaiepi

[19:58] <diakopter> heh portable

[20:26] *** Kaiepi left
[20:36] *** Kaiepi joined
[20:36] *** p6bannerbot sets mode: +v Kaiepi

[20:42] *** Kaiepi left
[20:42] *** Kaiepi joined
[20:43] *** p6bannerbot sets mode: +v Kaiepi

[21:49] *** squashable6 left
[21:50] *** squashable6 joined
[21:50] *** p6bannerbot sets mode: +v squashable6

[21:53] *** squashable6 left
[21:53] *** squashable6 joined
[21:54] *** p6bannerbot sets mode: +v squashable6

[23:29] <timotimo> i'm not sure where to stop adding "vectorized" stuff. like, i think coercing an array of int to an array of num and vice versa seems very useful to have

[23:30] <timotimo> but coercing int or num to str ... useful for sure, but not appropriate for the vectorapply op, i don't think

[23:54] *** greppable6 left
[23:54] *** greppable6 joined
[23:55] *** p6bannerbot sets mode: +v greppable6

