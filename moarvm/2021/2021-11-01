[00:02] *** reportable6 left
[00:10] *** kjp joined
[00:49] *** releasable6 joined
[00:50] *** statisfiable6 joined
[00:50] *** bloatable6 joined
[01:03] *** reportable6 joined
[01:05] *** dogbert11 joined
[01:08] *** dogbert17 left
[01:50] *** linkable6 joined
[03:02] *** nine left
[03:02] *** nine joined
[03:48] *** greppable6 joined
[03:49] *** nativecallable6 joined
[08:26] *** lizmat_ left
[08:26] *** TempIRCLogger joined
[08:26] *** lizmat joined
[08:28] *** dogbert11 left
[08:28] *** dogbert17 joined
[08:35] *** dogbert11 joined
[08:37] *** dogbert17 left
[08:44] *** dogbert17 joined
[08:46] *** dogbert11 left
[08:50] *** dogbert11 joined
[08:53] *** dogbert17 left
[08:56] *** dogbert11 left
[08:56] *** dogbert11 joined
[09:05] <Geth> Â¦ MoarVM: cd809ee472 | (Stefan Seifert)++ | src/6model/containers.c

[09:05] <Geth> Â¦ MoarVM: Fix possible access to fromspace in code_pair_configure_container_spec

[09:05] <Geth> Â¦ MoarVM: 

[09:05] <Geth> Â¦ MoarVM: MVM_string_ascii_decode_nt allocates, so fetch can get moved during decoding of

[09:05] <Geth> Â¦ MoarVM: store.

[09:05] <Geth> Â¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/cd809ee472

[09:06] <nine> dogbert11: this ^^^ fixes t/spec/S06-routine-modifiers/proxy.t. Thankfully it was a very straigt forward GC issue :)

[09:12] *** dogbert17 joined
[09:16] *** dogbert11 left
[09:17] *** releasable6 joined
[09:23] <dogbert17> nine++, so no rabbit hole this time :)

[09:52] *** dogbert11 joined
[09:55] *** dogbert17 left
[10:03] *** dogbert17 joined
[10:04] *** dogbert11 left
[10:32] <timo> :+1:

[10:32] <timo> i guess contspecs are only created very very early

[10:53] <nine> There may be a rabbit hole after all. I switched back to the new-disp-nativecall branch and accidentally run that test again instead of the one I wanted to continue on. And it segfaulted.

[10:54] <nine> It does so reproducibly due to a broken frame in dispatch. Now I wonder: is this something that's simply already fixed on master and my branch lacks that fix? Or is it something that my branch just unveils due to different memory layout or something like that. Or maybe even a direct regression.

[11:04] *** linkable6 left
[11:04] *** evalable6 left
[11:11] <dogbert17> oh, so there was a rabbit hole after all :)

[11:16] <nine> Ok, it's not a fix in master that the branch lacks

[11:17] *** bloatable6 joined
[11:18] <nine> According to my bisection result it's 93bfeab1ee3d62e1ba7415c3894d2c5803a947b7 "Remove old invoke protocol"

[11:18] <lizmat> aww

[11:19] <nine> Of all the commits in my branch, this one makes the most sense as it makes changes to frame allocation

[11:20] <nine> The segfault seems to be caused by overwriting unrelated memory when promoting a frame to the heap, which could be due to miscalculating frame size

[11:27] <dogbert17> it's good that you found it

[11:27] <dogbert17> perhaps I should emulate timo and suggest rr :)

[11:34] <nine> No need. That's how I know that its overwriting unrelated memory

[11:43] <timo> nine's computer go brr

[11:46] <nine> This is odd. jnthnwrthngtn++ recently changed it so a frame's work registeres are allocated on the callstack, basically as part of the frame. Yet MVM_frame_move_to_heap does not deal with work registers at all. The work pointer is just copied from the frame on the callstack and will still point into the callstack.

[11:47] <nine> Now this looks very much like a simple oversight and could cause such interesting issues. But it also sounds like it would wreak havoc long before my branch.

[11:50] <nine> Ah, I may just misunderstand things. Apparently the original callstack entry of the frame will remain

[11:50] <timo> maybe this is about whether we'll run code in there again?

[11:50] <timo> work is not accessible to inner frames and such, only the lexicals

[12:02] *** reportable6 left
[12:04] *** evalable6 joined
[12:06] *** linkable6 joined
[12:52] <nine> Oh what a perfect way to waste some time. Pro tip: after switching branches touching MoarVM headers, recompile rakudo.

[12:52] * nine can't wait to see extops gone

[12:57] <timo> d'oh

[12:58] *** frost joined
[13:04] *** reportable6 joined
[13:38] <lizmat> And yet another Rakudo Weekly news hits the Net: https://rakudoweekly.blog/2021/11/01/2021-44-1000-rakoons/

[13:38] <Geth> Â¦ MoarVM: 0821570aaa | (Stefan Seifert)++ | src/6model/containers.c

[13:38] <Geth> Â¦ MoarVM: Avoid MVMROOT by better sequencing of the code

[13:38] <Geth> Â¦ MoarVM: 

[13:38] <Geth> Â¦ MoarVM: zhuomingliang++ for suggesting this much better version of the GC issue fix

[13:38] <Geth> Â¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/0821570aaa

[13:49] *** frost left
[13:59] <jnthnwrthngtn> nine: The lifetime of ->work is always that of the dynamic scope of the frame, which is precisely the lifetime of the callstack record, so there's no need to move that (unlike the environment, which can - in a promoted frame - outlive the dynamic scope)

[13:59] <jnthnwrthngtn> This is very much by design, not an oversight.

[14:11] <nine> At least that motivated me to have a look at the remaining extops. Couldn't RAKUDO_FIRST_FLAG easily be replaced with a state var?

[14:12] <jnthnwrthngtn> Cheaper in terms of keeping the loop body inlinable would be a secret lexical in the outer scope.

[14:12] <jnthnwrthngtn> (We can't inline things with state vars, I'm not really hurrying to implement that, and it's probably easier to implement it as a lexical in the scope where the loop appears anyway)

[14:17] <timo> it can't be a local from the start?

[14:17] <timo> oh, only after inlining, of course

[14:51] *** Altai-man joined
[14:51] *** Voldenet left
[14:51] *** Altai-man left
[14:54] *** Voldenet joined
[16:02] *** Voldenet left
[16:07] *** Voldenet joined
[17:55] <dogbert17> Already set resume init args for this dispatcher

[17:55] <dogbert17>   in block  at t/spec/S02-types/range.t line 424

[17:55] <dogbert17>   in sub subtest at /home/dogbert/repos/rakudo/lib/Test.rakumod (Test) line 437

[17:56] <dogbert17> this pops up when running with a (very) small nursery and MVM_SPESH_BLOCKING=1 plus MVM_SPESH_NODELAY=1

[17:57] <timo> the --ll-exception here could be interesting

[18:01] <dogbert17> timo: https://gist.github.com/dogbert17/9c648c7e45d31a09abc686c6e046b573

[18:01] <timo> and dump_bytecode from inside that dispatcher as well

[18:01] <dogbert17> aha

[18:02] <timo> did we get any further for the "need to use tracked capture" one from the other day? that was you with a small nursery as well wasn't it?

[18:02] *** reportable6 left
[18:04] *** reportable6 joined
[18:05] <dogbert17> timo: gist updated

[18:06] <dogbert17> the other bug didn't want to show itself when nine tried to repro :(

[18:18] <timo> ok, so the only way to reach that error message is through the syscall dispatcher-set-resume-init-args

[18:18] <timo> and there's only one call to that in our dumped bytecode

[18:20] <timo> and this is the boot-resume-caller dispatcher i assume

[18:21] <timo> i think my local v6c.nqp from BOOTSTRAP doesn't match the line numbers supplied

[18:21] <timo> ok, i'm still on my branch so no big surprise

[18:22] <timo> what's that line on your machine there?

[18:30] <timo> might be interesting to see the contents of the record->rec.resume_inits

[18:55] <dogbert17>  6481     # Initialization of a non-trivial dispatch. Receives a dispatch resumption

[18:55] <dogbert17>    6482     # kind, which is zero if we're not resuming.

[18:55] <dogbert17>    6483     -> $capture {

[18:55] <dogbert17>    6484         # Extract and guard on the kind (first argument).

[19:01] <dogbert17> running it under gdb led to a 'MoarVM panic: Adding pointer 0x555555686208 to past fromspace to GC worklist'

[19:06] <dogbert17> (gdb) p *record->rec.resume_inits

[19:06] <dogbert17> $3 = {disp = 0x555556c9c698, capture = 0x55555555bc18}

[19:12] <dogbert17> I updated the gist with some info about the panic, perhaps nine++ can make something of that

[19:45] <timo> so perhaps we're not marking everything in these records

[19:53] *** Kaiepi left
[19:53] *** Kaiepi joined
[20:12] *** linkable6 left
[20:21] <timo> how many resume inits are in there? you'll want to print the entire record->rec actually, forgot how that works

[20:37] <dogbert17> (gdb) p record->rec

[20:37] <dogbert17> $7 = {initial_capture = {capture = 0x55555555b2b0, transformation = MVMDispProgramRecordingInitial, index = 21845, value_index = 1516444472, captures = 0x55555a6a3490, captures_num = 1, captures_alloc = 8}, 

[20:37] <dogbert17>   resume_kind = MVMDispProgramRecordingResumeCaller, inline_cache_size = 1, resumptions = 0x55555a69d6d0, resumptions_num = 3, resumptions_alloc = 4, values = 0x55555a6a4ac0, values_num = 26, 

[20:37] <dogbert17>   values_alloc = 34, resume_inits = 0x55555a69c7b0, resume_inits_num = 1, resume_inits_alloc = 4, outcome_value = 1516458416, outcome_capture = 0x0, bind_failure_resumption_flag = 1484418240, 

[20:37] <dogbert17>   bind_success_resumption_flag = 21845, map_bind_outcome_to_resumption = MVMDispProgramRecordingBindControlNone, do_not_install = 0 '\000'}

[20:41] <japhb> What's with all the hex 5's?

[20:42] <timo> ok so there's just the one resume_inits, the one you already posted, with the disp and the capture

[20:43] <japhb> (BTW, I'm not actually just being silly, strings of 0101 are often used as sentinels, so it is really weird seeing it so much here.)

[20:44] <timo> dogbert17 could give us the output of /proc/$pid/maps (or i guess gdb probably has a command that does something similar) where these address ranges live

[20:53] <dogbert17> timo: gist updated

[20:53] <timo> ok the 5s are harmless then

[21:54] <japhb> Weird, but yeah, I suppose so.

[22:13] *** linkable6 joined
[23:39] *** evalable6 left
[23:39] *** linkable6 left
[23:43] *** dogbert17 left
[23:46] *** dogbert17 joined
