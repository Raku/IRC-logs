[00:13] *** sxmx joined
[01:39] *** Altai-man_ left
[01:43] *** sena_kun joined
[03:31] *** harrow left
[03:43] *** harrow joined
[04:54] *** vrurg left
[04:55] *** vrurg joined
[06:35] *** frost-lab joined
[06:46] <nwc10> good *, #moarvm 

[07:30] *** ggoebel left
[07:31] *** ggoebel joined
[07:48] *** domidumont joined
[08:11] *** domidumont left
[08:59] *** patrickb joined
[08:59] <patrickb> o/

[09:01] <MasterDuke> m: my $a; my $s = now; $a = do given "hi" { when 3 { "three" }; when 5 { "five" }; when "hi" { "hello" }; when * > 40 { "> 40" }; default { "default" } } for ^40_000; say now - $s; say $a   # nine this was the code

[09:01] <camelia> rakudo-moar 726a75e24: OUTPUT: «3.7216878␤hello␤»

[09:02] <MasterDuke> wow. on 2020-11-12 that took 7.7s for camelia

[09:04] <MasterDuke> but a profile shows it's still dominated by https://github.com/rakudo/rakudo/blob/master/src/core.c/Backtrace.pm6#L98

[09:04] <MasterDuke> 42% of the time in GC (369 GC runs)

[09:13] <nine> MasterDuke: that camelia speedup is due to it running on a AMD Ryzen 7 3700X now

[09:14] <MasterDuke> oh, ha! no wonder it matched my local time much more closely than i remember it doing before

[09:15] <nine> MasterDuke: the good news is: my latest version for correct backtraces is about 25 % faster in that benchmark :)

[09:16] *** zakharyas joined
[09:19] <MasterDuke> nice!

[09:22] <nine> I wonder if it'd be possible to create the backtrace on-demand

[09:27] <MasterDuke> that sounds like it could make Failures even cheaper

[09:29] *** frost-lab left
[09:29] *** frost-lab joined
[10:04] *** sena_kun left
[10:06] *** frost-lab left
[10:08] *** sena_kun joined
[10:23] <jnthn> nine: I think so long as we keep hold of the nqp::ctx result, the Backtrace frames themselves can be lazily built out of it

[10:23] <jnthn> But maybe we already are and the cost is in the other bit

[10:24] <jnthn> Maybe also Failure can just stick the nqp::ctx into its $!backtrace and expand it on first request into a full-on Backtrace object

[10:30] <nine> jnthn: I'm pretty sure we can have it. But there are a few details to take care of. MVM_exception_backtrace doesn't work on an MVMContext. It needs an MVMException. A reason being that the MVMContext does not contain information about the position within that frame.

[10:31] <nine> Throwing an exception on the other hand does not preserve the callers' current positions. So the longer you wait with generating the backtrace, the higher the chance to get a wrong result.

[10:32] *** domidumont joined
[10:33] <nine> But that's kinda true for MVMException also, since it stores the information in the frame extra. But that works only once. It refuses to set the same information again. So it preserves the original backtrace but causes future backtraces containing the same frames from being correct.

[10:33] *** zakharyas left
[10:34] <nine> I wonder if this is a problem with MVMContext in other....contexts as well.

[10:35] <nine> If you got a call chain like A -> B -> C -> D -> nqp::ctx and later on A -> B -> E -> F -> nqp::ctx, the latter context will still think B is at the point where C was called.

[10:38] <jnthn> Ah, yes, there's some assumption about how long you'll hang on to and use the ctx, I guess

[10:39] <jnthn> The whole thing gets really icky too because you can have deopts and uninlining after the point of capturing the ctx

[10:40] <jnthn> And "just snapshot the lot" doesn't work either because it's also vulnerable to that happening.

[10:40] <jnthn> (The lexicals can move, for example.)

[10:41] *** zakharyas joined
[10:43] <nine> Funny how we're so eager to create backtraces for Failures (which we have to do get them right) but actually create them lazily for Exceptions.

[10:59] <jnthn> Yeah... That's largely thanks to exception handlers running on the stack top :)

[11:01] <jnthn> The best solution here would be to be able to eliminate the taking of the backtrace at all in the case the failure is getting disarmed immediately in the caller

[11:01] <jnthn> Either by hoping it will fall out of generic optimizations, such as a combination of inlining and EA, or maybe something more targetted (dunno how that'd look)

[12:11] *** zakharyas left
[15:29] *** rba left
[15:30] *** rba joined
[15:31] *** camelia left
[15:50] *** camelia joined
[16:01] *** zakharyas joined
[16:50] *** ggoebel left
[17:52] *** domidumont left
[19:21] <nwc10> So, yesterday my GPW2021 t-shirt arrived in the post, so I put it on and uploaded a picture to the conference chat channel.

[19:21] <nwc10> In the evening at the social (distancing) event the question came up of what t-shirt to wear the next day (today)

[19:21] <nwc10> suggested various other German Perl Workshop t-shirts

[19:21] <nwc10> corion said "no, obviously a Frankfurt YAPC::Europe t-shirt"

[19:21] <nwc10> and I said "which one?"

[19:22] <nwc10> so I'm wearing the alternative "Perl 6" version t-shirt that Pm produced

[19:23] <nwc10> YAPC::Europe 2012 is (to the best of my knowledge) the only Perl conference whose t-shirt was cool enough to get a mock version

[20:10] <MasterDuke> m: my $a; my $s := now; $a := now for ^100_000; say now - $s;

[20:10] <camelia> rakudo-moar 726a75e24: OUTPUT: «0.94673692␤»

[20:11] <MasterDuke> well, i haven't run any tests yet, but ^^^ now takes 0.03s on my machine

[20:11] <lizmat> that will make a lot of people happy  :-)

[20:12] <MasterDuke> bunch of tests fail, but at least there's something here to work with

[20:12] <MasterDuke> heh, make that lots of tests fail so far...

[20:13] <lizmat> well, I think there's some nqp::timex in test ?

[20:13] <lizmat> *Test

[20:16] <MasterDuke> i pretty much know where the problems are, it's just a matter of getting all the cases right (e.g., Instant + Instant, Instant + Duration)

[20:17] <MasterDuke> it's probably going to make sense to change Duration's $!tai to Int also, but i haven't done that yet

[20:19] <lizmat> babysteps  :-)

[20:20] <MasterDuke> maybe will make some more progress later tonight or tomorrow, afk for now

[20:52] *** vrurg left
[20:54] *** sena_kun left
[21:02] *** vrurg joined
[21:19] *** zakharyas left
[21:58] *** patrickb left
[22:15] <japhb> Yeah, I'm definitely one of those for whom MasterDuke++'s improvements will be happy-making

[22:16] <japhb> I have un-PR-ed changes to various modules to include high-resolution timing information, which I haven't pushed upstream because I needed to use nqp::time_n to avoid timing having a very affect on code performance

[22:20] <MasterDuke> cool. hopefully it won't take too long to get it both faster and passing tests...

[22:20] <jnthn> I wrote Log::Timeline to use Instant on the assumption that at some point it'd be good enough :)

[22:20] <jnthn> I'm happy that will happen

[22:20] <jnthn> MasterDuke++

