[00:02] *** reportable6 left
[00:03] <jnthnwrthngtn> ggoebel: No, and curiously it manages to have no overlap with the things I tested :)

[00:08] <jnthnwrthngtn> Though it's not quite testing the same thing I think; https://github.com/dyu/ffi-overhead/blob/master/node/newplus.cpp is for example using the Node.js C API, whereas all the ones I tested didn't require writing any such C or C++ binding code

[00:09] <jnthnwrthngtn> I tried with the Node.js FFI module with a more comparable API and it took 1 minute 57 seconds. I'm guessing that isn't the speediest option :)

[00:13] <jnthnwrthngtn> (Although "if I google <language> FFI and pick the first sensible looking option" is arguably the a good strategy for picking a representative FFI impl to benchmar...)

[00:17] <jnthnwrthngtn> Sleep o/

[00:19] <moon-child> I heard luajit cffi can be faster than c when calling into shared libs, because c has to go through plt and luajit can avoid that

[00:38] <timo> i quickly wrote a/the abs calling example and in the spesh log i see we're still creating an Int needlessly before doing the call. we do use the register that was used to create that Int, however, so that's good

[00:43] <timo> 1% of time spent in abs, says perf

[00:43] <timo> 14.28% spent in gc_free, 10.22% in gc_collect_free_nursery_uncopied, 6.49% in gc_allocate_nursery

[00:45] <timo> ah, with the perf map i now see 34.5% spent in <unit>, which is where the for loop got inlined into

[00:46] *** patrickb left
[00:58] <timo> it's using a lexical for my integer value, so there's more to be won there

[01:01] <timo> replacing abs($x) with abs(999) doesn't make things noticeably faster

[01:03] <timo> empty loop with the same amount of iterations takes 1.33s compared to the 2.3s with abs($x)

[01:05] *** reportable6 joined
[01:13] <timo> a loop of 500_000_000 written naively in C takes 1.25s

[01:14] <timo> this is with -fno-builtin

[02:01] <Geth> Â¦ MoarVM/spesh_unbox_i_cpointer: 97b3af3ebf | (Timo Paulssen)++ | src/6model/reprs/CPointer.c

[02:01] <Geth> Â¦ MoarVM/spesh_unbox_i_cpointer: Optimize passing CPointer to nativecall ever so slightly

[02:01] <Geth> Â¦ MoarVM/spesh_unbox_i_cpointer: 

[02:01] <Geth> Â¦ MoarVM/spesh_unbox_i_cpointer: We emit an unbox_i operation in a compiled nativecall body in order to

[02:01] <Geth> Â¦ MoarVM/spesh_unbox_i_cpointer: get the pointer value to pass to the native function. Without a spesh

[02:01] <Geth> Â¦ MoarVM/spesh_unbox_i_cpointer: method on the CPointer repr, this would interpret as, and jit into, a

[02:01] <Geth> Â¦ MoarVM/spesh_unbox_i_cpointer: call to CPointer's get_int.

[02:01] <Geth> Â¦ MoarVM/spesh_unbox_i_cpointer: 

[02:01] <Geth> Â¦ MoarVM/spesh_unbox_i_cpointer: Instead of a call, we just emit a spesh op to do the memory offset and

[02:01] <Geth> Â¦ MoarVM/spesh_unbox_i_cpointer: read for us, which the JIT also likes very much.

[02:01] <Geth> Â¦ MoarVM/spesh_unbox_i_cpointer: review: https://github.com/MoarVM/MoarVM/commit/97b3af3ebf

[02:05] *** evalable6 left
[02:05] *** linkable6 left
[02:07] *** linkable6 joined
[02:32] *** frost joined
[04:05] *** linkable6 left
[04:06] *** linkable6 joined
[04:08] *** evalable6 joined
[06:00] *** ggoebel left
[06:02] *** reportable6 left
[06:04] *** reportable6 joined
[07:53] <nine> timo: So....our loop with a native call is basically about a factor 6 off native C's performance? That's not that bad at all :)

[07:54] <timo> well, hopefully we can also get there without forcing a c-style loop loop on our users

[07:56] <nine> Btw. with that BEGIN EVAL issue in NativeCall sorted out, I measured a new record of 7.135s for csv-ip5xs.pl with 1_000_000 lines

[07:56] <nine> Best I got before new-disp was around 14s

[07:56] <timo> oh wow

[07:57] <nine> I can remember when I used 10000 lines when benchmarking and got around the same time :)

[08:03] *** dogbert17 left
[08:04] *** dogbert17 joined
[08:04] *** frost left
[08:04] <timo> interesting. here's a couple of BBs in a row where the first one has the next four as its direct successors, because there's an FH Goto in each of them. however, all the ops in the first two can not throw. the first one has two "set", the second one has just "unless_i"

[08:05] <timo> i wonder if we can win anything anywhere if we remove such useless connections when we detect that

[08:05] <timo> phis would get smaller for one

[08:05] <nine> Isn't it this way because of deopt?

[08:07] *** frost joined
[08:09] <timo> maybe you mean how the very first BB has every BB that can osr as a successor?

[08:10] <nine> Rather that we can't simplify that easily. But maybe this is one of the rare cases where we actually can :)

[08:19] <timo> hmpf, so the particles example from sdl2::raw has one single update loop, and there's a branch in it for when a particle in a given slot has zero-or-negative lifetime, then there's a chance for a new particle to be spawned in that place

[08:19] <timo> unfortunately, all the dispatches from that branch get "never dispatched"

[08:19] <timo> but the dispatch_o are rewritten to sp_dispatch_o, which don't log

[08:19] <timo> right now we don't get a second chance here

[08:29] <nine> There are no deopts from these non-optimal branches either, are there?

[08:30] <timo> you mean in practice or just from what ops there are?

[08:33] <nine> in practice

[08:33] <timo> lemme log dat

[08:41] <timo> ah, i couldn't find the corresponding spot because i was looking at the rwong code

[08:43] <timo> the deopt comes from a dispatch_v raku-sink

[08:46] <timo> simple-args-proto also gets deopted a fair bit, where it guardconcs against BOOTInt

[08:47] <timo> interesting. it grab the value of $*COMPILING_CORE_SETTING and that ends up in the guardconc

[08:48] <timo> so it used to be set to 0, but then it was not set any more?

[08:48] <timo> and it got speshed during compilation where the dynvar was present

[08:52] <nine> Sounds like a simple fix is to just always set that dynvar?

[09:03] <timo> then it will leak into userspace

[09:06] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: 29 commits pushed by (Stefan Seifert)++, (Nicholas Clark)++, (Timo Paulssen)++

[09:06] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: review: https://github.com/MoarVM/MoarVM/compare/074664581745...8bd92825147a

[09:09] <timo> sorry i got booted off the 'net

[09:12] *** linkable6 left
[09:12] *** evalable6 left
[09:13] <nine> Right...then of course the obvious solution is to unset it, instead of setting it to 0 in token comp_unit

[09:21] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: 4 commits pushed by (Stefan Seifert)++, (Timo Paulssen)++

[09:21] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: b339df6421 | Remove old invoke protocol

[09:21] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: daaefe238f | Stack allocate args, free_strs and free_rws lists in native calls

[09:21] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: e4ad83b382 | Add missing MVMROOT for libffi native calls

[09:21] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: 960bb7b314 | teach jit of runnativecall about CArray arguments

[09:21] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: review: https://github.com/MoarVM/MoarVM/compare/8bd92825147a...960bb7b31497

[09:27] <timo> i guess!

[09:27] <timo> unless lookup of nonexistent dynvars is very slow

[09:29] <nine> With unset I mean set it to NQPMu or whatever the we get in the dispatcher when the variable is never set

[09:30] <nine> Anyway this seems to be the perfect case for MasterDuke++'s work on throwing away spesh cands when there are too many deopts

[09:33] <timo> simple-args-proto doesn't get deopted that much ... or at least the other one gets deopted so much that anything else is drowned out

[09:39] <timo> but yes, agreed on MasterDuke's work

[09:39] <timo> it boggles me, kinda, how/why it breaks the way it does

[09:41] <timo> at some point i should RR it out. like really buckle up and try to really focus

[09:52] <nine> Yes. I only really started making progress on the return-from-nested-runloop issue when I fired up rr and single stepped all the way from the last callback to where it broke

[09:52] <nine> Seeing it live in action made it quite obvious

[10:03] *** MasterDuke left
[10:06] *** MasterDuke joined
[10:14] *** linkable6 joined
[10:14] <jnthnwrthngtn> moarning o/

[10:14] <lizmat> o/ jnthnwrthngtn 

[10:15] *** evalable6 joined
[10:16] <jnthnwrthngtn> timo: fwiw, my example just passed a literal to abs (knowing that it can't know to constant fold with FFI...)

[10:17] <timo> OK. i tried both $_, $x, and a 999, the difference was very small

[10:21] <MasterDuke> jnthnwrthngtn: i'm running a spectest now that i'm back on my desktop, but the rabbit hole i mentioned in https://github.com/MoarVM/MoarVM/pull/1600 is all the other encoders, which also don't take into account `start` or `length`

[10:22] <MasterDuke> all tests now pass

[10:29] <jnthnwrthngtn> MasterDuke: Yeah, I'm more inclined to just remove start/length arguments from all of them except maybe those where it serves some internal purpose (like you had).

[10:29] <jnthnwrthngtn> Rather than fix it

[10:29] <jnthnwrthngtn> I mean, substr exists :)

[10:31] <MasterDuke> in that case, the function could(should?) be removed

[10:34] <jnthnwrthngtn> What led you do want the start argument to the ASCII one? I'm guessing you discovered this for a reason

[10:34] <jnthnwrthngtn> We could in theory keep it for that if it's useful, and remove the others.

[10:34] <jnthnwrthngtn> Although if it's not a performance-critical place arguably just substr it for the ASCII one too

[10:35] <MasterDuke> some silly experimentation after seeing lizmat++'s benchmark where `my int $a = $foo.Int` was slower than `my int $a = str $ = $foo`

[10:36] <MasterDuke> the second form uses MVM_coerce_s_i, which is just strtoll, but the first goes via MVM_radix

[10:37] <lizmat> on that note: if we would have a CCLASS_DECIMAL, we could make Str.Int 3.5x as fast for strings < 19 chars

[10:37] <MasterDuke> so i was attempting to use strtoll in MVM_radix (assuming several conditions hold)

[10:37] <lizmat> CCLASS_DECIMAL being just 0,1,2,3,4,5,6,7,8,9

[10:38] <MasterDuke> and since MVM_radix takes an offset, i was trying to encode to a C string (for strtoll) just the correct substring of the MVMString passed

[10:38] <lizmat> CCLASS_NUMERIC also includes non-ascii numerics, which *do* break on the my int $ = my str $ = "123"   fast path

[10:39] <MasterDuke> so passed the offset given to MVM_radix to MVM_string_ascii_encode_substr and noticed it wasn't doing anything

[10:40] <jnthnwrthngtn> One could in theory look at if the string's representation claims to be ASCII or similar and then use the buffer directly

[10:41] <jnthnwrthngtn> Then it's zero copy and a cheap check, at the cost of a little encapsulation breakage.

[10:41] <jnthnwrthngtn> That said, if things we call expect zero termination, that won't quite work

[10:45] <MasterDuke> i assume strtoll expects a zero-terminated string, but i guess a memcpy into a new buffer 1 bigger would still be faster

[10:46] <jnthnwrthngtn> Yeah, and can (with length check also as a condition for applying the opt) alloca it too

[10:50] <MasterDuke> right. but hm, would we expect a lot of ascii? i think even a literal string given on the command line is *not* ascii (i.e., when i was using MVM_string_ascii_encode_substr it wasn't using the `if (str->body.storage_type == MVM_STRING_GRAPHEME_ASCII) {` branch)

[10:56] <jnthnwrthngtn> Dunno without looking at whether the utf8 decoder tracks this, tbh.

[11:00] <MasterDuke> do we have any functions to check whether "something" (e.g., an MVMString, array of bytes) is composed of just ascii chars?

[11:05] <MasterDuke> guess MVM_string_buf32_can_fit_into_8bit is close

[11:06] <moon-child> means all the codepoints are <255?

[11:06] <moon-child> <=

[11:07] <MasterDuke> https://github.com/MoarVM/MoarVM/blob/master/src/strings/ops.h#L66-L77

[11:12] <MasterDuke> could always implement https://lemire.me/blog/2020/07/21/avoid-character-by-character-processing-when-performance-matters/, but i wonder if MVM_string_buf32_can_fit_into_8bit is good enough? don't know what strtoll will do if it sees a non-ascii char

[12:02] *** reportable6 left
[12:05] *** reportable6 joined
[12:09] <MasterDuke> why do non-native string seem to get created with a single strand? e.g., in `use nqp; my $a = "123"; say nqp::radix(10, $a, 0, 0)[0]`, $a has a storage_type == MVM_STRING_STRAND

[12:34] *** squashable6 left
[12:50] *** Kaiepi left
[12:59] *** Kaiepi joined
[12:59] *** Kaiepi left
[13:00] *** Kaiepi joined
[13:00] *** Kaiepi left
[13:00] *** Kaiepi joined
[13:01] <MasterDuke> and then why in the world does str.body.storage.strands.blob_string.body.num_graphs == 111? 

[13:02] *** Kaiepi left
[13:02] *** Kaiepi joined
[13:03] *** Kaiepi left
[13:03] *** Kaiepi joined
[13:05] *** ggoebel joined
[13:05] *** Kaiepi left
[13:06] <MasterDuke> i ran that example under rr, put a breakpoint in MVM_radix, then did `watch -l str->body.num_strands` and reverse-continue'd

[13:07] <MasterDuke> it broke and shows the value going from 1 to 0 so i ran a backtrace

[13:08] <MasterDuke> and it's in process_worklist -> ... -> MVM_frame_takeclosure ?

[13:10] <timo> that looks odd, why is it storage.strands.blob_string, wouldn't it have to have a [0] in there somewhere?

[13:11] <MasterDuke> same with strands[0]

[13:15] <timo> can you double-check the REPR?

[13:16] <MasterDuke> (rr) p REPR(str)->name

[13:16] <MasterDuke> $40 = 0x7f9f74bb2731 "MVMString"

[13:16] <MasterDuke> (rr) p REPR(str.body.storage.strands[0])->name

[13:16] <MasterDuke> $42 = 0x7f9f74bb2731 "MVMString"

[13:19] <timo> OK

[13:20] <timo> but it's also changing from unrelated code, so perhaps the object got collected in the mean time and re-used or something?

[13:26] *** Kaiepi joined
[13:51] <MasterDuke> oh, maybe the string originally comes from nibbling the source code?

[13:52] <timo> oh, for some reason i thought we were talking about the return value of radix, but that isn't a string

[13:52] <timo> yeah i think we actually do have that, many strings being a reference into the source code they're compiled from. but only if they haven't gone through serialization

[13:59] <lizmat> fwiw, I discussed this the other day with samcv 

[14:00] <lizmat> substr will just index into a string, and thus keep the big string alive

[14:00] <lizmat> we discussed 2 ways of "separating" a substr from its source:

[14:00] <lizmat> nqp::flip(nqp::flip(str))

[14:00] <lizmat> and encode(decode())

[14:01] <lizmat> (or was it decode(encode())  :-)

[14:01] <jnthnwrthngtn> But nqp::indexingoptimized is probably the best bet?

[14:02] <lizmat> is that exposed?

[14:02] <jnthnwrthngtn> m: use nqp; say nqp::indexingoptimized('foo')

[14:02] <camelia> rakudo-moar 92c490ee4: OUTPUT: Â«fooâ¤Â»

[14:02] <lizmat> hmmm... even documented: https://github.com/Raku/nqp/blob/master/docs/ops.markdown#indexingoptimized

[14:03] <jnthnwrthngtn> I think it's a no-op in the situation that there's no strands

[14:03] <lizmat> still, not exposed at HLL level

[14:04] <lizmat> or otherwise used in the setting

[14:04] <MasterDuke> does .copy do it?

[14:04] <MasterDuke> *clone

[14:07] <Geth> Â¦ MoarVM: 592cc85489 | niner++ (committed using GitHub Web editor) | 44 files

[14:07] <Geth> Â¦ MoarVM: New disp nativecall (#1595)

[14:07] <Geth> Â¦ MoarVM: 

[14:07] <Geth> Â¦ MoarVM: With the new dispatch terminal, NativeCall will be able to benefit from the more efficient argument passing conventions. It will also benefit from dispatch programs tailored to the callsite, i.e. being able to replace more costly checks for containers with cheap guards.

[14:07] <Geth> Â¦ MoarVM: 

[14:07] <Geth> Â¦ MoarVM: Adds a new variant MVM_nativecall_dispatch which understands the new dispatcher argument passing convention to avoid allocating and populating an argument array for every call.

[14:07] <Geth> Â¦ MoarVM: 

[14:07] <Geth> Â¦ MoarVM: The dispatcher calling convention allows for unboxed values to get passed to a native function. Need to handle those in MVM_nativecall_dispatch instead of blindly assuming that we always get objects.

[14:07] <Geth> Â¦ MoarVM: <â¦commit message has 24 more linesâ¦>

[14:07] <Geth> Â¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/592cc85489

[14:08] *** linkable6 left
[14:08] <lizmat> nine: I guess I should also merge the NQP PR now, right?

[14:09] <MasterDuke> does it need a bump to go along with it?

[14:09] <lizmat> MasterDuke: am bumping atm

[14:10] *** linkable6 joined
[14:11] <lizmat> nqp builds and tests fine without it

[14:12] <timo> do we have any nativecall tests in nqp?

[14:12] <timo> i think we don't

[14:14] <lizmat> anyways, the Rakudo PR requires it, so I'll merge that now as well

[14:15] *** linkable6 left
[14:17] *** linkable6 joined
[14:22] *** linkable6 left
[14:24] *** frost left
[14:25] *** linkable6 joined
[14:27] <nine> yes, please :)

[14:30] <lizmat> testing  ...

[14:40] <lizmat> nine: all bumped now

[14:45] <lizmat> hmmm... so on strings:  nqp::clone(native str) is basically a noop, right ?

[14:46] <lizmat> because it will still refer to the same underlying static string?

[14:46] <jnthnwrthngtn> No, clone is an object op, so you'll be boxing it to a Str and then cloning the Str, which will indeed refer to the same underlying static string.

[14:46] <jnthnwrthngtn> So it's more of a wasteop :)

[14:46] <lizmat> indeed...  :-)

[14:47] <lizmat> ok, so if we would create a method clone(Str:D:) { nqp::indexingoptimized($!value) }

[14:47] <lizmat> that would sorta create the semantics that we would want to expose ?

[14:49] <jnthnwrthngtn> Ah, in detaching it from the original string it was substr'd from? Yes.

[14:49] <jnthnwrthngtn> Note there is a side-effect though

[14:49] <lizmat> ah?

[14:50] <jnthnwrthngtn> The compact representation of 'x' x 10000 relies on strands also, so you'd be exploding that into a flat string

[14:50] <jnthnwrthngtn> Probably not a big deal

[14:51] <lizmat> well, yeah...

[14:51] <jnthnwrthngtn> Especially as that optimization isn't part of the language spec, just something MoarVM does

[14:51] <lizmat> the thing is in the IRC log parsing, I currently slurp the whole file, and then start parsing from there

[14:52] <lizmat> this implies that all substrings taken from that (such as nick names, and messages) are substrings into that slurped string, and thus are keeping that alive

[14:52] <lizmat> I'm still not sure how much of an issue that is memory wise

[14:53] <MasterDuke> what if you make them natives? in my example above, making the variable a native str means it isn't a strand when it gets to MVM_radix

[14:53] <lizmat> but I do know that the whole slurped string will be stored with 4-byte ordinals because of the linefeeds in them

[14:54] <lizmat> however, most of the messages will be just ASCII, so could be stored as 1-byte ordinals

[14:54] <lizmat> which would save a lot of memory

[14:54] <lizmat> MasterDuke: native or not, would not make a difference at that level ?

[14:54] <MasterDuke> dunno

[14:54] <lizmat> a Str is just a class Str { has str $!value }

[14:55] <lizmat> aka just a wrapper around a native string

[14:55] <jnthnwrthngtn> Indeed, strands exist at the `str` level

[14:57] <MasterDuke> well, however it happens, in `use nqp; my $a = "123"; say nqp::radix(10, $a, 0, 0)[0]`, $a has a storage_type == MVM_STRING_STRAND. but if it's `my str $a <...>` the storage_type is not MVM_STRING_STRAND

[14:58] <lizmat> so nqp::radix is changing the type of its source ?

[14:58] <lizmat> that feels... unexpected ?

[14:59] <MasterDuke> radix isn't changing anything, i just mean when $a is passed into radix it's whichever type

[15:00] <lizmat> and what is nqp::getattr($a,Str,'$!value') ?

[15:02] <MasterDuke> don't know what you mean? MVM_radix doesn't know anything about $a, just that it was given an MVMString

[15:02] <nine> lizmat: I'd bet that all substrings of that large string will be in 4-byte representation as well. I don't think we go back implicitly from full unicode to ASCII as doing so requires a scan of the full string

[15:03] <lizmat> but an nqp::indexingoptimized(nqp::substr(...))  might ?

[15:04] <MasterDuke> no, it just copies whatever the bodies are composed of if they're all the same type, otherwise uses a grapheme iterator

[15:06] <lizmat> ok, so the only way to potentially go from 4byte to 1byte is to decode(encode()) ?

[15:06] <MasterDuke> oh wait, that iterator might actually do it

[15:07] <MasterDuke> yeah, if the resulting string can be 8bit the iterator converts everything to that

[15:08] <lizmat> but an nqp::indexingoptimized(nqp::substr(...))  would convert to 8bit when it can

[15:09] <MasterDuke> it looks like yes

[15:09] <lizmat> cool  :-)

[15:10] <lizmat> perhaps a Str.substr( :$clone!) candidate would be in order ?

[15:10] <jnthnwrthngtn> Maybe :detach ?

[15:10] <MasterDuke> or :isolate?

[15:10] <lizmat> sure, works for me  :-)

[15:11] <lizmat> :detach feels more natural to me, fwiw

[15:11] <jnthnwrthngtn> That it's achieved under the hood by cloning is an impl detail (and one we might some day choose to avoid by exposing a detach version right away)

[15:11] <lizmat> it described the action

[15:11] * lizmat will do a PR

[15:11] <jnthnwrthngtn> :detached also works because it describes the goal

[15:13] <MasterDuke> :clipped, :snipped, :cut-out, :exiled, :ostracized

[15:13] <lizmat> yeah, but you don't know whether it did that>

[15:13] <lizmat> ?

[15:13] <MasterDuke> :excised

[15:13] <lizmat> so feels to me that :detach describes intent

[15:13] <lizmat> not guarantee the result

[15:15] <MasterDuke> :sanctified

[15:15] <MasterDuke> lots of options for this concept

[15:15] <jnthnwrthngtn> Bless that sanctified little string

[15:16] <lizmat> meh

[15:16] <jnthnwrthngtn> .oO( @bikeshedders>>.exile )

[15:17] *** dogbert17 left
[15:20] <MasterDuke> huh. my initial experiment seemed to show that trying strtoll was a pretty big speedup, but now i'm not seeing it...

[15:21] <lizmat> ok, lots of Str.substr candidates...  will contemplate on right cause of action there

[15:26] *** dogbert17 joined
[15:33] *** ggoebel left
[15:34] <MasterDuke> if i up the number of iterations i'm benchmarking i start to see a speedup, but not sure it's worth the complexity

[15:35] <MasterDuke> no, nevermind, it's actually a slight slowdown

[15:36] *** squashable6 joined
[15:37] <[Coke]> :(

[15:41] <MasterDuke> maybe my earlier benchmarking was flawed (but i thought i was checking the right branches were being taken)

[15:42] <MasterDuke> maybe the cost of MVM_radix is really all in the overhead of allocating the array for the results

[15:46] *** Kaiepi left
[15:47] *** Kaiepi joined
[15:50] <lizmat> yeah, I mean the algo is pretty simple :-)

[15:56] <MasterDuke> ah, looks like my change makes it faster for longer strings. 4 chars is slower, but by 10 chars it's slightly faster

[15:56] <lizmat> I'd say radix is generally used on smaller numbers, aka smaller strings ?

[16:00] *** patrickb joined
[16:01] <MasterDuke> well, MVM_radix is limited anyway depending on the base, since it stores the result in an MVMint64

[16:08] <lizmat> well, yes... because it only knows about natives anyway ?

[16:08] <MasterDuke> MVM_bigint_radix is the arbitrary size version

[16:17] <lizmat> exposed as nqp::radix_I right ?

[16:17] <MasterDuke> yep

[16:20] <MasterDuke> interesting. radix_I is marked :pure, but radix isn't

[16:21] <MasterDuke> jnthnwrthngtn: think https://github.com/MoarVM/MoarVM/commit/ed9db7251d18d15bbf645e0a8b6cdb2654a32ece#diff-333e2b08027d476e7933a7c640cdd8840b28b352600e56742d3a2b5ab6845cacL277 was just an oversight?

[16:25] *** rypervenche left
[16:32] *** rypervenche joined
[16:51] <Geth> Â¦ MoarVM: MasterDuke17++ created pull request #1605: Mark nqp::radix as :pure

[16:51] <Geth> Â¦ MoarVM: review: https://github.com/MoarVM/MoarVM/pull/1605

[18:01] <japhb> Mentioning here because it's likely to be NativeCall related: https://github.com/jonathanstowe/Crypt-SodiumPasswordHash/issues/2

[18:02] <japhb> (Last commit in that repo appears to be from March)

[18:02] *** reportable6 left
[18:19] <jnthnwrthngtn> MasterDuke: hm, is that link meant to go to nfarunalt?

[18:20] <jnthnwrthngtn> Probably radix on the next line. I think radix is pure

[18:20] <jnthnwrthngtn> Yeah, it totally has to be

[18:20] <MasterDuke> yeah, see https://github.com/MoarVM/MoarVM/pull/1605

[18:20] <jnthnwrthngtn> Because all its inputs are immutable native values :)

[18:21] <Geth> Â¦ MoarVM: 9d5bcfc5d5 | (Daniel Green)++ | 2 files

[18:21] <Geth> Â¦ MoarVM: Mark nqp::radix as :pure

[18:21] <Geth> Â¦ MoarVM: 

[18:21] <Geth> Â¦ MoarVM: I suspect this was just overlooked in

[18:21] <Geth> Â¦ MoarVM: ed9db7251d18d15bbf645e0a8b6cdb2654a32ece (where nqp::radix_I *was* marked

[18:21] <Geth> Â¦ MoarVM: :pure).

[18:21] <Geth> Â¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/9d5bcfc5d5

[18:21] <Geth> Â¦ MoarVM: c779c6320a | (Jonathan Worthington)++ (committed using GitHub Web editor) | 2 files

[18:21] <Geth> Â¦ MoarVM: Merge pull request #1605 from MasterDuke17/mark_radix_as_pure_like_radix_I

[18:21] <Geth> Â¦ MoarVM: 

[18:21] <Geth> Â¦ MoarVM: Mark nqp::radix as :pure

[18:21] <Geth> Â¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/c779c6320a

[19:03] *** reportable6 joined
[19:49] <timo> .o( wonder if more-pea will be a rough rebase )

[19:50] <MasterDuke> ugh, reminds me i need to rebase remove-spesh-opt-if-too-many-deopts

[20:13] <lizmat> nine: in case you missed this on #raku / #raku-dev, but it looks like ip5xs went from 1.41 to 1.14 , and from 14.99 to 6.24 for ip5xs-20

[20:33] <[Coke]> ... heh. Was coming here to say that. :)

[20:38] <[Coke]> added another bug

[21:14] <lizmat> hmmm.... it looks like the nativecall merge broke my Ecosystem::Archive update functionality

[21:14] <lizmat> starts eating memory pretty fast without recovering

[21:15] <lizmat> too tired to look at it now... will do so tomorrow

[21:15] <lizmat> afk&

[21:28] <sena_kun> hmm, it seems the new nativecall introduced some regressions

[21:34] <nine> lizmat: Ecosystem::Archive's run-tests script reports ALL OK here

[21:35] <nine> sena_kun: if you mean the Blin output, at least the Inline::Perl5 version used there is outdated. 0.57 is out and works

[21:38] <sena_kun> nine, yup, but there are plenty of other modules failing bisecting to this other than Inline::Perl5. :S

[21:38] <jnthnwrthngtn> A few distinct failure modes too, by the looks of it

[21:39] <sena_kun> don't want to be the one who brings in bad news, but on the bright side breaking things means we are moving somewhere.

[21:39] <sena_kun> https://github.com/rakudo/rakudo/issues/4643

[21:39] * sena_kun sleep&

[21:39] <jnthnwrthngtn> sena_kun++ # blin run

[21:40] <nine> Well, that's what we have blin for :) Will start debugging those tomorrow

[21:40] <jnthnwrthngtn> Indeed, I'd have been surprised if a change of this magnitude didn't lead to blin finding something :)

[21:41] <sena_kun> nine, good luck, thanks for your continuous contribution.

[21:41] <nine> thanks

[22:58] *** vrurg_ joined
[23:01] *** vrurg left
[23:05] <lizmat> nine: the test script so far only tests if the module compiles

[23:28] *** vrurg_ left
[23:28] *** vrurg joined
