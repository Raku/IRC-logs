[02:15] *** MasterDuke left
[03:20] *** leont left
[04:20] *** linkable6 left
[04:20] *** evalable6 left
[04:21] *** evalable6 joined
[04:22] *** linkable6 joined
[05:37] *** japhb joined
[07:46] *** MasterDuke joined
[07:55] *** domidumont joined
[08:53] *** leont joined
[08:58] *** zakharyas joined
[09:18] *** sena_kun left
[09:27] *** sena_kun joined
[10:22] <dogbert11> nine: would you like to test something wrt Tux CSV module, time permitting?

[10:25] <dogbert11> it's simple, clone https://github.com/Tux/CSV.git, cd to the repo dir and run the included tests. I'm wondering if one of them hangs for you?

[10:25] <lizmat> dogbert11: should this be on HEAD or on a MoarVM branch ?

[10:26] <dogbert11> HEAD

[10:26] <dogbert11> specifically this test: t/78_fragment.t

[10:27] <lizmat> yup, that hangs for me

[10:27] <lizmat> now, how did Blin miss that ?

[10:28] <dogbert11> good question

[10:30] <dogbert11> it seems to spend all its time in VMArray_gc_mark

[10:33] *** MasterDuke left
[10:34] <lizmat> yeah, and growing at about 10MB / sec on my machine

[10:34] *** MasterDuke joined
[10:34] * lizmat presses ctrl-x at the 8GB mark

[10:35] *** zakharyas left
[10:36] <lizmat> $csv.colrange ([1, 4..6, 8..Inf]);   # there seems to be an infinite range involved

[10:36] <lizmat> dogbert11: could you make a rakudo issue for that

[10:38] <lizmat> dogbert11: golfed to : dd (1..10).map(~*)[1,4..6,8..Inf]

[10:38] <lizmat> nothing to do with CSV at all

[10:43] <lizmat> dogbert: further golf: (1..10)[1,^Inf]

[10:53] <dogbert11> I can fix the issue

[10:55] <dogbert11> i.e. I can make a Rakudo issue :-)

[10:56] <lizmat> yes, please

[10:58] <dogbert11> R#4216

[10:59] *** linkable6 left
[10:59] <dogbert11> haha

[11:00] *** linkable6 joined
[11:01] *** linkable6 left
[11:04] *** linkable6 joined
[11:05] <sena_kun> ouch

[11:06] <sena_kun> The module is Text::CSV, right?

[11:09] <sena_kun> Right. Interesting.

[11:11] <lizmat> yeah, but it is not a module issue

[11:13] <sena_kun> Blin says it fails on both points, and as we have lots of broken modules in eco I cannot check all 300+ of them each time. Now I suspect it might be the culprit for the Blin slowdown I investigated. I'll release a point.

[11:13] <lizmat> sena_kun: it has not been fixed yet, just identified

[11:13] <sena_kun> lizmat, well, yes, "release a point after its fixed and checked". :)

[11:14] <lizmat> ok, *phew*  no pressure  :-)

[11:17] <jnthn> Regression in Rakudo, or in Moar, or?

[11:18] <MasterDuke> rakudo

[11:18] <sena_kun> Regression in Rakudo.

[11:19] <jnthn> Ah, OK. I saw the note about gc_mark in VMArray and was thinking, how on earth could that get broken...

[11:19] <jnthn> Guess it's just a regression that leads to a lot of marking

[11:20] <lizmat> yeah... it's just stupidly applying non-lazy semantics on a lazy iterator

[11:20] <lizmat> which I broke  :-(

[11:21] <lizmat> but first I need to get this week's RWN out of my system :-)

[11:22] *** zakharyas joined
[11:27] <sena_kun> Also, another simple thing how we missed that: this tiny gist is not in roast.

[11:27] <lizmat> yeah  :-(

[11:43] <MasterDuke> anyone have a suggestion for a better way to debug https://github.com/MoarVM/MoarVM/issues/1434 ? the backtrace doesn't seem to make sense, i think because it's running a test, so there is forking and threading involved. i haven't gotten it to hit under valgrind, and the various gdb options to follow forks and such haven't worked

[11:44] <MasterDuke> i think i tried asan and tsan, no help

[12:02] *** zakharyas left
[12:03] <lizmat> just an ideaI just had: would it be possible obtain the amount of CPU used by execution of a block (I'm specifically thinking of a start block, but more general would be nice)

[12:03] <lizmat> or from one point in time to another point in time *in that thread*

[12:04] <lizmat> I know it's possible to get totals, but that would be useless to find out how much e.g. a batch in a hyper was taking to allow for automatic batch-size adjustments

[12:33] <MasterDuke> it looks like `getrusage` has a `WHO` parameter which can be set to `RUSAGE_THREAD`, but `uv_getrusage` just always calls it with `RUSAGE_SELF`

[12:34] <lizmat> ooohhh....  :-)

[12:35] <lizmat> how about adding a :thread to nqp::getrusage ?   :-)

[12:46] <MasterDuke> the problem is that nqp::getrusage uses uv_getrusage, so we'd have to patch it to accept a who parameter

[12:49] <MasterDuke> https://github.com/libuv/libuv/blob/c9406ba0e3d67907c1973a71968b89a6bd83c63c/src/unix/core.c#L969-L972

[12:57] <dogbert11> MasterDuke: is this better? https://gist.github.com/dogbert17/abb37bd9152fb9f5f45cb020d9896acf

[13:06] <lizmat> a different nqp op would also work for me  :-)

[13:13] <MasterDuke> dogbert11: huh. wonder if it's not safe to free the string passed to MVM_spesh_debug_printf without an MVM_spesh_debug_flush first?

[13:24] <MasterDuke> dogbert11: how easily can you repro it?

[13:28] <MasterDuke> lizmat: the unix implementation of uv_getrusage is pretty simple, it would be easy to copy it and add a parameter (or just make a hard-coded thread version). the windows version is a little bigger, and someone who actually knows windows would have to weigh in on whether the information is available per-thread (i would assume so, but have no idea).

[13:28] <MasterDuke> however, the bigger questions is whether the rakudo idea of a thread would match what `getrusage(RUSAGE_THREAD)` would return? don't rakudo threads move around libuv threads? but maybe they don't move within a block so you could do something at the start and end of a block and it would work out?

[13:29] <lizmat> well, as long as the block does not do an  (implicit) await, it is sure to stay on the same OS thread afaik

[13:29] <lizmat> jnthn ^^  ??

[13:32] <nine> A task won't get moved onto a different block in the middle of the execution. It's certainly so now and I'd guess that it's safe to rely on that

[13:32] <nine> It just wouldn't make sense to move an executing task

[13:32] <nine> s/different block/different thread/

[13:32] <lizmat> it might if it is doing an await!

[13:32] <nine> true

[13:48] *** cog__ left
[13:56] *** zakharyas joined
[14:03] <dogbert11> MasterDuke: relatively easily

[14:04] <MasterDuke> mind trying out a patch if i create one?

[14:09] *** cog joined
[15:02] <dogbert11> surw, no problem

[15:02] <dogbert11> *sure

[15:15] <MasterDuke> dogbert11: https://gist.github.com/MasterDuke17/1e160b6d169a1a0fc9b20fc3c8703932

[15:24] <MasterDuke> well, as long as i don't try to catch it in gdb/valgrind/etc it repros pretty easily, and no, the above patch does not fix it

[15:37] <lizmat> and another Rakudo Weekly hits the Net: https://rakudoweekly.blog/2021/02/22/2021-08-first-21/

[15:38] <lizmat> afk for a few hours&

[16:11] <MasterDuke> interesting, it's much more reproducible with --full-cleanup

[16:18] <MasterDuke> jnthn, nine: does https://github.com/MoarVM/MoarVM/issues/1434#issuecomment-783487192 point out anything obvious to you?

[16:37] *** MasterDuke left
[17:45] *** domidumont left
[17:51] *** domidumont joined
[18:01] *** domidumont left
[19:12] *** zakharyas left
[19:42] <Geth> ¦ MoarVM: salortiz++ created pull request #1439: VMArray: Use dest for select 'kind' in copy_elements

[19:42] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/pull/1439

[19:48] *** MasterDuke joined
[20:08] *** linkable6 left
[20:09] *** linkable6 joined
[20:20] <MasterDuke> samcv: is https://github.com/apankrat/notes/blob/master/fast-case-conversion/README.md#unicode applicable for moarvm?

[21:08] <nine> This gets infix:<eq> inlined into the loop body: MVM_SPESH_BLOCKING=1 ./rakudo-m -Ilib -e '          my $a = "foo"; my $b = "bar"; for ^10000 { my $c; $c := $a eq $b }'

[21:08] <nine> This doesnt:                                     MVM_SPESH_BLOCKING=1 ./rakudo-m -Ilib -e 'use Test; my $a = "foo"; my $b = "bar"; for ^10000 { my $c; $c := $a eq $b }'

[21:09] <nine> In the latter case it looks like spesh cannot identify the target static frame of the call and thus bails out of inlining without even bothering to mention it in the inline log

[21:11] <MasterDuke> is it just Test, or using any module?

[21:14] <nine> any module

[21:15] <MasterDuke> huh, seems a little less than ideal

[21:19] <jnthn> That's a bit odd.

[21:19] <nine> Because MVM_multi_cache_find_spesh can't find a candidate

[21:19] <jnthn> That it doesn't know the target, I mean

[21:19] <nine> Ordinarily I'd think that running more code will warm up those caches some more. But not that it drains them

[21:19] <jnthn> If it doesn't know the target then inlining isn't even a question

[21:20] <jnthn> No, the multi dispatch cache should get populated on first call

[21:20] <jnthn> Does it have the types of A and B figured out?

[21:20] <jnthn> uh, $a and $b

[21:22] <nine>       r3(4): usages=1, deopt=2,1, flags=9     KnTyp Concr (type: Scalar)

[21:22] <nine>       r4(4): usages=1, deopt=2, flags=9     KnTyp Concr (type: Scalar)

[21:27] <nine> MVM_multi_cache_find_spesh bails out because arg 0 doesn't have MVM_SPESH_FACT_KNOWN_DECONT_TYPE

[22:00] <nine> The last time we get any info about statistics on infix:<eq> is during module loading. Later on the log doesn't have anything on it anymore

[22:09] <MasterDuke> is that a consequence of MVM_SPESH_BLOCKING? are the results (sometimes) different without?

[22:10] <cog> Hi, what a Spesh slot and an effective Spesh slot ?

[22:15] <MasterDuke> my understanding is that spesh slots are a place to store data that's useful for a spesh candidate (i.e., an optimized version of code). when a frame is invoked, if it has a spesh candidate, it's spesh slots are copied into the effective spesh slots of the frame

[22:17] <cog> It is a Collectable so that means it can be anything ?

[22:17] <cog> ... collectable

[22:18] <MasterDuke> yeah

[22:19] <nine> yes

[22:19] <nine> It's a value that is constant for the spesh candidate.

[22:20] <cog> So a given candidate knows what it is ?

[22:23] <MasterDuke> yep https://github.com/MoarVM/MoarVM/blob/master/src/6model/reprs/MVMSpeshCandidate.h#L22-L23

