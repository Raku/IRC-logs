[00:02] *** reportable6 left
[00:05] *** reportable6 joined
[00:15] <timo> hum, we can't write to multiple registers from a single dispatch, right? callsites don't really have a concept of RW for registers

[00:37] <timo> bootarray, create, const_i64_16, setelemspos, const_i64_16, setelemspos, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o,

[00:37] <timo> getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode,

[00:37] <timo> push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o, getcode, push_o

[00:38] <timo> could totally become one syscall

[00:40] <timo> whats the max number of params to a dispatch_* i wonder

[01:00] <Geth> Â¦ MoarVM/new-special-return: f1edb2ba90 | (Jonathan Worthington)++ | 2 files

[01:00] <Geth> Â¦ MoarVM/new-special-return: Eliminate remove_one_frame

[01:00] <Geth> Â¦ MoarVM/new-special-return: 

[01:00] <Geth> Â¦ MoarVM/new-special-return: We can move all of the logic into MVM_callstack_unwind_frame, which

[01:00] <Geth> Â¦ MoarVM/new-special-return: works out rather more efficient. At least some compilers need a hint

[01:00] <Geth> Â¦ MoarVM/new-special-return: that it's OK to inline exit_frame still. Before the this the average

[01:00] <Geth> Â¦ MoarVM/new-special-return: call to remove_one_frame entailed 118 instructions (including those of

[01:00] <Geth> Â¦ MoarVM/new-special-return: the called MVM_callstack_unwind_frame). Now just 92 instructions are

[01:00] <Geth> Â¦ MoarVM/new-special-return: retired in MVM_callstack_unwind_frame.

[01:00] <Geth> Â¦ MoarVM/new-special-return: review: https://github.com/MoarVM/MoarVM/commit/f1edb2ba90

[01:01] <jnthnwrthngtn> timo: Limited by max callsite size

[01:01] <jnthnwrthngtn> Which is a 16-bit number of args

[01:05] <timo> perfect

[01:05] <timo> how do you feel about making that relatively common series of ops a syscall?

[01:05] <timo> well, it comes once per compunit i guess

[01:06] <timo> oh, there's no "coderef" callsite flag

[01:13] <jnthnwrthngtn> Could be quite beneficial

[01:13] <jnthnwrthngtn> Saves a hell of a lot of loops around the interpreter at least

[01:13] <jnthnwrthngtn> Sleep time for me, 'night

[01:17] <timo> also, it's code that only runs a single time, so here the "write it in C to go fast" approach actually makes sense for once

[02:58] *** Altai-man joined
[02:59] *** sena_kun left
[05:04] *** sourceable6 left
[05:04] *** committable6 left
[05:04] *** releasable6 left
[05:04] *** benchable6 left
[05:04] *** linkable6 left
[05:04] *** unicodable6 left
[05:04] *** notable6 left
[05:04] *** squashable6 left
[05:04] *** quotable6 left
[05:04] *** nativecallable6 left
[05:04] *** greppable6 left
[05:04] *** bisectable6 left
[05:04] *** statisfiable6 left
[05:04] *** evalable6 left
[05:04] *** tellable6 left
[05:04] *** reportable6 left
[05:04] *** bloatable6 left
[05:04] *** coverable6 left
[05:04] *** shareable6 left
[05:04] *** linkable6 joined
[05:04] *** nativecallable6 joined
[05:05] *** statisfiable6 joined
[05:05] *** greppable6 joined
[05:05] *** tellable6 joined
[05:05] *** squashable6 joined
[05:05] *** committable6 joined
[05:05] *** evalable6 joined
[05:06] *** coverable6 joined
[05:06] *** shareable6 joined
[05:06] *** bloatable6 joined
[05:07] *** sourceable6 joined
[06:04] *** benchable6 joined
[06:05] *** quotable6 joined
[06:05] *** reportable6 joined
[06:06] *** unicodable6 joined
[06:56] <Nicholas> good *, #moarvm 

[06:56] <Nicholas> nine: I think currently I'd view myself as "stuck".

[06:56] <Nicholas> Report is:

[06:57] <Nicholas> on master (strictly, the parent of the merge, so that it's the last master commit before new-disp-nativecall)

[06:58] <Nicholas> in MVM_nativecall_invoke, the memory at the pointer in the assignment `MVMNativeCallBody *body = MVM_nativecall_get_nc_body(tc, site);`

[06:58] <Nicholas> comes directly from MVM_nativecall_build

[07:00] <Nicholas> whereas in the first commit of new-disp-nativecall, b7d40359a1503dda41e8592297d305ea7b1f2ba5, that memory has been (incompletely) copied by copy_to in src/6model/reprs/NativeCall.c

[07:01] <Nicholas> and I don't spot a clean way to fix copy_to to work with both layouts. Or really, *what* needs copying, and how. (But I guess I figure that out by looking to see what gets freed when you deallocate a NativeCall thingy.)

[07:02] <Nicholas> aha, code with #ifdef HAVE_LIBFFI

[07:02] <Nicholas> (anyway, need to to somethign else first)

[07:05] *** notable6 joined
[07:06] *** bisectable6 joined
[07:06] *** releasable6 joined
[08:06] *** evalable6 left
[08:06] *** linkable6 left
[08:07] *** evalable6 joined
[08:08] *** linkable6 joined
[08:47] *** childlikempress joined
[08:47] *** Kaipi joined
[08:47] *** moon-child left
[08:50] *** Kaiepi left
[08:58] *** Kaipi left
[08:58] *** Kaiepi joined
[09:00] *** childlikempress is now known as moon-child

[09:22] *** Kaiepi left
[09:22] *** Kaiepi joined
[09:33] *** linkable6 left
[09:37] <nine> Oh what I would give to have 15-gh_1202.t finally stable...

[09:42] <Nicholas> how many hours do you have to give? :-/

[09:48] <nine> Quite a few looking at the time I've already spent fixing bugs. Trouble is that I don't know how to approach this as of course, I cannot reproduce the issues locally.

[10:03] <timo> have we tried running rr on the CI? in theory we could record every test we run with not a that big penalty, and if tests fail we keep the recording otherwise we delete it right away?

[10:34] *** evalable6 left
[10:36] *** linkable6 joined
[10:36] *** evalable6 joined
[10:37] <lizmat> hmmm... 3rd time this week that t/spec/S17-promise/nonblocking-await.t hangs for me  :-(

[10:47] <nine> Actually I can reproduce those segfaults by running the test in 16 shells in parallel!

[10:47] <nine> #0  find_interned_callsite (tc=0x7f42500cc350, cs_ptr=0x7f425e892038, steal=0) at src/core/callsite.c:194

[10:47] <nine> 194             if (callsites_equal(tc, interns->by_arity[num_flags][i], cs, num_flags, num_nameds)) {

[10:49] <jnthnwrthngtn> moarning o/

[10:50] <Nicholas> \o

[10:52] <lizmat> o/.all

[11:01] <nine> Of course I've yet to reproduce it in rr

[11:01] <nine> But at least I've got several core dumps that all point at the above location. So a bit of source code reading may raise an issue

[11:09] <Geth> Â¦ MoarVM/new-special-return: 05b3468567 | (Jonathan Worthington)++ | 2 files

[11:09] <Geth> Â¦ MoarVM/new-special-return: Eliminate remove_one_frame

[11:09] <Geth> Â¦ MoarVM/new-special-return: 

[11:09] <Geth> Â¦ MoarVM/new-special-return: We can move all of the logic into MVM_callstack_unwind_frame, which

[11:09] <Geth> Â¦ MoarVM/new-special-return: works out rather more efficient. At least some compilers need a hint

[11:09] <Geth> Â¦ MoarVM/new-special-return: that it's OK to inline exit_frame still. Before the this the average

[11:09] <Geth> Â¦ MoarVM/new-special-return: call to remove_one_frame entailed 118 instructions (including those of

[11:09] <Geth> Â¦ MoarVM/new-special-return: the called MVM_callstack_unwind_frame). Now just 92 instructions are

[11:09] <Geth> Â¦ MoarVM/new-special-return: retired in MVM_callstack_unwind_frame.

[11:09] <Geth> Â¦ MoarVM/new-special-return: review: https://github.com/MoarVM/MoarVM/commit/05b3468567

[11:13] <jnthnwrthngtn> nine: I think we need to read interns->num_by_arity[num_flags] and interns->by_arity[num_flags] once each before the loop

[11:14] <jnthnwrthngtn> Since those can change during it.

[11:16] <jnthnwrthngtn> I've pushed all I'm going to to new-special-return now (well, except changes in response to feedback).

[11:16] <jnthnwrthngtn> Figured I may as well take the changes to their logical conclusion, since "why didn't you just go the final step and..." would have been an obvious review comment :)

[11:16] <timo> jnthnwrthngtn: do you have a suggestion for how to handle that callsites don't have a flag for "coderef" for the proposed "collect-coderefs-into-array" or whatever syscall?

[11:17] <timo> the validator wouldn't be able to verify unless it special-cases the op, or if there's a flag for syscalls "only"

[11:20] <timo> it could use integers as indices into the codes table or something

[11:22] <jnthnwrthngtn> Hm, it's not actually such a good saving really because arguments always have to go into registers

[11:22] <jnthnwrthngtn> Even literal ones

[11:24] <timo> ah, so we'd be blowing up the number of locals

[11:24] <timo> and get a const_i64_16 for every coderef anyway

[11:24] <jnthnwrthngtn> Yeah. There must be some better way to do this though...

[11:24] <timo> .o( parallelize getcode )

[11:25] <timo> wval an integer array that has the numbers in it is one way

[11:29] <Geth> Â¦ MoarVM/fix-intern-lookup: 08d41d5e39 | (Jonathan Worthington)++ | src/core/callsite.c

[11:29] <Geth> Â¦ MoarVM/fix-intern-lookup: Avoid thread safety issues in intern lookups

[11:29] <Geth> Â¦ MoarVM/fix-intern-lookup: 

[11:29] <Geth> Â¦ MoarVM/fix-intern-lookup: The number of callsites and the pointer to the callsites memory may

[11:29] <Geth> Â¦ MoarVM/fix-intern-lookup: change. We carefully update these with a write barrier when doing the

[11:29] <Geth> Â¦ MoarVM/fix-intern-lookup: change, however the reading code also needs to take care to do that.

[11:29] <Geth> Â¦ MoarVM/fix-intern-lookup: review: https://github.com/MoarVM/MoarVM/commit/08d41d5e39

[11:29] <Geth> Â¦ MoarVM: jnthn++ created pull request #1591: Avoid thread safety issues in intern lookups

[11:29] <Geth> Â¦ MoarVM: review: https://github.com/MoarVM/MoarVM/pull/1591

[11:29] <jnthnwrthngtn> timo: Yeah, that (wval approach) may be bset

[11:30] <timo> can't see what's what from a spesh dump or moar --dump any more

[11:30] <jnthnwrthngtn> nine: ^^ may well help with the segv you posted above

[11:31] <nine> jnthnwrthngtn: I hope so. I did basically the same but without the barrier and can still reproduce the issue

[11:35] <jnthnwrthngtn> Ah, darn.

[11:36] <jnthnwrthngtn> Maybe the barrier matters, though

[11:36] <nine> Another segfault. Different location though:

[11:36] <nine> #0  0x00007f29fa514ef2 in MVM_disp_program_run (tc=0x7f29e40fe180, dp=0x7f29e40cf390, record=0x7f29d8064b78, spesh_cid=0, bytecode_offset=4294967295, dp_index=5) at src/disp/program.c:2944

[11:36] <nine> bt2944                  if (STABLE(val.o) != (MVMSTable *)dp->gc_constants[op.arg_guard.checkee])

[11:37] <nine> val.o is NULL

[11:37] <jnthnwrthngtn> We should never end up with real NULLs being read out of registers (and thus arguments)

[11:37] <nine> And another one in find_interned_callsite: (gdb) p arity_callsites[0]

[11:37] <nine> Cannot access memory at address 0xac0afec0

[11:39] <jnthnwrthngtn> Oh, hm.

[11:39] <timo> someone snuck a cafe in there

[11:40] <jnthnwrthngtn> OK, no idea

[11:40] <jnthnwrthngtn> It'd doing realloc_at_safepoint precisely to avoid any issues

[11:40] <nine> I noticed

[11:42] <nine> It gets weirder. With this particular segfault I don't even see any other threads dabbling in callsite code at the time of the segfault

[11:45] <Geth> Â¦ MoarVM: 14a8befd1c | (Stefan Seifert)++ | 3 files

[11:45] <Geth> Â¦ MoarVM: Eliminate hllbool/boot-boolify-boxed-int pairs in spesh

[11:45] <Geth> Â¦ MoarVM: 

[11:45] <Geth> Â¦ MoarVM: No need to turn an int into an HLL bool just to turn it back to an int when

[11:45] <Geth> Â¦ MoarVM: using it as a condition for jumps. Eliminate those pairs same as we do with

[11:45] <Geth> Â¦ MoarVM: box/unbox.

[11:45] <Geth> Â¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/14a8befd1c

[11:45] <Geth> Â¦ MoarVM: 6ff8155769 | (Jonathan Worthington)++ (committed using GitHub Web editor) | 3 files

[11:45] <Geth> Â¦ MoarVM: Merge pull request #1586 from MoarVM/optimize_hllbool_boolify_pairs

[11:45] <Geth> Â¦ MoarVM: 

[11:45] <Geth> Â¦ MoarVM: Eliminate hllbool/boot-boolify-boxed-int pairs in spesh

[11:45] <Geth> Â¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/6ff8155769

[11:55] *** sena_kun joined
[11:59] <nine> The pointer to the by_arity that's involved in the segfault does look different to the others:

[11:59] <nine> (gdb) p (MVMCallsite**[20])*(interns->by_arity)

[11:59] <nine> $33 = {0x15f958c, 0x15f95d4, 0x48ba864, 0x7f76ac0afec0, 0x35e05a0, 0x4127490, 0x3696fe0, 0x4a20c40, 0x15f99c4, 0x3db950c, 0x0, 0x3db9e0c, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0}

[11:59] <nine> It's the 0x7f76ac0afec0

[12:00] <timo> do you still have the list of memory maps?

[12:00] <nine> Oh...arity_callsites is 0xac0afec0

[12:00] <nine> Notice that they are not that different at all?

[12:01] <timo> some come from our rodata

[12:02] *** reportable6 left
[12:02] <lizmat> nine: 14a8befd1c feels as a reason to bump MoarVM

[12:02] <lizmat> agree?

[12:03] <nine> lizmat: yes, could make bisection easier in case it causes troubles

[12:04] <jnthnwrthngtn> I don't think there was a bump since 770e82e484 and it's also good to get that in and exercised separately to the special returns stuff also

[12:05] *** linkable6 left
[12:05] *** reportable6 joined
[12:05] <nine> "(gdb) maintenance info sections" shows the pointer is between:

[12:05] <nine>  [27]      0x7f76ac000000->0x7f76ac0b1000 at 0x036d3000: load7 ALLOC LOAD HAS_CONTENTS

[12:05] <nine>  [28]      0x7f76ac0b1000->0x7f76b0000000 at 0x03784000: load8 ALLOC READONLY

[12:06] *** linkable6 joined
[12:08] <nine> A different segfault shows the same weird pointer difference:

[12:08] <nine> (gdb) p interns->by_arity[5]

[12:08] <nine> $5 = (MVMCallsite **) 0x7fcb7c206210

[12:08] <nine> (gdb) p arity_callsites 

[12:08] <nine> $6 = (MVMCallsite **) 0x7c206210

[12:22] <gfldex> m: my $a = 42; say $a.not-there(); CATCH { when X::Method::NotFound { .resume } }

[12:22] <camelia> rakudo-moar ce0d31fb9: OUTPUT: Â«Already set resume init args for this dispatcherâ¤  in block <unit> at <tmp> line 1â¤â¤Â»

[12:22] <gfldex> jnthnwrthngtn: ^^^ this seams to be a regression (of sorts)

[12:42] <jnthnwrthngtn> I assume it previously indicated that the exception was not resumable?

[12:42] <lizmat> yes

[12:42] <lizmat> actually, no

[12:43] <lizmat> committable6 2021.04 my $a = 42; say $a.not-there(); CATCH { when X::Method::NotFound { .resume } }

[12:43] <lizmat> committable6: 2021.04 my $a = 42; say $a.not-there(); CATCH { when X::Method::NotFound { .resume } }

[12:43] <committable6> lizmat, Â¦2021.04: Â«Method 'not-there' not found for invocant of class 'Int'â¤  in block <unit> at /tmp/Jeekr0Y10o line 1â¤â¤ Â«exit code = 1Â»Â»

[12:43] <jnthnwrthngtn> Heh, as if the resume was ignored :)

[12:43] <lizmat> yup

[12:43] <lizmat> committable6: 2021.04 my $a = 42; say $a.not-there(); CATCH { }

[12:43] <committable6> lizmat, Â¦2021.04: Â«No such method 'not-there' for invocant of type 'Int'â¤  in block <unit> at /tmp/Nk3H4nJWD0 line 1â¤â¤ Â«exit code = 1Â»Â»

[12:45] <jnthnwrthngtn> Perhaps we need an X::NonResumable role with a method resume that dies, and to apply it to various things (probably including X::Comp).

[12:46] <jnthnwrthngtn> In theory we may be able to actually make method not found resumable now, but I'm not sure we should.

[12:50] <lizmat> why not?  have it return Nil as if .?method ?

[12:52] <jnthnwrthngtn> Feel free to try and implement it, if you think it's worth it.

[12:54] <jnthnwrthngtn> I suspect the typical consequence of resuming will be that the code that did the method call won't handle the situation too.

[12:56] <lizmat> hmmm..   well, if you have the CATCH in place to resume it, then you're sorta expecting it?

[12:56] <lizmat> I mean, there is overhead involved with .?method, right

[12:56] <lizmat> it would be a way to not have that overhead in the cases where it has the method?

[12:56] <jnthnwrthngtn> The overhead of .?method is going to be vastly lower than going through the exception system.

[12:57] <lizmat> but the overhead of .?method would be for every call, even the successful ones, no?

[12:58] <jnthnwrthngtn> m: class C { method m() { } }; for ^10_000_000 { C.m }; say now - INIT now

[12:58] <camelia> rakudo-moar ce0d31fb9: OUTPUT: Â«0.068384721â¤Â»

[12:58] <jnthnwrthngtn> m: class C { method m() { } }; for ^10_000_000 { C.?m }; say now - INIT now

[12:58] <camelia> rakudo-moar ce0d31fb9: OUTPUT: Â«0.060300922â¤Â»

[12:58] * nine will always use .? from now on instead of .

[12:58] <jnthnwrthngtn> heh, too small :)

[12:58] <jnthnwrthngtn> lol

[12:58] <jnthnwrthngtn> Anyway, I think that in the case the method exists on the type then . and .? result in the same dispatch program :)

[12:59] <lizmat> ok, in that case, colour me convinced :-)

[12:59] <jnthnwrthngtn> m: class C { method m() { } }; for ^100_000_000 { C.m }; say now - INIT now

[12:59] <camelia> rakudo-moar ce0d31fb9: OUTPUT: Â«0.618730025â¤Â»

[12:59] <jnthnwrthngtn> m: class C { method m() { } }; for ^100_000_000 { C.?m }; say now - INIT now

[12:59] <camelia> rakudo-moar ce0d31fb9: OUTPUT: Â«0.585454602â¤Â»

[12:59] <lizmat> that's a trend!

[13:00] * lizmat also thinks about always using .?method now  :-)

[13:10] *** vrurg_ joined
[13:12] *** vrurg left
[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: f6abc75ab2 | (Nicholas Clark)++ | src/6model/reprs/NativeCall.c

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: When NativeCall is libffi, don't leak ffi_arg_types during GC

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: 

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: body->ffi_arg_types is allocated with `MVM_malloc`, so needs a

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: corresponding `MVM_free`.

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: review: https://github.com/MoarVM/MoarVM/commit/f6abc75ab2

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: af6f9b84de | (Nicholas Clark)++ | src/6model/reprs/NativeCall.c

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: When NativeCall is libffi, copy `ffi_ret_type` and `ffi_arg_types`

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: 

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: This bug wasn't exposed until now.

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: review: https://github.com/MoarVM/MoarVM/commit/af6f9b84de

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: 26068a0440 | (Stefan Seifert)++ (committed by Nicholas Clark) | 8 files

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: Add boot-foreign-code dispatch terminal to replace native(call)invoke ops

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: 

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: With the new dispatch terminal, NativeCall will be able to benefit from the

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: more efficient argument passing conventions. It will also benefit from dispatch

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: programs tailored to the callsite, i.e. being able to replace more costly

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: checks for containers with cheap guards.

[13:49] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: review: https://github.com/MoarVM/MoarVM/commit/26068a0440

[14:02] <Nicholas> nine: effectively I'm sort-of-stuck. I have a question at the end of https://github.com/MoarVM/MoarVM/commit/26068a0440

[14:07] <nine> Nicholas: oh, sorry. It's pretty safe to ignore that particular test. It requires fully working manage-explicitly support which didn't appear until some time later (and requires cooperation between rakudo and MoarVM). Indeed I discovered that this was broken even pre-new-disp.

[14:07] *** TempIRCLogger left
[14:08] *** TempIRCLogger joined
[14:11] <Nicholas> OK. I might get a chance to get back to this in I guess about 4 hours

[14:18] <gfldex> If .resume would take an argument that is used as the failed expressions return value, one could actually handle this case (any like many other cases).

[14:23] <lizmat> gfldex: nqp::setpayload($!ex,value) in Exception.resume ?

[14:31] <jnthnwrthngtn> fwiw, I think the next thing I'll take on is the LEAVE and friends situation (from the point of view of efficiency and also fixing the odd disappearing return value bug I uncovered a while back)

[14:32] <lizmat> jnthnwrthngtn: bump MoarVM in the interest of testing and bisectability ?

[14:32] <jnthnwrthngtn> lizmat: I think you asked earlier and I agreed? :)

[14:33] <lizmat> oops, missed that  :-)

[14:33] <lizmat> going to do it now

[14:33] <jnthnwrthngtn> Anyway, said next thing will probably be for next week. I've got a rough sketch of a plan for it

[14:34] <jnthnwrthngtn> Basically, just emit code to run all of the exit phasers ahead of the (MoarVM) return op, so in a normal return they just run as normal code, and then identify the location of them within the block (handler style) for the unwind case.

[14:35] <nine> So far all I've apparently managed is to make it less common. I've also tried moving the first find_interned_callsite call to after we've taken the lock and as expected that makes the problem go away.

[14:35] <jnthnwrthngtn> Which will mean we also get inlining of them anyway.

[14:54] <dogbert17> nine: is this the place of the SEGV? 2944                 if (STABLE(val.o) != (MVMSTable *)dp->gc_constants[op.arg_guard.checkee])

[14:54] <nine> dogbert17: yes

[14:55] <nine> dogbert17: well for one of the two I see. The more frequent one is in find_interned_callsite

[14:58] <lizmat> fwiw, I can not just restart applications after the bump  :-(

[14:59] <lizmat> Missing or wrong version of dependency 'gen/moar/stage2/NQPHLL.nqp' (from 'site#sources/45334C557865A97D1ECA0D3F3A3FAF2017FCE553 (OO::Monitors)')

[14:59] <lizmat> always OO::Monitors  :-(

[15:00] <lizmat> installing / uninstalling OO::Monitors does not fix :-(

[15:01] <lizmat> uninstalling Cro::HTTP 

[15:02] <lizmat> installing Cro::HTTP fails with: Missing or wrong version of dependency 'gen/moar/stage2/NQPHLL.nqp' (from 'site#sources/45334C557865A97D1ECA0D3F3A3FAF2017FCE553 (OO::Monitors)')

[15:02] <lizmat> am I really the only one suffering from this ?

[15:03] <jnthnwrthngtn> I've not seen it, fwiw

[15:03] <vrurg_> lizmat: not this time, but sometimes it happens. Never in time for me to be able to trace it down.

[15:03] <vrurg_> I usually just reinstall. Modules too.

[15:05] <vrurg_> Feels like under some conditions modules are not recompiled and the bytecode remains bound to the previous NQPHLL. But this is only a feeling, no proofs.

[15:05] <lizmat> it's bloody annoying  :-(

[15:17] <lizmat> looks like nuking all precomp dirs is a solution

[15:18] <nine> We shouldn't even find precomp files that are bound to outdated NQP modules as we're managing precomp files by compiler-id. And the compiler-id is derived from a sha1 of rakudo's sources and NQP's id which in turn is a sha1 of its sources.

[15:18] <lizmat> well, that's the theory

[15:18] <lizmat> practice is different, for me at least

[15:19] <lizmat> the odd thing is, is that it always seem to center around OO::Monitors

[15:19] <nine> It's only gonna stop once someone digs down into it instead of deleting the evidence

[15:19] <lizmat> true

[15:19] <lizmat> is there a precompilation dir sanity tool ?

[15:23] *** [Coke] left
[15:29] <nine> Well there's at least one (minor) issue: _all_sources in tools/lib/NQP/Config/Rakudo.pm only looks for .nqp and .pm6 files which doesn't cover src/core.c/ParallelSequence.rakumod. _all_sources is used to find the things we need to sha1

[15:30] <lizmat> ok, that should be easily fixed

[15:31] <nine> lizmat: do you use any -j option when building rakudo?

[15:32] <lizmat> no

[15:32] <lizmat> perl Configure.pl --gen-moar --make-install

[15:32] <lizmat> is what I use

[15:36] <vrurg_> Rakudo build doesn't parallelize anyway.

[15:37] <vrurg_> I mean, .NOTPARALLEL is in action.

[15:37] *** vrurg_ is now known as vrurg

[15:39] <nine> Boy this stuff changed a whole lot since I wrote it. One thing seems definitely odd to me: the calculation of the source digest (which includes gen/nqp-version) got moved to this NQP::Config::Rakudo module which suggest that it's run as part of Configure.pl.

[15:39] <nine> But if that is so, how could it pick up changes since Configure.pl ran?

[15:40] <lizmat> aha... the plot thickens ?

[15:40] <lizmat> otoh, I've only seen this problem *after* a new Confiigure.pl

[15:41] <nine> If this source digest is calculated before Configure.pl updates NQP, then it won't pick up changes in NQP either. I think you are kinda special by relying on --gen-moar. I always update and install the 3 repos manually

[15:42] <lizmat> well, that's one of the reasons I keep using that, as that is the "user" way if building Rakudo  :-)

[15:57] *** [Coke] joined
[16:03] <nine> I think I know what's going on with find_interned_callsite. It's quite devious actually. If I'm correct, the segfaults I see now only appear with a --valgrind build of MoarVM. That's because with that option the FSA pre- and postfixes allocations with some red zone bytes. MVM_FSA_REDZONE_BYTES is defined to be 4. So all pointer arrays allocated with the FSA will be misaligned.

[16:04] <nine> That's why we only read half the pointer. The other half may not be written yet as atomicity of pointer writes can only be expected for properly aligned pointers.

[16:07] <jnthnwrthngtn> omg

[16:08] <jnthnwrthngtn> That's both feasible and terrible

[16:08] <nine> I've checked. The array is unaligned. I've now changed MVM_FSA_REDZONE_BYTES to 8 and running it again. So far no trouble

[16:08] <nine> And yes, terrible indeed

[16:09] <jnthnwrthngtn> So this was, after all, perhaps not the real problem?

[16:09] <jnthnwrthngtn> (Although I think there was actually a risk that the PR I did solves)

[16:09] <nine> Well you may have fixed the real problem already.

[16:09] <jnthnwrthngtn> Ah

[16:10] <jnthnwrthngtn> Well, the PR makes CI happy at least...but that may be luck given it failed rarely

[16:10] <nine> I guess I should try to reproduce the problem without your fix but with my red zone adjustment. But for now my waterrower calls and then dinner

[16:10] <jnthnwrthngtn> Enjoy :)

[16:38] *** nebuchadnezzar left
[16:55] *** CaCode joined
[17:13] *** dogbert17 left
[17:13] *** dogbert11 joined
[17:23] <timo> could be you need to explicitly Configure.pl so that the --version we report really changes?

[17:23] <timo> for the problem liz has with modules

[17:24] <timo> i see you already figured that part out

[17:25] <lizmat> fwiw, I haven't seen the issue since https://github.com/rakudo/rakudo/commit/e98e17da7d

[17:26] <lizmat> sanity check: if I have a *lot* of objects with an int64 attribute, if I replace that by an int32 attribute, would I save memory 4 bytes / object?

[17:29] <jnthnwrthngtn> Maybe not, because of alignment rules

[17:29] <jnthnwrthngtn> If you had two 64-bit attributes one after another and both became int32, yes, that's certainly a saving

[17:30] <lizmat> yeah I feared as much

[17:30] <lizmat> so that's one optimization out of the window  :-)

[17:31] <jnthnwrthngtn> This is why things like the heap snapshot analyzer do the inside-out pattern

[18:01] *** Kaiepi left
[18:02] *** Kaiepi joined
[18:15] *** sena_kun left
[18:16] <jnthnwrthngtn> home time &

[18:20] *** CaCode_ joined
[18:23] *** CaCode left
[18:38] <Geth> Â¦ MoarVM/libffi-nativecall-fixes: a3c17d0f5d | (Nicholas Clark)++ | src/6model/reprs/NativeCall.c

[18:38] <Geth> Â¦ MoarVM/libffi-nativecall-fixes: When NativeCall is libffi, don't leak ffi_arg_types during GC

[18:38] <Geth> Â¦ MoarVM/libffi-nativecall-fixes: 

[18:38] <Geth> Â¦ MoarVM/libffi-nativecall-fixes: body->ffi_arg_types is allocated with `MVM_malloc`, so needs a

[18:38] <Geth> Â¦ MoarVM/libffi-nativecall-fixes: corresponding `MVM_free`.

[18:38] <Geth> Â¦ MoarVM/libffi-nativecall-fixes: review: https://github.com/MoarVM/MoarVM/commit/a3c17d0f5d

[18:38] <Geth> Â¦ MoarVM/libffi-nativecall-fixes: a2a82f990a | (Nicholas Clark)++ | src/6model/reprs/NativeCall.c

[18:38] <Geth> Â¦ MoarVM/libffi-nativecall-fixes: When NativeCall is libffi, copy `ffi_ret_type` and `ffi_arg_types`

[18:38] <Geth> Â¦ MoarVM/libffi-nativecall-fixes: 

[18:38] <Geth> Â¦ MoarVM/libffi-nativecall-fixes: This bug was only exposed as a side effect of refactoring NativeCall to

[18:38] <Geth> Â¦ MoarVM/libffi-nativecall-fixes: use new dispatch.

[18:38] <Geth> Â¦ MoarVM/libffi-nativecall-fixes: review: https://github.com/MoarVM/MoarVM/commit/a2a82f990a

[18:38] <Geth> Â¦ MoarVM: nwc10++ created pull request #1592: libffi nativecall fixes

[18:38] <Geth> Â¦ MoarVM: review: https://github.com/MoarVM/MoarVM/pull/1592

[18:42] *** CaCode- joined
[18:45] *** CaCode_ left
[19:07] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: f0dd7be6cd | (Stefan Seifert)++ (committed by Nicholas Clark) | 4 files

[19:07] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: No longer allocate an argument array for generic native calls

[19:07] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: 

[19:07] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: Add a new variant MVM_nativecall_dispatch which understands the new dispatcher

[19:07] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: argument passing convention to avoid allocating and populating an argument

[19:07] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: array for every call.

[19:07] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: review: https://github.com/MoarVM/MoarVM/commit/f0dd7be6cd

[19:07] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: fc705d3f5a | (Nicholas Clark)++ | src/core/nativecall_libffi.c

[19:07] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: Implement MVM_nativecall_dispatch for libffi

[19:07] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: review: https://github.com/MoarVM/MoarVM/commit/fc705d3f5a

[19:07] <Nicholas> have one more commit.

[20:31] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: 68472b688e | (Stefan Seifert)++ (committed by Nicholas Clark) | src/core/nativecall_dyncall.c

[20:31] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: Fix segfaults when primitive parameters are passed to native function

[20:31] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: 

[20:31] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: The dispatcher calling convention allows for unboxed values to get passed to

[20:31] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: a native function. Need to handle those in MVM_nativecall_dispatch instead of

[20:31] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: blindly assuming that we always get objects.

[20:31] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: review: https://github.com/MoarVM/MoarVM/commit/68472b688e

[20:31] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: e88c027b74 | (Nicholas Clark)++ | src/core/nativecall_libffi.c

[20:31] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: Also handle primitive parameters without segfaulting in the libffi code.

[20:31] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: 

[20:31] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: The dispatcher calling convention allows for unboxed values to get passed to

[20:31] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: a native function. Need to handle those in MVM_nativecall_dispatch instead of

[20:31] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: blindly assuming that we always get objects.

[20:31] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: review: https://github.com/MoarVM/MoarVM/commit/e88c027b74

[20:47] <nine> The MVM_disp_program_run segfault looks like a deopt materialization issue

[20:50] <Nicholas> do I need to worry about this?

[20:51] <nine> nah

[21:00] <jnthnwrthngtn> Guess getting back into PEA should be my next stop after the LEAVE thing :)

[21:01] *** evalable6 left
[21:01] *** linkable6 left
[21:02] *** evalable6 joined
[21:13] <nine> 32657 rr recordings weighing 254 GB and 3 of them cought segfaults

[21:16] <Nicholas> jnthnwrthngtn: I sort of think "taking care not to burn out" should be your next step.

[21:23] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: abc6aacbbd | (Stefan Seifert)++ (committed by Nicholas Clark) | 4 files

[21:23] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: dispatcher-track-unbox-int

[21:23] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: review: https://github.com/MoarVM/MoarVM/commit/abc6aacbbd

[21:24] <jnthnwrthngtn> Well, kinda "working on" that by pretty much not working on MoarVM stuff at weekends, and not rushing back into RakuAST work.

[21:24] <nine> Weekends off...a fascinating concept :)

[21:24] *** leedo_ joined
[21:25] *** rba_ joined
[21:26] *** leedo left
[21:28] <lizmat> meh, how I wish IterationBuffer also has a splice method

[21:28] <jnthnwrthngtn> Weekends still seem to end up filled with things anyway. :)

[21:28] *** rba left
[21:28] *** rba_ is now known as rba

[21:32] <jnthnwrthngtn> lizmat: For what purpose?

[21:32] <lizmat> making Array::Sorted::Util work transparently on IterationBuffers also

[21:56] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: 4 commits pushed by (Stefan Seifert)++, (Nicholas Clark)++

[21:56] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: 86b83f9277 | Support passing unboxed pointers to native routines

[21:56] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: 7f312d99f0 |  Support passing unboxed pointers to native routines for libffi

[21:56] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: 3e1c615b03 | Support passing unboxed strings to native routines

[21:56] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: f367d29908 | Support passing unboxed strings to native routines for libffi

[21:56] <Geth> Â¦ MoarVM/new-disp-nativecall-libffi: review: https://github.com/MoarVM/MoarVM/compare/abc6aacbbd1d...f367d29908ff

[21:56] <Nicholas> I'm going to bed now.

[21:58] <jnthnwrthngtn> Rest well o/

[22:04] *** linkable6 joined
[22:17] <jnthnwrthngtn> Not far to go until a building Rakudo (`make`) is within a minute on my home box (it's ~62s now) :)

[22:20] <[Coke]> O_o;

[22:22] <jnthnwrthngtn> Ah, that's on the new-special-return branch, fwiw

[22:29] <[Coke]> does that include moar & nqp builds??

[22:29] <[Coke]> ah, you said "make", not "configure". :)

[22:29] <[Coke]> still, nice!

[22:30] *** Kaiepi left
[22:32] *** Kaiepi joined
[22:36] <jnthnwrthngtn> Yeah, it's a 6s MoarVM and 18s NQP build for me.

[22:36] <jnthnwrthngtn> Which ain't too bad either

[22:40] <[Coke]> OO^

[22:49] *** MasterDuke left
[23:33] *** CaCode- left
[23:55] *** nebuchadnezzar joined
