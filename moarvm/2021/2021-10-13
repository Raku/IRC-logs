[00:02] *** reportable6 left
[00:04] *** reportable6 joined
[00:05] *** linkable6 joined
[00:13] *** discord-raku-bot left
[00:14] *** discord-raku-bot joined
[00:14] *** discord-raku-bot left
[00:15] *** discord-raku-bot left
[00:16] *** discord-raku-bot joined
[01:04] <jdv> wuts up with yall and coffee?
[01:04] <jdv> dr told me to cut back but i only do 1 a day so...no?
[01:05] <jdv> reaching
[01:13] <timo> i don't drink coffee, i guess i'm one of relatively few computer-workers who don't?
[01:14] * leont doesn't drink coffee either
[01:30] <[Coke]> I do 2 or 3 caff's a day.
[01:56] *** linkable6 left
[01:56] *** evalable6 left
[01:57] *** evalable6 joined
[02:14] *** ggoebel left
[04:08] *** frost joined
[04:31] *** ggoebel joined
[04:56] *** linkable6 joined
[06:00] *** notable6 left
[06:00] *** evalable6 left
[06:00] *** bloatable6 left
[06:00] *** linkable6 left
[06:00] *** bisectable6 left
[06:00] *** releasable6 left
[06:00] *** coverable6 left
[06:00] *** sourceable6 left
[06:00] *** reportable6 left
[06:00] *** statisfiable6 left
[06:00] *** shareable6 left
[06:00] *** nativecallable6 left
[06:00] *** squashable6 left
[06:00] *** unicodable6 left
[06:00] *** benchable6 left
[06:00] *** greppable6 left
[06:00] *** committable6 left
[06:00] *** quotable6 left
[06:00] *** tellable6 left
[06:01] *** releasable6 joined
[06:01] *** notable6 joined
[06:01] *** nativecallable6 joined
[06:01] *** unicodable6 joined
[06:01] *** shareable6 joined
[06:02] *** sourceable6 joined
[06:03] *** squashable6 joined
[06:03] *** benchable6 joined
[06:28] <Nicholas> jdv: jnthnwrthngtn likes coffee. But sometimes his coffee machine doesn't like him. And sometimes I (also) have daft problems making coffee
[07:01] *** tellable6 joined
[07:01] *** linkable6 joined
[07:01] *** committable6 joined
[07:02] <Nicholas> good Universal Beverage Time, #moarvm
[07:03] * nine sticks to the traditional coffee
[07:03] *** bisectable6 joined
[07:03] <Nicholas> to be honest, right now I have regular coffee too
[07:04] <Nicholas> not some compromise-by-committee "brown liquid served with whipped cream and a straw" which was sort of what I was envisaging
[07:04] <Nicholas> (no, this is not me being infested with Vienese perverted ideas about what "cappochino" should mean, but more I started with "coke float" and then realised that ice cream wasn't likely to be univeral enough, but whipped cream seemed to be closer)
[07:05] <Nicholas> (I can't spell. This is not news)
[07:07] <nine> I did enjoy tee in the morning as well when I was at Liz and Wendy's but when my wife's first words in the morning are "I'd like coffee" there's just not much I can do :)
[07:22] *** Altai-man joined
[07:23] *** samcv joined
[07:24] *** [Coke]_ joined
[07:31] *** bartolin_ joined
[07:31] *** TempIRCLogger left
[07:31] *** RakuIRCLogger left
[07:31] *** [Coke] left
[07:31] *** sena_kun left
[07:31] *** bartolin left
[07:31] *** jnthnwrthngtn left
[07:48] *** sena_kun joined
[07:50] *** Altai-man left
[07:53] *** TempIRCLogger joined
[07:55] <lizmat> so the good news is: getting back in the morning, my local dev version of the log server *did* start up correctly, reading all the available logs and growing to about 5G in memory
[07:55] <lizmat> no idea as to how long it too to get there, but my feeling is about an hour  :-(
[07:56] <nine> That sounds rather excessive
[07:56] *** moon-child is now known as Mondenkind
[07:58] <lizmat> oddly enough, it appears to take *more* memory than pre-newdisp
[07:58] <lizmat> yeah...  I was used to ~1.5 mins
[07:58] <lizmat> actually, it feels like an old bug that was fixed
[07:59] <lizmat> so I'm thinking: maybe it got lost in the merge
[08:01] *** quotable6 joined
[08:02] <lizmat> anyways, it feels like it is blocking on start { } once the maximum number of threads has been reached
[08:03] *** greppable6 joined
[08:03] *** statisfiable6 joined
[08:03] <lizmat> anyways, https://github.com/rakudo/rakudo/commit/39e5834dc4bb956b16e211aa comes to mind
[08:03] *** evalable6 joined
[08:08] <lizmat> ah, also of note: control-c is also safe: once it is loading like that, control-c does *not* get served  (or at least not while I was waiting for a few minutes)
[08:18] *** tbrowder left
[08:18] *** tbrowder joined
[08:19] <lizmat> running with RAKUDO_SCHEDULER_DEBUG=1 gives a *lot* of "[SCHEDULER 3248] Will not add extra worker; hit 64 thread limit [branch with 0 total completed]" messages
[08:19] <lizmat> I guess one for each start block  :)
[08:27] *** evalable6 left
[08:27] *** statisfiable6 left
[08:27] *** greppable6 left
[08:27] *** quotable6 left
[08:27] *** TempIRCLogger left
[08:33] *** evalable6 joined
[08:33] *** statisfiable6 joined
[08:33] *** greppable6 joined
[08:33] *** quotable6 joined
[08:48] <lizmat> ok, the plot thickens:  looking at the start of the SCHEDULER debug output
[08:49] <lizmat> it looks like it gets into "Heuristic low utilization deadlock situation detected", then adds a worker thread, repeat until no more worker threads possible
[08:50] *** jnthnwrthngtn joined
[08:50] <lizmat> jnthnwrthngtn: not sure if you can backlog
[08:51] <lizmat> ok, the plot thickens:  looking at the start of the SCHEDULER debug output
[08:51] <lizmat> it looks like it gets into "Heuristic low utilization deadlock situation detected", then adds a worker thread, repeat until no more worker threads possible
[09:59] *** psydroid left
[09:59] *** AlexDaniel left
[10:02] *** coverable6 joined
[10:02] *** AlexDaniel joined
[10:07] *** squashable6 left
[10:10] *** squashable6 joined
[10:11] *** psydroid joined
[10:28] *** Altai-man joined
[10:32] <Nicholas> this logger stayed on the same side of the split as lizmat: https://colabti.org/irclogger/irclogger_log/moarvm?date=2021-10-13
[10:33] <lizmat> yeah...  need to make a merger of the different log versions  :-)
[10:48] <lizmat> ok, I give up on this:  I can see all threads being used and executing stuff...  it looks like they're waiting for each other on a lower level than I can see
[10:49] <lizmat> note that all of these threads *are* executing the same code, but on different files
[10:49] <lizmat> *log files
[10:50] <lizmat> note that at this stage, I will not be able to run the log server in production on new-disp  :-(
[11:02] *** reportable6 joined
[11:03] *** bloatable6 joined
[11:09] <lizmat> ok, one final datapoint: loading the log files of a channel with :1degree, is not markably slower than with :15degree
[11:09] <lizmat> which leads me to believe that affectively there is only one thread executing the log loading logic at a time
[11:10] <lizmat> *effectively
[11:16] *** Xliff joined
[11:31] <lizmat> one more final datapoint:
[11:31] <lizmat> I've just timed the loading of the channel logs *without* starting the server
[11:32] <lizmat> if I run with :1degree, I see 31 Threads for the process in MacOS's Process Monitor
[11:33] <lizmat> with :15degree, I see 71 threads in the Process Monitor
[11:33] <Altai-man> this sounds like a new blocker?
[11:33] <lizmat> however, there is *no* difference in wallclock time, but the :15degree case does take 2 more CPU seconds
[11:34] <lizmat> Altai-man: yes, I would say this is a blocker, as it would affect any server code, specifically Cro
[11:34] <Altai-man> lizmat, can you please create a new ticket?
[11:34] <lizmat> will do
[11:35] <lizmat> should I do that in MoarVM or Rakudo ?
[11:35] <lizmat> feels like a MoarVM issue, but then it could also be a dispatch issue
[11:36] <Altai-man> lizmat, rakudo one
[11:51] *** lizmat_ joined
[11:51] *** TempIRCLogger joined
[11:52] *** squashable6 left
[11:52] *** RakuIRCLogger joined
[11:54] *** lizmat left
[11:55] *** squashable6 joined
[11:57] *** lizmat_ left
[11:57] *** lizmat joined
[11:57] <lizmat> https://github.com/rakudo/rakudo/issues/4569
[11:57] <lizmat> jnthnwrthngtn nine ^^
[12:02] *** reportable6 left
[12:08] <jnthnwrthngtn> moarning o/
[12:09] <Altai-man> lizmat++
[12:09] <Altai-man> jnthnwrthngtn, morning!
[12:10] *** ggoebel left
[12:11] <jnthnwrthngtn> lizmat: Curiously, I did benchmark Cro prior to new-disp merge and saw an *improvement* relative to master
[12:12] <jnthnwrthngtn> lizmat: Please add repro instructions to the issue
[12:13] <jnthnwrthngtn> I guess I need 1) to know what to install, 2) which command to run, 3) enough data to run it with presumably
[12:13] <jnthnwrthngtn> Sigh, I'm hungry.
[12:14] <jnthnwrthngtn> lizmat: I don't suppose you've been able to repro some simpler .hyper/.race failing to parallelize?
[12:23] <jnthnwrthngtn> $ time raku -e '^10 .map({ my $x = 0; for ^10_000_000 { $x++ } })'
[12:23] <jnthnwrthngtn> real 0m3,931s
[12:23] <jnthnwrthngtn> $ time raku -e '^10 .race(:1batch, :10degree).map({ my $x = 0; for ^10_000_000 { $x++ } })'
[12:23] <jnthnwrthngtn> real 0m0,798s
[12:24] <jnthnwrthngtn> Sadly, nothing this simple cuts it
[12:32] *** frost left
[12:54] <lizmat> jnthnwrthngtn: maybe IO needs to be involved?
[12:54] <lizmat> anyways, releasing the module now, so should be able to just zef install it
[12:54] <lizmat> and symlink to another dir for the logs
[13:00] <jnthnwrthngtn> Thanks
[13:03] *** reportable6 joined
[13:37] *** [Coke]_ is now known as [Coke]
[13:44] * [Coke] starts on his second cup of coffee
[13:45] <lizmat> jnthnwrthngtn: https://github.com/rakudo/rakudo/issues/4569#issuecomment-942324062
[13:59] *** ggoebel joined
[14:05] <[Coke]> had a run() that I was then doing a .decode('utf8-c8') on the output of. Using Proc::Async, I want to use "whenever $proc.stdout.lines" - (from doc examples) - is there a similar need to manually decode?
[14:05] <[Coke]> ww
[14:16] <jnthnwrthngtn> Diky, will make a cup of tea and take a look :)
[14:17] <jnthnwrthngtn> [Coke]: Pass env => 'utf8-c8' :)
[14:17] <jnthnwrthngtn> uh
[14:17] <jnthnwrthngtn> enc, not env :
[14:17] <jnthnwrthngtn> :)
[14:18] <jnthnwrthngtn> argh, 4 hours sleep was not enough
[14:18] <[Coke]> ah, sweet.
[14:31] *** ggoebel left
[14:32] <jnthnwrthngtn> lizmat: First attempt: it said "Could not find App::Raku::Log:ver<0.0.1>:auth<zef:lizmat>". Turns out that the script in bin/ asks for 0.0.1, but the version in META6.json is 0.0.3. Tweaking the script gets me further but...
[14:32] <jnthnwrthngtn> ailed to get the directory contents of '/home/jnthn/dev/IRC-logs/base/descriptions': Failed to open dir: No such file or directory
[14:32] <jnthnwrthngtn> (I ran it standing in the clone of IRC-logs, and indeed on't see the base directory
[14:33] <lizmat> are you in the App-Raku-Log dir ?
[14:33] <lizmat> from the clone?
[14:34] <lizmat> you should be in the App-Raku-Log clone dir, not in rthe IRC-logs dir
[14:35] <lizmat> that should be a subdir of the App-Raku-Log dir now
[14:36] <Altai-man> "Invocant of method 'raku' must be an object instance of type 'Mu', not a type object of type 'Any'.  Did you forget a '.new'?" <- is this me or it is very bizarre? I see the exception when printing a value on new-disp, but not on release. The fun thing is that it _does_ print the value properly, but after that throws an error.
[14:40] <jnthnwrthngtn> lizmat: Ah, I see
[14:43] <jnthnwrthngtn> Intersting, on my machine it runs for longer with --degree=8
[14:43] <jnthnwrthngtn> And maxes out at 134% CPU, and more sys time also
[14:44] <lizmat> well, if you have 8+8 cores... it should max out at about 1500% (used to for me before new-disp)
[14:45] *** ggoebel joined
[14:46] <jnthnwrthngtn> #2  0x00007ffff7a4b1cd in uv_mutex_lock () from //home/jnthn/dev/MoarVM/install/lib/libmoar.so
[14:46] <jnthnwrthngtn> #3  0x00007ffff78d6a9d in MVM_callsite_intern ()
[14:46] <jnthnwrthngtn>    from //home/jnthn/dev/MoarVM/install/lib/libmoar.so
[14:46] <jnthnwrthngtn> Loads of threads there
[14:47] <lizmat> by default it runs to 71 CPU threads for me
[14:47] <lizmat> (that would be with --degree=15 and --batch=16
[14:51] <jnthnwrthngtn> $ cat fpic | grep 'Full polymorphic flattening' | wc -l
[14:51] <jnthnwrthngtn> 138799
[14:55] <lizmat> is that good or bad ?
[14:58] <jnthnwrthngtn> Bad that it happens, good in that it's debugging progress
[15:00] *** ggoebel left
[15:00] <jnthnwrthngtn> lizmat: Did this get slower even with --degree=1 ?
[15:01] <lizmat> you mean, compared --degree=15 ?
[15:01] <jnthnwrthngtn> No, I mean --degree=1 after new-disp vs before
[15:02] <jnthnwrthngtn> (If you don't know, don't worry, if you do it's interesting)
[15:02] <lizmat> I never played with that before new-disp..  I wanted it as fast as  possible, so always used the default of --degree=15
[15:03] <lizmat> m: say Kernel.cpu-cores
[15:03] <camelia> rakudo-moar 067bef4d0: OUTPUT: «4␤»
[15:03] <jnthnwrthngtn> Fair enough
[15:03] <lizmat> actually, that value
[15:03] <lizmat> (which is 16 for me)
[15:04] <jnthnwrthngtn> Well, we end up with 15,548 different callsites getting interned
[15:05] <jnthnwrthngtn> m: say 138799 / 15548
[15:05] <camelia> rakudo-moar 067bef4d0: OUTPUT: «8.927129␤»
[15:05] <jnthnwrthngtn> Yowser.
[15:05] <jnthnwrthngtn> Are you constructing objects with huge numbers of args?
[15:05] <jnthnwrthngtn> named args, to be precise
[15:06] <lizmat> don't think so?   lemme check
[15:07] <jnthnwrthngtn> Ah, I think you probably are. The hierarchy under IRC::Log::Entry
[15:07] <lizmat> with huge number you mean more 10 ?
[15:07] <lizmat> TWEAK there takes 4 named
[15:08] <lizmat> could it be that they are named native int parameters ?
[15:08] <jnthnwrthngtn> haha
[15:08] <jnthnwrthngtn> Let me check something to be sure...
[15:08] <lizmat> oki
[15:10] <jnthnwrthngtn> hah, yes
[15:11] <jnthnwrthngtn> time raku-logs-server --channels=raku-dev --degree=1 --dontstart
[15:11] <jnthnwrthngtn> Normally: real0m17,572s
[15:11] <jnthnwrthngtn> But if you disable hash randomization
[15:11] <jnthnwrthngtn> real0m2,459s
[15:11] <jnthnwrthngtn> Now, can anybody guess what's going on? :)
[15:12] <lizmat> hmmm...  excessive hashing ?
[15:13] <jnthnwrthngtn> Prior to new-disp, we could never specialize anything when you called it and flattened args. In new-disp we lift that limitation. So in theory, maybe we get to run faster.
[15:13] <jnthnwrthngtn> Doing that means that we need to intern the flattened callsites.
[15:13] <jnthnwrthngtn> It's possible to write a ridiculous program that causes pain, but this should not be one...
[15:14] <jnthnwrthngtn> ...except it is, because when we flatten in a hash, we iterate the hash.
[15:14] <lizmat> yes... we do...  :-)
[15:14] <jnthnwrthngtn> And that means we iterate it in many orders
[15:14] <jnthnwrthngtn> (thanks to randomization)
[15:15] <lizmat> so maybe hashes are not the right thing for that ?
[15:15] <jnthnwrthngtn> Meaning that we produce many possible permutations of callsite (since those have to commit to an order)
[15:15] <jnthnwrthngtn> I think we "just" need to iterate them in a stable order
[15:15] <jnthnwrthngtn> I mean, flattening hash arguments is something we do all over
[15:16] <lizmat> yeah, but unless you refer to %_ explicitely, that's all under the hood, no ?
[15:18] <jnthnwrthngtn> Well, the case here is that BUILDALL slurps up the args, and then calls the appropriate BUILD/TWEAK with them flattened
[15:19] <jnthnwrthngtn> Nicholas: If one wants a more consistent order when iterating a hash, what is the right thing to do?
[15:20] <Nicholas> "Doctor doctor, it hurts when I do this." "Well, don't do that then".
[15:20] <Nicholas> Um, I don't see a good answer to this, other than sort the keys
[15:20] <jnthnwrthngtn> Yeah, I feared that would be the answer
[15:20] <Nicholas> however, sort them on address
[15:20] <Nicholas> not values
[15:20] <Nicholas> just sort the pointers
[15:20] <jnthnwrthngtn> ?
[15:20] <jnthnwrthngtn> Really?
[15:20] <Nicholas> well, OK
[15:20] <jnthnwrthngtn> I suspect we don't intern strings hard enough
[15:20] <Nicholas> will different hashes arrive with the same keys? (but different copies of the values)
[15:21] <Nicholas> acutally, if the answer is "different copies of the same value" then IIRC the 64 bit hash value is the same for the same string value (in a given interpreter run)
[15:21] <jnthnwrthngtn> Different copies of the values, but in this case I suspect deserialized from JSON, so the strings will be all over the place
[15:21] <Nicholas> so likely sort *those* first, and then tie break on actual string vlaue
[15:21] <jnthnwrthngtn> Hash values of strings can be trusted?
[15:22] <jnthnwrthngtn> Uh, that's a bad question
[15:22] <Nicholas> they have to be determimistic (for a given interpreter run) else how do you find the key in the hash? :-)
[15:22] <lizmat> jnthnwrthngtn: actually, no deserializtion from JSON, but from colabti  tyle log files
[15:22] <jnthnwrthngtn> Hash values of strings are independent of any given hsah?
[15:22] <lizmat> *style
[15:22] <jnthnwrthngtn> Nicholas: Duh, good point :)
[15:22] <lizmat> but indeed..  with strings all over the place
[15:22] <jnthnwrthngtn> Not the smartest bear today...
[15:23] <Nicholas> hash value will be a function of 1) hash algorithm (ie siphash, until we change that)  2) the 64 bit per-process salt for all hashing 3) the codepoints of the string
[15:23] <lizmat> basically a lot of substr on the log file
[15:23] <jnthnwrthngtn> OK, and for a given execution of the VM, 1 and 2 are constant, so it's only 3
[15:23] <Nicholas> so, possibly even just sort on 64 bit hash value and if two happen to collide, then, oh well, that's two variants of the same thing interned
[15:23] <Nicholas> or do the job properly...
[15:24] <jnthnwrthngtn> Yeah, it'll be more expensive to take care of the collisions than it will be have the dupe interns
[15:24] <Nicholas> but IIRC when hacking on this stuff last year, my code was buggy and I *forgot* to check the actual strings
[15:24] <Nicholas> and we passsed all spectests
[15:24] <jnthnwrthngtn> 64 bits is enough for anybody
[15:24] <Nicholas> ie our 64 bit hash values are good enough that we "rarely" generate collisions
[15:26] <jnthnwrthngtn> Ah, and: I also see a speedup with --degree=8 over --degree=1 with hash randomization disabled
[15:28] <jnthnwrthngtn> OK, another cup of tea and I'll try to implement this
[15:29] * lizmat waits in great anticipation :-)
[15:29] <Nicholas> if thses are MVMString objects found as keys in a hash, then their s->body.cached_hash_code will always be valid and computed already
[15:30] <Nicholas> hence the interface in MVM_string_compute_hash_code() might be a bit less than optima
[15:30] <Nicholas> optmial
[15:30] <Nicholas> and "just cheating and breaking encapsulation inside the function passed to qsort()" might be the best plan
[15:35] <nine> If the hashing algorithm is any good, I'd be surprised to see a collision of those 64 bits just about ever
[15:57] *** dogbert17 left
[16:00] <jnthnwrthngtn> Nicholas: Turns out if I used qsort from the C standard library I can't reach the tc anyway, so I just grabbed the cached hash value out :)
[16:00] <jnthnwrthngtn> Ah, that's what you realized too and I missed it
[16:01] <jnthnwrthngtn> The change helps, currently running spectest
[16:06] *** dogbert17 joined
[16:06] <lizmat> jnthnwrthngtn: all of this doesn't make me understand why the performance between --degree=15 and --degree=1 are so similar
[16:07] <lizmat> whereas before new-disp they weren't ?
[16:11] <jnthnwrthngtn> lizmat: Hash randomization caused a huge blow-up in the number of possible callsite shapes. With new-disp we now try to intern those so we can use them as specialization keys.
[16:11] <jnthnwrthngtn> The first step to seeing if we already have that callsite is a search of all those with the same arity to see if any match.
[16:12] <jnthnwrthngtn> So the more you have, the longer that search gets
[16:12] <lizmat> I get that... and I guess that search has a lock on it?
[16:12] <jnthnwrthngtn> The variation has a second effect: it means that we don't detect the possibility to use an individual dispatch program.
[16:13] <jnthnwrthngtn> And so we end up slow-pathing those (re-recording them every time)
[16:13] <jnthnwrthngtn> Which forces an intern even if the one for flattening is an "if you can"
[16:13] <lizmat> I all understand that...  but wouldn't that just mean using *more* CPU
[16:13] <jnthnwrthngtn> And...you guessed it, the intern cache has a lock on it
[16:13] <lizmat> right, ok
[16:14] <lizmat> that explains
[16:14] <jnthnwrthngtn> That explains the huge increase in system time too
[16:14] <jnthnwrthngtn> (All the lock acquisitions)
[16:15] <lizmat> feels to me that using a lock for this wouldn't scale very well in the further future?
[16:15] <jnthnwrthngtn> What we could do on top of the fix I've already done is move the lookup in the intern cache out of the lock section
[16:15] <lizmat> I mean if the lookup could be done lockless  :-)
[16:15] <jnthnwrthngtn> It can but then you have to repeat it after you acquire the lock.
[16:15] <jnthnwrthngtn> Well, or some further mitigation of that race
[16:16] <jnthnwrthngtn> s/further/alternative/
[16:16] <lizmat> some use of cas ?
[16:16] <jnthnwrthngtn> Well, you could use an atomic integer that you read before looking, and then if it's the same after you acquire the lock you know the cache didn't change under you
[16:17] <jnthnwrthngtn> That's probably the way to go
[16:22] <Geth> ¦ MoarVM: e66404a859 | (Jonathan Worthington)++ | src/core/args.c
[16:22] <Geth> ¦ MoarVM: Ensure stable order of flattened named args
[16:22] <Geth> ¦ MoarVM: 
[16:22] <Geth> ¦ MoarVM: Hash randomization means that the iteration of hash keys varies from
[16:22] <Geth> ¦ MoarVM: hash to hash. In the context of a flattened hash of arguments, this
[16:22] <Geth> ¦ MoarVM: means that a given set of named arguments could appear in many orders
[16:22] <Geth> ¦ MoarVM: upon iteration. Previously, we built up the callsite arg names list in
[16:22] <Geth> ¦ MoarVM: whatever order we got from hash iteration. That means we're liable to
[16:22] <Geth> ¦ MoarVM: <…commit message has 6 more lines…>
[16:22] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/e66404a859
[16:23] * lizmat tries
[16:28] <jnthnwrthngtn> Yeah, over the execution of that program, even with the fix, it looks up 191,986 callsites, but only adds 2160 new ones
[16:29] <jnthnwrthngtn> m: say 191986 - 2160
[16:29] <camelia> rakudo-moar 067bef4d0: OUTPUT: «189826␤»
[16:29] <jnthnwrthngtn> That's quite a lot of saved lock acquisitions
[16:29] <lizmat> yup... 
[16:30] <lizmat> preliminary tests: degree=1  goes from 28.15 to 3.43
[16:30] <lizmat> preliminary tests: degree=15  goes from 30.39 to 1.785
[16:31] * lizmat is a lot happier camper
[16:31] * lizmat attempts a full load
[16:32] <lizmat> yup, eating CPU like crazy now  :-)
[16:32] <jnthnwrthngtn> nom nom nom
[16:32] <lizmat> less than a minute now to load all of the logs  :-)
[16:33] <lizmat> clocking in at about 5G memory  :-)
[16:36] *** ggoebel joined
[16:37] *** [Coke]_ joined
[16:39] *** [Coke] left
[16:42] <lizmat> perhaps time to do a MoarVM bump?
[16:43] <Altai-man> we can
[16:47] <jnthnwrthngtn> I've got another patch spectesting now for reducing locking on the intern cache
[16:48] *** ggoebel left
[16:48] *** ggoebel joined
[16:53] <Geth> ¦ MoarVM: f7d6bc6149 | (Jonathan Worthington)++ | 2 files
[16:53] <Geth> ¦ MoarVM: Avoid locking on intern cache lookup
[16:53] <Geth> ¦ MoarVM: 
[16:53] <Geth> ¦ MoarVM: We only really need to take the lock in order to serialize additions.
[16:53] <Geth> ¦ MoarVM: Rather than always searching again to see if the callsite was added, use
[16:53] <Geth> ¦ MoarVM: a total count of interns as a cheaper validation that nothing changed
[16:53] <Geth> ¦ MoarVM: between our search and the lock acquisition.
[16:53] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/f7d6bc6149
[16:53] <Altai-man> jnthnwrthngtn, want another one before taking a good rest?
[16:53] <jnthnwrthngtn> Altai-man: Hm, maybe...what is it?
[16:55] <Altai-man> jnthnwrthngtn, "Invocant of method 'raku' must be an object instance of type 'Mu', not a type object of type 'Any'" which started to happen on new-disp. Alas, there is no nice golf as the module does funky things with MOP. Want steps to reproduce?
[16:58] <jnthnwrthngtn> Um...no, I'd prefer a golf, tbh.
[16:59] <Altai-man> aha, I'll try to make one then
[16:59] <jnthnwrthngtn> What kind of bug is it, though? Spesh-sensitive?
[16:59] <jnthnwrthngtn> Or still there under MVM_SPESH_DISABLE=1?
[17:00] <Altai-man> still there when spesh is disabled
[17:00] <Altai-man> any other flags I should try?
[17:01] <jnthnwrthngtn> No, if it's still there when spesh is disabled then that's already ruled out all of spesh :)
[17:01] <jnthnwrthngtn> That will probably make it much easier to golf
[17:04] <Altai-man> well, the bug is in cro-ldap, tests explode in the parser and it relies on the meta generator, so all of this is a bit entangled.
[17:06] <jnthnwrthngtn> This is a recent regression, given we didn't see it in blin before?
[17:06] *** [Coke]_ is now known as [Coke]
[17:06] <Altai-man> the module is not in the ecosystem, so not something recent, alas
[17:06] <Altai-man> oh no, https://github.com/rakudo/rakudo/issues/4570
[17:07] <Altai-man> jnthnwrthngtn, I'll try to golf it down, anyway
[17:07] <jnthnwrthngtn> Yeah, I'd appreciate others doing golfing. I've done so much of it over the last weeks/months.
[17:08] <jnthnwrthngtn> I don't think that's sustainable for me, nor is the assumption that I'll do it good for others getting better at it.
[17:27] *** ggoebel left
[17:38] <jnthnwrthngtn> dinner &
[18:02] *** discord-raku-bot left
[18:02] *** discord-raku-bot joined
[18:02] *** reportable6 left
[18:06] *** discord-raku-bot left
[18:07] *** discord-raku-bot joined
[18:11] *** vrurg left
[18:12] *** vrurg joined
[18:17] *** vrurg left
[18:48] <dogbert17> hmm, this is the kind of problem nine++ tends to eat for lunch :)
[18:54] *** Xliff left
[18:57] <Altai-man> and I have a golf
[18:59] <Altai-man> https://gist.github.com/Altai-man/f2e7816a71b32320017fe5d5e72f283c
[19:04] *** reportable6 joined
[19:05] <Altai-man> m: class ASNType { has $.type is rw; }; my $new-type = Metamodel::ClassHOW.new_type(name => 'LDAPMessage'); my $attribute-type = ASNType.new(type => Int); my $attr = Attribute.new(name => '$!protocol-op', type => $attribute-type.type, package => $new-type, :has_accessor); $new-type.^add_attribute($attr); $new-type.^compose; say $new-type.new;
[19:05] <camelia> rakudo-moar bcd3ae062: OUTPUT: «Invocant of method 'raku' must be an object instance of type 'Mu', not␤a type object of type 'Int'.  Did you forget a '.new'?␤  in block <unit> at <tmp> line 1␤␤»
[19:05] *** Altai-man left
[19:06] *** vrurg joined
[21:02] <jnthnwrthngtn> I like short golfs and I cannnot lie...
[21:11] *** linkable6 left
[21:12] <[Coke]> ... did you already fix it??
[21:12] <jnthnwrthngtn> Yes :)
[21:13] <[Coke]> https://www.youtube.com/watch?v=PSZy6lGgOcI
[21:16] <nine> dogbert17: I might eat those for lunch, but jnthnwrthngtn++ eats those for a quick little snack in between
[21:21] <dogbert17> nine: you're up late
[21:21] <jnthnwrthngtn> Wonder if GC debug options and/or a small nursery might narrow https://github.com/rakudo/rakudo/issues/4570 down...
[21:22] <dogbert17> jnthnwrthngtn: I ran with a 24k nursery
[21:22] <nine> dogbert17: indeed. A friend came over and now I'm waiting till the bathroom's free
[21:24] <jnthnwrthngtn> dogbert17: Ah, OK
[21:24] <jnthnwrthngtn> Well, maybe I'll take a look tomorrow
[21:27] <dogbert17> I'll try a bit more and see if I can get better info
[21:34] <jnthnwrthngtn> Nice, thanks
[22:09] <sena_kun> jnthnwrthngtn++ # outstanding!
[22:09] *** ggoebel joined
[22:10] <sena_kun> also thanks for nudging me to golf it, it was kinda fun
[22:22] *** ggoebel left
[22:36] *** ggoebel joined
