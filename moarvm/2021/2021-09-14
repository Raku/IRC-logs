[00:13] *** MasterDuke91 joined
[00:13] <MasterDuke91> timo: you might find https://github.com/Raku/nqp/commit/0d4885d7450b22ccf2000823f9c2d7908fbe9019#diff-334e324024646938dfd714aea7c2e92d8d222991697cece6052559e43b98d7d7 interesting

[00:19] <timo> well, that disappeared

[00:19] <MasterDuke91> yep

[00:21] <MasterDuke91> timo: with your change, `raku --ll-exception -e 'use MONKEY; say EVAL "die";'` gives:

[00:21] <MasterDuke91> Died

[00:21] <MasterDuke91>    at gen/moar/CORE.c.setting:49703  (/home/dan/Source/perl6/install/share/perl6/runtime/CORE.c.setting.moarvm:throw)

[00:21] <MasterDuke91>  from gen/moar/CORE.c.setting:1015  (/home/dan/Source/perl6/install/share/perl6/runtime/CORE.c.setting.moarvm:die)

[00:21] <MasterDuke91>  from gen/moar/CORE.c.setting:1011  (/home/dan/Source/perl6/install/share/perl6/runtime/CORE.c.setting.moarvm:die)

[00:22] <MasterDuke91> without that change:

[00:22] <MasterDuke91> Died

[00:22] <MasterDuke91>    at SETTING::src/core.c/Exception.pm6:62  (/home/dan/Source/perl6/install/share/perl6/runtime/CORE.c.setting.moarvm:throw)

[00:22] <MasterDuke91>  from SETTING::src/core.c/control.pm6:213  (/home/dan/Source/perl6/install/share/perl6/runtime/CORE.c.setting.moarvm:die)

[00:22] <MasterDuke91>  from SETTING::src/core.c/control.pm6:209  (/home/dan/Source/perl6/install/share/perl6/runtime/CORE.c.setting.moarvm:die)

[00:24] <timo> i need to revert that

[00:26] <timo> we may want to see if we can optimize that. a lot,  ideally

[00:27] <MasterDuke91> please do

[01:11] <timo> so during parsing, we hit mostly the first entry in the list or the last

[01:12] <timo> while going through the mast stage however we kind of just linearly go from the start to the end, where the list is 228 entries long

[01:12] <timo> some kind of little cache could probably do a lot to help here

[01:13] <timo> perhaps splitting the directives array into one array of line numbers and one with filenames

[01:14] <timo> so we dont have a bunch of nested lists of int, str in the directives list

[01:14] <timo> so the line numbers list can become a native int list as well

[01:14] <timo> native str list is a little better than regular list with strings in it as well i think?

[01:15] <timo> additionally / alternatively, there could be a binary search there

[01:24] *** evalable6 left
[01:24] *** linkable6 left
[01:27] *** linkable6 joined
[01:55] *** kjp left
[01:56] *** kjp joined
[03:25] *** evalable6 joined
[04:00] *** MasterDuke91 left
[04:05] *** reportable6 joined
[04:25] *** Xliff left
[05:33] *** committable6 left
[05:33] *** statisfiable6 left
[05:33] *** greppable6 left
[05:33] *** sourceable6 left
[05:33] *** releasable6 left
[05:33] *** linkable6 left
[05:33] *** evalable6 left
[05:33] *** squashable6 left
[05:33] *** bisectable6 left
[05:33] *** shareable6 left
[05:33] *** bloatable6 left
[05:33] *** nativecallable6 left
[05:33] *** unicodable6 left
[05:33] *** benchable6 left
[05:33] *** notable6 left
[05:33] *** coverable6 left
[05:33] *** quotable6 left
[05:33] *** tellable6 left
[05:33] *** reportable6 left
[05:33] *** unicodable6 joined
[05:34] *** evalable6 joined
[05:34] *** nativecallable6 joined
[05:34] *** coverable6 joined
[05:34] *** tellable6 joined
[05:35] *** greppable6 joined
[05:36] *** committable6 joined
[05:36] *** shareable6 joined
[05:39] *** Altai-man left
[06:03] *** reportable6 joined
[06:34] *** sourceable6 joined
[06:34] *** linkable6 joined
[06:35] *** quotable6 joined
[06:36] *** benchable6 joined
[06:36] *** notable6 joined
[06:36] *** bloatable6 joined
[06:36] *** squashable6 joined
[06:56] *** frost joined
[07:12] <Nicholas> good *, #moarvm 

[07:36] *** bisectable6 joined
[07:36] *** statisfiable6 joined
[08:36] *** releasable6 joined
[08:41] <timo> good

[08:59] * lizmat switched back to the new-disp branch

[09:00] <lizmat> and did some test-t timing:   master:   1.32 / 0.60   (test-t and test-t --race

[09:01] <lizmat> new-disp: 2.11 / 0.81

[09:02] <lizmat> startup: .12 (master) and .16 (new-disp)

[09:02] <lizmat> just some data points...  no pressure  :-)

[09:07] <Nicholas> I'm sure it's all brrt's fault for not JITting it all yet :-)

[09:08] <lizmat> while doing some timing stuff, something struck me (again) that I feel warrants some thinking

[09:09] <lizmat> when just measuring bare startup, every now and then I get an outlier that is *way* below average

[09:10] <lizmat> just now, on master: 5 times .126 in a row, and then one with .095

[09:11] <lizmat> and I can't help but think: maybe that outlier didn't have its spesh thread started for some reason

[09:11] <lizmat> is that a weird idea?

[09:12] <lizmat> or are there other easy ways to all of a sudden get a much faster startup ?

[09:12] <lizmat> (well, and shutdown of course)

[09:20] <timo>  it would be quite strange for the spesh thread to not start

[09:20] <Nicholas> lizmat: to paraphrase the Spacex reddit answer of "it's ice. it's always ice" (which isn't quite always true) we always seem to say "it's hash randomisation, and it's causing spesh to have a good day" (or bad day). As in

[09:21] <Nicholas> I'd suggest that, but I have no idea how to test that theory

[09:21] <timo> but i'm also not entirely sure if we're perhaps waiting a noticeably long time for the process to shut down due to the spesh thread?

[09:21] <timo> we can systematically test one bajillion hash randomization seeds, right?

[09:22] <Nicholas> In parallel universes in constant time, sure. But it's probably faster to test about 100 runs (or whatever it is) with hash randomisation "normal", and then try 100 with it disabled (or fixed to one salt) and see if the latter doesn't have these outliers

[09:22] <lizmat> if it *is* hash randomization, then from the bajillion possible seeds, maybe we could choose from a subset that is faster 30% faster  :-)

[09:23] <lizmat> how does one start up with it disabled again  ?

[09:24] <timo> oh i thought that was a compile time change

[09:24] <Nicholas> er, I'm not sure if it's possible without changing a #define and recompiling MoarVM.

[09:24] <lizmat> ah...  ok

[09:25] <Nicholas> and there were actually two things to disable

[09:25] <Nicholas> 1) the random 64 bit value used to peturb the calls to SIPhash generating the 64 bit hash value for any string

[09:25] <Nicholas> 2) the random number in each hash that gets "mixed" into that

[09:33] *** lizmat_ joined
[09:37] *** lizmat left
[09:37] *** lizmat_ is now known as lizmat

[09:37] *** lizmat left
[09:37] *** lizmat joined
[09:44] <timo> so, um, who knows how moar and nqp handle nonexistant dynamic variables, why do they get a list when they are @ sigiled and why do you get the same list back every time?

[09:45] * lizmat only knows of the Rakudo way :-(

[10:19] <jnthnwrthngtn> I believe NQP also has some kind of fallback semantics

[10:20] <jnthnwrthngtn> lizmat: The test-t one is very likely mostly down to the missing inlining still.

[10:20] <jnthnwrthngtn> lizmat: I'm continuing work on that today; we'll see how far I get

[10:20] <jnthnwrthngtn> Startup is a thornier issue.

[10:21] <lizmat> ++jnthnwrthngtn    :-)

[10:23] <jnthnwrthngtn> We do save on deserializing method caches, but we probably make that up in deserializing meta-objects.

[10:24] <jnthnwrthngtn> Although deserialization is by far dominated by the inefficient way NFAs are stored

[10:24] <lizmat> what could be done to store them more efficiently?

[10:24] <timo> we currently store them both as a bunch of arrays and an actual nfa object

[10:25] <timo> the nfa object has essentially its own optimized serialization

[10:25] <timo> and you can relatively easily make the one form from the other

[10:25] <jnthnwrthngtn> Right, if we could recover the bunch of arrays from the NFA object that'd be a kinda solution but...

[10:25] <timo> did the branch where i implemented that nqp op ever get merged, i wonder

[10:25] <jnthnwrthngtn> ...when I glanced "how much effort is this" it seemed one'd have to restructure quite a bit of the code too

[10:26] <timo> yeah, we need the bunch-of-arrays form so that we can modify the nfa from nqp code

[10:26] <jnthnwrthngtn> Then I was like, sigh, we need to re-work the grammar engine more broadly, so this is annoying throwaway work

[10:26] <lizmat> which brings me back to the idea I once had, of reimplementing the grammar engine in Rakudo :-)

[10:26] <timo> surely we can't just make an nfa multi-dim-subscriptable?

[10:27] <jnthnwrthngtn> timo: That's...interesting

[10:27] <timo> probably troublesome for in-between forms while we're modifying stuff

[10:28] <jnthnwrthngtn> lizmat: For prototyping a new design, or as the thing to use?

[10:28] <jnthnwrthngtn> (It'd present some...bootstrapping problems...if the latter.)

[10:28] <lizmat> potentially both ?

[10:28] <jnthnwrthngtn> I mean, we'd want to use it for NQP too

[10:29] <jnthnwrthngtn> For prototyping it makes sense at least.

[10:29] <timo> clearly needs a raku to nqp compiler :)

[10:29] <jnthnwrthngtn> I already have a terrible partial one of those :P

[10:29] <jnthnwrthngtn> (That's what the AST implementation does.)

[10:30] <lizmat> he.. indeed  :-)

[10:33] <timo> yup

[10:35] <timo> nqp-js: sub a() { say(nqp::objectid(@*a)); }; sub m() { say(nqp::objectid(@*a)); }; sub x() { a(); m(); }; a(); a(); x();  m();m(); a(); m(); 

[10:35] <camelia> nqp-js: OUTPUT: ¬´sudo: /home/camelia/nqp-js: command not found‚ê§¬ª

[10:35] <timo> nqp-jvm: sub a() { say(nqp::objectid(@*a)); }; sub m() { say(nqp::objectid(@*a)); }; sub x() { a(); m(); }; a(); a(); x();  m();m(); a(); m(); 

[10:35] <camelia> nqp-jvm: OUTPUT: ¬´sudo: /home/camelia/rakudo-j-inst/bin/nqp-j: command not found‚ê§¬ª

[10:36] <timo> nqp: sub a() { say(nqp::objectid(@*a)); }; sub m() { say(nqp::objectid(@*a)); }; sub x() { a(); m(); }; a(); a(); x();  m();m(); a(); m(); 

[10:36] <camelia> nqp-moarvm: OUTPUT: ¬´21030072‚ê§21030072‚ê§21030072‚ê§21030072‚ê§21030072‚ê§21030072‚ê§21030072‚ê§21030072‚ê§¬ª

[10:36] <timo> jnthn, would you consider this a bug?

[10:36] <timo> nothing declares this dyn var but still we somehow store it somewhere?

[10:43] <jnthnwrthngtn> Can you say .HOW.name of the thing given to objectid too?

[10:43] <jnthnwrthngtn> (My suspicion is that it's NQPMu)

[10:45] <timo> nqp: sub a() { say(nqp::objectid(@*a)); say(@*a.HOW.name(@*a)) }; sub m() { say(nqp::objectid(@*a)); }; sub x() { a(); m(); }; a(); a(); x();  m();m(); a(); m(); 

[10:45] <camelia> nqp-moarvm: OUTPUT: ¬´45652648‚ê§NQPArray‚ê§45652648‚ê§NQPArray‚ê§45652648‚ê§NQPArray‚ê§45652648‚ê§45652648‚ê§45652648‚ê§45652648‚ê§NQPArray‚ê§45652648‚ê§¬ª

[10:45] <timo> well there we have that

[10:46] <timo> nqp: sub a() { say(nqp::objectid(@*a)); say(@*a.HOW.name(@*a)) }; sub m() { say(nqp::objectid(@*b)); }; sub x() { a(); m(); }; a(); a(); x();  m();m(); a(); m(); 

[10:46] <camelia> nqp-moarvm: OUTPUT: ¬´42068920‚ê§NQPArray‚ê§42068920‚ê§NQPArray‚ê§42068920‚ê§NQPArray‚ê§42069536‚ê§42069536‚ê§42069536‚ê§42068920‚ê§NQPArray‚ê§42069536‚ê§¬ª

[10:46] <jnthnwrthngtn> Is it a concrete array or just the type object?

[10:46] <jnthnwrthngtn> If the former, what on earth...

[10:46] <timo> nqp: sub a() { say(nqp::objectid(@*a)); say(@*a.HOW.name(@*a)); say(nqp::isconcrete(@*a)) }; sub m() { say(nqp::objectid(@*b)); }; sub x() { a(); m(); }; a(); a(); x();  m();m(); a(); m(); 

[10:46] <camelia> nqp-moarvm: OUTPUT: ¬´40005000‚ê§NQPArray‚ê§1‚ê§40005000‚ê§NQPArray‚ê§1‚ê§40005000‚ê§NQPArray‚ê§1‚ê§40005616‚ê§40005616‚ê§40005616‚ê§40005000‚ê§NQPArray‚ê§1‚ê§40005616‚ê§¬ª

[10:46] <timo> concrete

[10:47] <timo> my thought is the mechanism that gives us an array when the dyn var doesnt exist since we asked for a @ sigil is somehow wonky

[10:48] <jnthnwrthngtn> Yeah, I'm just wondering where on earth it stores it

[10:49] <jnthnwrthngtn>                 $ast := QAST::VarWithFallback.new(

[10:49] <jnthnwrthngtn>                     :name(~@name.pop), :scope('contextual'),

[10:49] <jnthnwrthngtn>                     :fallback($global_fallback)

[10:49] <jnthnwrthngtn>                 );

[10:49] <jnthnwrthngtn> And $global_fallback involves

[10:49] <jnthnwrthngtn> lexical_package_lookup(['GLOBAL',  ~$<sigil> ~ $<desigilname>], $/),

[10:50] <jnthnwrthngtn> Yeah, that does indeed vivify it in GLOBAL

[10:51] <jnthnwrthngtn> m: say(GLOBAL.WHO<@a>); @*a; say(GLOBAL.WHO<@a>);

[10:51] <camelia> rakudo-moar 10b327292: OUTPUT: ¬´(Any)‚ê§Dynamic variable @*a not found‚ê§  in block <unit> at <tmp> line 1‚ê§‚ê§¬ª

[10:52] <jnthnwrthngtn> oh, NQP

[10:52] <jnthnwrthngtn> nqp: say(GLOBAL.WHO<@a>); @*a; say(GLOBAL.WHO<@a>);

[10:52] <camelia> nqp-moarvm: OUTPUT: ¬´‚ê§‚ê§¬ª

[10:52] <jnthnwrthngtn> nqp: say(nqp::existskey(GLOBAL.WHO, '@a')); @*a; say(nqp::existskey(GLOBAL.WHO, '@a'));

[10:52] <camelia> nqp-moarvm: OUTPUT: ¬´0‚ê§0‚ê§¬ª

[10:52] <jnthnwrthngtn> nqp: say(nqp::existskey(GLOBAL.WHO, '@*a')); @*a; say(nqp::existskey(GLOBAL.WHO, '@*a'));

[10:52] <camelia> nqp-moarvm: OUTPUT: ¬´0‚ê§0‚ê§¬ª

[10:53] <jnthnwrthngtn> nqp: say(nqp::existskey(GLOBAL.WHO, '@*a')); say(nqp::objectid(@*a)); say(nqp::existskey(GLOBAL.WHO, '@*a'));

[10:53] <camelia> nqp-moarvm: OUTPUT: ¬´0‚ê§21036176‚ê§0‚ê§¬ª

[10:53] <jnthnwrthngtn> nqp: say(nqp::existskey(GLOBAL.WHO, '@a')); say(nqp::objectid(@*a)); say(nqp::existskey(GLOBAL.WHO, '@a'));

[10:53] <camelia> nqp-moarvm: OUTPUT: ¬´0‚ê§47254240‚ê§0‚ê§¬ª

[10:53] <jnthnwrthngtn> Huh.

[10:54] <jnthnwrthngtn> No idea, but yeah, agree that it vivifying an array is wrong

[10:58] <lizmat> afk for a few hours&

[10:59] *** squashable6 left
[11:05] *** lizmat left
[11:08] *** TempIRCLogger left
[11:09] *** lizmat joined
[11:10] *** TempIRCLogger joined
[11:26] *** brrt joined
[11:50] <Nicholas> good *, brrt 

[11:54] <timo>  bood *, grrt

[12:00] *** squashable6 joined
[12:03] *** reportable6 left
[12:13] *** brrt left
[12:19] <timo> now i can look where the right spot to hang the comp line directives is

[12:19] <timo> its really at the compunit level i think?

[12:20] <timo> and the same spot that gets that would also get the tiny cache to make lookups fastered

[13:05] *** reportable6 joined
[13:16] <jnthnwrthngtn> Getting somewhere with inlining calls with resumptions set up; it will find such a resumption and it works with the interp, but not with the JIT

[13:16] <jnthnwrthngtn> It seems finding the current active deopt index doesn't work if we're in the frame on the stack top

[13:19] <timo>  does the resumption op need an annotation in the oplist that causes some varABle to get updated when its reached?

[13:21] <jnthnwrthngtn> m: say 0x7f590e8eb82b - 0x7f590e8eb337

[13:21] <camelia> rakudo-moar 10b327292: OUTPUT: ¬´1268‚ê§¬ª

[13:23] <jnthnwrthngtn> No, it should really give the label immediately after the sp_dispatch that wants to resume, but doesn't

[13:24] <jnthnwrthngtn> That first number is what it probably should find, the second is what is in *tc->jit_return_address

[13:24] *** frost left
[13:25] *** brrt joined
[13:25] <brrt> good *, timo, Nicholas

[13:25] <jnthnwrthngtn> oh yay, it's brrt :)

[13:25] <brrt> also, I learnt recently that hacker news has a 'brnt' user, also from the Netherlands

[13:26] <brrt> ohai jnthnwrthgtn.... I fear something is broken about the JIT again

[13:26] <brrt> :-)

[13:27] <jnthnwrthngtn> brrt: I'm having trouble getting MVM_jit_code_get_active_deopt_idx to give a valid result when it's about the currently executing frame

[13:27] <jnthnwrthngtn> brrt: We're running an sp_dispatch at the time. I first though it was 'cus that wasn't marked :invokish, but I just tried that.

[13:28] <brrt> ehm.

[13:28] <brrt> hmm

[13:28] <jnthnwrthngtn> The piece I don't really understand: in the prologue we do:

[13:28] <jnthnwrthngtn>         | lea rax, [rsp-0x8];

[13:29] <jnthnwrthngtn>         | mov aword TC->jit_return_address, rax;

[13:29] <jnthnwrthngtn> And null it out in the epilogue, but what is it that actually updates that location?

[13:29] <jnthnwrthngtn> Is it the `call` instruction, 'cus it's the (ABI-level) location of the return address?

[13:29] <brrt> yes

[13:30] <brrt> the 'call' instruction does this

[13:30] <brrt> that's... the beauty of it, really

[13:30] <brrt> this can go wrong if we use `push` and `pop` in the assembly

[13:30] <brrt> which I don't think we do?

[13:31] <jnthnwrthngtn> doesn't look liek it

[13:31] <jnthnwrthngtn> https://github.com/MoarVM/MoarVM/blob/new-disp/src/jit/x64/emit.dasc is the JIT of sp_dispatch

[13:31] <jnthnwrthngtn> In theory the label is right after it

[13:33] * brrt will have a look

[13:33] <jnthnwrthngtn> Oh. Uhhh.

[13:34] <jnthnwrthngtn> When we inline something...there isn't a DEOPT_ALL on it any more

[13:34] <jnthnwrthngtn> I wonder if that in turn means no label.

[13:35] <brrt> two steps back pls

[13:35] <brrt> what lines should I be looking at

[13:38] <jnthnwrthngtn> hah, yes, I figured out a fix

[13:38] <brrt> :-)

[13:38] <jnthnwrthngtn> brrt: Today in after_ins we have:

[13:38] <brrt> good.

[13:39] <jnthnwrthngtn>         } else if (ann->type == MVM_SPESH_ANN_DEOPT_ALL_INS) {

[13:39] <brrt> yeah

[13:39] <jnthnwrthngtn> If I change it to

[13:39] <jnthnwrthngtn>         } else if (ann->type == MVM_SPESH_ANN_DEOPT_ALL_INS ||

[13:39] <jnthnwrthngtn>                 (ann->type == MVM_SPESH_ANN_DEOPT_INLINE && (ins->info->jittivity & MVM_JIT_INFO_INVOKISH))) {

[13:39] <jnthnwrthngtn> Then it works for inlines also, although this feels mildly cheaty

[13:41] <jnthnwrthngtn> I guess my next question is "how did we get away with this"... :)

[13:57] <Geth> ¬¶ MoarVM/new-disp: dfde811154 | (Jonathan Worthington)++ | 3 files

[13:57] <Geth> ¬¶ MoarVM/new-disp: Ensure we have JIT deopt info for inlined dispatch

[13:57] <Geth> ¬¶ MoarVM/new-disp: 

[13:57] <Geth> ¬¶ MoarVM/new-disp: * Mark it invokish

[13:57] <Geth> ¬¶ MoarVM/new-disp: * When we see an inline deopt annotation on an invokish instruction,

[13:57] <Geth> ¬¶ MoarVM/new-disp:   treat it like a deopt all

[13:57] <Geth> ¬¶ MoarVM/new-disp: review: https://github.com/MoarVM/MoarVM/commit/dfde811154

[13:59] <brrt> ugh

[13:59] <brrt> I promise I probably knew one time

[14:01] <timo> looking very forward to the next commit that i assume will be spesh linking and possibly inlining of things that use resumption

[14:04] <jnthnwrthngtn> We already have spesh linking of that, it's inlining

[14:04] <jnthnwrthngtn> I do locally have the first step to reinstating inlining working, but:

[14:04] <jnthnwrthngtn> 1. I know I need to do a bit more work with regard to deopt, but it's surprisingly tricky to write an example that triggers it

[14:05] <jnthnwrthngtn> (And still does all the required inlines, and triggers it at the right time to make the situation that needs handling)

[14:05] <jnthnwrthngtn> 2. I see a couple of spectest regressions, although they don't involve resumption, so I think I'm allowing more inlining and exposing something else that wants fixing

[14:06] <jnthnwrthngtn> I'd like to sort out 1 before I push it

[14:06] <timo> phew. okay

[14:07] <jnthnwrthngtn> The step after that for more inlining is to allow us to inline sp_resumption itself, which I think is really mostly work in the graph merge; the way I wrote the code in the resumption search should already handle multi-level inlines.

[14:08] <jnthnwrthngtn> However, in the inline log I see a huge amount of "a deopt may happen before arguments are processed"

[14:08] <jnthnwrthngtn> Which I think is our main blocker

[14:09] <jnthnwrthngtn> And I think that's due to things like hllize sticking in guards in the dispatcher translation that are not require

[14:09] <jnthnwrthngtn> *required

[14:09] <jnthnwrthngtn> BUT when I stop inserting those, the NQP build blows up

[14:10] <jnthnwrthngtn> That will need sorting out before we can really have a chance of inlining as well as before

[14:14] <timo> you gave me the hope of inlining better than before :D but that will come in time of course

[14:16] <jnthnwrthngtn> Well, there will be things we can inline now that we couldn't before

[14:16] <jnthnwrthngtn> Actually my test case is of a simple (but not onlystar) proto, where we inline the proto itself

[14:16] <jnthnwrthngtn> Which was impossible before

[14:16] <jnthnwrthngtn> Oh finally, I managed to cause a deopt that busts things

[14:17] <timo> de-ooped

[14:19] <jnthnwrthngtn> OK, now to recreate dispatch run call records...

[14:22] <jnthnwrthngtn> Hmmm. I wonder if I really should do it that way...

[14:24] <jnthnwrthngtn> The code would be vastly simpler with a special kind of call stack record for a deopt'd resume init arg set

[14:25] <jnthnwrthngtn> Hm, or would it

[14:35] <jnthnwrthngtn> Yup, it's possible to reconstruct a sufficiently convincing run dispatch record, but not pleasant.

[14:35] <jnthnwrthngtn> Deopt is difficult enough to debug already.

[16:01] <jnthnwrthngtn> Got it "working" for my example. Turns out somewhere deep in compiling CORE.setting it now segfaults though :/

[16:13] <jnthnwrthngtn> Thankfully, it was a silly thinko

[16:22] <Geth> ¬¶ MoarVM/new-disp: 56067a06ad | (Jonathan Worthington)++ | 8 files

[16:22] <Geth> ¬¶ MoarVM/new-disp: Allow inlining of dispatches with resume init args

[16:22] <Geth> ¬¶ MoarVM/new-disp: 

[16:22] <Geth> ¬¶ MoarVM/new-disp: This enables inlining optimizations in `sp_runbytecode` when there are

[16:22] <Geth> ¬¶ MoarVM/new-disp: `sp_resumption` instructions stacked up before it. (It does not yet

[16:22] <Geth> ¬¶ MoarVM/new-disp: allow inlining of `sp_resumption` instructions themselves). The key

[16:22] <Geth> ¬¶ MoarVM/new-disp: pieces are:

[16:22] <Geth> ¬¶ MoarVM/new-disp: 

[16:22] <Geth> ¬¶ MoarVM/new-disp: <‚Ä¶commit message has 11 more lines‚Ä¶>

[16:22] <Geth> ¬¶ MoarVM/new-disp: review: https://github.com/MoarVM/MoarVM/commit/56067a06ad

[16:28] <jnthnwrthngtn> That was kinda tricky to work out how to do, but the implementation is relatively straightforward in the end

[16:30] *** evalable6 left
[16:30] *** linkable6 left
[16:32] *** evalable6 joined
[16:38] <dogbert11> jnthnwrthngtn++

[17:15] *** brrt left
[17:21] <Geth> ¬¶ MoarVM/new-disp: 31d53e35d5 | (Jonathan Worthington)++ | 3 files

[17:21] <Geth> ¬¶ MoarVM/new-disp: Enable inlining of sp_resumption

[17:21] <Geth> ¬¶ MoarVM/new-disp: 

[17:21] <Geth> ¬¶ MoarVM/new-disp: By doing all of the required index fixup:

[17:21] <Geth> ¬¶ MoarVM/new-disp: 

[17:21] <Geth> ¬¶ MoarVM/new-disp: * In the sp_resumption op itself

[17:21] <Geth> ¬¶ MoarVM/new-disp: * In the inline table

[17:21] <Geth> ¬¶ MoarVM/new-disp: * In the spesh resume init table

[17:21] <Geth> ¬¶ MoarVM/new-disp: 

[17:21] <Geth> ¬¶ MoarVM/new-disp: And merging the spesh resume init table itself.

[17:21] <Geth> ¬¶ MoarVM/new-disp: review: https://github.com/MoarVM/MoarVM/commit/31d53e35d5

[17:23] <lizmat> jnthnwrthngtn: so should that make a performance difference for test-t?

[17:23] <lizmat> or would you like me to find out?  :-)

[17:24] <jnthnwrthngtn> We have some newly busted stuff to hunt from this, alas, but that triage would be nice to share.

[17:25] <lizmat> ok

[17:25] <jnthnwrthngtn> lizmat: Maybe, but so much inlining is being forbidden by "potential deopt before args processing" that I suspect it'll block many of the benefits.

[17:26] <jnthnwrthngtn> Some improvement in test-t is likely (it'd be interesting to see how much)

[17:27] <jnthnwrthngtn> Running it with MVM_SPESH_INLINE_LOG=1 and looking for "a deopt may happen before arguments are processed" will give a feel for how much is being left undone because of that issue

[17:29] <jnthnwrthngtn> Time to cook, rest, etc. bbl

[17:33] <lizmat> It's remarkably quick:

[17:33] <lizmat> $ time raku test-t.pl <hello.csv

[17:33] <lizmat> Segmentation fault: 11

[17:34] <[Coke]> Regarding post-deploy merge - I think the windows build issue is a blocker, but the nativecall concurrency issue is probably not (though I think we'll need to track that down over the next month.) I can see if I can duplicate ... was it masterduke? Nine? 's fix for the VLA.

[17:34] <[Coke]> (if no one else gets to it.)

[17:35] <[Coke]> Is there a list of issues to fix before the merge / list of expected things to hit before first release?

[17:36] <[Coke]> (afk)

[18:03] *** reportable6 left
[18:04] <dogbert11> MoarVM oops: Failed to find deopt index when processing resume

[18:05] *** patrickb joined
[18:05] <jnthnwrthngtn> dogbert11: Yeah, spotted that one; it only happens with the JIT enabled

[18:08] <lizmat> jnthnwrthngtn: so no test-t numbers

[18:08] <dogbert11> jnthnwrthngtn: aha

[18:30] *** linkable6 joined
[18:49] <lizmat> m: sub e() { 42 }; say e

[18:49] <camelia> rakudo-moar 10b327292: OUTPUT: ¬´2.718281828459045‚ê§¬ª

[18:49] <lizmat> hmmm

[19:05] *** reportable6 joined
[19:22] *** patrickb left
[19:23] <timo>  yeah cuz e is a term, right?

[19:24] <lizmat> yup

[19:24] <lizmat> but I thought locally defined things would have precedence?

[19:25] <lizmat> or is that because the name of the sub is really &e

[19:25] <lizmat> and "foo" is just syntactic sugar for "&foo()" ?

[19:45] <timo> probably terms will always have precedence over subs without parens

[19:51] *** cognominal left
[19:59] <lizmat> I guess  :-)

[19:59] <lizmat> it's still a bit of a gotcha

[20:00] <lizmat> m: sub now() { 42 }; dd now

[20:00] <camelia> rakudo-moar 10b327292: OUTPUT: ¬´42‚ê§¬ª

[20:00] <lizmat> he?

[20:00] <lizmat> I though now was also a term ?

[20:00] <lizmat> hmmm

[20:03] <lizmat> m: sub pi() { 42 }; dd pi

[20:03] <camelia> rakudo-moar 10b327292: OUTPUT: ¬´3.141592653589793e0‚ê§¬ª

[20:03] <lizmat> hmmm....

[20:03] * lizmat goes away for a bit for some epibration

[20:06] <lizmat> https://nl.wikipedia.org/wiki/Epibreren   # for the more Dutch inclined  :-)

[20:26] <dogbert11> jnthnwrthngtn: not the best golf ever but try the code snippet below with MVM_SPESH_NODELAY=1

[20:26] <dogbert11> for ^10 { my $proc = Proc::Async.new($*EXECUTABLE, '-e', '$*OUT.write(Blob.new(65, 66))'); my $result = ''; $proc.stdout.tap({ $result ~= $_ }); await $proc.start; }

[20:38] <japhb> lizmat: That is a truly excellent term.  Right up there with 'defenestration' I think.

[21:24] <jnthnwrthngtn> dogbert11: Thanks, will look at it tomorrow

[23:01] *** Geth joined
