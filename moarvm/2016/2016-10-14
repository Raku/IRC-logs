[00:37] *** psch joined
[00:37] *** [Coke] joined
[00:37] *** moritz joined
[01:48] *** ilbot3 joined
[05:25] *** domidumont joined
[05:31] *** domidumont joined
[05:50] *** domidumont joined
[05:57] *** domidumont joined
[06:30] <domidumont> timotimo: the spawnned process is defunct when moar hangs on run command.

[07:07] <brrt[work]> good * #moarvm

[08:10] <nebuchadnezzar> hello

[08:11] <nebuchadnezzar> domidumont: I'll be off for two weeks, I'm going to http://2016.opennebulaconf.com/ and take the opportunity to visit Barcelona and Valencia ;-)

[08:39] <domidumont> nebuchadnezzar: ok. Envoy your time off. :-)

[09:09] *** geekosaur joined
[13:18] <[Coke]> brrt[work]: o/

[13:50] <brrt[work]> hi [Coke]

[14:27] * brrt[work] afk

[14:54] *** FROGGS joined
[15:12] *** dalek joined
[15:20] <FROGGS> o/

[15:43] <domidumont> o/

[16:22] *** domidumont joined
[17:26] <domidumont> FROGGS: any idea on why gcc is zombie process when moar is hung ?

[18:04] *** LLamaRider joined
[18:14] <FROGGS> domidumont: no, no idea

[18:14] <FROGGS> domidumont: I also dont know how to continue debugging....

[18:43] *** harrow joined
[18:46] *** BinGOs_ joined
[18:48] *** BinGOs joined
[18:49] *** FROGGS_ joined
[18:51] *** eviltwin_b joined
[18:51] <domidumont> FROGGS: me neither...

[18:58] *** JimmyZ joined
[19:30] *** dalek joined
[19:56] *** vendethiel joined
[20:29] *** stmuk joined
[20:38] *** brrt joined
[20:38] <brrt> it's in a zombie state, iirc, because moar spawned it, it has exited, but moar hasn't yet reaped it

[20:38] <brrt> reaping involves wait()-ing

[20:39] <brrt> also, if it is hung, start gdb, and attach to it using gdb attach

[20:39] <timotimo> so how in the hell is libuv missing it?

[20:39] <brrt> that will give you access to the live heap and threads

[20:39] <brrt> that, i don't know :-)

[20:40] <brrt> can't be a knowitall and actually know everything, now can i

[20:40] <brrt> :-P

[20:40] <timotimo> of course

[20:41] * brrt finds his personal laptop to be faster than his work macbook, and is surprised about it

[20:43] <timotimo> huh

[20:43] <timotimo> but maybe it has more battery life

[20:43] <timotimo> or something

[20:51] *** Dunearhp joined
[20:51] <brrt> it does, yes

[20:51] <brrt> and it is more silent

[20:51] <brrt> but speed is also important

[21:02] <timotimo> if only there was a way to tell a big beefy machine what to do and it could do whatever you want for you

[21:02] <brrt> yes, over the internet or something like that

[21:02] <timotimo> yeah, or maybe just over the phone or something

[21:02] <timotimo> maybe tell it via a telegram

[21:08] *** Dunearhp joined
[21:18] <brrt> running classification algorithms in pl/pgsql; not the cleverest of ideas

[21:33] <timotimo> i wonder when i should look out for more stuff being compiled than last time i looked (with the new jit)

[22:00] <japhb> .ask brrt Classifying what?

[22:00] <japhb> SIGH

[22:00] <timotimo> i believe brrt backlogs

[22:00] <timotimo> at the very least this channel completely

[22:05] * jnthn would be fine with us having a message bot here, fwiw

[22:08] <timotimo> right

[22:08] <japhb> I'm not a chanop.  Can someone /invite yoleaux ?

[22:08] <japhb> Or convince $Zoffix to bring one.  :-)

[22:15] <geekosaur> also not a chanop, sorry

[22:24] <jnthn> grmbl, it won't let me op myself

[22:25] <timotimo> jnthn: i've thought a few times about how we're going to do the "grab a private chunk from the fsa" thing for fast per-thread allocations

[22:26] <jnthn> timotimo: Did you read the paper on the hoard allocator?

[22:26] <timotimo> oh, no

[22:26] <jnthn> It's good food for thought at a minimum :)

[22:26] <timotimo> i was just wondering, are individual threads 100% owners of the lexical environments and locals that go with frames?

[22:26] <timotimo> because frames can still escape and become GC-managed, right?

[22:26] <jnthn> Sure

[22:27] <jnthn> And locals too

[22:27] <jnthn> Uh, locals can as well as lexicals I mean

[22:27] <jnthn> Consider a continuation taken in one thread and resumed in another

[22:27] <timotimo> oh, that is because all threads are stopped when gc happens

[22:28] <timotimo> and items that belong to another thread get passed to that thread's inbox, yeah?

[22:28] <timotimo> that's what that is for?

[22:28] <jnthn> Yeah

[22:28] <jnthn> At GC time, we take the set of threads that are alive and divide up the full set of threads among them

[22:28] <jnthn> Hm, awake is better than alive I guess

[22:29] <timotimo> i suggest "not blocked"

[22:29] <jnthn> Yes, even better :)

[22:29] <jnthn> So the inbox is processed by whichever thread is GCing the thread in question.

[22:30] <timotimo> OK. we have freelists for these pages, right? i'd need to check if the whole page has become free by going through the freelist, or do we count how many things are still allocated in there?

[22:30] <jnthn> No, you'd have to check it's entirely a fresslist

[22:30] <jnthn> *freelist

[22:30] <timotimo> OK

[22:30] <jnthn> We could of course add metadata on that

[22:30] <timotimo> i'm just doing a broad survey of the problem to see if maybe i'd be able to pull it off easily

[22:31] <jnthn> I'm not sure I'd call it "easy"

[22:31] <timotimo> do you see difficulties for this that i might miss?

[22:31] <jnthn> Well, I suggest at least skimming the hoard paper

[22:32] <jnthn> It does iirc nicely make the point that if you're not careful, you can get into trouble with producer/consumer patterns

[22:32] <jnthn> And discuss how they mitigate that

[22:32] <timotimo> oh, because the consumer will get all these objects passed that now belong to another thread

[22:33] <timotimo> and they'll come to die in that other thread

[22:33] <jnthn> Yeah

[22:33] <jnthn> You could end up with one thread having tons of empty pages

[22:33] <jnthn> Or similar

[22:33] <timotimo> becaus we won't compact, yeah

[22:34] <timotimo> so we're already going to use these private pages for everything, not "only" lexical environments and locals

[22:34] <jnthn> I remember reading the paper when pondering the problem and it convinced me that I needed to think harder about it :)

[22:34] <timotimo> OK, that's a good warning :)

[22:34] <jnthn> Or put better, it convinced me that it's easy to get some bad failure modes with naive solutions.

[22:35] <jnthn> The current failure mode is "argh slow", which is desirable to fix, but not if the alternative is "argh some kinds of program eat infinite memory" :)

[22:35] <jnthn> On thread locality though, I'd assume at the moment that everything can escape between threads

[22:35] <jnthn> At some point in the future we'll have EA

[22:36] <timotimo> right

[22:36] <jnthn> And be able to do better there

[22:36] <jnthn> Also

[22:36] <jnthn> We already do a basic kind of EA

[22:36] <timotimo> right, for frames

[22:36] <jnthn> In that we allocate frames on the callstack region

[22:36] <timotimo> yeah

[22:36] <jnthn> And we can extend that without too much trouble to include the lexicals, iirc

[22:36] <jnthn> Did the analysis on that a while ago

[22:36] <timotimo> if we end up with a bunch of pages that are mostly empty belonging privately to a thread, they could go back into the global pool

[22:36] <jnthn> Yeah

[22:36] <timotimo> but before i speculate more, i'll read that paper

[22:37] <jnthn> Yeah, I found it useful

[22:37] <jnthn> Though mostly in that it convinced me to put the problem off rather than hurt our userbase with a half-assed solution :)

[22:38] <timotimo> fair enough

[22:38] <timotimo> maybe i'll go through with the "allocate two things at once with the same lock" and do some measurements how that feels

[22:38] <jnthn> (And no, not trying to discourage you from working on it, just warning you it's not trivial. :))

[22:38] <timotimo> i appreciate that you're not just letting me run into an open blade ;)

[22:39] <timotimo> (not sure if that makes sense to say in english)

[22:40] <jnthn> It's...not an idiom I've heard of, but I can parse it :)

[22:40] <timotimo> "in's offene messer laufen lassen" in german

[22:53] <dalek> MoarVM: f2369b4 | timotimo++ | src/io/dirops.c:

[22:53] <dalek> MoarVM: ensure errno is grabbed before MVM_free is called

[22:53] <dalek> MoarVM: review: https://github.com/MoarVM/MoarVM/commit/f2369b4784

[23:21] *** geekosaur joined
[23:25] <timotimo> neat, horde will re-use completely freed pages for any other size that may exist

[23:25] <timotimo> i'm not actually sure if our gen2 pages are each of the same size, though, or if they depend on the size of the objects that go in them

[23:27] <timotimo> looks like to achieve the sorting into bins ordered by "freeness" we'll have to have a "amount of allocated objects" piece of metadata per page

[23:35] *** avar joined
