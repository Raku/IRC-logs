[01:43] *** eternaleye joined
[03:31] *** woosley joined
[03:55] *** woosley joined
[04:13] *** colomon joined
[05:46] * lue is almost surprised the macro-happy-ish source didn't factor out sigs beginning with (MVMThreadContext *tc, to SIG_TC(    :)

[07:11] *** FROGGS joined
[07:21] <FROGGS> lue: jnthn is not fond of overmacroing it :o)

[10:33] *** jnthn joined
[10:56] <FROGGS> hmmm, nqp-m -e '1' takes 0m0.175s while nqp-p slurps in a 35kb text file within 0m0.112s

[10:56] <FROGGS> nqp-m needs 0m0.209s to slurp it

[11:03] <tadzik> man the profilers! :P

[11:07] <FROGGS> already doing :o)

[11:07] <FROGGS> but lunch first

[11:07] <FROGGS> &

[12:14] *** tgt joined
[12:34] *** woolfy left
[12:45] <FROGGS> jnthn: here is the heap profile for `nqp-m -e 1` btw http://froggs.de/perl6/nqpm-e1.ps

[12:46] <FROGGS> though, might not that readable on screen for you :/

[12:52] <timotimo> i can't get that to render in okular nor evince

[12:52] <timotimo> ah, converted it to a pdf, now it works

[12:53] * timotimo doesn't know what to do with that info

[12:54] <jnthn> hm...can I have that PDF? :)

[12:54] * nwc10 can confirm that it renders OK here, but no good idea what to do with that info, even if I have time, which I don't

[12:54] <timotimo> jnthn: you don't have ps2pdf installed? ;)

[12:54] <timotimo> gimme a sec.

[12:54] <timotimo> where do i upload this to :|

[12:55] * timotimo mails it

[12:58] <jnthn> oh, nice!

[12:58] <jnthn> FROGGS: When I see somehting like:

[12:59] <timotimo> so, that was memory usage, not time usage, right?

[12:59] <jnthn> deserialize_frames

[12:59] <jnthn> 0.1 (1.4%)

[12:59] <jnthn> of 0.6 (5.4%)

[12:59] <timotimo> yeah, heap profile

[12:59] <jnthn> What are the first and second lines about?

[12:59] <jnthn> incl/excl?

[12:59] <timotimo> it seems to me one is the time the thing itself takes, the other the thing plus its children

[12:59] <jnthn> But that doesn't make sense to me either...

[12:59] <timotimo> and one compared to its parents

[12:59] <timotimo> fwiw, 10 MB is pretty decent

[13:00] <jnthn> Yeah.

[13:01] <jnthn> That add_page mallocs most is not so surprising.

[13:02] <jnthn> But we may want to tweak bin sizing or something.

[13:04] *** FROGGS joined
[13:05] <FROGGS> jnthn: there is also other stuff that I can generate, see http://code.google.com/p/gperftools/wiki/GooglePerformanceTools

[13:05] <timotimo> ah, it's perf!

[13:05] <timotimo> perf is so excellent :)

[13:06] <timotimo> oh, wait, that's not the thing i was thinking of

[13:07] <jnthn> FROGGS: Hm, what does the CPUPROFILE thing give as output?

[13:07] <FROGGS> jnthn: I'll look into that after $meeting

[13:44] *** tgt joined
[14:12] *** jnap joined
[15:02] *** tgt joined
[15:15] *** FROGGS[mobile] joined
[15:58] *** FROGGS joined
[18:13] *** ssutch joined
[19:20] *** lizmat joined
[19:27] *** tgt joined
[19:42] <FROGGS> jnthn: http://froggs.de/perl6/cpu_nqpm-e1.pdf

[19:45] <nwc10> that was a long meeting :-)

[19:46] <nwc10> [yes, strictly, "after" doesn't mean "immediately after"]

[19:47] <FROGGS> http://froggs.de/perl6/cpu_nqpm_slurp35kb.pdf

[19:48] <FROGGS> nwc10: I had to find out first why it didn't work :o)

[19:49] <jnthn> FROGGS: Normally 'cus nobody listens, or there's not enough coffee...

[19:50] <FROGGS> hmm?

[19:50] <jnthn> Why meetings don't work :P

[19:50] <FROGGS> hehe

[19:50] <FROGGS> well, yeah

[19:51] <jnthn> OK, I can see things to do from this graph :)

[19:51] <FROGGS> it was kinda ridiculous

[19:51] <FROGGS> that is a nice renderer btw

[19:52] <jnthn> One outstanding task is to get the serialization blog dragged out of the string heap and into its own segment.

[19:52] <jnthn> uh, blob.

[19:53] <jnthn> heh, serialization blog. That's be fascinating. "I just wrote an int32 to disk!" "I just wrote an int16 to disk!" "I just wrote a string heap index!"

[19:54] <nwc10> instead couldn't you send it to Twitter, and see if it improves the signal to noise ratio?

[19:54] <nwc10> and find out how many followers you pick up

[19:59] *** lizmat joined
[20:18] <diakopter> FROGGS: the numbers in that graph seem much too small to indicate anything

[20:19] <diakopter> sample size, I mean

[20:19] <diakopter> only 15 samples?

[20:20] <FROGGS> well, I'd need a better test case then :o)

[20:21] <jnthn> If the test case is "startup"... :)

[20:21] <jnthn> The exact percentages may be a bit off (sampling profilers trade that in for low overhead), but I think the big picture is quite believable.

[20:23] <FROGGS> gperf I used earlier lets you rerun the test and merge the results to get better percentages

[20:23] <jnthn> Ah, that'd do nicely too :)

[20:28] <FROGGS> btw, the first trap I fell into was when looking at the heapmap: why does add_page take so long?

[20:29] <FROGGS> I know, it was silly of me :o)

[20:32] <jnthn> It's fast, just hungry. Like a cheetah that didn't eat in a while.

[20:56] <FROGGS> diakopter: I was able to increase the sample size...

[20:56] <diakopter> ok :)

[20:57] <diakopter> url?

[20:57] <FROGGS> http://froggs.de/perl6/cpu_nqpm-e1.pdf

[20:57] <FROGGS> same link as before, I hope it does not cache it

[20:57] <diakopter> invalid pdf

[20:58] <diakopter> (web server cached some partial write?)

[20:58] <FROGGS> ohh, the upload got stuck

[21:00] <FROGGS> hmmm

[21:00] <FROGGS> diakopter: now?

[21:10] <nwc10> thought I had a few days ago - PyPy 2.2 recently released emphasising that it's just gained incremental GC: http://morepypy.blogspot.co.uk/2013/11/pypy-22-incrementalism.html

[21:10] <diakopter> yeah, but 39 is still way too small; I posted a link to the output of somehting that instrumented and logged millions of calls

[21:10] <nwc10> Incremetnal GC seemed to be a big new feature of Rubinius recently

[21:11] <jnthn> diakopter: sampling != instrumental

[21:11] <nwc10> superficially this looks like "everyone needs incremental GC"

[21:11] <diakopter> I know.

[21:11] <diakopter> jnthn: my point was that it's possible to sampl all of them.

[21:11] <diakopter> and that 39 is miniscule compared to what it could get

[21:11] <nwc10> but I think it actually means "you can be a sucessful project for at least 5 years before incremental GC becomes the most important thing to fix"

[21:11] <FROGGS> diakopter: then I'd need to set the sample-per-seconds to a gazillion

[21:12] <jnthn> diakopter: Yes, mine is that IME even a smallish number of samples (granted, normally 100s, not 10s) can be enough to give a good idea... :)

[21:12] <diakopter> FROGGS: definitely... try it.. set it to 10,000

[21:12] <diakopter> at least

[21:12] <diakopter> or 1e6

[21:12] <FROGGS> that was the command: LD_PRELOAD="/usr/lib/libprofiler.so" CPUPROFILE_FREQUENCY=1000000 CPUPROFILE=_cpuprofile nqp-m -e 1

[21:12] <FROGGS> I can add more zeros though :o)

[21:13] <diakopter> but anyway the total startup time is quite good; why optimize that?

[21:13] <diakopter> (it's like 8ms on windows msvc)

[21:13] <diakopter> at least 50s goes to loading shared libraries

[21:13] <jnthn> nwc10: Incremental is a bit of a trade-off too. In general, shorter pause times trade off against overall throughput.

[21:14] <FROGGS> the startup time is at 0.2s while nqp-p can startup and slurp a 35kb test file within 0.125s

[21:14] <nwc10> jnthn: yes, I remember you saying that, and it seems intuitive

[21:14] <FROGGS> diakopter: nqp-m's startup time?

[21:14] <diakopter> yes?

[21:14] <nwc10> I guess what's been bugging them is that they have users who want to write games or stuff with some degree of desired responsiveness

[21:15] <nwc10> but, anyway, at least 5 years until it matters :-)

[21:15] <jnthn> As another data point, .Net ships with a client GC and a server GC

[21:15] <diakopter> I vehemently disagree; there are tons of definitions of "successful project" and I dont think pypy meets very many of them

[21:16] <FROGGS> I would say that C is successful

[21:16] <diakopter> who wouldn't?

[21:16] <FROGGS> :o)

[21:19] <diakopter> if there were only 39 samples, and it was trying to make 1e6 of them per second, then it seems it only profiled for 39 microseconds

[21:20] <FROGGS> which is weird that the samples only increase to 41 when I add several zeros

[21:20] <diakopter> well, it's reached some limit

[21:21] <diakopter> which isn't helpful for such short-lived programs

[21:21] <diakopter> I already reported that 90% of the startup time (in code, not loading shared libraries) was spent in deserialization

[21:22] <diakopter> (and nearly all of that in decoding and initialization strings)

[21:22] <diakopter> *initializing

[21:23] <diakopter> nwc10: from what the rubinius x guy said, pypy basically failed to garner hardly any users

[21:23] <nwc10> diakopter: oh interesting. Where did he say that? I'd not spotted that

[21:24] <nwc10> implied - Rubinius has won itself a userbase?

[21:25] <diakopter> he didn't seem to imply that

[21:26] <nwc10> oh, OK.

[21:26] <diakopter> ergh

[21:45] *** benabik joined
[22:07] *** benabik joined
[22:18] *** lizmat joined
[22:41] *** BenGoldberg joined
[22:41] *** woolfy joined
