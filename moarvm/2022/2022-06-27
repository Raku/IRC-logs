[00:07] *** reportable6 left
[00:10] *** reportable6 joined
[00:35] <Geth> ¦ MoarVM/validator_labels_array_bitfield: 1744a2e45a | (Timo Paulssen)++ | src/core/validation.c

[00:35] <Geth> ¦ MoarVM/validator_labels_array_bitfield: use fixedsize allocator in validator for labels arr

[00:35] <Geth> ¦ MoarVM/validator_labels_array_bitfield: review: https://github.com/MoarVM/MoarVM/commit/1744a2e45a

[00:35] <Geth> ¦ MoarVM/validator_labels_array_bitfield: 86bc450310 | (Timo Paulssen)++ | src/core/validation.c

[00:35] <Geth> ¦ MoarVM/validator_labels_array_bitfield: use bitfield for validator label positions

[00:35] <Geth> ¦ MoarVM/validator_labels_array_bitfield: review: https://github.com/MoarVM/MoarVM/commit/86bc450310

[00:35] <timo> anyone want to test if this improves startup times? it kind of looks like it doesn't on my machine

[00:38] <timo> raku -e 'say "hi"' allocates a total of 380 kbytes with this patch, so it'd have been 4 times that without. that's only the sum, though, and these allocations are short-lived, too

[00:42] <timo> about 300 kbytes is the size of the biggest single allocation without the / 4 factor

[00:42] <timo> i think we can even still halve the size, since we are 16 bit aligned with the bytecode at the moment

[00:42] *** vrurg left
[00:43] *** vrurg joined
[00:54] <Geth> ¦ MoarVM/validator_labels_array_bitfield: 02e896f923 | (Timo Paulssen)++ | src/core/validation.c

[00:54] <Geth> ¦ MoarVM/validator_labels_array_bitfield: branchlessly update fb->specializable

[00:54] <Geth> ¦ MoarVM/validator_labels_array_bitfield: review: https://github.com/MoarVM/MoarVM/commit/02e896f923

[00:54] <timo> this little bit of code actually emitted a branch, believe it or not :P

[00:54] <timo> here's where the real perf happens

[00:56] <timo> it feels like the validator is a good candidate for a little bit of vectorization work

[01:47] *** kjp left
[01:49] <Geth> ¦ MoarVM/update_ops_look_for_preexisting_sequences: a2b60e7003 | (Timo Paulssen)++ | tools/update_ops.raku

[01:49] <Geth> ¦ MoarVM/update_ops_look_for_preexisting_sequences: find a new op's argument flags in earlier ops

[01:49] <Geth> ¦ MoarVM/update_ops_look_for_preexisting_sequences: review: https://github.com/MoarVM/MoarVM/commit/a2b60e7003

[01:51] <timo> the code here spits out that the space taken up by flags for ops could shrink from 2.4kbytes down to 925 bytes. however, that does not include that when we move the operands flags out, all ops will still have a pointer-sized entry in them. could go down to two bytes if turned into an offset into the array of all flags, though?

[01:54] <timo> 1916 bytes of offsets or 7664 bytes of pointers

[01:54] <timo> so the 2.4kbytes would be if all flags were concatenated, skipping the empty flags, which are currently inlined to the MVMOpInfo struct and therefore always 8 bytes big

[01:55] <timo> but in fact, the total size based 

[01:55] <timo> on the 8 bytes for flags is the same as the 7664 number

[01:56] <timo> so if we have a big buffer of flags that would be just 925 bytes big, we'll pay an additional 1916 bytes to put indices where the flags lived

[01:56] <timo> m: say 7664 - (925 + 1916)

[01:56] <camelia> rakudo-moar 7cf264572: OUTPUT: «4823␤»

[01:57] <timo> m: say 7664 - (2497 + 1916)

[01:57] <camelia> rakudo-moar 7cf264572: OUTPUT: «3251␤»

[01:58] <timo> we could save 3251 bytes with a simple approach (just concatenate and then save 6 bytes per op info entry) or 4823 bytes with a slightly more involved approach (find op flags anywhere earlier in the op flags buffer, including overlapping between different ops)

[01:59] <timo> this is also a "smallest common supersequence" problem that can be solved to optimize that 925 number even further

[02:01] <timo> little trade-off here in code complexity (a pointer indirection every time we need to get at an op's flags) growing, but memory in total shrinking

[02:02] <timo> always count on timo to swoop in with some probably only barely useful optimization idea

[02:45] *** frost joined
[03:45] *** coverable6 left
[03:45] *** releasable6 left
[03:45] *** bloatable6 left
[03:45] *** notable6 left
[03:45] *** unicodable6 left
[03:45] *** greppable6 left
[03:45] *** benchable6 left
[03:45] *** evalable6 left
[03:45] *** sourceable6 left
[03:45] *** shareable6 left
[03:45] *** quotable6 left
[03:45] *** linkable6 left
[03:45] *** reportable6 left
[03:45] *** nativecallable6 left
[03:45] *** statisfiable6 left
[03:45] *** tellable6 left
[03:45] *** committable6 left
[03:45] *** bisectable6 left
[03:45] *** quotable6 joined
[03:45] *** shareable6 joined
[03:45] *** linkable6 joined
[03:45] *** bloatable6 joined
[03:45] *** committable6 joined
[03:46] *** coverable6 joined
[03:46] *** bisectable6 joined
[03:46] *** statisfiable6 joined
[03:46] *** notable6 joined
[03:46] *** greppable6 joined
[03:47] *** releasable6 joined
[03:47] *** sourceable6 joined
[03:47] *** reportable6 joined
[03:47] *** unicodable6 joined
[03:47] *** evalable6 joined
[03:47] *** benchable6 joined
[03:47] *** nativecallable6 joined
[03:48] *** tellable6 joined
[04:48] *** statisfiable6 left
[04:48] *** reportable6 left
[04:48] *** tellable6 left
[04:48] *** unicodable6 left
[04:48] *** bloatable6 left
[04:48] *** committable6 left
[04:48] *** nativecallable6 left
[04:48] *** linkable6 left
[04:48] *** evalable6 left
[04:48] *** bisectable6 left
[04:48] *** benchable6 left
[04:48] *** notable6 left
[04:48] *** coverable6 left
[04:48] *** sourceable6 left
[04:48] *** greppable6 left
[04:48] *** releasable6 left
[04:48] *** shareable6 left
[04:48] *** quotable6 left
[04:49] *** shareable6 joined
[04:49] *** bisectable6 joined
[04:49] *** bloatable6 joined
[04:49] *** coverable6 joined
[04:49] *** committable6 joined
[04:49] *** reportable6 joined
[04:49] *** benchable6 joined
[04:49] *** linkable6 joined
[04:50] *** evalable6 joined
[04:50] *** tellable6 joined
[04:50] *** greppable6 joined
[04:50] *** nativecallable6 joined
[04:50] *** releasable6 joined
[04:51] *** quotable6 joined
[04:51] *** sourceable6 joined
[04:51] *** notable6 joined
[04:51] *** statisfiable6 joined
[04:51] *** unicodable6 joined
[05:51] *** benchable6 left
[05:51] *** releasable6 left
[05:51] *** unicodable6 left
[05:51] *** notable6 left
[05:51] *** bloatable6 left
[05:51] *** shareable6 left
[05:51] *** linkable6 left
[05:51] *** evalable6 left
[05:51] *** tellable6 left
[05:51] *** quotable6 left
[05:51] *** sourceable6 left
[05:51] *** statisfiable6 left
[05:51] *** committable6 left
[05:51] *** greppable6 left
[05:51] *** bisectable6 left
[05:51] *** reportable6 left
[05:51] *** coverable6 left
[05:51] *** nativecallable6 left
[05:51] *** tellable6 joined
[05:51] *** bloatable6 joined
[05:51] *** coverable6 joined
[05:52] *** statisfiable6 joined
[05:52] *** reportable6 joined
[05:52] *** notable6 joined
[05:52] *** sourceable6 joined
[05:52] *** bisectable6 joined
[05:52] *** benchable6 joined
[05:52] *** releasable6 joined
[05:52] *** shareable6 joined
[05:52] *** committable6 joined
[05:52] *** greppable6 joined
[05:53] *** nativecallable6 joined
[05:53] *** unicodable6 joined
[05:53] *** evalable6 joined
[05:53] *** quotable6 joined
[05:53] *** linkable6 joined
[06:07] *** reportable6 left
[06:08] *** reportable6 joined
[06:38] <nine> Huh...I thought the fixed size allocator went away when we switched to mimalloc

[07:23] <timo> oh, is mimalloc good enough at that? okay :D

[07:23] <timo> i'm woefully out of date, clearly

[07:27] <nine> Apparently we haven't thrown out the fixed size allocator yet, but it doesn't give any advantages over mimalloc

[07:37] <timo> we don't even get storage reduction through not double-tracking allocation sizes?

[07:48] <nine> Don't know about that one

[08:28] *** frost left
[08:31] *** frost joined
[08:36] <timo> well, the branch is not only fixedsized allocator transformation. maybe the rest is still worth having

[08:37] <timo> but i may not have time to measure things properly today

[09:09] *** crystalfrost[m] joined
[09:10] <nine> 482 spectest files passing on RakuAST. 302 without doing a non-RakuAST spectest run first

[09:10] <timo> \o/

[09:30] *** linkable6 left
[09:30] *** linkable6 joined
[09:37] *** Altai-man joined
[09:40] *** sena_kun left
[09:48] *** Altai-man left
[10:33] *** sena_kun joined
[11:15] <lizmat> nine++

[12:08] *** reportable6 left
[12:10] *** reportable6 joined
[12:15] *** frost left
[12:33] *** frost joined
[13:26] *** frost left
[14:21] <lizmat> And yet another Rakudo Weekly News hits the Net: https://rakudoweekly.blog/2022/06/27/2022-26-conference-seasoned/

[14:43] <vrurg> I wonder if valgrind is capable of helping me to trace down likely memory issues. In my work project I get errors like Buf[int8] not matching Blob, VMNull from symbol lookups, etc. Could be caused by double-free, wrong pointers, whatever. But for now I have no clue what to look at.

[15:22] <timo> it's worth a try at least, but i can't make any guarantees

[17:17] *** vrurg_ joined
[17:17] *** vrurg left
[17:26] *** sena_kun left
[18:07] *** reportable6 left
[18:08] *** reportable6 joined
[18:18] *** sena_kun joined
[19:17] *** japhb left
[19:19] *** sena_kun left
[19:20] *** sena_kun joined
[19:22] *** japhb joined
[19:41] *** sena_kun left
[19:46] *** vrurg_ is now known as vrurg

[20:04] *** sena_kun joined
[21:49] *** kjp joined
[23:14] *** [Coke]_ joined
[23:16] *** [Coke] left
[23:28] *** mst left
