[00:21] *** benabik joined
[01:16] *** FROGGS_ joined
[02:04] *** benabik joined
[02:08] *** jnap joined
[02:24] *** donaldh joined
[04:26] *** jnap1 joined
[05:26] *** jnap joined
[05:57] *** vendethiel joined
[06:24] *** vendethiel joined
[06:26] *** vendethiel joined
[06:27] *** jnap joined
[06:32] *** vendethiel joined
[06:56] *** FROGGS joined
[07:03] *** Ven joined
[07:05] *** zakharyas joined
[07:16] *** donaldh_ joined
[07:28] *** jnap joined
[08:29] *** jnap joined
[08:53] <jnthn> short backlog is short...

[09:05] <FROGGS> jnthn: come over to #perl6... we have cookies! :o)

[09:09] *** domidumont joined
[09:18] *** domidumont joined
[09:28] *** woosley joined
[09:29] *** jnap joined
[09:34] *** domidumont joined
[10:30] *** jnap joined
[10:51] <nwc10> jnthn: stage timing numbers are sufficiently variable on the Pi (with spinning rust swap) that I don't think that I can make sensible decisions about optimisation strategies

[10:51] <nwc10> (other than "reduce the I64s")

[10:51] <nwc10> but it is adequate for basic porting, and basic "does it pass tests"

[10:52] <nwc10> I think that the problem is "spinning rust swap" - solid state swap (of any form) might be more repeatable

[10:55] <jnthn> nwc10: Makes sense. At the point things are giving more stable numbers, profiling at C level may also be informative.

[10:56] <nwc10> there's more important stuff to nail first

[10:56] <nwc10> portability

[10:56] <nwc10> and performance on "modern" hardware against the percieved competition

[10:57] <nwc10> where I am actually unsure as to what the percieved competition is

[10:57] <nwc10> not just using wooly language to be diplomatic

[11:31] *** jnap joined
[11:34] <jnthn> Mostly for me it's not so much winning benchmarks as having people using Rakudo not immediately feel "ooh, it's slow!"

[11:39] <nwc10> yes, sorry, to be clear, by "performance" I didn't mean benchmarks

[11:39] <nwc10> having viable concurrency is going to mean that "good enough" elsewhere is sufficient

[11:41] <nwc10> whippitupitude and manipulexity for the win.

[11:41] <bonsaikitten> just don't be consistently last in benchmarks ;)

[12:32] *** jnap joined
[13:32] *** jnap joined
[13:35] *** jnap left
[14:00] *** btyler joined
[14:21] *** jnap joined
[14:28] *** retupmoca joined
[16:07] <japhb> I stand by my general feeling from last year: <2x slower than perl5: good; <10x slower than perl5: OK; anything worse: BAD.

[16:07] <TimToady> well, we probably need to fix the O(N^2) in strings

[16:07] <nwc10> jnthn: I'm also thinkin that 10x is the minimal target

[16:08] *** jnap1 joined
[16:10] <japhb> TimToady: Yeah, string performance is near the top of my "still painful in r-m" list.  :-/

[16:11] <TimToady> my gut feeling is that a lot of our improvement will come from better native int array handling, which will also be fundamental for NFG

[16:12] <TimToady> it would be nice if we could write the NFG implementatoin in Perl 6 and have it be fast

[16:12] <jnthn> Seems unlikely in the near term.

[16:12] <jnthn> At least, it's not the fast path to having strings performing well.

[16:13] <jnthn> There's just a bunch of hard things needing doing to get Perl 6 code to perform well.

[16:13] <jnthn> I'm working through them, but there's a dozen other things needing my attention too.

[16:14] <TimToady> sure, I'm just looking forward to the day when I can write my C code in Perl 6 :)

[16:14] <jnthn> *nod*

[16:14] <jnthn> The other thing that'd help on Moar is figuring out why we can't build with -O3 on gcc

[16:15] <TimToady> is that also true of clang?

[16:15] <jnthn> Not sure.

[16:15] <jnthn> I do know that when I got some native int loop benchmark to run faster than my system Perl 5 locally by a factor of 2-3, nobody else could reproduce it with other compilers. Nor can I, for that matter.

[16:16] <jnthn> r-m in my Linux VM using GCC is notably slower then r-m built with MSVC running outside the VM

[16:16] <jnthn> Of course, virtualization may be a little to blame, but it can't take all the blame.

[16:16] <jnthn> But we only gcc -O1 at present.

[16:16] <jnthn> So -O3 may easily make up the difference.

[16:18] <TimToady> I'm thinking we should have NFG and uniprops written in Perl 6 for portability, then backtranslate to native VM where necessary for speed

[16:18] <TimToady> or at least in nqp rather than in C

[16:19] <jnthn> NQP is more feasible.

[16:20] <jnthn> But doing that right now is not likely to lead us quickly to faster strings.

[16:21] <jnthn> Post-JIT/inlining/escape-analysis etc? Perhaps then it's OK.

[16:22] <nwc10> doing right now in NQP is likely to get to a working prototype more quickly, even if that implementation isn't (yet) fast

[16:22] <TimToady> uniprops in non-C would give us uniprops on the other backends

[16:22] <nwc10> someone doing it at all is better than it not happening yet :-)

[16:22] <TimToady> and just thinking we'll understand the semantics of NFG better if it's prototyped in a higher language

[16:22] <nwc10> meanwhile, unlike last Sunday, the prospects are looking good for the hammock

[16:24] <TimToady> and certainly a linear but slowish P6 implementation of NFG will beat out a fast but quadratic C implementation for many real-world problems

[16:24] <jnthn> True

[16:25] <TimToady> and we could call it NFGish, and play with it, while keeping the default at codepoints for now

[16:26] <TimToady> well, just thinking where I could apply the most leverage over this summer that would be complementary to what you're doing

[16:27] <jnthn> If somebody wants to work on doing this at NQP level, that works fine for me. If so, I'll focus on trying to make it so the NQP impl runs fast enough anyway :)

[16:27] *** lue joined
[16:27] <jnthn> Well, question is what I should work on. I suspect performance and concurrency things and hard bugs?

[16:28] <TimToady> makes sense to me

[16:28] <jnthn> That's the kinda trajectory I'd been considering.

[16:28] <lizmat> I wouldn't mind giving NFG a stab in NQP

[16:28] <TimToady> another direction I'm anxious to push is multi-dim arrays, but I suspect someone other than jnthn++ should do that

[16:29] <lizmat> didn't we have patches for that already ?

[16:29] <TimToady> it does get down into repr issues thoguh

[16:29] <lizmat> but jnthn wasn't happy with them ?

[16:29] <TimToady> though, even

[16:29] <jnthn> Well, yeah, it wants some level of VM support

[16:29] <jnthn> native arrays surely do

[16:29] <jnthn> Same for fixed size

[16:31] <japhb> I still really want to be able to look at a single memory extent with many different packed array "views" on it.

[16:31] * TimToady just gets a little tired of writing .[@x]Â».[@y] to do 2-dimensional slices, when [@x;@y] oughta work

[16:32] <TimToady> and there's a bunch of RC tasks waiting for matrices :)

[16:32] <japhb> rcdd

[16:32] <japhb> :-)

[16:32] <TimToady> ayup :)

[16:33] <TimToady> RC is a pretty good measure of generalpurposenesslessnesslessness

[16:33] <japhb> Well it certainly does reward whipuptitude

[16:34] <lizmat> .oO( RC? )

[16:35] <nwc10> fail! a big cloud

[16:36] <japhb> lizmat: Rosetta Code

[16:36] <lizmat> ah, duh  :-)

[16:36] <lizmat> japhb++

[17:03] *** FROGGS joined
[17:47] <jnthn> OK, time to make dinner, then some hacking :)

[17:47] *** woolfy1 joined
[18:39] *** zakharyas joined
[19:19] <timotimo> yay

[20:21] <timotimo> i wonder if jnthn dinner'd successfully yet

[20:23] <lizmat> perhaps jnthn is enjoying a post-dinner nap

[20:24] <timotimo> mhm :)

[20:26] <lizmat> or he is silently hacking away not paying attention to us attention cravers :-)

[20:28] <jnthn> I cooked steak with bernaise sauce, nommed it, then felt like a walk :)

[20:46] *** benabik joined
[20:48] <jnthn> So, let's find out what exactly causes the NQP parse fail in the latest spesh stuff...

[21:12] <jnthn> Seems it's something to do with using spesh log of invoke_o results

[21:16] <jnthn> Darn, this is a pain to find...

[21:28] <jnthn> hah, narrowed it down to soemthing involving the pblock rule and an opt done off invoke_o's logging

[21:29] <tadzik> jnthn: do you have a working testcase for that closures/nativecall bug?

[21:30] <jnthn> tadzik: No, I ran into it, investigated enough to find the workaround I sent you as a hack, and that was all...

[21:30] <tadzik> ah

[21:31] <tadzik> not sure if I told you, but the hack makes things segfault :)

[21:32] <jnthn> ergh

[21:32] <jnthn> OK, that didn't happen ehre

[21:37] *** benabik joined
[21:57] <jnthn> Grr

[21:57] <jnthn> The more I narrow it down, the odder it gets

[23:07] <jnthn> By now I've got it down to the exact transformation that breaks it, and it still makes little sense... :/

[23:14] <jnthn> Well, will sleep on it. 'night
