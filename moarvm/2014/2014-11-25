[00:10] <timotimo> cool :)

[02:06] <dalek> MoarVM: 4d3c45d | jimmy++ | src/jit/emit_x64.dasc:

[02:06] <dalek> MoarVM: s/dec/sub/ && s/inc/add/, which is cheaper

[02:06] <dalek> MoarVM: review: https://github.com/MoarVM/MoarVM/commit/4d3c45d2d7

[02:07] <timotimo> https://stackoverflow.com/questions/13383407/is-add-1-really-faster-than-inc-x86  /  https://stackoverflow.com/questions/12163610/why-inc-and-add-1-have-different-performances  /  https://stackoverflow.com/questions/5993326/relative-performance-of-x86-inc-vs-add-instruction

[02:11] <timotimo> On some micro-architectures, with some instruction streams, INC will incur a "partial flags update stall" (because it updates some of the flags while preserving the others).  ADD sets the value of all of the flags, and so does not risk such a stall.

[02:11] <timotimo> that's apparently what's up

[02:14] *** jimmy_ joined
[02:14] <jimmy_> which means it's better to do out-of-order execution?

[02:15] <japhb> Or at least use multiple execution units more effectively

[02:24] *** timotimo joined
[02:30] <JimmyZ> https://stackoverflow.com/questions/12163610/why-inc-and-add-1-have-different-performances?answertab=votes#tab-top

[02:47] <timotimo> so, did our performance just go through the roof? :)

[03:43] <hoelzro> so I'm trying to understand how bytecode loading works

[03:44] <hoelzro> I see these calls to nqp::loadbytecode in ModuleLoader.nqp, but I don't understand how the loaded symbols make it into @GLOBALish

[03:45] <JimmyZ> MVM_cu_from_bytes ?

[03:46] <hoelzro> JimmyZ: you probably know better than I =)

[03:47] <hoelzro> I just don't see any return value being used, so I'm guessing something in NQP/Moar pushes something into @GLOBALish through a reference of some sort

[03:48] <JimmyZ> anyway, the code is in src/core/compunit.c which returns a compunit

[06:05] *** jimmy_ joined
[07:05] <dalek> MoarVM: 9e03616 | TimToady++ | src/6model/reprs/NFA.c:

[07:05] <dalek> MoarVM: act needs to fit into 32-bit signed (for jvm)

[07:05] <dalek> MoarVM: review: https://github.com/MoarVM/MoarVM/commit/9e03616031

[07:22] *** nebuchadnezzar joined
[07:31] <JimmyZ> .oO(MoarVM on JVM)

[07:48] *** FROGGS joined
[07:58] *** brrt joined
[08:04] *** kjs_ joined
[09:27] *** kjs_ joined
[10:20] *** zakharyas joined
[11:20] *** kjs_ joined
[12:52] <timotimo> hoelzro: i think the code in each comp unit has a frame that's responsible for doing the deserialization and installation of symbols

[12:52] <timotimo> have you --dump'd a simple module?

[12:53] *** timo joined
[12:59] *** lue joined
[13:16] <hoelzro> timotimo: I haven't

[13:16] <timotimo> maybe it'd be a good idea :)

[13:16] <hoelzro> sounds good =)

[13:16] * hoelzro .oO( how does one do that? )

[13:17] <tadzik> use weechat :)

[13:19] <timotimo> moarvm --dump foobar.moarvm

[13:20] <hoelzro> [7:20:22] rob@eridanus /tmp/golfed-abc $ moar --dump lib/ABC/Grammar.pm

[13:20] <hoelzro> Unhandled exception: Bytecode stream shorter than header

[13:20] <hoelzro> =/

[13:21] <tadzik> .pm doesn't look like bytecode stream :)

[13:21] <timotimo> yeah

[13:21] <hoelzro> oops

[13:21] * hoelzro needs coffee

[13:46] <hoelzro> what's a frame and a callsite? I'm guessing the former is like a scope of sorts?

[13:49] *** kjs_ joined
[14:09] <timotimo> frames are pieces of code together with local and lexical variables that can be invoked

[14:09] <timotimo> callsites are shared structures that hold information about the shape of a call used at any given point

[14:10] <timotimo> for example:

[14:10] <timotimo> m: say "hello"; say "goodbye";

[14:10] <camelia> rakudo-moar 316f99: OUTPUT«hello␤goodbye␤»

[14:10] <timotimo> these two invocations of "say" share a callsite, because they both have just one argument

[14:10] <timotimo> callsites are important to moar because they give us a way to hang specializations off of invocations

[14:11] <timotimo> a callsite is, however, not tied to a given "target"

[14:11] <timotimo> m: say "hello"; print "what"

[14:11] <camelia> rakudo-moar 316f99: OUTPUT«hello␤what»

[14:11] <timotimo> these two invocations would have the same callsite assigned to them, too

[14:11] <hoelzro> I see, thanks!

[14:12] <hoelzro> btw, I went over the dump of a very stupid module

[14:13] <hoelzro> and I'm no closer to figuring it out =/

[14:13] <hoelzro> granted, the module is just 'package ABC {}', so it's probably too little to tell me anything

[17:35] *** kjs_ joined
[17:54] *** lizmat joined
[18:01] *** kjs_ joined
[18:17] <dalek> MoarVM: 4d71a93 | TimToady++ | src/6model/reprs/NFA.c:

[18:17] <dalek> MoarVM: lazier longlit initialization

[18:17] <dalek> MoarVM: review: https://github.com/MoarVM/MoarVM/commit/4d71a93b81

[18:33] *** travis-ci joined
[18:33] <travis-ci> MoarVM build errored. TimToady 'lazier longlit initialization'

[18:33] <travis-ci> http://travis-ci.org/MoarVM/MoarVM/builds/42110425 https://github.com/MoarVM/MoarVM/compare/9e03616031a3...4d71a93b814c

[18:33] *** travis-ci left
[18:44] *** FROGGS joined
[18:52] <timotimo> jnthn: in order to figure out if i should put an allocation into the interp/spesh/jit bucket, i'll investigate tc->cur_frame->spesh_cand(if unset -> interp)->jitcode(if unset -> spesh | if set -> jit)?

[19:20] *** kjs__ joined
[20:07] *** FROGGS joined
[20:24] <timotimo> though, since profiling uses the spesh mechanism, doesn't that mean the spesh_cand is always set?

[20:33] *** brrt joined
[20:33] <brrt> \o

[20:33] <brrt> nobody broke JIT today, right? :-)

[20:36] <TimToady> did it need breaking? :P

[20:38] <jnthn> timotimo: Why all the trouble? Just track in the profiler callgraph node object how the current routine was entered

[20:38] <[Coke]> brrt: I assume you're not talking to the OS X people. :)

[20:39] <jnthn> timotimo: We already convey if we entered through interp, spesh, or JIT

[20:39] <jnthn> I think that data is already stored in the call graph node data structure.

[20:43] <timotimo> oh, cool

[20:44] <timotimo> does that mean i don't even have to store three numbers in callgraph node objects

[20:44] <timotimo> except maybe in "collected" ones if we introduce the callgraph flattening again?

[20:44] <timotimo> the data is already in the json dump anyway?

[20:45] <timotimo> ah, not quite

[20:45] <timotimo> it seems like the PCN stores how often it was entered per type of entering

[20:45] <timotimo> so it'd still want three integers

[20:46] <timotimo> and the entry_mode member (that is persisted because continuations) is what i could just use to figure out where to +1 the allocation count

[20:50] <jnthn> No, I think you'd need to store the numbers.

[20:50] <jnthn> But yes, entry_mode is what you want.

[20:52] <brrt> [Coke]: not especially today,  no

[20:52] <brrt> TimToady: it didn't need it, but it might happen nevertheless :-)

[20:53] <brrt> hmm does anybody know a more recent version of open-source darwin than 2011

[20:56] <brrt> jnthn: back from .cn? :-)

[20:56] <jnthn> brrt: Aye :)

[20:57] <jnthn> I'm currently in Stockholm, midly jetlug, teaching TDD with...Java. :)

[20:57] <jnthn> The neat thing about Java is, there's so little syntax you basically can't get it wrong.

[20:58] <japhb> Too bad you can't just teach people to do the Java tests in Perl 6 ...

[20:59] <jnthn> I did tell a (true) story about a recent project where I *did* write a test suite and prototype in Perl 6, then replaced the `is` sub with something that spat out JUnit tests to exercise the final impl which had to be in Java. They were like...wow, that's neat. :)

[21:01] <japhb> That is actually a very nice use of prototyping freedom

[21:02] <japhb> jnthn: Is that translation piece open sourceable?

[21:02] <jnthn> No, and thanks to NDA I can't say any more about the project really :(

[21:02] * japhb sees another shape of foot to stick in the door at hardcore Java shops.

[21:03] <japhb> Ah well.  NDA happens.

[21:03] <jnthn> Only that I feel very comfortable saying that doing the prototype in Perl 6 first was a net win time (and thus cost) wise.

[21:04] <japhb> Good!

[21:07] <japhb> Which reminds me, we haven't been in close enough time zones (or mental states) for a while to discuss this, but while working on the stress branch for perl6-bench it occurred to me that since r-j and r-m were *both* failing at divide-and-conquer, that implies something is wrong with concurrency either in the NQP threading primitives or in the Rakudo layers -- and *not* necessarily in the VMs themselves.  Mind you, the two VMs crash in different ways, so it coul

[21:08] <timotimo> cut off after "so it could"?

[21:08] <japhb> ... so it could be two different bugs in the NQP primitives instead of one bug in the Rakudo code ... or maybe they just have different  failure behavior for essentially the same bug.

[21:08] <japhb> I hate that irssi does not

[21:08] <japhb> *show* you that the line got cut off.

[21:09] <japhb> (Or better, just split the line for you.)

[21:09] * brrt agrees with jnthns java-comment

[21:10] <brrt> java is really very simple, it just has layers of people avoiding their problems in it

[21:10] <japhb> Welcome to the waterbed theory of complexity.

[21:10] <timotimo> there is a irssi plugin that splits for you

[21:10] <timotimo> weechat does it by default

[21:11] * japhb can't imagine why the default behavior would be FAIL for an otherwise smart client

[21:11] <jnthn> brrt: Yes, I did point that out to the folks I was teaching today, in a slightly different context. I was talking about the law of demeter, and pointing out that when your languages makes near enough everything look like a normal object, it's harder to see how to apply it...

[21:12] <jnthn> japhb: Well, from a Moar perspective, even if there are concurrency bugs at Rakudo level, SEGV is the wrong answer.

[21:12] <jnthn> japhb: I suspect we have bugs in both places.

[21:13] <japhb> Yeah, agreed.

[21:14] <timotimo> we have bugs in all the places :)

[21:14] <timotimo> i don't understand why, but my enthusiasm seems a bit limited this week

[21:14] <[Coke]> timotimo: you and me both

[21:14] <japhb> Everybody has down weeks.  You need to accomplish something.  And get more sun.  :-)

[21:15] <timotimo> i think i need a low-effort, big-payoff project :P

[21:15] <jnthn> Get more sun? I'M IN SWEDEN.

[21:15] <japhb> Involving FREAKIN' LASERS

[21:15] <timotimo> unfortunately, sun was swallowed by oracle

[21:15] <timotimo> ever since then, i didn't have the heart to look it in the eye

[21:15] <jnthn> We greedily use up all our sun in the summer, and in winter there's noe left...

[21:15] <japhb> jnthn: OK, so spend a lot of time under the aurorae?

[21:15] <jnthn> Not in a north enough bit of Sweden for those :(

[21:16] <japhb> Well geez, no way to win on that one.

[21:16] <jnthn> I know.

[21:16] <brrt> japhb: my high school teacher called that the law of conservation of misery :-)

[21:16] <japhb> Heh!

[21:16] <jnthn> If I do get to see one at home, it'd probably mean we got a solar flare big enough to damage something or other :)

[21:17] <jnthn> At least the temperature is nice and cool here now :)

[21:25] <brrt> dutchland is also cooling down (finally)

[21:26] * timotimo is looking at the code to walk the allocation nodes and is sad javascript doesn't have what perl6 has

[21:26] <timotimo> hypers and such

[21:34] <timotimo> i'm not really seeing how to correctly "enhance" the code here ...

[21:34] <timotimo> maybe i'll just count up the total directly in the "count" and then have numbers for spesh and jit that have to be subtracted, so to speak, to get the interp_allocation_count

[21:38] <japhb> jnthn: If I could figure out stress tests for the NQP-layer threading primitives, would that be a big benefit, or just another data point that's unlikely to do much for you?

[21:39] <jnthn> japhb: I'm not sure it'd give me a lot more, tbh.

[21:39] <japhb> OK, fair enough.

[21:40] <jnthn> japhb: Certainly I'd be lying if I said "big benefit". I can't say it wouldn't be one for somebody else coming into this.

[21:40] <japhb> Hmmm, that's an interesting point.

[21:40] <jnthn> But I tend to have a clear enough mental map of the layers we have to have little trouble seeing my way through them.

[21:40] <japhb> Yeah, I figured that might be the case.

[21:40] <jnthn> So I'm a bad example in that sense. :)

[21:41] <japhb> But that brings up the point that maybe the reason you're the only concurrency debugger is that no one else currently can wrap their heads around all the layers and their interactions.

[21:42] <japhb> So even if it wouldn't help you, maybe it will open up the debugging task to others.

[21:42] <jnthn> Right.

[21:43] <jnthn> So "would that be a big benefit" may have a different answer to "will it do much for you". :)

[21:43] <japhb> Heh.

[21:44] <jnthn> (As in, if it opens it up to someone else, that's a big beneift...to everyone :))

[21:44] <japhb> Truedat

[21:48] <brrt> by the way, i removed MVM_exception_throw_adhoc in the JIT for MVM_panic

[21:48] <brrt> if something is wrong in the JIT, it shouldn't be caught by an exception handler

[21:48] <jnthn> If there's no way to sanely reover, then yeah

[21:48] <brrt> well... the sane recovery strategy is not to JIT

[21:49] <japhb> Is there any NQP-level code (examples, tests, etc.) that uses the threading ops, or just Rakudo?

[21:49] <brrt> but any cases in which it would happen are clearly programmer errors

[21:49] <jnthn> The downside is that panic assumes the VM state is corrupted and doesn't show a backtrace, iirc.

[21:49] <jnthn> japhb: Just Rakudo, sadly.

[21:49] <brrt> as in JIT programmer errors :-)

[21:49] <jnthn> japhb: nqp tests for them would be totally kosher.

[21:49] <brrt> true, which is why i think i used throw_adhoc in the first place

[21:49] <jnthn> japhb: Mostly they don't exist for historical reasons.

[21:49] <japhb> jnthn: Wheee!  I get to figure out how red blood cells work by dissecting a moose!

[21:50] <japhb> ;-)

[21:50] * brrt doesn't get something, and that's probably OK

[21:50] <jnthn> japhb: The reasons being that I did the original impl on the JVM in terms of Java interpo, in the Rakudo core setting.

[21:51] <jnthn> japhb: Then when I came to abstract it, I already had a bunch of tests at Rakudo level to guide me.

[21:51] <japhb> nodnod

[21:51] <jnthn> And given my usual...abundance...of time, that was Good Enough.

[21:51] <japhb> Heh

[21:52] <jnthn> <- still working on "done and gets stuff smart" :)

[21:53] <japhb> I still think you qualify on that count just based on your tendency to CDD that ends up being committed to mainline

[21:53] <brrt> i can hardly count the possible meaningful permutations of these words

[21:54] <japhb> C == Conference

[21:54] <brrt> i was just about to ask

[21:54] <brrt> :-)

[21:54] <japhb> :-)

[21:55] <brrt> done smart stuff and gets

[21:55] <brrt> and smart stuff gets done

[21:56] <japhb> brrt: That one works really well for the second part of an aphorism

[21:57] <brrt> :-) what a monster of a sentence

[22:02] *** kjs_ joined
[22:05] <jnthn> Early sleep...still fighting jetlag, plus teaching tomorrow...

[22:10] <brrt> sleep well :-)

[22:41] *** brrt left
[23:13] *** kjs_ joined
