[00:42] *** BinGOs joined
[00:45] * [Coke] finds that once, somewhere, jonathan used the wrong email address in a commit.

[00:51] *** dalek joined
[00:59] *** dalek joined
[01:12] *** BinGOs joined
[01:37] *** dalek joined
[02:26] *** BinGOs joined
[04:45] *** ilbot3 joined
[04:52] *** flussence joined
[06:30] *** BinGOs joined
[06:58] <tadzik> ah, doing releases, I see :)

[07:09] *** vendethiel joined
[08:07] *** domidumont joined
[08:18] *** FROGGS joined
[08:18] *** dalek joined
[08:22] *** BinGOs joined
[08:29] *** zakharyas joined
[08:38] *** BinGOs joined
[09:02] *** zakharyas joined
[09:23] *** zakharyas joined
[09:32] *** dalek joined
[09:36] *** Ven joined
[09:41] *** nebuchadnezzar joined
[09:48] *** kjs_ joined
[09:58] *** Ven joined
[10:41] *** domidumont joined
[10:42] *** flaviusb joined
[11:18] *** zakharyas joined
[12:09] *** ggoebel7 joined
[12:22] *** Ven joined
[12:24] *** domidumont joined
[12:28] *** ShimmerFairy joined
[12:31] *** Peter_R joined
[13:01] *** domidumont joined
[13:38] *** kjs_ joined
[13:52] *** ShimmerFairy joined
[14:03] *** ggoebel7 joined
[14:26] *** domidumont joined
[14:46] *** zakharyas joined
[15:34] *** domidumont joined
[15:55] <timotimo> on my JSON::Fast benchmark, self times are interesting: 11% Self on MVM_frame_dec_ref, 10% on MVM_interp_run, 8.23% on MVM_fixed_size_alloc, 5.11% on MVM_frame_acquire_ref, 4.74% on MVM_frame_invoke, 2.68% on MVM_frame_inc_ref_by_frame  (with a few things in between)

[15:57] *** ggoebel7 joined
[16:00] <timotimo> with a check for num_user_threads == 0, the self gets down to 8.18%

[16:00] <timotimo> (as reported by perf)

[16:07] <timotimo> my naive attempt to implement MVM_frame_acquire_ref seems to not work :\

[16:07] <timotimo> i'll run a full spec test now.

[16:09] *** brrt joined
[16:12] <timotimo> i think it should be safe to do the checks there, as going from 0 to 1 user thread cannot happen while inside the non-threaded version of these operations

[16:12] <timotimo> and the other direction would just mean that we accidentally do the checks with atomic ops at least once when not needed

[16:12] <timotimo> could it be problematic if the threads somehow go from 1 to 0 to 1?

[16:16] <brrt> good * #moarvm

[16:17] <timotimo> heyo brrt!

[16:17] <brrt> hey timotiom

[16:17] <brrt> timotimo

[16:17] <timotimo> i'm starting to miss the ability to have perf show me disassembly of jitted frames :|

[16:17] <brrt> my win10 download has disappeareed for some reason

[16:17] <timotimo> :o

[16:17] <timotimo> disappeared?!

[16:17] <brrt> yeah, weird

[16:17] <brrt> why can't perf do that?

[16:18] <brrt> what would you need for it to do that?

[16:18] <timotimo> i expect we need to export the perf map thingie that tells it where things start and end?

[16:18] <brrt> hmmm

[16:18] <brrt> supposedly, yes

[16:19] <timotimo> i should verify my claim before sending you off on a goose-chase!

[16:19] <brrt> jit integration with external tooling would be a nice goal to have

[16:19] <timotimo> on the other hand, i can just let the jit export the .o files, eh?

[16:19] <brrt> yeah, but they won't be ELFs

[16:19] <timotimo> but that won't give me per-instruction timings

[16:19] <timotimo> as long as i can dump the assembly, that'll help a little bit

[16:19] <timotimo> but they don't show what source bytecode what assembly op comes from, eh?

[16:20] <brrt> no, they don't

[16:20] <brrt> i can usually tell with the jit log in hand

[16:20] <brrt> but it's not automated

[16:20] <timotimo> bleh. lowlevel/lock.t and promise/start.t seem to hang here

[16:21] <timotimo> is "hang with cpu usage non-zero" livelock and "hang with no cpu usage" deadlock?

[16:21] <brrt> yes

[16:21] <timotimo> as in: is that the correct differentiation metric?

[16:23] <JimmyZ> you may like ktap since SystemTAP is hard to use on ubuntu/debian

[16:23] <JimmyZ> which is easy to use as per

[16:24] <timotimo> is that the right thing to use here? ktap sounds a bit like a kernel tool?

[16:24] <JimmyZ> *perf

[16:24] * [Coke] sighs as jvm spectest is also dying.

[16:24] <brrt> i think that is right, yes

[16:24] <JimmyZ> you can use it to gen Flame Graph

[16:25] <[Coke]> nine: ===SORRY!===

[16:25] <[Coke]> Could not find Test:ver<True>:auth<True>:api<True> in:

[16:25] <[Coke]> on the jvm. updating again...

[16:25] <timotimo> brrt: do you have a clue how good our current jit is with IntLexRef?

[16:25] <JimmyZ> [Coke]: moarvm here :)

[16:25] <brrt> no clue timotimo

[16:26] <timotimo> every instance of $pos = $pos + 1 is two getlex, a decont_i, an add_i, an assign_i; i wonder if it's cheap or expensive

[16:26] <timotimo> and i use that a whole lot in my code

[16:26] <timotimo> also every reference to $pos is, of course, a getlex and a decont_i

[16:27] <brrt> y not $pos++

[16:28] <timotimo> because that's a million times more expensive :)

[16:28] <brrt> but to be honest.. .we need heroic optimization before we ever see the JIT, before we get there

[16:28] <brrt> why :-(

[16:28] <timotimo> m: my int $foo = 0; while $foo < 10_000_000 { $foo++ }; say now - INIT now

[16:28] <camelia> rakudo-moar 0a61b9: OUTPUT«6.1351965␤»

[16:29] <timotimo> m: my int $foo = 0; while $foo < 10_000_000 { $foo = $foo + 1 }; say now - INIT now

[16:29] <camelia> rakudo-moar 0a61b9: OUTPUT«0.0661555␤»

[16:29] <timotimo> oh, just a hundred times

[16:29] <timotimo> lexical references passed to operators are currently preventing inlining in both the static and the dynamic optimizer

[16:29] <timotimo> for ... some reason

[16:30] <timotimo> m: sub dotheloop(int $foo is rw) { while $foo < 10_000_000 { $foo = $foo + 1 } }; my int $bar = 0; dotheloop($bar); say now - INIT now

[16:30] <camelia> rakudo-moar 0a61b9: OUTPUT«0.349984␤»

[16:30] <timotimo> wowza

[16:30] <[Coke]> JimmyZ: whoops, ww.

[16:31] <timotimo> look at that, it's 5 times slower with the intlexref

[16:31] <timotimo> however, i have no clue if that slowness impacts my JSON::Fast times at all

[16:31] <timotimo> or if it's other stuff

[16:36] <brrt> timotimo: i was thinking of writing, for the perl6 advent calendar, a post describing how to write performant perl6 code

[16:36] <brrt> in fact, i was thinking of writing a msgpack module

[16:37] <timotimo> do you really want to tell people "yeah, just put 'use nqp' at the top and throw away all the nice operators we have. also, don't use variables anywhere!"? :)

[16:37] <brrt> not because msgpack is any good, it isn't, but because it uses binary stuff rather nicely

[16:37] <brrt> hmmm

[16:37] <brrt> good point

[16:37] <brrt> how well do native types work these days?

[16:37] <timotimo> "if you can, write your loops as SEQ( ... ) while ..." :P

[16:37] <timotimo> they work rather well. especially now that we can pass native vars around as "is rw"

[16:38] <brrt> seq?

[16:38] <brrt> well, hmm...

[16:38] <timotimo> basically what do { .. } does, but without a lexical scope

[16:38] <timotimo> and without an invocation or anything

[16:38] <brrt> oh really

[16:38] <timotimo> i used it to reduce the number of BOOTCode allocations in nom-ws

[16:39] <timotimo> wasn't worth terribly much, because nom-ws only takes a small part of the complete time

[16:39] <timotimo> and there's still the CATCH in there to catch what nqp::ordat does when it reaches beyond EOS

[16:39] <timotimo> hm. perhaps it'd be performant to put an actual bounds check there.

[16:40] <timotimo> AFK for a bit

[16:40] <timotimo> i'm not against a post "writing performant code", but there are these caveats :(

[16:41] <hoelzro> o/ #moarvm

[16:42] <brrt> good * #moarvm

[16:42] <brrt> eh hoelzro

[16:43] <hoelzro> o/ brrt

[17:11] <timotimo> found the answer to my question about assign_i: of course we're not doing that extremely well. otherwise it'd be a sp_bind_i64 or a p6obind_i

[17:11] <timotimo> probably the former

[17:20] <brrt> aye

[17:20] *** kjs_ joined
[17:21] <brrt> diakopter: i'm trying to install windows 10 + vs2015 now... not sure what i'll need, but i'll keep you posteed

[17:21] <brrt> i'm not supposed to like it, but windows 10 is actually quite nice

[17:35] <timotimo> oh, sp_bindi64 isn't right; there needs to be a pointer deref in the middle. so new spesh ops are needed

[17:49] * TimToady needs to rename SEQ to avoid confusion...

[17:49] <TimToady> since "sequence" is already overloaded two ways without that

[17:51] <timotimo> tell me when that happens :)

[17:51] <timotimo> or perhaps have a deprecation cycle? or is SEQ really not meant to be for end-users at all?

[17:58] <TimToady> we never specced it...

[17:58] <TimToady> at a time when we were still trying to spec everything :)

[17:58] <TimToady> it doesn't occur in roast, so it's not officially Perl 6... :P

[17:59] <TimToady> maybe we need to put in all the C operators as C|| C<< C, and such...

[18:00] <timotimo> MVMInt64 *target = *((MVMInt64 *)((char *)o + GET_UI16(cur_op, 2)));

[18:00] <timotimo> *target          = GET_REG(cur_op, 4).o;

[18:00] <timotimo> i *think* this is what i mean when i say:

[18:00] <TimToady> but now this is language design, so OT :)

[18:00] <[Coke]> at this point, we should probably gut everything in advance of a release that is officially deprecated, and not ship v6.c with deprecations baked in.

[18:00] <timotimo> at the offset "cur_op, 2" there is a pointer to an MVMInt64. i want to set the target of the pointer to the value "cur_op, 4"

[18:00] <timotimo> except that needs to end in .i64

[18:01] <timotimo> i think the * after the target = may be wrong

[18:02] <timotimo> i know that if i put an & there i get the address of the pointer i wanted to follow. that's not the right thing.

[18:03] <timotimo> if i just put the thing there, will C assign the address of the RHS into the LHS, too? or would that require a & there?

[18:03] <timotimo> i think assigning a pointery thing to a pointer variable just updates the pointer to point at the same thing

[18:07] <timotimo> oh, brrt left

[18:07] <timotimo> i was about to ask him to implement that in the jit, please :D

[18:07] <timotimo> poor him

[18:13] *** pyrimidine joined
[18:25] *** diakopter joined
[18:47] *** domidumont joined
[18:48] *** diakopter joined
[19:00] <timotimo> the implementation seems wrong

[19:00] <timotimo> at least i'm getting quite wrong values

[19:01] <timotimo> shows what i know about pointer arithmetic and such :)

[19:03] *** diakopter joined
[19:12] <TimToady> timotimo: is SEQ actually being used in the ecosystem?

[19:13] <timotimo> only in JSON::Fast since the very latest commit

[19:13] <TimToady> because I'm gonna break it...

[19:13] <timotimo> and perhaps tadzik just merged that commit in :)

[19:13] <TimToady> it'll rename itself to STATEMENT_LIST

[19:13] <timotimo> ah, not in panda yet

[19:13] <TimToady> well, it'll fail with an obvious message :)

[19:14] <timotimo> it'll rename itself? that's nice, so i don't have to do anything? :)

[19:17] * TimToady blames the french...

[19:48] <dalek> MoarVM/spesh_nativeref_assign_decont: c7706c4 | timotimo++ | / (6 files):

[19:48] <dalek> MoarVM/spesh_nativeref_assign_decont: A spesh op like sp_bind/get_i64 with an extra pointer deref

[19:48] <dalek> MoarVM/spesh_nativeref_assign_decont: review: https://github.com/MoarVM/MoarVM/commit/c7706c4a6c

[19:48] <dalek> MoarVM/spesh_nativeref_assign_decont: de68134 | timotimo++ | src/ (2 files):

[19:48] <dalek> MoarVM/spesh_nativeref_assign_decont: Allow NativeRef to spesh assign_i and decont_i

[19:48] <dalek> MoarVM/spesh_nativeref_assign_decont:

[19:48] <dalek> MoarVM/spesh_nativeref_assign_decont: this uses the op the previous commit introduced.

[19:48] <dalek> MoarVM/spesh_nativeref_assign_decont: review: https://github.com/MoarVM/MoarVM/commit/de68134b2c

[20:15] <dalek> MoarVM/spesh_nativeref_assign_decont: 6a95b60 | timotimo++ | src/jit/ (2 files):

[20:15] <dalek> MoarVM/spesh_nativeref_assign_decont: implement sp_deref_bind/get_i64/n in the JIT

[20:15] <dalek> MoarVM/spesh_nativeref_assign_decont: review: https://github.com/MoarVM/MoarVM/commit/6a95b605ea

[20:19] <timotimo> i implemented stuff in the jit and ... it got slower?!

[20:21] <[Coke]> timotimo: more switching between jit and non jit?

[21:00] *** synbot6 joined
[21:32] <timotimo> nah

[21:34] <timotimo> these frames in question were jit compilable before, then became non-jit-compilable when i introduced sp_bind_i64 and friends and then became jit-compilable again when i implemented them

[21:36] <jnthn> If you're trying to mesaure changes at that level, you probably need something that can tell you stuff like how many instructions were retired

[21:36] <jnthn> And maybe cache stats

[21:37] <timotimo> that'd be a better metric, i agree.

[21:38] <timotimo> but i was hoping the change would be noticable

[21:38] <timotimo> since assign_i and decont_i weren't even going through the REPRop devirtualization yet

[21:41] <timotimo> hmm. 14.5 vs 16.2

[21:42] <timotimo> 12.65 was the time earlier today

[21:42] <timotimo> before i started touching moar. and now that same task costs 14.5?!

[21:50] *** diakopter_______ joined
[21:53] <diakopter_______> timotimo: jitting is expensive!

[21:53] <diakopter_______> what are the units there

[22:14] *** diakopter_______ joined
[22:15] <timotimo> seconds for the file i'm parsing with JSON::Fast

[22:15] <diakopter_______> eek

[22:15] <diakopter_______> I was hoping you'd say microseconds

[22:16] <timotimo> hahahaha

[22:16] <timotimo> yeah, right

[22:16] <timotimo> not this year, my friend

[22:30] *** kjs_ joined
[22:33] <diakopter_______> timotimo: hoping, for the code's sake, I mean

[22:39] <timotimo> oh, like ... if it ain't microseconds, it'll get to spend a lot more time under my thumb

[22:44] *** njmurphy_ joined
[22:55] <lizmat> another P6W: https://p6weekly.wordpress.com/2015/11/30/2015-4849-arrays-shape-up-curli-lands-and-supply-splits/

[22:57] <diakopter_______> lizmat++

[22:59] <jnthn> lizmat: nice! :)

[22:59] <jnthn> lizmat++

[23:02] <diakopter_______> here's a gem from the reddit comments linked: "Rakudo's had more testing since it's been around forever but MoarVM is where my hopes lie."

[23:02] <diakopter_______> er, I mean HN comments

[23:03] <diakopter_______> here's another "Want to get Perl 6 running on the .Net CLR? Implement an NQP interpreter (which is supposed to be fairly easy) and you're 99% done (at least that's my understanding)."

[23:04] <diakopter_______> .oO( have you ever squelched a laugh so hard you cried silently?? )

[23:04] <jnthn> "fairly easy" :D

[23:04] <timotimo> lizmat: did you also post it on #perl6? :)

[23:07] <lizmat> yes

[23:07] <lizmat> but I think it got snowed under there

[23:09] <diakopter_______> this one makes me cry in other ways: "Show me the more advanced parts of the language, are they transducers, monads, functors, natural transformations, auto-compilers, self-replicating systems, high AI in action, ML, NLP. What is the honey spot for this new language?"

[23:16] <timotimo> i wish it had said "MLP" instead

[23:17] <timotimo> but damn! they found out perl6 does nothing in particular excellently! nooooooo my only weakness!

[23:22] *** diakopter_______ joined
[23:45] <diakopter_______> anyone have an interest in making a port of MoarVM/rakudo for seL4? http://sel4.systems/Info/Docs/seL4-manual-2.0.0.pdf
