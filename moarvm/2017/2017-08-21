[01:41] *** geekosaur joined
[01:51] *** ilbot3 joined
[03:21] *** geekosaur joined
[03:36] *** geekosaur joined
[06:25] *** domidumont joined
[06:30] *** domidumont joined
[06:56] *** brrt joined
[07:40] <nine> .tell brrt now that you've reverted my erroneous param_rp_* JIT commit, I really wonder how that could have ever worked in the first place :)

[07:40] <yoleaux> nine: I'll pass your message to brrt.

[07:41] *** zakharyas joined
[07:47] *** jsimonet joined
[07:50] *** jsimonet joined
[07:56] *** robertle joined
[08:00] *** domidumont joined
[08:09] *** robertle joined
[08:39] <jnthn> OK, at present HEAD on Windows says:

[08:39] <jnthn> .\3rdparty\dynasm\minilua.exe .\3rdparty\dynasm\dynasm.lua -D WIN32=1 -o src\jit\emit_win32_x64.c src\jit\emit_x64.dasc

[08:39] <jnthn> src\jit\emit_x64.dasc:1829: error: bad operand mode in `lea i?,x?':

[08:39] <jnthn> | lea ARG5, WORK[result]

[08:39] <jnthn> src\jit\emit_x64.dasc:2380: error: bad operand mode in `mov i?,i?':

[08:39] <jnthn> | mov ARG5, 0;                           // NULL to &was_multi

[08:39] <jnthn> src\jit\emit_x64.dasc:*: info: 2 errors in input file -- no output file generated.

[08:40] <Geth> ¦ MoarVM: a42c89a7b8 | (Timo Paulssen)++ | src/jit/emit_x64.dasc

[08:40] <Geth> ¦ MoarVM: fix usage of ARG5 on windows to use stack instead

[08:40] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/a42c89a7b8

[08:40] <Geth> ¦ MoarVM: 882ed0bcd9 | (Bart Wiegmans)++ (committed by Timo Paulssen) | src/jit/graph.c

[08:40] <Geth> ¦ MoarVM: Revert "JIT param_rp_i" and "JIT param_rp_o"

[08:40] <Geth> ¦ MoarVM:

[08:40] <Geth> ¦ MoarVM: This reverts commits 84f426ecaa8578bdeeb532ace82400e219b4cc38 and

[08:40] <Geth> ¦ MoarVM: 9c578330f79c9f1e831b94c074ea7ca4d7de33f9.

[08:40] <Geth> ¦ MoarVM:

[08:40] <Geth> ¦ MoarVM: param_rp_o and param_rp_i return structs, and struct returning

[08:40] <Geth> ¦ MoarVM: isn't well-specified by the x86-64 ABI either on windows or

[08:40] <Geth> ¦ MoarVM: on posix.

[08:40] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/882ed0bcd9

[08:40] <Geth> ¦ MoarVM: 8ad8c23fe0 | (Jonathan Worthington)++ (committed using GitHub Web editor) | 2 files

[08:40] <Geth> ¦ MoarVM: Merge pull request #655 from MoarVM/fix_new_jit_ops_win32

[08:40] <Geth> ¦ MoarVM:

[08:40] <nwc10> a clean build had built on Linux, so I guess that's how it slipped through

[08:40] <Geth> ¦ MoarVM: Fix new jit ops win32

[08:40] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/8ad8c23fe0

[08:40] <jnthn> That merge helped

[08:41] * nwc10 reads more and isn't quite so sure any more about what's going on, other than "Linux did not appear to be broken at HEAD 5 minutes ago"

[08:47] <jnthn> nwc10: Windows build was broken. brrt++ prepared a PR that fixes it. I merged it. So far, agreeing it fixes it.

[08:53] <jnthn> Well, it builds.

[08:53] <jnthn> And Rakudo passes its tests

[08:54] <jnthn> NQP seems to have had some tests added that aren't Windows-happy

[09:08] <Geth> ¦ MoarVM: c1933c0559 | (Jonathan Worthington)++ | VERSION

[09:08] <Geth> ¦ MoarVM: Bump VERSION.

[09:08] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/c1933c0559

[09:09] <Geth> ¦ MoarVM: 2117110f30 | (Jonathan Worthington)++ | docs/ChangeLog

[09:09] <Geth> ¦ MoarVM: ChangeLog entry for 2017.08.1.

[09:09] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/2117110f30

[09:12] <jnthn> https://www.moarvm.org/releases/MoarVM-2017.08.1.tar.gz

[09:13] <jnthn> And tag pushed

[09:13] <jnthn> AlexDaniel: ^^

[10:02] <AlexDaniel> what about errata tests?

[10:04] <jnthn> AlexDaniel: I won't have time to do any further debugging ahead of my trip

[10:05] <jnthn> If somebody else can figure something out, sure, I can probably cut another point release while away.

[10:11] <jnthn> As I understand it, there's a documented workaround if anybody runs into this too (run with MVM_SPESH_DISABLE=1)

[10:11] <jnthn> s/documented/known/

[10:11] <jnthn> But documentable

[10:20] *** dogbert17 joined
[10:57] *** committable6 joined
[11:28] *** domidumont joined
[12:11] *** domidumont joined
[12:16] *** domidumont joined
[12:20] *** domidumont joined
[12:26] *** zakharyas joined
[12:34] *** domidumont joined
[12:43] <timotimo> jnthn: turns out we won't need another release; the problem was how DEPRECATED reacted to next-interesting-index from Backtrace giving Nil in some cases, and inlining changed the backtrace

[12:43] *** domidumont joined
[12:43] <jnthn> timotimo: Aha!

[12:44] <timotimo> though perhaps we want to deopt inlines to get a proper backtrace?

[12:44] <jnthn> That's a long-standing issue...would be nice to do something like deopt does to get straight backtraces in the future

[12:44] <timotimo> i.e. will inlining ruin our backtraces?

[12:44] <timotimo> ah

[12:44] <jnthn> I don't think we need to actually deopt

[12:44] <timotimo> so not deopt, but look at the data we have

[12:44] <jnthn> We can just use the data that deopt all would use

[12:44] <timotimo> that makes a lot of sense, yeah

[12:46] <timotimo> i put it into my "timo's ideas and tasks" project on moarvm

[13:34] <dogbert17> perhaps we should look into the Coverity Scan report after the release?

[14:01] *** domidumont joined
[14:31] *** brrt joined
[14:34] <brrt> good hi

[14:34] <yoleaux> 07:40Z <nine> brrt: now that you've reverted my erroneous param_rp_* JIT commit, I really wonder how that could have ever worked in the first place :)

[14:34] <brrt> .tell nine platform incompatibilities :-)

[14:34] <yoleaux> brrt: I'll pass your message to nine.

[14:38] <timotimo> yo brrt

[14:39] <timotimo> i wasn't at tcpia but i'll be at spw

[14:39] <timotimo> but you won't be, right?

[14:39] <brrt> ohai timotimo

[14:39] <brrt> nope :-(

[14:39] <brrt> by the way

[14:39] <timotimo> way the by?

[14:39] <brrt> any idea where the next european perl conference will be?

[14:40] <timotimo> great britain

[14:40] <timotimo> in the north somewhere

[14:41] <ilmari> Glasgow

[14:42] <brrt> (are we talking about the british perl workshop, or the next yapc?)

[14:42] <timotimo> yapc

[14:42] <ilmari> the next TPC in Europe

[14:42] <ilmari> the London Perl Workshop is stil in London

[14:44] <ilmari> 2017-11-15 http://act.yapc.eu/lpw2017/

[14:44] <jnthn> timotimo: oh, you're coming to SPW? :)

[14:46] <timotimo> yeah, i got a little bit of help so i could make it after all

[14:46] <jnthn> Ah, nice :)

[14:47] <brrt> cool :-)

[14:47] <brrt> so the other half of #moarvm will be at SPW :-P

[14:47] <nine> Until the UK decides to secede from the European contintental shelf, the TPC joke won't really fly ;)

[14:47] <yoleaux> 14:34Z <brrt> nine: platform incompatibilities :-)

[14:49] <Geth> ¦ MoarVM: c1f66bb699 | (Timo Paulssen)++ | src/spesh/optimize.c

[14:49] <Geth> ¦ MoarVM: put in a mising break, dogbert17++

[14:49] <Geth> ¦ MoarVM:

[14:49] <Geth> ¦ MoarVM: wouldn't cause any harm by missing, but if anything else

[14:49] <Geth> ¦ MoarVM: were added between this case and the default, that would

[14:49] <Geth> ¦ MoarVM: be trouble.

[14:49] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/c1f66bb699

[14:53] <dogbert17> jnthn: are you still around?

[14:55] <dogbert17> coverity complains about using a null reference here: https://github.com/MoarVM/MoarVM/blob/master/src/spesh/arg_guard.c#L416  is that a problem or is this code not in use yet?

[14:56] <jnthn> What does it thinkis NULL?

[14:57] <jnthn> I mean, guard trees are structured in such a way that MVM_SPESH_GUARD_OP_LOAD_ARG will always occur ahead of anything that looks a test

[14:57] <jnthn> But I doubt coverity is able to reason about that

[14:59] <dogbert17> test

[14:59] <dogbert17> CID 163624 (#1 of 4): Explicit null dereferenced (FORWARD_NULL) [select issue]

[15:00] <dogbert17> it refers to this line 'MVMObject *test = NULL'

[15:00] <dogbert17> so it's a false positive then

[15:04] <jnthn> I'd say so

[15:17] <timotimo> ugh, rakudo's complaining about OO::Monitor's tests where not-full and not-empty are being "used in sink context" even though it really doesn't look like sink context

[15:18] <timotimo> one time in the "is conditioned(<not-empty not-full>)" and then in the wait-condition and/or meet-condition calls

[15:30] <brrt> btw, the reason about the platform incompatibilities is, that windows compilers sometimes take the liberty of returning small structrues in the pair of (rax,rcx)

[15:31] <brrt> which is why, on windows, this is a particularly more efficient way to do it than returning a pointer

[15:31] <nine> I wonder why they do it only on Windows

[15:32] <nine> From what I've read it'd be allowed in general.

[15:32] <brrt> struct returning isn't well-specified by the ABI

[15:35] <nine> Anyway, my next try is gonna be to split MVM_args_get_pos_int into a variant that just returns the int (for required params) and one for optional params that returns the full MVMArgInfo

[15:58] *** zakharyas joined
[16:16] *** AlexDaniel joined
[16:19] *** dogbert2 joined
[16:20] <dogbert2> jnthn: thx for looking

[16:24] <timotimo> jnthn: heap snapshot was broken because a few new spesh things weren't dealing with worklist being null; i removed calls to those, but should they perhaps learn how to interact with the heap snapshot system so we get more accurate data in the heap snapshots themselves? things like "the spesh log is keeping too many things alive" for example

[16:28] <timotimo> oh, huh, the specialization log actually shows up in a path here

[16:59] <jnthn> timotimo: Yeah, it could do with some describe_refs impls adding

[17:00] <jnthn> Especially for spesh stats

[17:28] <timotimo> i know how to make describe_refs work with a REPR; would we here just have a MVM_spesh_stats_gc_describe directly next to and mostly exactly mirroring _gc_mark, and then based on whether worklist is null call one or the other?

[17:31] <jnthn> timotimo: yes

[17:33] <timotimo> ah, because otherwise add_collectable would just make that decision for me based on the REPR having/not having that op

[18:15] *** raschipi joined
[18:30] <nine> This does look a little disturbing to me: https://gist.github.com/niner/1238c1cccd110d998f0b5a77b79d2497

[18:34] <timotimo> can we get perl6-gdb-m of that with a backtrace and everything?

[18:42] <nine> That's...not easy as the process throwing this is the precompilation process

[18:43] <nine> But with debug symbols I get this: //home/nine/rakudo/install/lib/libmoar.so(MVM_spesh_candidate_add+0x6c8)[0x7fba73748e7b]

[18:44] <nine> While the first backtrace shows: //home/nine/rakudo/install/lib/libmoar.so(MVM_vm_exit+0x62)[0x7fa5ee9287f6]

[18:44] <nine> So...maybe the spesh thread did not get the message that we're shutting down in time?

[18:44] <nine> I.e. it's still speshing while the VM is already shutting down?

[18:48] <Geth> ¦ MoarVM: e4e9c042f5 | (Stefan Seifert)++ | 5 files

[18:48] <Geth> ¦ MoarVM: JIT param_rp_i and param_rp_o

[18:48] <Geth> ¦ MoarVM:

[18:48] <Geth> ¦ MoarVM: As the ABI for returning structs from functions is not clearly defined, we

[18:48] <Geth> ¦ MoarVM: split MVM_args_get_pos_obj and MVM_args_get_pos_int into variants for the

[18:48] <Geth> ¦ MoarVM: arg being required and one with and optional arg. In the required case, we

[18:48] <Geth> ¦ MoarVM: are not really interested in the MVMArgInfo but the value itself, so the

[18:48] <Geth> ¦ MoarVM: function can return a simple value which is safe to JIT.

[18:48] <Geth> ¦ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/e4e9c042f5

[19:14] <timotimo> huh, but when we shut down we don't destroy a tc or anything?

[19:26] *** geekosaur joined
[21:06] <lizmat> and yet another Perl 6 Weekly hits the Net: https://p6weekly.wordpress.com/2017/08/21/2017-34-going-atomic/

[21:17] <jnthn> lizmat++

[22:41] *** MasterDuke joined
[22:48] <MasterDuke> jnthn: do you think you'll be able to look at https://github.com/MoarVM/MoarVM/pull/631 and https://github.com/MoarVM/MoarVM/pull/632 sometime ? or is there someone else who knows the relevant code well enough to review them? no particular hurry, i just don't want to forget about them

[22:57] <jnthn> MasterDuke: Sometime, sure. Just a bit busy this week with SPW trip prep and so forth

[23:03] <MasterDuke> cool, no worries

[23:22] <jnthn> Should go rest up before the long journey starting tomorrow :)

[23:23] <timotimo> gnite jnthn

[23:23] <timotimo> i'm also going to bed Right Now

[23:23] <jnthn> 'night o/

[23:23] <timotimo> i kinda feel like $*default-read-elems is not applicable to our async reads, but i have no logical explanation for that feeling

[23:23] <jnthn> timotimo: See you in Villars :)

[23:24] <jnthn> timotimo: I assume you know the railway from Germany to Switzerland is pretty kaput?

[23:24] <jnthn> (In case that's how you were planning to travel)

[23:25] * jnthn is going via Austria and so is safe, at least from that bit of disruption...

[23:27] <MasterDuke> huh, i wouldn't have thought a german/swiss train would have problems

[23:27] <timotimo> liz is picking me up in 'er car :D

[23:27] <MasterDuke> i think if them as being second only to the japanese for reliability, etc

[23:27] <timotimo> the route from echt to villars actually either goes past karlsruhe (where i live) or through france (which i guess you'd have to pay tolls/fares/whatevs for)

[23:28] <timotimo> MasterDuke: there's a major problem near where i live right now

[23:28] <jnthn> So far as I understand it, there was a construction accident, which caused the ground beneath some tracks to give way

[23:29] <jnthn> But yeah, in general the Swiss train system is outstanding.

[23:29] <timotimo> i only saw a whole bunch of ambulances parked in front of the station when i picked up a friend last week

[23:29] <MasterDuke> guess that could cause some delays

[23:29] <timotimo> then i was told karlsruhe/raststatt is the last stop for trains in that direction

[23:29] <timotimo> oh, i'll be riding a train back from switzerland, though

[23:30] <jnthn> Oh. Then, plan ahead some, I guess...

[23:30] <timotimo> i'm not sure how well that would work, i should really check that with lizmat tomorrow

[23:30] <timotimo> yeah, thanks for the heads-up!

[23:31] <timotimo> looks like there's just about 20 minutes of bus riding to get around the problematic part

[23:31] <timotimo> (21 minutes of waiting before that)

[23:32] <jnthn> Yeah, I figure they'll have got some kinda workaround in place by now

[23:32] <timotimo> yeah, they usually get buses up in a manner of an hour

[23:33] <jnthn> :)

[23:33] <jnthn> Alrighty, sleep time o/

[23:33] <timotimo> nite!
