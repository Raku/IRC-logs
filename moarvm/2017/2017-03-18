[00:01] <TimToady> m: my $a = 0; my @a = eager ($a++,) Zxx 42; say $a; say @a; say $a

[00:01] <camelia> rakudo-moar 16ef21: OUTPUT: ¬´0‚ê§[(0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41)]‚ê§42‚ê§¬ª

[00:03] <TimToady> it does seem a bit antisocial to ignore eagerness

[00:03] <TimToady> m: my $a = 0; my @a = ($a++,) Zxx 42; say @a.is-lazy

[00:03] <camelia> rakudo-moar 16ef21: OUTPUT: ¬´False‚ê§¬ª

[00:40] *** agentzh joined
[02:49] *** ilbot3 joined
[02:51] *** dogbert2 joined
[02:53] *** mtj_ joined
[03:34] *** geekosaur joined
[04:47] <Geth> ¬¶ MoarVM: c9b3a35a51 | (Samantha McVey)++ | docs/ChangeLog

[04:47] <Geth> ¬¶ MoarVM: Add more details on speed improvement to changelog

[04:47] <Geth> ¬¶ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/c9b3a35a51

[05:20] *** agentzh joined
[06:06] *** agentzh joined
[07:10] <samcv> jnthn, putty probably doesn't use fallback fonts or something. i never liked putty because it wasn't very full features. noto fonts is not just one font because it covers so much of unicode it can't fit in one font

[07:40] *** brrt joined
[08:09] *** agentzh joined
[08:50] *** domidumont joined
[10:23] <Geth> ¬¶ MoarVM: 7d7a6b1881 | (Samantha McVey)++ | src/strings/ops.c

[10:23] <Geth> ¬¶ MoarVM: Fix bug in indexic_s if expanding cp is the last cp

[10:23] <Geth> ¬¶ MoarVM:

[10:23] <Geth> ¬¶ MoarVM: There was a bug where if a codepoint such as 'Ô¨Ü' which expands under

[10:23] <Geth> ¬¶ MoarVM: foldcase was the last codepoint, it would return -1 instead of returning the

[10:23] <Geth> ¬¶ MoarVM: correct index. Fixes the nqp tests that used to be todo'd.

[10:23] <Geth> ¬¶ MoarVM: review: https://github.com/MoarVM/MoarVM/commit/7d7a6b1881

[11:18] <jnthn> m: my $a = 0; say (($a++,) Zxx 42).is-lazy

[11:18] <camelia> rakudo-moar 304107: OUTPUT: ¬´False‚ê§¬ª

[11:19] <jnthn> Hmm

[11:19] <jnthn> Ah, there was a revert

[12:14] <MasterDuke> jnthn: i think i'm running into the bug you did this workaround for https://github.com/perl6/nqp/commit/79e10b42b3e8e4accf5c8926be477e8c774ed165

[12:16] <MasterDuke> which i think is related to this:

[12:16] <MasterDuke> m: class :: { has uint64 $.x; }.new( x => 2**64-1 ).x.say

[12:16] <camelia> rakudo-moar 304107: OUTPUT: ¬´-1‚ê§¬ª

[12:32] *** ilmari[m] joined
[13:00] <jnthn> MasterDuke: Yeah, I think that's 'cus we had no getattr_u yet

[13:00] *** geekosaur joined
[13:09] <MasterDuke> yeah, pretty sure that's one i added in my `add a whole bunch of _u ops` branch

[13:10] <MasterDuke> also trying to figure out this one now:

[13:10] <MasterDuke> m: my uint64 $x = 2**64-1; say $x

[13:10] <camelia> rakudo-moar 304107: OUTPUT: ¬´-1‚ê§¬ª

[13:11] <MasterDuke> i'm returning the right value out of mp_get_int64, but haven't yet figured out where it gets lost

[14:11] *** agentzh joined
[14:37] *** geekosaur joined
[14:37] <MasterDuke> if i don't care about fixing attributes and the more general _u problem, i have a fix for https://github.com/MoarVM/MoarVM/issues/513, that make two todos now pass

[14:38] <MasterDuke> however, this test https://github.com/perl6/roast/blob/master/S02-types/native.t#L167 `is class :: { has uint64 $.x; }.new( x => 2**64-1 ).x, 2**64-1, 'uint64 attributes don\'t get sign-extended';`, which is currently todoed, now dies

[14:39] <MasterDuke> because attributes are all treated as signed, and since that value is too large for a signed native, my fix for #513 causes it to throw

[14:42] <MasterDuke> my fix for #513 wouldn't cause it to throw if unsigned attributes worked correctly

[14:42] <MasterDuke> so would modifying that test as a workaround be ok?

[16:00] <timotimo> src\jit\emit_win32_x64.c(8) : warning C4129: 'j' : unrecognized character escape sequence

[16:00] <timotimo> src\jit\emit_win32_x64.c(8) : warning C4129: 'e' : unrecognized character escape sequence

[16:00] <timotimo> what could this be?

[16:44] *** agentzh joined
[17:30] *** zakharyas joined
[17:32] *** agentzh joined
[18:46] *** agentzh joined
[19:26] <MasterDuke> timotimo: any idea why copying this https://github.com/MoarVM/MoarVM/blob/master/src/strings/ops.c#L1244-L1252 and changing 32s to 8s causes errors like `Unhandled exception: Error encoding UTF-8 string: could not encode codepoint 1836085614`?

[19:34] *** Ven joined
[19:46] <MasterDuke> .ask samcv parsing the json from a travis log with JSON::Fast spends 46% of its time here https://github.com/MoarVM/MoarVM/blob/master/src/strings/ops.c#L86-L139, which mentions it could be smarter. see anything you could do to optimize it?

[19:46] <yoleaux2> MasterDuke: I'll pass your message to samcv.

[19:46] <timotimo> can you give me the actual code you used, MasterDuke?

[19:49] <MasterDuke> https://gist.github.com/MasterDuke17/80bcdafc504582fafe09bb915c563c8d

[19:51] <timotimo> result->body.storage_type    = MVM_STRING_GRAPHEME_32;

[19:51] <timotimo> that's why it's erroring out

[19:53] <MasterDuke> ah

[19:59] <timotimo> i'd expect that re_nfg could be implemented to detect that no change is necessary at all

[19:59] <MasterDuke> so should the MVM_STRING_GRAPHEME_8 case have the exact same body as the MVM_STRING_GRAPHEME_32 case?

[20:00] <timotimo> alternatively it can use almost-all-of the previous string by refering to it from a rope and then a little piece in the middle that combines the end and beginning into a grapheme, and then most-of the second string

[20:00] <timotimo> almost the same body. the pgraphs has a different meaning based on what the storage type is

[20:01] <timotimo> so you have to copy pgraphs * sizeof(MVMGrapheme32) in one case and pgraehs * sizeof(MVMGrapheme8)

[20:01] <timotimo> the heap analyzer ought to help here :)

[20:02] <MasterDuke> same error

[20:02] <timotimo> are you also setting the correct storage type for result?

[20:02] <MasterDuke> nope

[20:03] <timotimo> well, that's the problem, then

[20:04] <timotimo> though of course both parts must have the same storage type

[20:04] <MasterDuke> but i could only do that if i know that all the pieces and the separator are MVM_STRING_GRAPHEME_8 right?

[20:10] <timotimo> right

[20:10] <timotimo> otherwise you'll have to do a loop and assign

[20:10] <timotimo> memcpy can't do upscaling like that

[20:10] <MasterDuke> think the loop is faster than the current default case?

[20:11] <timotimo> maybe there's some fast way to do it, and if you have a tight loop it could very much be that gcc gives you that for free

[20:11] <timotimo> oh i didn't know about nfg_is_concat_stable

[20:12] <timotimo> do we check that everywhere before we re_nfg?

[20:12] <timotimo> yeah, we do

[20:12] <timotimo> so it could be interesting to figure out why our json stuff thinks the concat isn't stable

[20:12] <timotimo> is there any reason to assume that?

[20:15] <MasterDuke> i hope that was a rhetorical question, i don't know this nfg stuff at all

[20:17] <timotimo> i didn't look at the function yet, but i assume it checks the last grapheme of a and the first of b

[20:19] <timotimo> and if the first of b is a combiner without its base, it'll complain

[20:19] <timotimo> or if a ends in a pre-pendable combiner

[20:20] <MasterDuke> i'm looking at it, and without knowing these things at all, the comments seem to suggest what you just said

[20:22] <timotimo> OK, how about this:

[20:22] <timotimo> we should have code to encode a substr of a string to utf8, right?

[20:22] <timotimo> when we hit the case that concat isn't stable, we output the string in question

[20:22] <timotimo> or maybe even the graphemes as integers

[20:23] <MasterDuke> there is a MVM_string_utf8_encode_substr

[20:23] <timotimo> fantastic

[20:23] <timotimo> though maybe using the ints directly is more helpful

[20:23] <timotimo> because the strings are supposed to have "magical" unicode chars in them

[20:23] <timotimo> and they might turn invisible or hard-to-see when we just encode&print them

[20:25] <MasterDuke> in moar or json::fast?

[20:25] <timotimo> in moar

[20:29] <MasterDuke> for debugging purposes?

[20:30] <timotimo> yes, only for that

[20:35] <MasterDuke> ha, i was a bit confused there at first

[20:38] <timotimo> will you try doing that?

[20:43] <timotimo> oh, interesting

[20:43] <timotimo> look, it thinks as soon as there's a synthetic it wouldn't be stable

[20:43] <MasterDuke> so if not nfg_is_concat_stable, print out the MVM_string_utf8_encode_substr of the piece and separator?

[20:44] <timotimo> a newline is rather common, but it's a synthetic

[20:44] <timotimo> maybe we'll want to special-case something there

[20:44] <timotimo> (but first see what it's actually all about)

[20:45] <timotimo> oh, also ... we'll want both the encoded and the pure graphemes, i think

[20:49] <MasterDuke> why do we need the *_encode_substr function?

[20:49] <timotimo> it's not strictly necessary, but if you see something like "-324" in the string, you don't necessarily know what's up

[20:59] <MasterDuke> segv, did something wrong

[20:59] <timotimo> perhaps, let me see your code?

[21:00] <MasterDuke> fprintf(stderr, "pieces[i - 1]: %s, p: %s\n", MVM_string_utf8_encode(tc, pieces[i - 1], MVM_string_graphs(tc, pieces[i - 1]), 0), MVM_string_utf8_encode(tc, piece, MVM_string_graphs(tc, piece), 0));

[21:01] <MasterDuke> oh, i need to encode to C str?

[21:06] <geekosaur> fprintf isn't going to understand lists of codepoints, much less lists of graphemes; you need to feed it UTF8 in C's (char [])

[21:09] <timotimo> maybe we'll use only the graphemes for now

[21:11] <MasterDuke> so that printed a whole lot

[21:11] <timotimo> mhm

[21:11] <timotimo> that's only if it's not stable, right?

[21:11] <timotimo> can has a bit of example?

[21:12] <MasterDuke> with pieces[i - 1] == `^M` a lot

[21:12] <timotimo> which one is that again ...

[21:12] <MasterDuke> `else if (!MVM_nfg_is_concat_stable(tc, pieces[i - 1], piece)) {`

[21:12] <timotimo> that's a control character?

[21:14] <MasterDuke> isn't that a \r that get left from bad dos <-> unix line endings?

[21:15] <MasterDuke> here's the first couple lines of output https://gist.github.com/MasterDuke17/d75d9a4235c44384d1bd83747f1dddf0

[21:16] <timotimo> maybe you're accessing one past the string?

[21:16] <MasterDuke> i changed the format string to "pieces[i - 1]: |%s|, p: |%s|\n"

[21:16] <timotimo> though it should have a bounds check

[21:16] <timotimo> but yeah

[21:16] <timotimo> those are all newlines

[21:16] <timotimo> newline is a synthetic grapheme, because \r\n and \n are supposed to be the same thing

[21:17] <timotimo> too many things at once, where do i get the json we have again?

[21:18] <MasterDuke> https://api.travis-ci.org/jobs/212455149

[21:19] <timotimo> oh, i know

[21:19] <timotimo> that's because of how json_fast parses strings

[21:19] <timotimo> it goes until it sees the first \*

[21:19] <timotimo> and then it parses chunks and joins them

[21:20] <timotimo> so you'll pretty much always have something like a newline where join is used

[21:20] <timotimo> i don't see a "Done" in there at all

[21:21] <MasterDuke> there's at least one line with "Done" according to grep

[21:22] <timotimo> i must be doing something wrong

[21:22] <timotimo> {"id":212455149,"number":"7436.3","config":{"language":"perl","os":"linux","sudo":false,"fast_finish":true,"install":"echo","dist":"trusty","addons":{"apt":{"sources":["ubuntu-toolchain-r-test"],"packages":["gcc-6","openjdk-7-jdk"]}},"script":["perl Configure.pl $RAKUDO_OPTIONS --moar-option=--cc=$(command -v gcc-6 >/dev/null 2>&1; if [ $? -eq 1 ]; then printf \"gcc\"; else printf \"gcc-6\"; fi)","make

[21:22] <timotimo> test","make install"],"branches":{"only":["nom","/smoke-me/"]},"notifications":{"irc":{"channels":["irc.freenode.net#perl6-dev"],"on_success":"change","on_failure":"always","template":["Rakudo build %{result}. %{author} '%{commit_message}'","%{build_url} %{compare_url}"]}},"env":"RAKUDO_OPTIONS=\"--backends=moar --gen-nqp=master

[21:22] <timotimo> --gen-moar=master\"",".result":"configured","group":"stable"},"repository_id":1242635,"build_id":212455146,"state":"finished","result":1,"status":1,"started_at":"2017-03-18T14:22:12Z","finished_at":"2017-03-18T14:29:07Z","log":"","commit":"dd3f22875c8f803ec97e0d4e39eef2c29ff49695","branch":"nom","message":"Log all commits to date\n\nDocuments commits:\ne1ebb50 f94a2c7 3de5fb2 79bb179 65b0040 10f5f74

[21:22] <timotimo> 9644fc3","committed_at":"2017-03-18T14:21:35Z","author_name":"Zoffix Znet","author_email":"cpan@zoffix.com","committer_name":"Zoffix Znet","committer_email":"cpan@zoffix.com","compare_url":"https://github.com/rakudo/rakudo/compare/3041072578f6...dd3f22875c8f","worker":null}

[21:22] <timotimo> this be all i get

[21:24] <MasterDuke> added the file i have to my gist

[21:24] <timotimo> thanks

[21:24] <MasterDuke> and there's definitely one and only one "Done" in it

[21:25] <timotimo> yeah that's like 100x as long as what i get

[21:25] <MasterDuke> wait, nm, could be more

[21:25] <timotimo> hm?

[21:25] <IOninja> travis trimmed an old job log?

[21:25] <IOninja> I see no log in browser in that url... nor Done

[21:26] <timotimo> *shrug*, maybe i'm not logged in or whatever?

[21:26] <IOninja> gonna try on my box in ~10m (on phone right now)

[21:27] <timotimo> i'll see what i can do about nfg_concat_is_stable

[21:27] <timotimo> because we definitely know that the \n grapheme is okay (as it's a control characterr

[21:27] <timotimo> )

[21:27] <MasterDuke> would it make sense for json::fast to also grab the next char if it sees a '\r'?

[21:28] <timotimo> well, to do that, it'll have to concat, too

[21:28] <timotimo> we wouldn't escape that problem

[21:29] <timotimo> "escape"

[21:29] <timotimo> badum-tss

[21:29] <MasterDuke> but wouldn't "foo\r\nbar" get split into "foo", "\r", "\nbar" right now?

[21:29] <MasterDuke> or "foo", "\r", "\n", "bar"?

[21:30] <timotimo> yup

[21:30] <timotimo> the latter

[21:31] <MasterDuke> wouldn't you want "foo", "\r\n, "bar"?

[21:31] <MasterDuke> "foo", "\r\n", "bar"

[21:32] <timotimo> if you want to write the code that handles consecutive escape sequences like that, sure.

[21:35] <MasterDuke> heh, i do not

[21:35] <timotimo> so there :)

[21:35] <timotimo> but we don't actually have \r\n, right?

[21:36] <timotimo> in our file i mean

[21:37] <timotimo> oh crap, we totally do

[21:37] <timotimo> a whole fricking lot of 'em

[21:37] <timotimo> in that case we always have to renormalize

[21:37] <timotimo> okay, it might be worthwhile to special-case \r\n

[21:37] <timotimo> i'll try implementing it

[21:38] <IOninja> yeah, that link expired. tis empty on my box too

[21:38] <IOninja> nearly empty

[21:39] <MasterDuke> glad i saved it off then

[21:40] <timotimo> could have just used a newer link

[21:40] <timotimo> may want to put a fresher link into tickets that are about this

[21:40] <IOninja> I just grabbed one from a new job; noms 2.3GB there too: https://gist.githubusercontent.com/zoffixznet/eada23f2d7488adfb1a735f65678bb3b/raw/8496c7daadd708a08944fd665d9cf65ab6de6b6c/gistfile1.txt

[21:41] <IOninja> I've updated my snippet to use ^ that permalink now: https://github.com/timo/json_fast/issues/21#issuecomment-287570921

[21:41] <timotimo> i forgot to use -Ilib

[21:41] <timotimo> so i was using system-wide installed JSON::Fast %)

[21:41] <IOninja> heh

[21:42] <timotimo> stripped off half a gig

[21:42] <timotimo> time perl6 -Ilib -e 'use JSON::Fast; from-json(slurp("/tmp/mem_leak.json"))'

[21:42] <timotimo> 2.83user 0.63system 0:03.49elapsed 99%CPU (0avgtext+0avgdata 2166808maxresident)k

[21:42] <timotimo> 0inputs+0outputs (0major+537101minor)pagefaults 0swaps

[21:42] <timotimo> timo@schmetterling ~/p/e/json_fast (master)> time perl6 -e 'use JSON::Fast; from-json(slurp("/tmp/mem_leak.json"))'

[21:42] <timotimo> 2.56user 0.79system 0:03.38elapsed 99%CPU (0avgtext+0avgdata 2620180maxresident)k

[21:42] <timotimo> 0inputs+0outputs (0major+650303minor)pagefaults 0swaps

[21:43] <MasterDuke> nice

[21:44] <IOninja> \o/

[21:48] <timotimo> not good enough, of course

[21:48] <timotimo> but a bit better

[21:49] <timotimo> # at t/06-control-characters.t line 42

[21:49] <timotimo> # expected: '"\r\n"'

[21:49] <timotimo> #      got: '"

[21:50] <timotimo> "'

[21:50] <timotimo> welp :|

[21:50] <timotimo> that isn't right

[21:50] <timotimo> okay, fixed it

[21:51] <timotimo> pushed it, you can try if it makes things better

[21:52] <timotimo> it could be that it has been handling \r\n wrong for a while

[21:54] <timotimo> yup, totally

[21:54] <timotimo> sounds like a version bump is in order

[21:54] <MasterDuke> seeing less mem usage also

[21:54] <MasterDuke> re_nfg is still 49% according to perf though

[21:55] <timotimo> right

[21:55] <timotimo> not unexpected

[21:55] <timotimo> we only reduced the number of concat operations

[21:56] <timotimo> not gotten around the problem in general

[21:56] <MasterDuke> yup

[21:58] <MasterDuke> fwiw, here's heaptrack's summary now http://i.imgur.com/4bw1Bup.png

[21:58] <MasterDuke> for just parsing it once

[22:05] <samcv> MasterDuke, so it may be from \r \n it having to renormalize so much?

[22:06] <samcv> and we call re_nfg so much when we concatenate yes?

[22:08] <MasterDuke> believe so

[22:09] <MasterDuke> but timotimo's really the one who knows what's going on

[22:09] <samcv> yeah that's pretty wasteful

[22:09] <samcv> i'm pretty sure i understand what's happening too

[22:09] <samcv> from the scrollback

[22:10] <MasterDuke> heh, i was having the conversation and don't understand

[22:10] <samcv> i'll look at it later today. doing stuff for the next few hours

[22:10] <samcv> :)

[22:10] <MasterDuke> cool

[22:14] <timotimo> i found it a little bit surprising that re_nfg allocated such a gigantic amount of data

[22:14] <samcv> how much is gigantic?

[22:15] <MasterDuke> 2g to parse a 200k json file

[22:15] <samcv> lol.

[22:15] <samcv> ok that's gigantic

[22:15] <timotimo> a little bit :3

[22:16] <MasterDuke> i'm kind of surprised re_nfg hasn't cropped up in any other profiles

[22:17] <samcv> maybe because we've had \n line endings?

[22:20] <timotimo> it had lots of \r\n in it

[22:20] <timotimo> i improved the memory usage by half a gig (a quarter in total) by special-casing \r\n to be done in one step

[22:25] <jnthn> Huh, how on earth is re_nfg managing that...

[22:25] <yoleaux2> 16:58Z <japhb> jnthn: https://6guts.wordpress.com/2017/03/16/considering-hyperrace-semantics/ keeps asserting incorrect arithmetic (6+5=12,9+5=15,9+5=16).

[22:25] <yoleaux2> 19:53Z <IOninja> jnthn: recall I kept mentioning buggable leaking? Seems it's just something with JSON::Fast (and it doesn't seem to be leaking but just using lots of RAM). Swapping to JSON::Tiny avoids the issue.

[22:25] <MasterDuke> i think heaptrack said most of the allocations happened here https://github.com/MoarVM/MoarVM/blob/master/src/strings/ops.c#L100 `MVMGrapheme32 *out_buffer = MVM_malloc(bufsize * sizeof(MVMGrapheme32));`

[22:26] <MasterDuke> and bufsize == in->body.num_graphs

[22:27] <jnthn> Oh heh

[22:27] <jnthn> Yeah, that's a pretty lazy implementation :)

[22:28] <jnthn> Though I'm now curious how JSON::Fast triggers that case :)

[22:29] <MasterDuke> i think it's lots of concats where !nfg_is_concat_stable

[22:29] <MasterDuke> in MVM_string_join

[22:29] <timotimo> it sees \r\n which is < 0 and so it never says is_stable

[22:29] <jnthn> Ah

[22:30] <jnthn> But that can never combine with anything else, so we could potentially special-case it.

[22:30] <jnthn> But still, re_nfg could be done in a smarter way

[22:30] <MasterDuke> most were here https://github.com/MoarVM/MoarVM/blob/master/src/strings/ops.c#L1237 `else if (!MVM_nfg_is_concat_stable(tc, pieces[i - 1], piece))`

[22:32] * jnthn has had a headache all evening, so will be pretty useless for thinking much about this :/

[22:33] <timotimo> yup

[22:36] <timotimo> i had headache yesterday and was also rather useless

[22:37] <jnthn> Had sore throat/ears the last couple of days, and somewhat today, and today gained a stuffy nose, so I guess I'm doing some kind of cold.

[22:37] <timotimo> ugh, i hate that kind of thing

[22:38] <timotimo> oh, it seems like i recurse in parse-string instead of looping somehow

[22:39] <timotimo> that could explain why it joins often

[22:41] <timotimo> yeah, if it doesn't see a " after the escape sequence, it'll recurse

[22:41] <timotimo> that's Bad

[22:45] <timotimo> but i have a fix

[22:48] <timotimo> time perl6 -Ilib -e 'use JSON::Fast; from-json(slurp("/tmp/mem_leak.json"))'

[22:48] <timotimo> 1.39user 0.05system 0:01.46elapsed 98%CPU (0avgtext+0avgdata 92652maxresident)k

[22:48] <timotimo> how do you like this?

[22:49] <MasterDuke> hot damn!

[22:49] <timotimo> now only has to be correct

[22:50] <jnthn> Did it get any faster with all the reduction in allocations? :)

[22:57] <timotimo> yeah, a bit

[22:57] <timotimo> let me do proper measurements

[22:58] <samcv> timotimo, can it be any json file with \r\n lineendings?

[22:58] <timotimo> um ... huh.

[22:59] <timotimo> no, it got significantly slower

[23:05] <timotimo> somehow it also reached almost a gig again?!?

[23:08] <timotimo> grr

[23:10] <timotimo> i haven't a good clue what's going wrong

[23:11] <timotimo> can't get it down any further :(

[23:11] <timotimo> not sure why it was 1/10 in between

[23:17] <MasterDuke> 1/20 even, right?

[23:18] <MasterDuke> edit history you can undo through?

[23:18] <timotimo> yeah, well

[23:24] <MasterDuke> samcv: if you want the file we've been testing with you can find it here https://gist.github.com/MasterDuke17/d75d9a4235c44384d1bd83747f1dddf0

[23:24] <samcv> mem_leak.json?

[23:25] <samcv> there's two there

[23:25] <MasterDuke> yeah

[23:27] <samcv> what's the profiling program yoeu're using MasterDuke

[23:27] <samcv> heh 2.4GB that's insane

[23:28] <MasterDuke> the memory one? heaptrack

[23:28] <MasterDuke> you're using arch right? it's in the aur

[23:28] <samcv> yeah

[23:28] <MasterDuke> you have to run moar directly though

[23:29] <MasterDuke> i.e., the command that actually is exec'ed in perl6-m

[23:29] <samcv> yeah i get what you mean

[23:29] <samcv> ;)

[23:36] <samcv> why do we even have to re-nfg it. unless it's trying to concat two codepoints that may combine

[23:36] <samcv> anyway i've gotto go to dinner

[23:37] <samcv> renfging the whole string seems wasteful, but i don't think it should allocate that much space..

[23:37] <samcv> so that needs to be fixed regardless i guess

[23:38] <MasterDuke> well, the comment right above the allocate says `/* Create the output buffer. We used to believe it can't ever be bigger than the initial estimate, but utf8-c8 showed us otherwise. */`

[23:39] <MasterDuke> but maybe that allocation can be delayed until we know more info and can be more precise about it?

[23:41] <samcv> but that shouldn't account for all the 1.2GB though?

[23:42] <samcv> it's not that big of a file

[23:43] <MasterDuke> but it's joining lots of pieces, potentially having to re_nfg each piece and the separator each time

[23:46] <samcv> yeah

[23:47] <samcv> i mean we really should only renormalize the end of it

[23:47] <samcv> not the whole thing

[23:49] <MasterDuke> what "it"?

[23:51] <samcv> uh. string `in`

[23:52] <samcv> i'm not sure how strands work tbh. but we just need to go back along the string until we're sure it can't combine differently with the thing on the right

[23:52] <samcv> and then normalize that section

[23:52] <samcv> though i guess it's fed the string after it has already been concatted?

[23:52] <MasterDuke> that certainly sounds faster

[23:53] <MasterDuke> well, i think there are two fixes to be made. re_nfg can be made better/faster, but MVM_string_join also shouldn't be calling it in all the cases it does

[23:53] <samcv> yeah

[23:54] <samcv> will be back in a few hours or something. bbl dinner

[23:54] <MasterDuke> later...
