[01:23] *** SmokeMachine left
[01:26] *** SmokeMachine joined
[01:37] *** SmokeMachine left
[01:38] *** lucasb left
[01:52] *** SmokeMachine joined
[03:09] *** quotable6 left
[03:09] *** squashable6 left
[03:09] *** unicodable6 left
[03:09] *** undersightable6 left
[03:09] *** notable6 left
[03:09] *** benchable6 left
[03:09] *** reportable6 left
[03:09] *** statisfiable6 left
[03:09] *** greppable6 left
[03:09] *** evalable6 left
[03:09] *** committable6 left
[03:09] *** bisectable6 left
[03:09] *** shareable6 left
[03:09] *** releasable6 left
[03:09] *** nativecallable6 left
[03:09] *** bloatable6 left
[03:09] *** coverable6 left
[03:09] *** nativecallable6 joined
[03:10] *** releasable6 joined
[03:10] *** notable6 joined
[03:10] *** bisectable6 joined
[03:11] *** committable6 joined
[03:11] *** undersightable6 joined
[03:11] *** squashable6 joined
[03:11] *** quotable6 joined
[03:12] *** statisfiable6 joined
[03:12] *** benchable6 joined
[03:12] *** coverable6 joined
[03:13] *** shareable6 joined
[03:13] *** bloatable6 joined
[03:13] *** unicodable6 joined
[03:13] *** greppable6 joined
[03:14] *** evalable6 joined
[03:14] *** reportable6 joined
[05:03] *** robertle left
[06:08] *** nebuchadnezzar left
[06:08] *** nebuchadnezzar joined
[06:15] *** domidumont joined
[06:49] *** brrt joined
[07:02] <brrt> \o

[07:02] <nwc10> o/

[07:11] *** patrickb joined
[08:34] *** robertle joined
[09:10] <jnthn> So yesterday I implemented some "is this point in a branch relative to this one" thing as a quick heuristic check, but was thinking, hmm, this is ad-hoc, but there must be a proper way to do this...

[09:10] <jnthn> Realized in the pub last night: I wanted postdominance.

[09:11] <jnthn> Though not sure if it's worth calculating if all we really need it for is a heuristic.

[09:12] <lizmat> .oO( post dominance for a post modern language )

[09:12] <nwc10> pubs++

[09:15] *** zakharyas joined
[09:27] *** dogbert11 joined
[09:29] *** dogbert17 left
[09:58] <brrt> what is postdominance?

[09:59] <timotimo> probably very similar to the dominance we use to get the SSA form right, but instead of from the beginning towards the end it'd go from the end towards the beginning?

[09:59] <jnthn> brrt: Dominance but with the arrows reversed

[10:00] <jnthn> Or intuitively, "what do we always exit via"

[10:00] <jnthn> (Where dominance is "what do we always enter via")

[10:02] <Woodi> would be nice to have in precompiled modules but if runtime needs just heurestics then can be costly ?

[10:06] <timotimo> we only calculate those things for things that are measured to be hot during run time

[10:06] <timotimo> calculating it for everything while precompiling modules is wasteful

[10:06] <timotimo> especially since earlier optimizations can already throw out branches completely

[10:07] <jnthn> Well, also probably what the VM optimizer considers a basic block is similar to what Perl 6 does anyway, especially given it has to be re-calc'd after inlines

[10:14] <brrt> oh, I see

[10:15] <brrt> .... that would've been a nice term to have, I had that precise problem half a year ago

[10:55] *** brrt left
[11:17] *** zakharyas left
[11:30] *** domidumont left
[11:31] *** domidumont joined
[11:45] <timotimo> the MVM_op_infos array is about 35 kib big

[11:45] <timotimo> i do believe we have a few fields that don't need to be 8 bit wide

[11:46] * timotimo tries bitfield support in C for this

[11:46] <timotimo> 28 kib, cool.

[11:47] <timotimo> hmm. we have an MVMuint16 num_operands, but the maximum operand coulnt we allow is 8; the higher values are just for the benefit of PHI nodes

[11:48] <timotimo> hm, 28.6 kib actually

[11:50] <timotimo> having the operands in-line with the structs themselves means we pay 8 byte for every op, which is 917 bytes

[11:53] <timotimo> there's only 4 ops with 8 operands, 6 with 7, 14 with 6

[11:54] <timotimo> silly me, it's not 917 bytes, it's 917 * 8 bytes

[11:54] <timotimo> m: say 2360 / (917 * 8)

[11:54] <evalable6> timotimo, rakudo-moar 8ec2c43f1: OUTPUT: «0.321701␤»

[11:55] <timotimo> about 66% space savings available with a more packed operands storage

[11:55] <timotimo> m: say 917 * 8

[11:55] <evalable6> timotimo, rakudo-moar 8ec2c43f1: OUTPUT: «7336␤»

[11:55] <timotimo> save 5 more kilobytes off these 28

[11:56] <timotimo> that's my useless timewaste for the day, thank you very much

[11:58] *** brrt joined
[12:00] <timotimo> but if we see what spesh and the bytecode validator tend to need vs not need, we might get the tiniest bit of performance out of less cache contention

[12:05] <brrt> Well, yes, spesh etc use the op_infos table quite heavily

[12:05] <brrt> so a saving would be nice :-)

[12:05] <timotimo> oh, i have to add 917 * 2 back for the savings, because we'll obviously need an index into the ops list

[12:05] <timotimo> (though actually that can re-use parts that repeat, which would be cool)

[12:07] <timotimo> collect all operands bits, calculate overlaps, tile the shortest array with it, make update_ops.p6 take ten minutes to complete

[12:07] <timotimo> i'm kind of sort of interested now

[12:08] <timotimo> FWIW, tools/lib/MAST/Ops.pm has a setup much like this already :)

[12:08] <timotimo> completely without overlap finding, though

[12:11] <brrt> well, if you first make update_ops.p6 take ten minutes, we'll all have a challenge to reduce that to a couple seconds

[12:12] <timotimo> :D

[12:12] <timotimo> a simple greedy algorithm should be just fine and very fast

[12:12] <brrt> so, you know what else I found

[12:12] <brrt> I expect that tiling will Just Work on a linear IR

[12:13] <timotimo> oh?

[12:13] <timotimo> that sounds good

[12:13] <timotimo> no changes needed for that part of the code

[12:13] <brrt> well, some changes

[12:13] <timotimo> which i imagine is a difficult part of the code

[12:13] <timotimo> like the rest of the code :)

[12:13] <brrt> I expect it will be simpler

[12:14] <brrt> right now, we do a postorder (bottom-up) iteration, and then a top-down iteration

[12:15] <brrt> but all we really need bottom-up for, is to ensure that nodes are processed before the nodes that reference them;

[12:15] <brrt> that is easily ensured by the order of the linear IR

[12:15] <timotimo> nice

[12:15] <timotimo> sounds like a whole phase can be tossed

[12:15] <brrt> and the inverse is true for top-down

[12:16] <brrt> not sure about the phase, but we can translate a tree traversal to a linear iteration, without a change in semantics

[12:16] <timotimo> ah, sweet

[12:16] <brrt> another thing that the tiler currently does, is create the basic blocks

[12:16] <brrt> that would be handled in an earlier phase

[12:17] <brrt> (and assigning labels)

[12:17] <brrt> because it translates between the graph form, and the linear form

[12:17] <brrt> so if we have a linear form throughout, we no longer need that translation (it'll happen in the perl comopiler)

[12:18] <brrt> and finally. Because of the linear IR, I can ensure that any operand loads are emitted before the template that references them. This will eliminate entirely the missing-ancestor problem

[12:19] <brrt> and the optimizer can move them and eliminate them if it proves that this is uneccesary

[12:20] <brrt> I guess the point is that the adding an explicit relative order of operations allows you to work on that relative order

[12:20] <brrt> which isn't possible in the graph IR as that leaves them unspecified

[12:25] <timotimo> i've got a preliminary result

[12:26] <brrt> I'm interested?

[12:26] <timotimo> it's built a list of 722 elements

[12:27] <timotimo> compare that to 917 * 8 elements for "no overlap attempts"

[12:27] <timotimo> er

[12:27] <timotimo> that's "not tightly packed"

[12:27] <timotimo> and 2360 for "tightly packed"

[12:27] <timotimo> that's not all yet

[12:27] <timotimo> because when i find no match, currently i just append the whole thing to the end without checking for a tail overlap

[12:30] <timotimo> m: say 722 / (917 * 8)

[12:30] <evalable6> timotimo, rakudo-moar 8ec2c43f1: OUTPUT: «0.098419␤»

[12:30] <timotimo> m: say 722 / (2360)

[12:30] <evalable6> timotimo, rakudo-moar 8ec2c43f1: OUTPUT: «0.305932␤»

[12:30] <timotimo> i had meant to work on something else today, but that's not a terrible win

[12:31] <timotimo> m: say 722 - (917 * 8)

[12:31] <evalable6> timotimo, rakudo-moar 8ec2c43f1: OUTPUT: «-6614␤»

[12:31] <timotimo> so a bit more than 6kb savings for the operands array

[12:33] *** brrt left
[12:41] <timotimo> if i don't "have to" put the opcodes in at the same order as they are in the input, i can potentially make better decisions

[12:44] <timotimo> Cowardly refusing to permutate more than 20 elements, tried 821

[12:44] <timotimo> %)

[12:48] <timotimo> 641 is my best score so far based on "just" reordering the ops randomly

[12:49] <timotimo> reproducible builds this is not

[12:49] <timotimo> except i srand($attempt-number)

[12:49] <timotimo> 632, cool

[12:50] *** sena_kun joined
[12:53] <timotimo> and it parallelizes trivially, of course

[12:53] <timotimo> oh, hm, but random state is per thread context, and if any of the blocks had an await in it or were otherwise descheduled, they would resume with different random values

[12:55] *** zakharyas joined
[12:56] <timotimo> oh, throwing out all the 1-parameter ops at the beginning could be interesting; there's 117 of them, and 12 0-parameter ops, too

[12:57] <timotimo> they can just be put in at the end. either they overlap anywhere or they'll go in at the end anywhere, but they shouldn't cause a potential chain to break by being appended at the end

[13:00] *** Guest2775 left
[13:02] <timotimo> i can't find the name of this problem; it should totally be a common comp-sci problem to solve

[13:18] *** Guest55475 joined
[13:21] <timotimo> oh!

[13:21] <timotimo> write registers

[13:22] <timotimo> two opcodes that have a write register can only have overlapping beginnings

[13:22] <timotimo> only all-read-operand opcodes can be partially inside or overlapping beginning and end of other ops

[13:22] *** lucasb joined
[13:27] <timotimo> ([71 71 71 71 167 71 39 63 39 39 71 55 55 39 71 63 71 71 71 71 39 71 71 63 167 23 63 63 39 39 39 71 63 63 63 71 39 39 63 39 23 23 71 71 71 71 71 71 63 71 63 39 79 39 55 55 55 71 71 79 63 39 71 71 63 63 71 39 63 63 39 71 71 71 39 39 71 39 23 79 71 23 23 55 167 55 167 63 55 71 63 71 71 71 63 39 39 71 167 143 ...] 396 31)

[13:27] <timotimo> ([2 1 1 0 0 2 1 1 1 1 1 1 1 1 1 2 0 0 0 1 1 0 1 0 2 3 2 1 0 2 0 1 4 1] 34 5)

[13:28] <timotimo> these are the lists followed by score followed by random seed for all operands with r/w and lex/reg/literal masked out followed by all operands with only their r/w lex/reg_literal

[13:28] <timotimo> if we keep those separate, which may be a PITA, we can get a much tighter packing

[13:36] *** robertle left
[13:38] *** robertle joined
[13:39] <timotimo> on top of the fact that the values themselves are now smaller, so they could be less than 8 bits per entry, but that's also annoying to deal with depending on the API we have to offer

[14:02] <timotimo> anyway, the r/w, lit/reg/lex bits are only 3 out of 8, so i can't just store one in 4 bits per entry and the other in 4 bits per entry

[14:02] <timotimo> however

[14:03] <timotimo> if i do a 4/4 split, even though the values aren't entirely meaningful then, i can get the whole thing stored in 240 bytes

[14:03] <timotimo> whereas if i use 8 bits per entry with one list for the upper 5 and one for the lower 3 bits i'd spend 430 bytes

[14:03] <timotimo> either is better than spending the 624

[14:04] <timotimo> though of course there's diminishing returns at some point, and i might be going into "actually useless" territory by now

[14:49] <nine> Well if you mange to make it fit in 64 bytes or so, you'd be down to a single cache line :)

[14:49] <timotimo> rather unlikely :D

[15:08] <timotimo> MFW a sequence that doesn't try to put only parts of the new operand data at the end when no match was found yet is better than sequences that try to find overlaps for the end

[15:20] <timotimo> gaaah tantalizingly close to getting the "start" indices for one of the arrays to fit into 8 bits

[15:20] <timotimo> 271 entries

[15:20] *** domidumont left
[15:26] *** AlexDani` joined
[15:29] *** AlexDani` is now known as AlexDaniel

[15:29] *** AlexDaniel left
[15:29] *** AlexDaniel joined
[15:30] <AlexDaniel> ⚠ https://github.com/perl6/problem-solving/pull/23#issuecomment-488716403

[15:42] *** robertle left
[15:59] *** patrickb left
[16:28] *** brrt joined
[16:36] *** patrickb joined
[16:39] *** zakharyas left
[16:41] *** squashable6 left
[16:42] *** squashable6 joined
[16:47] *** zakharyas joined
[16:55] *** brrt left
[16:58] *** domidumont joined
[17:12] *** robertle joined
[17:34] *** zakharyas left
[18:41] *** domidumont left
[18:44] *** brrt joined
[19:21] *** zakharyas joined
[19:43] <timotimo> only 35 of the first 820 have any marks; that's 2 bytes in every op

[19:43] <timotimo> m: say (820 - 35) * 2

[19:43] <evalable6> timotimo, rakudo-moar 8ec2c43f1: OUTPUT: «1570␤»

[19:44] <timotimo> and i think the marks are only ever needed by the validator anyway

[19:48] <brrt> you can extract them in a separate array?

[19:48] <brrt> so that the rest is more compact

[19:48] <timotimo> sure

[19:48] <timotimo> would also be possible to have an array of spans that'd be quick to scan through

[19:52] <timotimo> the only two usages of the mark struct member are in validation.c and ext.c

[19:55] <timotimo> so that shouldn't be too bad

[19:55] <timotimo> moving it away would already be a good thing i'm sure

[19:56] <timotimo> i mean ... barely

[19:56] <timotimo> but, you know

[19:56] <timotimo> so, how widespread is bitfield support in C compilers that we target?

[20:21] <MasterDuke> can we set up *BSDs in travis, appveyor, or circleci? that's the main platform missing right? otherwise i'd say create a PR and see what ci reports

[20:22] <brrt> if a C compiler doesn't support bitfields, it's not a C compiler at all imho

[20:23] <timotimo> in other words, it would be safe to use bitfields in moarvm code?

[20:40] *** zakharyas left
[20:44] *** brrt left
[21:33] *** sena_kun left
[21:40] *** sena_kun joined
[21:49] *** sena_kun left
[22:02] *** patrickb left
[22:18] <mornfall> bitfields are fine, what isn't are assumptions about their layout

[22:22] *** Kaiepi joined
[22:49] *** sena_kun joined
[23:06] *** lizmat_ joined
[23:08] *** lizmat left
[23:34] *** Kaypie joined
[23:34] *** Kaiepi left
[23:37] *** sena_kun left
[23:37] *** sena_kun joined
